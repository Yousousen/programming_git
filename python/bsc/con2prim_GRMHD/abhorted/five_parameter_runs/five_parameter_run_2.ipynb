{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPvB1xoSUZhR"
      },
      "source": [
        "# Neural network to learn conservative-to-primitive conversion in relativistic hydrodynamics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eKD484DvExD"
      },
      "source": [
        "## How to use this notebook\n",
        "\n",
        "### Local installation\n",
        "\n",
        "1. Install required packages with `pip install -r requirements.txt` to your desired environment.\n",
        "2. If a script version of this notebook is desired, comment (not uncomment) the first line of `nbconvert` cell.\n",
        "\n",
        "### Colab installation\n",
        "\n",
        "1.  Comment (not uncomment) the first line of the drive mounting cell.\n",
        "2.  Comment (not uncomment) the first line of the `pip install` cell.\n",
        "\n",
        "<!-- - For colab we also want to set the runtime to GPU by clicking _Change runtime_ in the _Runtime_ menu, and -->\n",
        "<!-- - We want to wait for the google drive connection popup to appear and follow the instructions. -->\n",
        "\n",
        "### Training without optimization\n",
        "\n",
        "3. Set `OPTIMIZE = False` in section _Constants and flags to set_.\n",
        "4. Run the entire notebook.\n",
        "\n",
        "### Training with optimization\n",
        "\n",
        "3. Set `OPTIMIZE = True` in section _Constants and flags to set_.\n",
        "4. Run the entire notebook.\n",
        "\n",
        "### Loading an already trained model\n",
        "\n",
        "3. Run cells in section _Initialization_.\n",
        "4. Run cells with definitions in section _Generating the data_.\n",
        "5. Run cell with the definition of _Net_ in section _Defining the neural network_.\n",
        "6. Make sure the `net.pth`, `optimizer.pth`, `scheduler.pth`, `var_dict.json` and `train_output.csv` files are in the directory containing this notebook.\n",
        "7. Run the cells in section _Loading_ and continue from there.\n",
        "\n",
        "### Generating the C++ model\n",
        "\n",
        "8. Run section _Porting the model to C++_, this requires a model to be loaded.\n",
        "9. Set the path to the `net.pt` file in the C++ source file.\n",
        "10. `mkdir build && cd build`,\n",
        "11. `cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch/ ..`,\n",
        "10. Compile and run, e.g. `cmake --build . --config release && ./executable`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYPfIIglvExD"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsv90vHWvExE"
      },
      "source": [
        "\n",
        "Use this first cell to **convert this notebook** to a python script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqdgdNLHUZhV",
        "outputId": "e7d2bc0a-9aaa-42de-d9b7-e0f27f8fa412",
        "tags": [
          "remove_cell"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skipping\n"
          ]
        }
      ],
      "source": [
        "%%script echo skipping\n",
        "\n",
        "!jupyter nbconvert five_parameter_run_1.ipynb --TagRemovePreprocessor.enabled=True --TagRemovePreprocessor.remove_cell_tags='{\"remove_cell\"}' --to script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzcUr0LnUZhw"
      },
      "source": [
        "Next some cells for working on **google colab**,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Jm_7_2r1vExG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# check if the drive is mounted\n",
        "drive_mounted = os.path.exists(\"/content/drive\")\n",
        "# change this to your desired folder\n",
        "drive_folder = \"/content/drive/My Drive/bsc/con2prim_towards_GRMHD/five_parameter_run_2\"\n",
        "\n",
        "# define a function to save a file to the drive or the current directory\n",
        "def save_file(file_name):\n",
        "  if drive_mounted:\n",
        "    # save the file to the drive folder\n",
        "    file_path = os.path.join(drive_folder, file_name)\n",
        "    # copy the file from the current directory to the drive folder\n",
        "    shutil.copyfile(file_name, file_path)\n",
        "  else:\n",
        "    # do nothing as the file is already in the current directory\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecHw2_xlUZhx",
        "outputId": "5d1e697e-31c0-4b1d-d418-b73c6b7ca448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#%%script echo skipping\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1rcStMLUZhy",
        "outputId": "8d74b6ef-b3ac-4b61-bbcf-06abb02964f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.2)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.11.1)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.40.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "#%%script echo skipping\n",
        "\n",
        "!pip install optuna tensorboard tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDsq9gG1vExH"
      },
      "source": [
        "Importing the **libraries** and setting the **device**,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "tREdWQUVUZhz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import optuna\n",
        "import tensorboardX as tbx\n",
        "\n",
        "# Checking if GPU is available and setting the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38GvmerjUZhz"
      },
      "source": [
        "### Constants and flags to set\n",
        "Defining some constants and parameters for convenience.\n",
        "\n",
        "**NOTE**: Some **subparameters** still need to be adjusted in the `create_model` function itself as of (Tue May 16 07:42:45 AM CEST 2023)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ei6VZDYKUZh0"
      },
      "outputs": [],
      "source": [
        "\n",
        "N_TRIALS = 225 # Number of trials for hyperparameter optimization\n",
        "OPTIMIZE = True # Whether to optimize the hyperparameters or to use predetermined values from Dieseldorst et al..\n",
        "ZSCORE_NORMALIZATION = False # Whether to z-score normalize the input data.\n",
        "\n",
        "# I try out here the values as obtained in Optuna run 5, but I will increase the number of epochs.\n",
        "# N_LAYERS_NO_OPT = 3\n",
        "# N_UNITS_NO_OPT = [78, 193, 99]\n",
        "# HIDDEN_ACTIVATION_NAME_NO_OPT = \"ReLU\"\n",
        "# OUTPUT_ACTIVATION_NAME_NO_OPT = \"Linear\"\n",
        "# LOSS_NAME_NO_OPT = \"MSE\"\n",
        "# OPTIMIZER_NAME_NO_OPT = \"Adam\"\n",
        "# LR_NO_OPT = 0.00036516467819506355\n",
        "# BATCH_SIZE_NO_OPT = 170\n",
        "# N_EPOCHS_NO_OPT = 400\n",
        "# SCHEDULER_NAME_NO_OPT = \"ReduceLROnPlateau\"\n",
        "\n",
        "N_LAYERS_NO_OPT = 3\n",
        "N_UNITS_NO_OPT = [555, 458, 115]\n",
        "HIDDEN_ACTIVATION_NAME_NO_OPT = \"ReLU\"\n",
        "OUTPUT_ACTIVATION_NAME_NO_OPT = \"ReLU\"\n",
        "LOSS_NAME_NO_OPT = \"Huber\"\n",
        "OPTIMIZER_NAME_NO_OPT = \"RMSprop\"\n",
        "LR_NO_OPT = 0.000122770896701404\n",
        "BATCH_SIZE_NO_OPT = 49\n",
        "N_EPOCHS_NO_OPT = 400\n",
        "SCHEDULER_NAME_NO_OPT = \"ReduceLROnPlateau\"\n",
        "\n",
        "c = 1  # Speed of light (used in compute_conserved_variables and sample_primitive_variables functions)\n",
        "gamma = 5 / 3  # Adiabatic index (used in eos_analytic function)\n",
        "n_train_samples = 80000 # Number of training samples (used in generate_input_data and generate_labels functions)\n",
        "n_test_samples = 10000 # Number of test samples (used in generate_input_data and generate_labels functions)\n",
        "rho_interval = (0, 10.1) # Sampling interval for rest-mass density (used in sample_primitive_variables function)\n",
        "vx_interval = (0, .57 * c) # Sampling interval for velocity in x-direction (used in sample_primitive_variables function)\n",
        "vy_interval = (0, .57 * c) # Sampling interval for velocity in y-direction (used in sample_primitive_variables function)\n",
        "vz_interval = (0, .57 * c) # Sampling interval for velocity in z-direction (used in sample_primitive_variables function)\n",
        "epsilon_interval = (0, 2.02) # Sampling interval for specific internal energy (used in sample_primitive_variables function)\n",
        "\n",
        "np.random.seed(42) # Uncomment for pseudorandom data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlaP5UL2UZh1"
      },
      "source": [
        "## Generating the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "s_EvGFZcUZh1"
      },
      "outputs": [],
      "source": [
        "# Defining an analytic equation of state (EOS) for an ideal gas\n",
        "def eos_analytic(rho, epsilon):\n",
        "    \"\"\"Computes the pressure from rest-mass density and specific internal energy using an analytic EOS.\n",
        "\n",
        "    Args:\n",
        "        rho (torch.Tensor): The rest-mass density tensor of shape (n_samples,).\n",
        "        epsilon (torch.Tensor): The specific internal energy tensor of shape (n_samples,).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The pressure tensor of shape (n_samples,).\n",
        "    \"\"\"\n",
        "    # Adding some assertions to check that the input tensors are valid and have \n",
        "    # the expected shape and type \n",
        "    assert isinstance(rho, torch.Tensor), \"rho must be a torch.Tensor\"\n",
        "    assert isinstance(epsilon, torch.Tensor), \"epsilon must be a torch.Tensor\"\n",
        "    assert rho.shape == epsilon.shape, \"rho and epsilon must have the same shape\"\n",
        "    assert rho.ndim == 1, \"rho and epsilon must be one-dimensional tensors\"\n",
        "    assert rho.dtype == torch.float32, \"rho and epsilon must have dtype torch.float32\"\n",
        "\n",
        "    return (gamma - 1) * rho * epsilon\n",
        "\n",
        "\n",
        "\n",
        "# Defining a function that samples primitive variables from uniform distributions\n",
        "def sample_primitive_variables(n_samples):\n",
        "    \"\"\"Samples primitive variables from uniform distributions.\n",
        "\n",
        "    Args:\n",
        "        n_samples (int): The number of samples to generate.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple of (rho, vx, vy, vz, epsilon), where rho is rest-mass density,\n",
        "            vx is velocity in x-direction,\n",
        "            vy is velocity in y-direction,\n",
        "            vz is velocity in z-direction,\n",
        "            epsilon is specific internal energy,\n",
        "            each being a numpy array of shape (n_samples,).\n",
        "    \"\"\"\n",
        "    # Sampling from uniform distributions with intervals matching Dieseldorst \n",
        "    # et al.\n",
        "    rho = np.random.uniform(*rho_interval, size=n_samples)  # Rest-mass density\n",
        "    vx = np.random.uniform(*vx_interval, size=n_samples)  # Velocity in x-direction\n",
        "    vy = np.random.uniform(*vy_interval, size=n_samples)  # Velocity in y-direction\n",
        "    vz = np.random.uniform(*vz_interval, size=n_samples)  # Velocity in z-direction \n",
        "    epsilon = np.random.uniform(*epsilon_interval, size=n_samples)  # Specific internal energy\n",
        "\n",
        "    # Returning the primitive variables\n",
        "    return rho, vx, vy, vz, epsilon\n",
        "\n",
        "\n",
        "\n",
        "# Defining a function that computes conserved variables from primitive variables\n",
        "def compute_conserved_variables(rho, vx, vy, vz, epsilon):\n",
        "    \"\"\"Computes conserved variables from primitive variables.\n",
        "\n",
        "    Args:\n",
        "        rho (torch.Tensor): The rest-mass density tensor of shape (n_samples,).\n",
        "        vx (torch.Tensor): The velocity in x-direction tensor of shape (n_samples,)\n",
        "        vy (torch.Tensor): The velocity in y-direction tensor of shape (n_samples,)\n",
        "        vz (torch.Tensor): The velocity in z-direction tensor of shape (n_samples,)\n",
        "        epsilon (torch.Tensor): The specific internal energy tensor of shape (n_samples,).\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple of (D, Sx, Sy, Sz, tau), where D is conserved density,\n",
        "            Sx is conserved momentum in x-direction,\n",
        "            Sy is conserved momentum in y-direction,\n",
        "            Sz is conserved momentum in z-direction,\n",
        "            tau is conserved energy density,\n",
        "            each being a torch tensor of shape (n_samples,).\n",
        "    \"\"\"\n",
        "\n",
        "  # Computing the pressure from the primitive variables using the EOS\n",
        "    p = eos_analytic(rho, epsilon)\n",
        "    # Computing the Lorentz factor from the velocity.\n",
        "    v2 = vx ** 2 + vy ** 2 + vz ** 2\n",
        "    W = 1 / torch.sqrt(1 - v2 / c ** 2)\n",
        "    # Specific enthalpy\n",
        "    h = 1 + epsilon + p / rho  \n",
        "\n",
        "    # Computing the conserved variables from the primitive variables\n",
        "    D = rho * W  # Conserved density\n",
        "    Sx = rho * h * W ** 2 * vx  # Conserved momentum in x-direction\n",
        "    Sy = rho * h * W ** 2 * vy  # Conserved momentum in y-direction\n",
        "    Sz = rho * h * W ** 2 * vz  # Conserved momentum in z-direction\n",
        "    tau = rho * h * W ** 2 - p - D  # Conserved energy density\n",
        "\n",
        "    # Returning the conserved variables\n",
        "    return D, Sx, Sy, Sz, tau\n",
        "\n",
        "# Defining a function that generates input data (conserved variables) from given samples of primitive variables\n",
        "def generate_input_data(rho, vx, vy, vz, epsilon):\n",
        "    # Converting the numpy arrays to torch tensors and moving them to the device\n",
        "    rho = torch.tensor(rho, dtype=torch.float32).to(device)\n",
        "    vx = torch.tensor(vx, dtype=torch.float32).to(device)\n",
        "    vy = torch.tensor(vy, dtype=torch.float32).to(device)\n",
        "    vz = torch.tensor(vz, dtype=torch.float32).to(device)\n",
        "    epsilon = torch.tensor(epsilon, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Computing the conserved variables using the compute_conserved_variables function\n",
        "    D, Sx, Sy, Sz, tau = compute_conserved_variables(rho, vx, vy, vz, epsilon) \n",
        "\n",
        "    # Stacking the conserved variables into a torch tensor\n",
        "    x = torch.stack([D, Sx, Sy, Sz, tau], axis=1)\n",
        "\n",
        "    # Returning the input data tensor\n",
        "    return x\n",
        "\n",
        "# Defining a function that generates output data (labels) from given samples of primitive variables\n",
        "def generate_labels(rho, epsilon):\n",
        "    # Converting the numpy arrays to torch tensors and moving them to the device\n",
        "    rho = torch.tensor(rho, dtype=torch.float32).to(device)\n",
        "    epsilon = torch.tensor(epsilon, dtype=torch.float32).to(device)\n",
        "   \n",
        "    # Computing the pressure from the primitive variables using the EOS\n",
        "    p = eos_analytic(rho, epsilon)\n",
        "\n",
        "    # Returning the output data tensor\n",
        "    return p\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dczop2rUZh3"
      },
      "source": [
        "Sampling the primitive variables using the sample_primitive_variables function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "cKubR6C8UZh4"
      },
      "outputs": [],
      "source": [
        "rho_train, vx_train, vy_train, vz_train ,epsilon_train = sample_primitive_variables(n_train_samples)\n",
        "rho_test, vx_test ,vy_test ,vz_test ,epsilon_test = sample_primitive_variables(n_test_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zhbYH5HkvExJ",
        "outputId": "4cc061c1-9510-4143-d9ce-b8ad43efed99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.7828552 , 9.60221449, 7.39313881, ..., 3.85518754, 1.30928573,\n",
              "       9.5675983 ])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.46635374, 0.08280376, 0.53948436, ..., 0.16854057, 0.45173399,\n",
              "       0.26113605])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.53015873, 0.34538885, 0.19004683, ..., 0.0427437 , 0.34608123,\n",
              "       0.18076349])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.04282752, 0.19716017, 0.37988219, ..., 0.47604939, 0.2403435 ,\n",
              "       0.02051602])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3414766 , 0.74092354, 1.3575724 , ..., 1.16268917, 1.80454638,\n",
              "       1.01489375])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.97842592, 3.18870559, 0.52428795, ..., 7.55288969, 8.90198997,\n",
              "       6.30910266])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.15696855, 0.0231761 , 0.5565851 , ..., 0.55641507, 0.0694273 ,\n",
              "       0.55457227])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2806517 , 0.00769195, 0.47276771, ..., 0.16427298, 0.22592983,\n",
              "       0.47809263])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00997133, 0.10847447, 0.4806396 , ..., 0.501241  , 0.11057264,\n",
              "       0.43016179])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.21308179, 1.24785629, 1.86907234, ..., 1.65279226, 0.65476648,\n",
              "       0.60812168])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "rho_train\n",
        "vx_train\n",
        "vy_train\n",
        "vz_train \n",
        "epsilon_train\n",
        "rho_test\n",
        "vx_test \n",
        "vy_test \n",
        "vz_test \n",
        "epsilon_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "VMp6XJ6RUZh4"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"last_expr_or_assign\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "E5YFdqKjUZh5",
        "outputId": "c2521452-af33-4ec9-f25e-6fa5b2502a01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting the histograms of rho, vx and epsilon\n",
        "plt.figure(figsize=(16, 4))\n",
        "plt.subplot(1, 5, 1)\n",
        "plt.hist(rho_train, bins=20)\n",
        "plt.xlabel(\"rho\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "#plt.yscale(\"log\")\n",
        "plt.subplot(1, 5, 2)\n",
        "plt.hist(vx_train, bins=20)\n",
        "plt.xlabel(\"vx\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "#plt.yscale(\"log\")\n",
        "plt.subplot(1, 5, 3)\n",
        "plt.hist(vy_train, bins=20)\n",
        "plt.xlabel(\"vy\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "#plt.yscale(\"log\")\n",
        "plt.subplot(1, 5, 4)\n",
        "plt.hist(vz_train, bins=20)\n",
        "plt.xlabel(\"vz\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "#plt.yscale(\"log\")\n",
        "plt.subplot(1, 5, 5)\n",
        "plt.hist(epsilon_train, bins=20)\n",
        "plt.xlabel(\"epsilon\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "#plt.yscale(\"log\")\n",
        "plt.suptitle(\"Primitive variables\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "1fsekS7zvExL"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "7ubtOXVgUZh6"
      },
      "outputs": [],
      "source": [
        "# Generating the input and output data for train and test sets.\n",
        "x_train = generate_input_data(rho_train, vx_train ,vy_train, vz_train, epsilon_train)\n",
        "y_train = generate_labels(rho_train, epsilon_train) \n",
        "x_test = generate_input_data(rho_test, vx_test, vy_test, vz_test, epsilon_test)\n",
        "y_test = generate_labels(rho_test, epsilon_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "lG_10Fx0vExM",
        "outputId": "b50b9813-17c4-4914-c177-14a791eed46a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.3518,  5.5407,  6.2987,  0.5088,  5.6678],\n",
              "        [10.5083,  2.1281,  8.8768,  5.0672, 10.4496],\n",
              "        [10.1694, 24.6210,  8.6734, 17.3371, 28.7775],\n",
              "        ...,\n",
              "        [ 4.4721,  2.5686,  0.6514,  7.2552,  7.7801],\n",
              "        [ 1.6649,  3.8329,  2.9365,  2.0393,  5.2449],\n",
              "        [10.0924,  7.4824,  5.1795,  0.5879, 12.0876]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8612, 4.7430, 6.6911,  ..., 2.9883, 1.5751, 6.4734], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 9.4826,  2.1303,  3.8089,  0.1353,  2.8137],\n",
              "        [ 3.2086,  0.2304,  0.0765,  1.0786,  4.0821],\n",
              "        [ 1.0799,  5.0950,  4.3277,  4.3998,  7.4208],\n",
              "        ...,\n",
              "        [11.7645, 38.2826, 11.3023, 34.4865, 48.7155],\n",
              "        [ 9.2215,  1.3869,  4.5133,  2.2089,  6.8695],\n",
              "        [11.9479, 25.2658, 21.7815, 19.5978, 31.0534]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.2754, 2.6527, 0.6533,  ..., 8.3222, 3.8858, 2.5578], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "x_train\n",
        "y_train\n",
        "x_test\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "CqQxpKTYvExM"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"last_expr_or_assign\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "T2bsgZyzvExM",
        "outputId": "82cf4d79-7c1b-47c6-eae6-6a0cbc9880ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAOlCAYAAACfUS1RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACmaklEQVR4nOzdeVhV5d7/8Q+ggNMGJ0BzIjWHnDGRMjPliEalacchMzTLJwNL6Zj5HENt0iynErNRmszpyTpJaeTUSVEL5WiaHu1YWApmJqgpKNy/P/ztddwCKrpkM7xf17Uv3Wvde6173Xv48tlr2B7GGCMAAAAAgC083d0BAAAAAChLCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWcBVatSokYYNG+bubpR7J06c0EMPPaSgoCB5eHhozJgxhbblObs8P/30kzw8PJSQkFDkx06ePFkeHh46cuTIJdsW9/Ph3K6XX37Z1uXu3btXPXv2lJ+fnzw8PPTJJ5/YunzgfB4eHpo8ebJ1PyEhQR4eHvrpp5+KtR/uWi9Q0hGygPM4i8V3331X4Pxu3bqpVatWV72ezz//3KU44uq98MILSkhI0KhRo/T+++9r6NCh7u7SZZs3b94VBRmULFFRUdqxY4eef/55vf/+++rYsaO7uwTY5oUXXuCLA6AIKri7A0Bpt2fPHnl6Fu37is8//1zx8fEELRutWbNGnTt31qRJky7Z9kqes2tp3rx5qlWrVonbu9awYUOdOnVKFStWdHdXSrxTp04pOTlZf//73xUTE+Pu7qAcGjp0qAYNGiQfH59rsvwXXnhB9957r/r27Vus6wVKq5LzVwZQSvn4+JS6P0JPnjzp7i7Y7vDhw/L397+stqXxOStOZ8+eVU5Ojjw8POTr6ysvLy93d6nE++233yTpsl+Dl6Msvk+L6s8//3R3Fy6L8z3jTl5eXvL19ZWHh0e5WC9Q0hGygKt04fkkZ86c0ZQpU9S0aVP5+vqqZs2a6tKli5KSkiRJw4YNU3x8vKRzx9Q7b04nT57UE088ofr168vHx0fNmjXTyy+/LGOMy3pPnTqlxx57TLVq1VK1atV0991369dff813nL7z3Jhdu3bpvvvuU/Xq1dWlSxdJ0vbt2zVs2DBdf/318vX1VVBQkB588EH9/vvvLutyLuPf//637r//fvn5+al27dp6+umnZYzRgQMH1KdPHzkcDgUFBWnGjBn5xunVV1/VjTfeqMqVK6t69erq2LGjFi5ceMnxPXz4sEaMGKHAwED5+vqqbdu2evfdd63569atk4eHh/bv36/ExERrPC92fsCFz5nzMNENGzYoNjZWtWvXVpUqVXTPPfdYfzyf/9g777xTX375pdq1aydfX1+1bNlSH3/8cYFjdqELz19o1KiRdu7cqfXr11t979atW4H9PnPmjGrUqKHhw4fnm5eVlSVfX1/97W9/kyTl5OQoLi5OISEh8vPzU5UqVXTrrbdq7dq1Lo87//yk2bNnq3HjxvLx8dGuXbsKPCfrcl8zTkeOHNGAAQPkcDhUs2ZNPf744zp9+nSBbc937NgxjRkzxnofNGnSRC+++KLy8vJc2i1atEghISGqVq2aHA6HWrdurTlz5lxy+U6zZs1Sw4YNValSJd122236/vvv87XZvXu37r33XtWoUUO+vr7q2LGj/vGPf1jzJ0+erIYNG0qSxo0bJw8PDzVq1Miav23bNvXu3VsOh0NVq1ZVjx49tGnTJpd1OF8X69ev16OPPqqAgADVq1fPmv/FF1/o1ltvVZUqVVStWjVFRkZq586dl9y+8z9jLrxd6hyavXv3qn///goKCpKvr6/q1aunQYMGKTMz06XdBx98oE6dOlnv7a5du+rLL790aTNv3jzdeOON8vHxUd26dRUdHa1jx465tHEejp2SkqKuXbuqcuXK+t///V9JUnZ2tiZNmqQmTZrIx8dH9evX15NPPqns7OxLjoFzubt27dLtt9+uypUr67rrrtP06dPztb3U54108ffM1X5WXu77tiAXfrY4+1LQ7fzPv5dfflk333yzatasqUqVKikkJETLli1zWbaHh4dOnjypd999N98yCjsnqyjP+eU8N0Bpw+GCQAEyMzMLPGH/zJkzl3zs5MmTNXXqVD300EPq1KmTsrKy9N1332nr1q36y1/+ov/5n//RwYMHlZSUpPfff9/lscYY3X333Vq7dq1GjBihdu3aadWqVRo3bpx+/fVXzZo1y2o7bNgwLVmyREOHDlXnzp21fv16RUZGFtqvv/71r2ratKleeOEFK7AlJSXpP//5j4YPH66goCDt3LlTb7zxhnbu3KlNmzblCwkDBw5UixYtNG3aNCUmJuq5555TjRo19Prrr6t79+568cUX9eGHH+pvf/ubbrrpJnXt2lWS9Oabb+qxxx7Tvffea/2RvX37dm3evFn33XdfoX0+deqUunXrpn379ikmJkbBwcFaunSphg0bpmPHjunxxx9XixYt9P7772vs2LGqV6+ennjiCUlS7dq1L/lcXWj06NGqXr26Jk2apJ9++kmzZ89WTEyMFi9e7NJu7969GjhwoB555BFFRUVpwYIF+utf/6qVK1fqL3/5S5HWOXv2bI0ePVpVq1bV3//+d0lSYGBggW0rVqyoe+65Rx9//LFef/11eXt7W/M++eQTZWdna9CgQZLOha633npLgwcP1sMPP6zjx4/r7bffVkREhLZs2aJ27dq5LHvBggU6ffq0Ro4cKR8fH9WoUSNfoJGK/poZMGCAGjVqpKlTp2rTpk165ZVX9Mcff+i9994rdEz+/PNP3Xbbbfr111/1P//zP2rQoIE2btyoCRMm6NChQ5o9e7bVl8GDB6tHjx568cUXJUk//PCDNmzYoMcff/ziAy/pvffe0/HjxxUdHa3Tp09rzpw56t69u3bs2GE9Bzt37tQtt9yi6667Tk899ZSqVKmiJUuWqG/fvvq///s/3XPPPerXr5/8/f01duxYDR48WHfccYeqVq1qPf7WW2+Vw+HQk08+qYoVK+r1119Xt27dtH79eoWGhrr06dFHH1Xt2rUVFxdn7cl6//33FRUVpYiICL344ov6888/9dprr6lLly7atm2bS6C70IWfMZI0ceJEHT582OpjQXJychQREaHs7GyNHj1aQUFB+vXXX7VixQodO3ZMfn5+kqQpU6Zo8uTJuvnmm/XMM8/I29tbmzdv1po1a9SzZ09J5z4Tp0yZovDwcI0aNUp79uzRa6+9pm+//VYbNmxw2av8+++/q3fv3ho0aJDuv/9+BQYGKi8vT3fffbe++eYbjRw5Ui1atNCOHTs0a9Ys/fvf/76s84T++OMP9erVS/369dOAAQO0bNkyjR8/Xq1bt1bv3r0lXd7nzfkKes84XelnZVHftxfTr18/NWnSxGVaSkqKZs+erYCAAGvanDlzdPfdd2vIkCHKycnRokWL9Ne//lUrVqywasr7779v1bSRI0dKkho3blzouovynF/OcwOUSgaAZcGCBUbSRW833nijy2MaNmxooqKirPtt27Y1kZGRF11PdHS0Kejt98knnxhJ5rnnnnOZfu+99xoPDw+zb98+Y4wxKSkpRpIZM2aMS7thw4YZSWbSpEnWtEmTJhlJZvDgwfnW9+eff+ab9tFHHxlJ5uuvv863jJEjR1rTzp49a+rVq2c8PDzMtGnTrOl//PGHqVSpksuY9OnTJ9+4XY7Zs2cbSeaDDz6wpuXk5JiwsDBTtWpVk5WVZU1v2LDhJcf9/Lbn98/5vIeHh5u8vDxr+tixY42Xl5c5duyYy2Mlmf/7v/+zpmVmZpo6deqY9u3bW9OcY3Yh57r2799vTbvxxhvNbbfddll9X7VqlZFkPvvsM5fpd9xxh7n++uut+2fPnjXZ2dkubf744w8TGBhoHnzwQWva/v37jSTjcDjM4cOHXdo75y1YsMCaVtTXzN133+3S9tFHHzWSzL/+9S9r2oXPx7PPPmuqVKli/v3vf7s89qmnnjJeXl4mLS3NGGPM448/bhwOhzl79my+Pl2Mc7sqVapkfvnlF2v65s2bjSQzduxYa1qPHj1M69atzenTp61peXl55uabbzZNmzbNt8yXXnrJZV19+/Y13t7e5scff7SmHTx40FSrVs107drVmuZ8XXTp0sVle44fP278/f3Nww8/7LLc9PR04+fnl2/6pUyfPt1IMu+9995F223bts1IMkuXLi20zd69e42np6e55557TG5urss85/vo8OHDxtvb2/Ts2dOlzdy5c40k884771jTbrvtNiPJzJ8/32VZ77//vvH09DT//Oc/XabPnz/fSDIbNmy46LY4l3v+NmdnZ5ugoCDTv39/a9rlft5c7D1ztZ+Vl/u+Ncbk+6wv6LPlfL/99ptp0KCBad26tTlx4oQ1/cL3dE5OjmnVqpXp3r27y/QqVaq49LWw9V7Jc36p5wYojThcEChAfHy8kpKS8t3atGlzycf6+/tr586d2rt3b5HX+/nnn8vLy0uPPfaYy/QnnnhCxhh98cUXkqSVK1dKOvet9/lGjx5d6LIfeeSRfNMqVapk/f/06dM6cuSIOnfuLEnaunVrvvYPPfSQ9X8vLy917NhRxhiNGDHCmu7v769mzZrpP//5j8u0X375Rd9++22h/SvI559/rqCgIA0ePNiaVrFiRT322GM6ceKE1q9fX6TlXcrIkSNd9sTceuutys3N1c8//+zSrm7durrnnnus+w6HQw888IC2bdum9PR0W/t0oe7du6tWrVoue9f++OMPJSUlaeDAgdY0Ly8va09XXl6ejh49qrNnz6pjx44FPrf9+/e/rL1/RX3NREdHu9x3vkY///zzQtexdOlS3XrrrapevbqOHDli3cLDw5Wbm6uvv/5a0rnX1cmTJ61DcYuqb9++uu6666z7nTp1UmhoqNW3o0ePas2aNRowYICOHz9u9eP3339XRESE9u7dq19//bXQ5efm5urLL79U3759df3111vT69Spo/vuu0/ffPONsrKyXB7z8MMPu5wDl5SUpGPHjmnw4MEuY+Hl5aXQ0NDLOozMae3atZowYYJGjx59yatvOvdUrVq1qtDzoj755BPl5eUpLi4u34VknO+jr776Sjk5ORozZoxLm4cfflgOh0OJiYkuj/Px8cl3OOzSpUvVokULNW/e3GUMunfvbm3XpVStWlX333+/dd/b21udOnVy+Zwq6ufNxd4zV/pZWdT37eXKzc3V4MGDdfz4cS1fvlxVqlSx5p3/nv7jjz+UmZmpW2+99YrXV9Tn/HKeG6A04nBBoACdOnUq8PLLzj/6LuaZZ55Rnz59dMMNN6hVq1bq1auXhg4delkB7eeff1bdunVVrVo1l+ktWrSw5jv/9fT0VHBwsEu7Cw8NOd+FbaVzf0ROmTJFixYt0uHDh13mXXjehSQ1aNDA5b6fn598fX1Vq1atfNPPP0dn/Pjx+uqrr9SpUyc1adJEPXv21H333adbbrml0P5K57azadOm+f6Au3A87HLh9lWvXl3SuT88ztekSZN8h8XdcMMNks6drxEUFGRrv85XoUIF9e/fXwsXLlR2drZ8fHz08ccf68yZMy4hS5LeffddzZgxQ7t373Y51LWg10JB0wpS1NdM06ZNXe43btxYnp6eFz0faO/evdq+fXuhf8A61/voo49qyZIl6t27t6677jr17NlTAwYMUK9evS5rWy7sm3TueVyyZIkkad++fTLG6Omnn9bTTz9daF/OD2rn++233/Tnn3+qWbNm+ea1aNFCeXl5OnDggG688UZr+oXPg/PLGmeguJDD4Shw+oV++eUXDRw4ULfccotmzpxpTT916lS+5y0oKEjBwcGKjY3VzJkz9eGHH+rWW2/V3XffbZ1nJEk//vijPD091bJly0LX63yPXjgG3t7euv766/O9h6+77jqXw2Clc2Pwww8/XPL1cDH16tXL956tXr26tm/f7tLXonzeXOw9c6WflVLR3reXa+LEiVqzZo0SExPzHea3YsUKPffcc0pNTXU5x+1KL2RR1Of8cp4boDQiZAE269q1q3788Ud9+umn+vLLL/XWW29p1qxZmj9/vsu3m8Xt/G8rnQYMGKCNGzdq3LhxateunapWraq8vDz16tWrwPNxCrrKXGFXnjPnXaijRYsW2rNnj1asWKGVK1fq//7v/zRv3jzFxcVpypQpV7FV9rqcbblchf2BkpubW+RlXWjQoEF6/fXX9cUXX6hv375asmSJmjdvrrZt21ptPvjgAw0bNkx9+/bVuHHjFBAQIC8vL02dOlU//vhjvmUW9PooSFFfMxe6nD/c8vLy9Je//EVPPvlkgfOdgTYgIECpqalatWqVvvjiC33xxRdasGCBHnjggXwXK7gSzu3529/+poiIiALbXOyLjStx4fPg7MP7779fYHivUOHSZTwnJ0f33nuvfHx8tGTJEpfHLF68ON+eI+frfcaMGRo2bJj1WfbYY49Z59adf1EOOxX0OszLy1Pr1q1dwuH56tevf8nl2vnedrrYe+ZKPyuL+r69HJ988olefPFFPfvss/m+gPjnP/+pu+++W127dtW8efNUp04dVaxYUQsWLLisCxPZ4Vo8N0BJQMgCrgHnFeCGDx+uEydOqGvXrpo8ebIVsgr7Q7Nhw4b66quvdPz4cZe9Wbt377bmO//Ny8vT/v37Xb6N37dv32X38Y8//tDq1as1ZcoUxcXFWdOv5DDHy1GlShUNHDhQAwcOVE5Ojvr166fnn39eEyZMkK+vb4GPadiwobZv3668vDyXb5cvHI/i5tzDcf7z+O9//1uSrIsQOPeCHTt2zOWy3gXtfSvqN8Zdu3ZVnTp1tHjxYnXp0kVr1qyxLprhtGzZMl1//fX6+OOPXZZ/Ob8jVpgrec3s3bvX5Rv4ffv2KS8v76IXa2jcuLFOnDih8PDwS/bJ29tbd911l+666y7l5eXp0Ucf1euvv66nn376kgGooH7/+9//tvrmPMSvYsWKl9WXC9WuXVuVK1fWnj178s3bvXu3PD09LxkQnHsdAgICrqgPkvTYY48pNTVVX3/9db6LqkRERFz0cMvWrVurdevWmjhxojZu3KhbbrlF8+fP13PPPafGjRsrLy9Pu3btKvSCDM736J49e1wOmczJydH+/fsva5saN26sf/3rX+rRo8c1vUx4Sfi8sft9++9//1tRUVHq27evdaXG8/3f//2ffH19tWrVKpffuVqwYEG+tpc79nY850BZwDlZgM0uPPSjatWqatKkicthGM7j4S+8nO0dd9yh3NxczZ0712X6rFmz5OHhYV1pyfmt+rx581zavfrqq5fdT+e3hxd+W+i8cpudLhwTb29vtWzZUsaYi16x8Y477lB6errL+Udnz57Vq6++qqpVq+q2226zva+X4+DBg1q+fLl1PysrS++9957atWtn7W1w/nHsPH9IknUJ5AtVqVIl32vhYjw9PXXvvffqs88+0/vvv6+zZ8/mO1SwoOd38+bNSk5Ovuz1XOhKXjPOnytwcr5GL3bVsAEDBig5OVmrVq3KN+/YsWM6e/aspPyvK09PT+uw3Mu5tPcnn3zick7Vli1btHnzZqtvAQEB6tatm15//XUdOnQo3+MvvLz/hby8vNSzZ099+umnLodHZmRkaOHCherSpcslD/eLiIiQw+HQCy+8UOB75VJ9WLBggV5//XXFx8erU6dO+ebXqVNH4eHhLjfp3GvaOc5OrVu3lqenpzW2ffv2laenp5555pl8ezGdr5Hw8HB5e3vrlVdecXndvP3228rMzLzoFVGdBgwYoF9//VVvvvlmvnmnTp2y7ffESsLnjZ3v2xMnTuiee+7RddddZ116vaD1eXh4uOxh/+mnnwq8YuPlfk7Z8ZwDZQF7sgCbtWzZUt26dVNISIhq1Kih7777TsuWLVNMTIzVJiQkRNK5b5gjIiLk5eWlQYMG6a677tLtt9+uv//97/rpp5/Utm1bffnll/r00081ZswY6w/3kJAQ9e/fX7Nnz9bvv/9uXcLduTflcr5xdDgc6tq1q6ZPn64zZ87ouuuu05dffqn9+/fbPiY9e/ZUUFCQbrnlFgUGBuqHH37Q3LlzFRkZme/8s/ONHDlSr7/+uoYNG6aUlBQ1atRIy5Yt04YNGzR79uyLPvZauuGGGzRixAh9++23CgwM1DvvvKOMjAyXb3979uypBg0aaMSIERo3bpy8vLz0zjvvqHbt2kpLS3NZXkhIiF577TU999xzatKkiQICAgo9B8dp4MCBevXVVzVp0iS1bt3aOm/E6c4779THH3+se+65R5GRkdq/f7/mz5+vli1b6sSJE1e03Vfymtm/f7/uvvtu9erVS8nJyfrggw903333uRzaeKFx48bpH//4h+68804NGzZMISEhOnnypHbs2KFly5bpp59+Uq1atfTQQw/p6NGj6t69u+rVq6eff/5Zr776qtq1a5dvPArSpEkTdenSRaNGjVJ2drZmz56tmjVruhymGB8fry5duqh169Z6+OGHdf311ysjI0PJycn65Zdf9K9//eui63juueeUlJSkLl266NFHH1WFChX0+uuvKzs7+7J+C8jhcOi1117T0KFD1aFDBw0aNMh6DSUmJuqWW27J96WM05EjR/Too4+qZcuW8vHx0QcffOAy/5577nG5AML51qxZo5iYGP31r3/VDTfcoLNnz+r999+Xl5eX+vfvb43f3//+dz377LO69dZb1a9fP/n4+Ojbb79V3bp1NXXqVNWuXVsTJkzQlClT1KtXL919993as2eP5s2bp5tuusnlggeFGTp0qJYsWaJHHnlEa9eu1S233KLc3Fzt3r1bS5Ys0apVqwo8h7aoSsLnjZ3v2ylTpmjXrl2aOHGiPv30U5d5jRs3VlhYmCIjIzVz5kz16tVL9913nw4fPqz4+Hg1adIk3zlRISEh+uqrrzRz5kzVrVtXwcHB+X6CQJItzzlQJhTz1QyBEs15Kdpvv/22wPm33XbbJS/h/txzz5lOnToZf39/U6lSJdO8eXPz/PPPm5ycHKvN2bNnzejRo03t2rWNh4eHy6W+jx8/bsaOHWvq1q1rKlasaJo2bWpeeukll0uLG2PMyZMnTXR0tKlRo4apWrWq6du3r9mzZ4+R5HKZYOclhX/77bd82/PLL7+Ye+65x/j7+xs/Pz/z17/+1Rw8eLDQy8BfuIyoqChTpUqVS47T66+/brp27Wpq1qxpfHx8TOPGjc24ceNMZmZmgeN8voyMDDN8+HBTq1Yt4+3tbVq3bu1ySXEnOy7hfuHzvnbtWiPJrF27Nt96Vq1aZdq0aWN8fHxM8+bNC7zUdUpKigkNDTXe3t6mQYMGZubMmQVeZjk9Pd1ERkaaatWqGUmXdTn3vLw8U79+/QIv+e+c/8ILL5iGDRsaHx8f0759e7NixQoTFRVlGjZsaLUr7NLj5887f7yL+prZtWuXuffee021atVM9erVTUxMjDl16pTLei58Pow59z6YMGGCadKkifH29ja1atUyN998s3n55Zet99KyZctMz549TUBAgDXG//M//2MOHTp00bE7f5tnzJhh6tevb3x8fMytt97qcml5px9//NE88MADJigoyFSsWNFcd9115s477zTLli27rHHcunWriYiIMFWrVjWVK1c2t99+u9m4caNLm0t99qxdu9ZEREQYPz8/4+vraxo3bmyGDRtmvvvuu0tuZ2G3wi71bYwx//nPf8yDDz5oGjdubHx9fU2NGjXM7bffbr766qt8bd955x3Tvn174+PjY6pXr25uu+02k5SU5NJm7ty5pnnz5qZixYomMDDQjBo1yvzxxx8ubQr6fHXKyckxL774ornxxhut9YSEhJgpU6Zc8nOksOVe+F4w5vI+by72XF/tZ+Xlvm+NufQl3KOiogp97s9/v7399tumadOm1mfZggULCvwJit27d5uuXbuaSpUquSyjsEvHX81zXtD2AqWNhzGcWQiUFampqWrfvr0++OADDRkyxN3dKZMaNWqkVq1aacWKFe7uCgAAKKE4JwsopU6dOpVv2uzZs+Xp6amuXbu6oUcAAACQOCcLKLWmT5+ulJQU3X777apQoYJ1CeuRI0de1iWNAQAAcG0QsoBS6uabb1ZSUpKeffZZnThxQg0aNNDkyZPzXcobAAAAxYtzsgAAAADARpyTBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYqIK7O+BOeXl5OnjwoKpVqyYPDw93dwcAyg1jjI4fP666devK05Pv+5yoSwDgPnbWpnIdsg4ePKj69eu7uxsAUG4dOHBA9erVc3c3SgzqEgC4nx21qVyHrGrVqkk6N5AOh8PNvQGA8iMrK0v169e3PodxDnUJANzHztpUrkOW81AMh8NBMQMAN+CQOFfUJQBwPztqEwfCAwAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2Ktc/Royr1+ipxAKn/zQtsph7AgCQCv9clvhsBoDiQsgq5UpbyLlY8S9MSd0WAAAAoCCErHKGbzgBAACAa4uQVUZdyR6jsrR+AAAAwF0IWdfIlRzGRzABAAAASj9C1lUqS8GoLG0LAAAA4C5cwh0AAAAAbMSerGLG3iIAAACgbGNPFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiogrs7AFxKo6cSC53307TIYuwJAAAAcGnsyQIAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAZcq0adPk4eGhMWPGWNNOnz6t6Oho1axZU1WrVlX//v2VkZHh8ri0tDRFRkaqcuXKCggI0Lhx43T27FmXNuvWrVOHDh3k4+OjJk2aKCEhId/64+Pj1ahRI/n6+io0NFRbtmy5FpsJACjBCFkAgDLj22+/1euvv642bdq4TB87dqw+++wzLV26VOvXr9fBgwfVr18/a35ubq4iIyOVk5OjjRs36t1331VCQoLi4uKsNvv371dkZKRuv/12paamasyYMXrooYe0atUqq83ixYsVGxurSZMmaevWrWrbtq0iIiJ0+PDha7/xAIASg5AFACgTTpw4oSFDhujNN99U9erVremZmZl6++23NXPmTHXv3l0hISFasGCBNm7cqE2bNkmSvvzyS+3atUsffPCB2rVrp969e+vZZ59VfHy8cnJyJEnz589XcHCwZsyYoRYtWigmJkb33nuvZs2aZa1r5syZevjhhzV8+HC1bNlS8+fPV+XKlfXOO+8U72AAANyKkAUAKBOio6MVGRmp8PBwl+kpKSk6c+aMy/TmzZurQYMGSk5OliQlJyerdevWCgwMtNpEREQoKytLO3futNpcuOyIiAhrGTk5OUpJSXFp4+npqfDwcKvNhbKzs5WVleVyAwCUfhXc3QEAAK7WokWLtHXrVn377bf55qWnp8vb21v+/v4u0wMDA5Wenm61OT9gOec7512sTVZWlk6dOqU//vhDubm5BbbZvXt3gf2eOnWqpkyZcvkbCgAoFdiTBQAo1Q4cOKDHH39cH374oXx9fd3dnSKZMGGCMjMzrduBAwfc3SUAgA2uechy91WeAABlW0pKig4fPqwOHTqoQoUKqlChgtavX69XXnlFFSpUUGBgoHJycnTs2DGXx2VkZCgoKEiSFBQUlK8OOe9fqo3D4VClSpVUq1YteXl5FdjGuYwL+fj4yOFwuNwAAKXfNQ1Z7r7KEwCg7OvRo4d27Nih1NRU69axY0cNGTLE+n/FihW1evVq6zF79uxRWlqawsLCJElhYWHasWOHy1UAk5KS5HA41LJlS6vN+ctwtnEuw9vbWyEhIS5t8vLytHr1aqsNAKB8uGbnZJ1/lafnnnvOmu68ytPChQvVvXt3SdKCBQvUokULbdq0SZ07d7au8vTVV18pMDBQ7dq107PPPqvx48dr8uTJ8vb2drnKkyS1aNFC33zzjWbNmqWIiIhrtVkAgBKmWrVqatWqlcu0KlWqqGbNmtb0ESNGKDY2VjVq1JDD4dDo0aMVFhamzp07S5J69uypli1baujQoZo+fbrS09M1ceJERUdHy8fHR5L0yCOPaO7cuXryySf14IMPas2aNVqyZIkSExOt9cbGxioqKkodO3ZUp06dNHv2bJ08eVLDhw8vptEAAJQE12xPlruv8lQQruIEAOXTrFmzdOedd6p///7q2rWrgoKC9PHHH1vzvby8tGLFCnl5eSksLEz333+/HnjgAT3zzDNWm+DgYCUmJiopKUlt27bVjBkz9NZbb7l8sTdw4EC9/PLLiouLU7t27ZSamqqVK1fmuxgGAKBsuyZ7skrCVZ4qVaqUb91cxQkAyod169a53Pf19VV8fLzi4+MLfUzDhg31+eefX3S53bp107Zt2y7aJiYmRjExMZfdVwBA2WP7nqySfJUnruIEAAAA4FqzPWSVlKs8FYSrOAEAAAC41mwPWSXlKk8AAAAA4A62n5NVkq7yBAAAAADF7Zpdwv1iZs2aJU9PT/Xv31/Z2dmKiIjQvHnzrPnOqzyNGjVKYWFhqlKliqKiogq8ytPYsWM1Z84c1atXL99VngAAAACguBVLyHLnVZ4AAAAAoDhds9/JAgAAAIDyiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiogrs7AFyNRk8lFjj9p2mRxdwTAAAA4Bz2ZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQBKtddee01t2rSRw+GQw+FQWFiYvvjiC2v+6dOnFR0drZo1a6pq1arq37+/MjIyXJaRlpamyMhIVa5cWQEBARo3bpzOnj3r0mbdunXq0KGDfHx81KRJEyUkJOTrS3x8vBo1aiRfX1+FhoZqy5Yt12SbAQAlGyELAFCq1atXT9OmTVNKSoq+++47de/eXX369NHOnTslSWPHjtVnn32mpUuXav369Tp48KD69etnPT43N1eRkZHKycnRxo0b9e677yohIUFxcXFWm/379ysyMlK33367UlNTNWbMGD300ENatWqV1Wbx4sWKjY3VpEmTtHXrVrVt21YRERE6fPhw8Q0GAKBE8DDGGHd3wl2ysrLk5+enzMxMORyOK1pGo6cSbe4V7PDTtEh3dwHARdjx+XsxNWrU0EsvvaR7771XtWvX1sKFC3XvvfdKknbv3q0WLVooOTlZnTt31hdffKE777xTBw8eVGBgoCRp/vz5Gj9+vH777Td5e3tr/PjxSkxM1Pfff2+tY9CgQTp27JhWrlwpSQoNDdVNN92kuXPnSpLy8vJUv359jR49Wk899dRl9fta1yU+GwGgcHbWJvZkAQDKjNzcXC1atEgnT55UWFiYUlJSdObMGYWHh1ttmjdvrgYNGig5OVmSlJycrNatW1sBS5IiIiKUlZVl7Q1LTk52WYazjXMZOTk5SklJcWnj6emp8PBwq01BsrOzlZWV5XIDAJR+toesknRsPACgfNixY4eqVq0qHx8fPfLII1q+fLlatmyp9PR0eXt7y9/f36V9YGCg0tPTJUnp6ekuAcs53znvYm2ysrJ06tQpHTlyRLm5uQW2cS6jIFOnTpWfn591q1+//hVtPwCgZLE9ZJWUY+MBAOVHs2bNlJqaqs2bN2vUqFGKiorSrl273N2tS5owYYIyMzOt24EDB9zdJQCADSrYvcC77rrL5f7zzz+v1157TZs2bVK9evX09ttva+HCherevbskacGCBWrRooU2bdqkzp0768svv9SuXbv01VdfKTAwUO3atdOzzz6r8ePHa/LkyfL29tb8+fMVHBysGTNmSJJatGihb775RrNmzVJERITdmwQAKOG8vb3VpEkTSVJISIi+/fZbzZkzRwMHDlROTo6OHTvmsjcrIyNDQUFBkqSgoKB8VwF0HmFxfpsLj7rIyMiQw+FQpUqV5OXlJS8vrwLbOJdREB8fH/n4+FzZRgMASqxrek6Wu46NBwCUb3l5ecrOzlZISIgqVqyo1atXW/P27NmjtLQ0hYWFSZLCwsK0Y8cOl6sAJiUlyeFwqGXLllab85fhbONchre3t0JCQlza5OXlafXq1VYbAED5YfueLOncsfFhYWE6ffq0qlatah0bn5qaWizHxleqVKnAfmVnZys7O9u6zwnGAFD6TZgwQb1791aDBg10/PhxLVy4UOvWrdOqVavk5+enESNGKDY2VjVq1JDD4dDo0aMVFhamzp07S5J69uypli1baujQoZo+fbrS09M1ceJERUdHW3uZHnnkEc2dO1dPPvmkHnzwQa1Zs0ZLlixRYuJ/r+QXGxurqKgodezYUZ06ddLs2bN18uRJDR8+3C3jAgBwn2sSspzHxmdmZmrZsmWKiorS+vXrr8WqimTq1KmaMmWKu7sBALDR4cOH9cADD+jQoUPy8/NTmzZttGrVKv3lL3+RJM2aNUuenp7q37+/srOzFRERoXnz5lmP9/Ly0ooVKzRq1CiFhYWpSpUqioqK0jPPPGO1CQ4OVmJiosaOHas5c+aoXr16euutt1wOUR84cKB+++03xcXFKT09Xe3atdPKlSvzfSkIACj7rknIcvex8YWZMGGCYmNjrftZWVlcyQkASrm33377ovN9fX0VHx+v+Pj4Qts0bNhQn3/++UWX061bN23btu2ibWJiYhQTE3PRNgCAsq9YfieruI+NL4yPj491aXnnDQAAAADsZPuerJJybDwAAAAAuIPtIaukHBsPAAAAAO7gYYwx7u6Eu2RlZcnPz0+ZmZlXfOhgo6fYe1YS/TQt0t1dAHARdnz+lkXXui7x2QgAhbOzNhXLOVkAAAAAUF4QsgAAAADARoQsAAAAALARIQsAAAAAbETIAgAAAAAbEbIAAAAAwEaELAAAAACwESELAAAAAGxEyAIAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARoQsAAAAALARIQsAAAAAbETIAgAAAAAbEbIAAAAAwEaELAAAAACwUQV3dwC4Fho9lVjg9J+mRRZzTwAAAFDesCcLAAAAAGxEyAIAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARoQsAAAAALARIQsAAAAAbETIAgAAAAAbEbIAAAAAwEaELAAAAACwESELAFCqTZ06VTfddJOqVaumgIAA9e3bV3v27HFpc/r0aUVHR6tmzZqqWrWq+vfvr4yMDJc2aWlpioyMVOXKlRUQEKBx48bp7NmzLm3WrVunDh06yMfHR02aNFFCQkK+/sTHx6tRo0by9fVVaGiotmzZYvs2AwBKNkIWAKBUW79+vaKjo7Vp0yYlJSXpzJkz6tmzp06ePGm1GTt2rD777DMtXbpU69ev18GDB9WvXz9rfm5uriIjI5WTk6ONGzfq3XffVUJCguLi4qw2+/fvV2RkpG6//XalpqZqzJgxeuihh7Rq1SqrzeLFixUbG6tJkyZp69atatu2rSIiInT48OHiGQwAQIngYYwx7u6Eu2RlZcnPz0+ZmZlyOBxXtIxGTyXa3CtcSz9Ni3R3FwDIns/fwvz2228KCAjQ+vXr1bVrV2VmZqp27dpauHCh7r33XknS7t271aJFCyUnJ6tz58764osvdOedd+rgwYMKDAyUJM2fP1/jx4/Xb7/9Jm9vb40fP16JiYn6/vvvrXUNGjRIx44d08qVKyVJoaGhuummmzR37lxJUl5enurXr6/Ro0frqaeeKpZxuVhd4jMQAApnZ22yfU9WSTtsAwBQvmRmZkqSatSoIUlKSUnRmTNnFB4ebrVp3ry5GjRooOTkZElScnKyWrdubQUsSYqIiFBWVpZ27txptTl/Gc42zmXk5OQoJSXFpY2np6fCw8OtNhfKzs5WVlaWyw0AUPrZHrJK0mEbAIDyJS8vT2PGjNEtt9yiVq1aSZLS09Pl7e0tf39/l7aBgYFKT0+32pwfsJzznfMu1iYrK0unTp3SkSNHlJubW2Ab5zIuNHXqVPn5+Vm3+vXrX9mGAwBKlAp2L9B5yIRTQkKCAgIClJKSYh228fbbb2vhwoXq3r27JGnBggVq0aKFNm3apM6dO+vLL7/Url279NVXXykwMFDt2rXTs88+q/Hjx2vy5Mny9vbW/PnzFRwcrBkzZkiSWrRooW+++UazZs1SRESE3ZsFACgFoqOj9f333+ubb75xd1cuy4QJExQbG2vdz8rKImgBQBlwzS984a7DNgrCYRkAUHbFxMRoxYoVWrt2rerVq2dNDwoKUk5Ojo4dO+bSPiMjQ0FBQVabCw9bd96/VBuHw6FKlSqpVq1a8vLyKrCNcxkX8vHxkcPhcLkBAEq/axqy3HnYRkE4LAMAyh5jjGJiYrR8+XKtWbNGwcHBLvNDQkJUsWJFrV692pq2Z88epaWlKSwsTJIUFhamHTt2uFwFMCkpSQ6HQy1btrTanL8MZxvnMry9vRUSEuLSJi8vT6tXr7baAADKh2saspyHbSxatOharuayTZgwQZmZmdbtwIED7u4SAOAqRUdH64MPPtDChQtVrVo1paenKz093frCzc/PTyNGjFBsbKzWrl2rlJQUDR8+XGFhYercubMkqWfPnmrZsqWGDh2qf/3rX1q1apUmTpyo6Oho+fj4SJIeeeQR/ec//9GTTz6p3bt3a968eVqyZInGjh1r9SU2NlZvvvmm3n33Xf3www8aNWqUTp48qeHDhxf/wAAA3Mb2c7KcnIdtfP3114UetnH+3qwLD9u48Mcbi3rYRkF8fHysYgkAKBtee+01SVK3bt1cpi9YsEDDhg2TJM2aNUuenp7q37+/srOzFRERoXnz5lltvby8tGLFCo0aNUphYWGqUqWKoqKi9Mwzz1htgoODlZiYqLFjx2rOnDmqV6+e3nrrLZfzgAcOHKjffvtNcXFxSk9PV7t27bRy5cp8R14AAMo220OWMUajR4/W8uXLtW7duosettG/f39JBR+28fzzz+vw4cMKCAiQVPBhG59//rnLss8/bAMAUD5czs89+vr6Kj4+XvHx8YW2adiwYb66cqFu3bpp27ZtF20TExOjmJiYS/YJAFB22R6yoqOjtXDhQn366afWYRvSucM1KlWq5HLYRo0aNeRwODR69OhCD9uYPn260tPTCzxsY+7cuXryySf14IMPas2aNVqyZIkSE/lxYAAAAADuY/s5Wa+99poyMzPVrVs31alTx7otXrzYajNr1izdeeed6t+/v7p27aqgoCB9/PHH1nznYRteXl4KCwvT/fffrwceeKDAwzaSkpLUtm1bzZgxI99hGwAAAABQ3K7J4YKXUpyHbQAAAABAcbrmv5MFAAAAAOUJIQsAAAAAbETIAgAAAAAbEbIAAAAAwEaELAAAAACwESELAAAAAGxEyAIAAAAAGxGyAAAAAMBGtv8YMQAAKJkaPZVY4PSfpkUWc08AoGxjTxYAAAAA2Ig9WShXCvsWV+KbXAAAANiDPVkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAKNW+/vpr3XXXXapbt648PDz0ySefuMw3xiguLk516tRRpUqVFB4err1797q0OXr0qIYMGSKHwyF/f3+NGDFCJ06ccGmzfft23XrrrfL19VX9+vU1ffr0fH1ZunSpmjdvLl9fX7Vu3Vqff/657dsLACj5bA9ZJanYAQDKvpMnT6pt27aKj48vcP706dP1yiuvaP78+dq8ebOqVKmiiIgInT592mozZMgQ7dy5U0lJSVqxYoW+/vprjRw50pqflZWlnj17qmHDhkpJSdFLL72kyZMn64033rDabNy4UYMHD9aIESO0bds29e3bV3379tX3339/7TYeAFAi2R6ySkqxAwCUD71799Zzzz2ne+65J988Y4xmz56tiRMnqk+fPmrTpo3ee+89HTx40PoS8IcfftDKlSv11ltvKTQ0VF26dNGrr76qRYsW6eDBg5KkDz/8UDk5OXrnnXd04403atCgQXrsscc0c+ZMa11z5sxRr169NG7cOLVo0ULPPvusOnTooLlz5xbLOAAASg7bQ1ZJKXYAAOzfv1/p6ekKDw+3pvn5+Sk0NFTJycmSpOTkZPn7+6tjx45Wm/DwcHl6emrz5s1Wm65du8rb29tqExERoT179uiPP/6w2py/Hmcb53oKkp2draysLJcbAKD0K9Zzsoqz2AEAkJ6eLkkKDAx0mR4YGGjNS09PV0BAgMv8ChUqqEaNGi5tClrG+esorI1zfkGmTp0qPz8/61a/fv2ibiIAoASqUJwrs7PYBQcH51uGc1716tULXH92drays7Ot+3xjiPM1eiqxwOk/TYss5p4AKC8mTJig2NhY635WVhZBCwDKgHJ1dUG+MQSA8iUoKEiSlJGR4TI9IyPDmhcUFKTDhw+7zD979qyOHj3q0qagZZy/jsLaOOcXxMfHRw6Hw+UGACj9ijVkFWexK8iECROUmZlp3Q4cOHB1GwQAKNGCg4MVFBSk1atXW9OysrK0efNmhYWFSZLCwsJ07NgxpaSkWG3WrFmjvLw8hYaGWm2+/vprnTlzxmqTlJSkZs2aWUdPhIWFuazH2ca5HgBA+VGsIas4i11B+MYQAMqeEydOKDU1VampqZLOnf+bmpqqtLQ0eXh4aMyYMXruuef0j3/8Qzt27NADDzygunXrqm/fvpKkFi1aqFevXnr44Ye1ZcsWbdiwQTExMRo0aJDq1q0rSbrvvvvk7e2tESNGaOfOnVq8eLHmzJnjcqjf448/rpUrV2rGjBnavXu3Jk+erO+++04xMTHFPSQAADezPWSVlGIHACgfvvvuO7Vv317t27eXJMXGxqp9+/aKi4uTJD355JMaPXq0Ro4cqZtuukknTpzQypUr5evray3jww8/VPPmzdWjRw/dcccd6tKli8vPgvj5+enLL7/U/v37FRISoieeeEJxcXEuPy9y8803a+HChXrjjTfUtm1bLVu2TJ988olatWpVTCMBACgpPIwxxs4Frlu3Trfffnu+6VFRUUpISJAxRpMmTdIbb7yhY8eOqUuXLpo3b55uuOEGq+3Ro0cVExOjzz77TJ6enurfv79eeeUVVa1a1Wqzfft2RUdH69tvv1WtWrU0evRojR8/vkh9zcrKkp+fnzIzM694r1ZhF0tA2cGFLwD72fH5Wxa5qy7xOQcA9tYm268u2K1bN10st3l4eOiZZ57RM888U2ibGjVqaOHChRddT5s2bfTPf/7zivsJAAAAANdCubq6IAAAAABca4QsAAAAALBRsf4YMQAAKHkudh4X52sBQNGxJwsAAAAAbETIAgAAAAAbEbIAAAAAwEaELAAAAACwESELAAAAAGxEyAIAAAAAG3EJd+ASuLQxAAAAioI9WQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjfgxYuAqFPZDxfxIMQAAQPlFyAIAAIXiyyQAKDoOFwQAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARoQsAAAAALARv5MFXAOF/a6MxG/LAAAAlHWELAAAUGT8SDEAFI7DBQEAAADARoQsAAAAALARhwsCxYxDbAAAAMo29mQBAAAAgI3YkwUAAGzD1VUBgJAFlBgcRggAAFA2lPrDBePj49WoUSP5+voqNDRUW7ZscXeXAADlHLUJAMq3Ur0na/HixYqNjdX8+fMVGhqq2bNnKyIiQnv27FFAQIC7uwfY4mKH3hSGvV+A+1CbCsceewDlhYcxxri7E1cqNDRUN910k+bOnStJysvLU/369TV69Gg99dRTl3x8VlaW/Pz8lJmZKYfDcUV9uJI/gAF34o8ZlAR2fP6WVFdTm6hL+fGZBaC42FmbSu2erJycHKWkpGjChAnWNE9PT4WHhys5ObnAx2RnZys7O9u6n5mZKencgF6pvOw/r/ixgDs0GLu0SO2/nxJxjXqC8sz5uVuKv+crUFFrE3Xp0vjMAlBc7KxNpTZkHTlyRLm5uQoMDHSZHhgYqN27dxf4mKlTp2rKlCn5ptevX/+a9BEoC/xmu7sHKMuOHz8uPz8/d3fDNkWtTdQl+/GZBeBq2VGbSm3IuhITJkxQbGysdT8vL09Hjx5VzZo15eHhUeTlZWVlqX79+jpw4ECpONyltPVXKn19Lm39lUpfn0tbf6XS1+fi6K8xRsePH1fdunWvyfJLi/Jel+zG9rP9bD/bfzXbb2dtKrUhq1atWvLy8lJGRobL9IyMDAUFBRX4GB8fH/n4+LhM8/f3v+q+OByOUvViLm39lUpfn0tbf6XS1+fS1l+p9PX5Wve3LO3BcipqbaIuXRtsP9vP9rP9V8qu2lRqL+Hu7e2tkJAQrV692pqWl5en1atXKywszI09AwCUV9QmAIBUivdkSVJsbKyioqLUsWNHderUSbNnz9bJkyc1fPhwd3cNAFBOUZsAAKU6ZA0cOFC//fab4uLilJ6ernbt2mnlypX5Tji+Vnx8fDRp0qR8h3qUVKWtv1Lp63Np669U+vpc2vorlb4+l7b+ljTurE3l/blj+9l+tp/tLynbX6p/JwsAAAAASppSe04WAAAAAJREhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsq5QfHy8GjVqJF9fX4WGhmrLli3u7lKhJk+eLA8PD5db8+bN3d0ty9dff6277rpLdevWlYeHhz755BOX+cYYxcXFqU6dOqpUqZLCw8O1d+9e93T2/7tUn4cNG5ZvzHv16uWezkqaOnWqbrrpJlWrVk0BAQHq27ev9uzZ49Lm9OnTio6OVs2aNVW1alX1798/3w+qlqT+duvWLd8YP/LII27pryS99tpratOmjfUjiGFhYfriiy+s+SVpfJ0u1eeSNsa4tNJUm67GpepaSXy/XQ076uTRo0c1ZMgQORwO+fv7a8SIETpx4kQxbsWVsaPeltZtl+yr32lpaYqMjFTlypUVEBCgcePG6ezZs8W5KVfErr8H3LH9hKwrsHjxYsXGxmrSpEnaunWr2rZtq4iICB0+fNjdXSvUjTfeqEOHDlm3b775xt1dspw8eVJt27ZVfHx8gfOnT5+uV155RfPnz9fmzZtVpUoVRURE6PTp08Xc0/+6VJ8lqVevXi5j/tFHHxVjD12tX79e0dHR2rRpk5KSknTmzBn17NlTJ0+etNqMHTtWn332mZYuXar169fr4MGD6tevX4ntryQ9/PDDLmM8ffp0t/RXkurVq6dp06YpJSVF3333nbp3764+ffpo586dkkrW+F5un6WSNca4uNJYm67GxepaSXy/XQ076uSQIUO0c+dOJSUlacWKFfr66681cuTI4tqEK2ZHvS2t2y7ZU79zc3MVGRmpnJwcbdy4Ue+++64SEhIUFxfnjk0qEjv+HnDb9hsUWadOnUx0dLR1Pzc319StW9dMnTrVjb0q3KRJk0zbtm3d3Y3LIsksX77cup+Xl2eCgoLMSy+9ZE07duyY8fHxMR999JEbepjfhX02xpioqCjTp08ft/Tnchw+fNhIMuvXrzfGnBvTihUrmqVLl1ptfvjhByPJJCcnu6ublgv7a4wxt912m3n88cfd16nLUL16dfPWW2+V+PE9n7PPxpSOMcZ/lbbadDUuVtdK0/vtSlxJndy1a5eRZL799lurzRdffGE8PDzMr7/+Wmx9v1pXUm/LyrY7XUn9/vzzz42np6dJT0+32rz22mvG4XCY7Ozs4t2Aq3Qlfw+4a/vZk1VEOTk5SklJUXh4uDXN09NT4eHhSk5OdmPPLm7v3r2qW7eurr/+eg0ZMkRpaWnu7tJl2b9/v9LT013G28/PT6GhoSV6vCVp3bp1CggIULNmzTRq1Cj9/vvv7u6SJTMzU5JUo0YNSVJKSorOnDnjMs7NmzdXgwYNSsQ4X9hfpw8//FC1atVSq1atNGHCBP3555/u6F4+ubm5WrRokU6ePKmwsLASP75S/j47ldQxhqvSWpuuRmF1rTS83+x0OXUyOTlZ/v7+6tixo9UmPDxcnp6e2rx5c7H32W4Xq7dlbduvpH4nJyerdevWLj+IHhERoaysLJcjF0qDK/l7wF3bX+GaLbmMOnLkiHJzc12eKEkKDAzU7t273dSriwsNDVVCQoKaNWumQ4cOacqUKbr11lv1/fffq1q1au7u3kWlp6dLUoHj7ZxXEvXq1Uv9+vVTcHCwfvzxR/3v//6vevfureTkZHl5ebm1b3l5eRozZoxuueUWtWrVStK5cfb29pa/v79L25IwzgX1V5Luu+8+NWzYUHXr1tX27ds1fvx47dmzRx9//LHb+rpjxw6FhYXp9OnTqlq1qpYvX66WLVsqNTW1xI5vYX2WSuYYo2ClsTZdjYvVtZL8eXYtXE6dTE9PV0BAgMv8ChUqqEaNGqV+TC5Vb8vStl9p/U5PTy/w9eGcV1pc6d8D7tp+QlY50Lt3b+v/bdq0UWhoqBo2bKglS5ZoxIgRbuxZ2TVo0CDr/61bt1abNm3UuHFjrVu3Tj169HBjz6To6Gh9//33Jeq8vIsprL/nH0/funVr1alTRz169NCPP/6oxo0bF3c3JUnNmjVTamqqMjMztWzZMkVFRWn9+vVu6cvlKqzPLVu2LJFjDEgXr2uVKlVyY89Q3EpyvbVbaavfditNfw9IXPiiyGrVqiUvL698V23JyMhQUFCQm3pVNP7+/rrhhhu0b98+d3flkpxjWprHW5Kuv/561apVy+1jHhMToxUrVmjt2rWqV6+eNT0oKEg5OTk6duyYS3t3j3Nh/S1IaGioJLl1jL29vdWkSROFhIRo6tSpatu2rebMmVNix1cqvM8FKQljjIKVhdp0Nc6vayX5/XYtXE6dDAoKyncBlLNnz+ro0aNlbkwurLdlZduvpn4HBQUV+PpwzisNrubvAXdtPyGriLy9vRUSEqLVq1db0/Ly8rR69WqX8xhKshMnTujHH39UnTp13N2VSwoODlZQUJDLeGdlZWnz5s2lZrwl6ZdfftHvv//utjE3xigmJkbLly/XmjVrFBwc7DI/JCREFStWdBnnPXv2KC0tzS3jfKn+FiQ1NVWSStTrOi8vT9nZ2SVufC/G2eeClMQxxjlloTZdjfPrWml6v9nhcupkWFiYjh07ppSUFKvNmjVrlJeXZ/1BWlZcWG9L+7bbUb/DwsK0Y8cOl7CZlJQkh8NhHR5eUtnx94Dbtv+aXVKjDFu0aJHx8fExCQkJZteuXWbkyJHG39/f5aolJckTTzxh1q1bZ/bv3282bNhgwsPDTa1atczhw4fd3TVjjDHHjx8327ZtM9u2bTOSzMyZM822bdvMzz//bIwxZtq0acbf3998+umnZvv27aZPnz4mODjYnDp1qkT2+fjx4+Zvf/ubSU5ONvv37zdfffWV6dChg2natKk5ffq0W/o7atQo4+fnZ9atW2cOHTpk3f7880+rzSOPPGIaNGhg1qxZY7777jsTFhZmwsLCSmR/9+3bZ5555hnz3Xffmf3795tPP/3UXH/99aZr165u6a8xxjz11FNm/fr1Zv/+/Wb79u3mqaeeMh4eHubLL780xpSs8b2cPpfEMcbFlbbadDUuVddK4vvtathRJ3v16mXat29vNm/ebL755hvTtGlTM3jwYHdt0mWzo96W1m03xp76ffbsWdOqVSvTs2dPk5qaalauXGlq165tJkyY4I5NKhI7/h5w1/YTsq7Qq6++aho0aGC8vb1Np06dzKZNm9zdpUINHDjQ1KlTx3h7e5vrrrvODBw40Ozbt8/d3bKsXbvWSMp3i4qKMsacuzzt008/bQIDA42Pj4/p0aOH2bNnT4nt859//ml69uxpateubSpWrGgaNmxoHn74Ybf+oVNQXyWZBQsWWG1OnTplHn30UVO9enVTuXJlc88995hDhw6VyP6mpaWZrl27mho1ahgfHx/TpEkTM27cOJOZmemW/hpjzIMPPmgaNmxovL29Te3atU2PHj2sgGVMyRpfp4v1uSSOMS6tNNWmq3GpulYS329Xw446+fvvv5vBgwebqlWrGofDYYYPH26OHz/uhq0pGjvqbWnddmPsq98//fST6d27t6lUqZKpVauWeeKJJ8yZM2eKeWuKzq6/B9yx/R7/fwMAAAAAADbgnCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARoQsAAAAALARIQsAAAAAbETIAgAAAAAbEbIAAAAAwEaELKCE8fDw0CeffHLZ7SdPnqx27dpdtM2wYcPUt2/fq+oXAKD8ojYBRUPIAororrvuUq9evQqc989//lMeHh7avn37FS//0KFD6t279xU//loxxiguLk516tRRpUqVFB4err1797q7WwAAld/a9PHHH6tnz56qWbOmPDw8lJqa6u4uAZIIWUCRjRgxQklJSfrll1/yzVuwYIE6duyoNm3aFHm5OTk5kqSgoCD5+PhcdT/tNn36dL3yyiuaP3++Nm/erCpVqigiIkKnT592d9cAoNwrr7Xp5MmT6tKli1588UV3dwVwQcgCiujOO+9U7dq1lZCQ4DL9xIkTWrp0qUaMGKHff/9dgwcP1nXXXafKlSurdevW+uijj1zad+vWTTExMRozZoxq1aqliIgISfkPyRg/frxuuOEGVa5cWddff72efvppnTlzJl+/Xn/9ddWvX1+VK1fWgAEDlJmZWeg25OXlaerUqQoODlalSpXUtm1bLVu2rND2xhjNnj1bEydOVJ8+fdSmTRu99957OnjwYJEOHwEAXBvlsTZJ0tChQxUXF6fw8PBLjBBQvAhZQBFVqFBBDzzwgBISEmSMsaYvXbpUubm5Gjx4sE6fPq2QkBAlJibq+++/18iRIzV06FBt2bLFZVnvvvuuvL29tWHDBs2fP7/A9VWrVk0JCQnatWuX5syZozfffFOzZs1yabNv3z4tWbJEn332mVauXKlt27bp0UcfLXQbpk6dqvfee0/z58/Xzp07NXbsWN1///1av359ge3379+v9PR0lyLm5+en0NBQJScnX3LMAADXVnmsTUCJZgAU2Q8//GAkmbVr11rTbr31VnP//fcX+pjIyEjzxBNPWPdvu+020759+3ztJJnly5cXupyXXnrJhISEWPcnTZpkvLy8zC+//GJN++KLL4ynp6c5dOiQMcaYqKgo06dPH2OMMadPnzaVK1c2GzdudFnuiBEjzODBgwtc54YNG4wkc/DgQZfpf/3rX82AAQMK7SsAoPiUt9p0vv379xtJZtu2bZdsCxSHCu4MeEBp1bx5c918881655131K1bN+3bt0///Oc/9cwzz0iScnNz9cILL2jJkiX69ddflZOTo+zsbFWuXNllOSEhIZdc1+LFi/XKK6/oxx9/1IkTJ3T27Fk5HA6XNg0aNNB1111n3Q8LC1NeXp727NmjoKAgl7b79u3Tn3/+qb/85S8u03NyctS+ffsijQMAoOSgNgElByELuEIjRozQ6NGjFR8frwULFqhx48a67bbbJEkvvfSS5syZo9mzZ6t169aqUqWKxowZY51A7FSlSpWLriM5OVlDhgzRlClTFBERIT8/Py1atEgzZsy44n6fOHFCkpSYmOhS/CQVelKzsxhmZGSoTp061vSMjIxLXqIXAFB8ylNtAkoyQhZwhQYMGKDHH39cCxcu1HvvvadRo0bJw8NDkrRhwwb16dNH999/v6RzJ/P++9//VsuWLYu0jo0bN6phw4b6+9//bk37+eef87VLS0vTwYMHVbduXUnSpk2b5OnpqWbNmuVr27JlS/n4+CgtLc0qvJcSHBysoKAgrV692gpVWVlZ2rx5s0aNGlWkbQIAXDvlqTYBJRkhC7hCVatW1cCBAzVhwgRlZWVp2LBh1rymTZtq2bJl2rhxo6pXr66ZM2cqIyOjyIWsadOmSktL06JFi3TTTTcpMTFRy5cvz9fO19dXUVFRevnll5WVlaXHHntMAwYMyHc4hnTuZOW//e1vGjt2rPLy8tSlSxdlZmZqw4YNcjgcioqKyvcYDw8PjRkzRs8995yaNm2q4OBgPf3006pbty4/JAkAJUh5qk2SdPToUSvMSdKePXsknTsCo6D1AMWFqwsCV2HEiBH6448/FBERYX1TJ0kTJ05Uhw4dFBERoW7duikoKOiKwsjdd9+tsWPHKiYmRu3atdPGjRv19NNP52vXpEkT9evXT3fccYd69uypNm3aaN68eYUu99lnn9XTTz+tqVOnqkWLFurVq5cSExMVHBxc6GOefPJJjR49WiNHjtRNN92kEydOaOXKlfL19S3ydgEArp3yVJv+8Y9/qH379oqMjJQkDRo0SO3bty/0qohAcfEw5rzrfAIAAAAArgp7sgAAAADARoQsAAAAALBRub7wRV5eng4ePKhq1apZV94BAFx7xhgdP35cdevWlacn3/c5UZcAwH3srE3lOmQdPHhQ9evXd3c3AKDcOnDggOrVq+fubpQY1CUAcD87alO5DlnVqlWTdG4gL/yVcgDAtZOVlaX69etbn8M4h7oEAO5jZ20q1yHLeSiGw+GgmAGAG3BInCvqEgC4nx21iQPhAQAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARoQsAAAAALARIQsAAAAAbETIAgAAAAAblesfI7ZDo6cSC5z+07TIYu4JAACF1yWJ2gQAxYU9WQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAypRp06bJw8NDY8aMsaadPn1a0dHRqlmzpqpWrar+/fsrIyPD5XFpaWmKjIxU5cqVFRAQoHHjxuns2bMubdatW6cOHTrIx8dHTZo0UUJCQr71x8fHq1GjRvL19VVoaKi2bNlyLTYTAFCCEbIAAGXGt99+q9dff11t2rRxmT527Fh99tlnWrp0qdavX6+DBw+qX79+1vzc3FxFRkYqJydHGzdu1LvvvquEhATFxcVZbfbv36/IyEjdfvvtSk1N1ZgxY/TQQw9p1apVVpvFixcrNjZWkyZN0tatW9W2bVtFRETo8OHD137jAQAlBiELAFAmnDhxQkOGDNGbb76p6tWrW9MzMzP19ttva+bMmerevbtCQkK0YMECbdy4UZs2bZIkffnll9q1a5c++OADtWvXTr1799azzz6r+Ph45eTkSJLmz5+v4OBgzZgxQy1atFBMTIzuvfdezZo1y1rXzJkz9fDDD2v48OFq2bKl5s+fr8qVK+udd94p3sEAALjVVYUsDskAAJQU0dHRioyMVHh4uMv0lJQUnTlzxmV68+bN1aBBAyUnJ0uSkpOT1bp1awUGBlptIiIilJWVpZ07d1ptLlx2RESEtYycnBylpKS4tPH09FR4eLjVBgBQPlxxyOKQDABASbFo0SJt3bpVU6dOzTcvPT1d3t7e8vf3d5keGBio9PR0q835Acs53znvYm2ysrJ06tQpHTlyRLm5uQW2cS7jQtnZ2crKynK5AQBKvysKWRySAQAoKQ4cOKDHH39cH374oXx9fd3dnSKZOnWq/Pz8rFv9+vXd3SUAgA2uKGSV1kMy+MYQAMqelJQUHT58WB06dFCFChVUoUIFrV+/Xq+88ooqVKigwMBA5eTk6NixYy6Py8jIUFBQkCQpKCgo36HtzvuXauNwOFSpUiXVqlVLXl5eBbZxLuNCEyZMUGZmpnU7cODAFY8DAKDkKHLIKq2HZEh8YwgAZVGPHj20Y8cOpaamWreOHTtqyJAh1v8rVqyo1atXW4/Zs2eP0tLSFBYWJkkKCwvTjh07XA45T0pKksPhUMuWLa025y/D2ca5DG9vb4WEhLi0ycvL0+rVq602F/Lx8ZHD4XC5AQBKvwpFaew8JCMpKanUHZIhnfvGMDY21rqflZVF0AKAUq5atWpq1aqVy7QqVaqoZs2a1vQRI0YoNjZWNWrUkMPh0OjRoxUWFqbOnTtLknr27KmWLVtq6NChmj59utLT0zVx4kRFR0fLx8dHkvTII49o7ty5evLJJ/Xggw9qzZo1WrJkiRITE631xsbGKioqSh07dlSnTp00e/ZsnTx5UsOHDy+m0QAAlARFClnnH5LhlJubq6+//lpz587VqlWrrEMyzt+bdeEhGRdeBbCoh2R4eXkV+ZAM6dw3hs5iCQAoP2bNmiVPT0/1799f2dnZioiI0Lx586z5Xl5eWrFihUaNGqWwsDBVqVJFUVFReuaZZ6w2wcHBSkxM1NixYzVnzhzVq1dPb731liIiIqw2AwcO1G+//aa4uDilp6erXbt2WrlyZb4jLwAAZVuRQpbzkIzzDR8+XM2bN9f48eNVv35965CM/v37Syr4kIznn39ehw8fVkBAgKSCD8n4/PPPXdZT2CEZffv2lfTfQzJiYmKKOAQAgLJm3bp1Lvd9fX0VHx+v+Pj4Qh/TsGHDfLXnQt26ddO2bdsu2iYmJoZaBADlXJFCFodkAAAAAMDFFSlkXQ4OyQAAAABQnnkYY4y7O+EuWVlZ8vPzU2Zm5hVf0anRU4kFTv9pWuTVdA0AyjQ7Pn/LomtZlyRqEwBcjJ216Yp+JwsAAAAAUDBCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAKNVee+01tWnTRg6HQw6HQ2FhYfriiy+s+adPn1Z0dLRq1qypqlWrqn///srIyHBZRlpamiIjI1W5cmUFBARo3LhxOnv2rEubdevWqUOHDvLx8VGTJk2UkJCQry/x8fFq1KiRfH19FRoaqi1btlyTbQYAlGyELABAqVavXj1NmzZNKSkp+u6779S9e3f16dNHO3fulCSNHTtWn332mZYuXar169fr4MGD6tevn/X43NxcRUZGKicnRxs3btS7776rhIQExcXFWW3279+vyMhI3X777UpNTdWYMWP00EMPadWqVVabxYsXKzY2VpMmTdLWrVvVtm1bRURE6PDhw8U3GACAEqFIIYtvCwEAJc1dd92lO+64Q02bNtUNN9yg559/XlWrVtWmTZuUmZmpt99+WzNnzlT37t0VEhKiBQsWaOPGjdq0aZMk6csvv9SuXbv0wQcfqF27durdu7eeffZZxcfHKycnR5I0f/58BQcHa8aMGWrRooViYmJ07733atasWVY/Zs6cqYcffljDhw9Xy5YtNX/+fFWuXFnvvPOOW8YFAOA+RQpZfFsIACjJcnNztWjRIp08eVJhYWFKSUnRmTNnFB4ebrVp3ry5GjRooOTkZElScnKyWrdurcDAQKtNRESEsrKyrPqWnJzssgxnG+cycnJylJKS4tLG09NT4eHhVpuCZGdnKysry+UGACj9ihSy+LYQAFAS7dixQ1WrVpWPj48eeeQRLV++XC1btlR6erq8vb3l7+/v0j4wMFDp6emSpPT0dJeA5ZzvnHexNllZWTp16pSOHDmi3NzcAts4l1GQqVOnys/Pz7rVr1//irYfAFCyXPE5WaXt20KJbwwBoKxq1qyZUlNTtXnzZo0aNUpRUVHatWuXu7t1SRMmTFBmZqZ1O3DggLu7BACwQYWiPmDHjh0KCwvT6dOnVbVqVevbwtTU1GL5tvCPP/4o9NvC3bt3X7TvU6dO1ZQpU4q6yQCAEs7b21tNmjSRJIWEhOjbb7/VnDlzNHDgQOXk5OjYsWMu9SkjI0NBQUGSpKCgoHzn9TrPJz6/zYXnGGdkZMjhcKhSpUry8vKSl5dXgW2cyyiIj4+PfHx8rmyjAQAlVpH3ZJXWbwslvjEEgPIiLy9P2dnZCgkJUcWKFbV69Wpr3p49e5SWlqawsDBJUlhYmHbs2OFyXm9SUpIcDodatmxptTl/Gc42zmV4e3srJCTEpU1eXp5Wr15ttQEAlB9F3pNVWr8tlPjGEADKogkTJqh3795q0KCBjh8/roULF2rdunVatWqV/Pz8NGLECMXGxqpGjRpyOBwaPXq0wsLC1LlzZ0lSz5491bJlSw0dOlTTp09Xenq6Jk6cqOjoaKtmPPLII5o7d66efPJJPfjgg1qzZo2WLFmixMREqx+xsbGKiopSx44d1alTJ82ePVsnT57U8OHD3TIuAAD3uerfyeLbQgCAOx0+fFgPPPCAmjVrph49eujbb7/VqlWr9Je//EWSNGvWLN15553q37+/unbtqqCgIH388cfW4728vLRixQp5eXkpLCxM999/vx544AE988wzVpvg4GAlJiYqKSlJbdu21YwZM/TWW28pIiLCajNw4EC9/PLLiouLU7t27ZSamqqVK1fmO7wdAFD2eRhjzOU2LujbwhdffNEqZqNGjdLnn3+uhIQE69tCSdq4caOkcxfLaNeunerWrWt9Wzh06FA99NBDeuGFFySdu4R7q1atFB0dbX1b+NhjjykxMdEqZosXL1ZUVJRef/1169vCJUuWaPfu3UUqZllZWfLz81NmZqYcDsdlP+58jZ5KLHD6T9Mir2h5AFAe2PH5WxZdy7okUZsA4GLsrE1FOlzQ+W3hoUOH5OfnpzZt2uT7ttDT01P9+/dXdna2IiIiNG/ePOvxzm8LR40apbCwMFWpUkVRUVEFfls4duxYzZkzR/Xq1Svw28LffvtNcXFxSk9PV7t27fi2EAAAAECJUKQ9WWUNe7IAwD3Yk1Uw9mQBgPvYWZuu+pwsAAAAAMB/EbIAAAAAwEaELAAAAACwESELAAAAAGxEyAIAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARoQsAAAAALARIQsAAAAAbETIAgAAAAAbEbIAAAAAwEaELAAAAACwESELAAAAAGxEyAIAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARoQsAAAAALARIQsAAAAAbETIAgAAAAAbEbIAAAAAwEaELAAAAACwESELAAAAAGxEyAIAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARoQsAAAAALARIQsAUKpNnTpVN910k6pVq6aAgAD17dtXe/bscWlz+vRpRUdHq2bNmqpatar69++vjIwMlzZpaWmKjIxU5cqVFRAQoHHjxuns2bMubdatW6cOHTrIx8dHTZo0UUJCQr7+xMfHq1GjRvL19VVoaKi2bNli+zYDAEq2IoUsChkAoKRZv369oqOjtWnTJiUlJenMmTPq2bOnTp48abUZO3asPvvsMy1dulTr16/XwYMH1a9fP2t+bm6uIiMjlZOTo40bN+rdd99VQkKC4uLirDb79+9XZGSkbr/9dqWmpmrMmDF66KGHtGrVKqvN4sWLFRsbq0mTJmnr1q1q27atIiIidPjw4eIZDABAiVCkkEUhAwCUNCtXrtSwYcN04403qm3btkpISFBaWppSUlIkSZmZmXr77bc1c+ZMde/eXSEhIVqwYIE2btyoTZs2SZK+/PJL7dq1Sx988IHatWun3r1769lnn1V8fLxycnIkSfPnz1dwcLBmzJihFi1aKCYmRvfee69mzZpl9WXmzJl6+OGHNXz4cLVs2VLz589X5cqV9c477xT/wAAA3KZIIYtCBgAo6TIzMyVJNWrUkCSlpKTozJkzCg8Pt9o0b95cDRo0UHJysiQpOTlZrVu3VmBgoNUmIiJCWVlZ2rlzp9Xm/GU42ziXkZOTo5SUFJc2np6eCg8Pt9pcKDs7W1lZWS43AEDpd1XnZJWmQiZRzACgrMvLy9OYMWN0yy23qFWrVpKk9PR0eXt7y9/f36VtYGCg0tPTrTbn1yXnfOe8i7XJysrSqVOndOTIEeXm5hbYxrmMC02dOlV+fn7WrX79+le24QCAEuWKQ1ZpK2QSxQwAyrro6Gh9//33WrRokbu7clkmTJigzMxM63bgwAF3dwkAYIMrDlmlrZBJFDMAKMtiYmK0YsUKrV27VvXq1bOmBwUFKScnR8eOHXNpn5GRoaCgIKvNhRdpct6/VBuHw6FKlSqpVq1a8vLyKrCNcxkX8vHxkcPhcLkBAEq/KwpZpbGQSRQzACiLjDGKiYnR8uXLtWbNGgUHB7vMDwkJUcWKFbV69Wpr2p49e5SWlqawsDBJUlhYmHbs2OFy8aSkpCQ5HA61bNnSanP+MpxtnMvw9vZWSEiIS5u8vDytXr3aagMAKB+KFLIoZACAkiY6OloffPCBFi5cqGrVqik9PV3p6ek6deqUJMnPz08jRoxQbGys1q5dq5SUFA0fPlxhYWHq3LmzJKlnz55q2bKlhg4dqn/9619atWqVJk6cqOjoaPn4+EiSHnnkEf3nP//Rk08+qd27d2vevHlasmSJxo4da/UlNjZWb775pt5991398MMPGjVqlE6ePKnhw4cX/8AAANymQlEaR0dHa+HChfr000+tQiadK2CVKlVyKWQ1atSQw+HQ6NGjCy1k06dPV3p6eoGFbO7cuXryySf14IMPas2aNVqyZIkSExOtvsTGxioqKkodO3ZUp06dNHv2bAoZAJRDr732miSpW7duLtMXLFigYcOGSZJmzZolT09P9e/fX9nZ2YqIiNC8efOstl5eXlqxYoVGjRqlsLAwValSRVFRUXrmmWesNsHBwUpMTNTYsWM1Z84c1atXT2+99ZYiIiKsNgMHDtRvv/2muLg4paenq127dlq5cmW+c4gBAGWbhzHGXHZjD48Cp59fyE6fPq0nnnhCH330kUshO/8wvp9//lmjRo3SunXrrEI2bdo0Vajw38y3bt06jR07Vrt27VK9evX09NNPW+twmjt3rl566SWrkL3yyisKDQ297I3PysqSn5+fMjMzr/jQwUZPJRY4/adpkVe0PAAoD+z4/C2LrmVdkqhNAHAxdtamIoWssoaQBQDuQcgqGCELANzHztp0Vb+TBQAAAABwRcgCAAAAABsRsgAAAADARoQsAAAAALARIQsAAAAAbETIAgAAAAAbEbIAAAAAwEaELAAAAACwESELAAAAAGxEyAIAAAAAG1VwdwcAAEDxaPRUYoHTf5oWWcw9AYCyjT1ZAAAAAGAj9mRdI3xbCAAAAJRP7MkCAAAAABsRsgAAAADARoQsAAAAALARIQsAAAAAbETIAgAAAAAbEbIAAAAAwEaELAAAAACwESELAAAAAGxEyAIAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARoQsAAAAALARIQsAAAAAbETIAgAAAAAbEbIAAAAAwEaELAAAAACwESELAAAAAGxEyAIAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwBQqn399de66667VLduXXl4eOiTTz5xmW+MUVxcnOrUqaNKlSopPDxce/fudWlz9OhRDRkyRA6HQ/7+/hoxYoROnDjh0mb79u269dZb5evrq/r162v69On5+rJ06VI1b95cvr6+at26tT7//HPbtxcAUPIVOWRRzAAAJcnJkyfVtm1bxcfHFzh/+vTpeuWVVzR//nxt3rxZVapUUUREhE6fPm21GTJkiHbu3KmkpCStWLFCX3/9tUaOHGnNz8rKUs+ePdWwYUOlpKTopZde0uTJk/XGG29YbTZu3KjBgwdrxIgR2rZtm/r27au+ffvq+++/v3YbDwAokYocsihmAICSpHfv3nruued0zz335JtnjNHs2bM1ceJE9enTR23atNF7772ngwcPWl8S/vDDD1q5cqXeeusthYaGqkuXLnr11Ve1aNEiHTx4UJL04YcfKicnR++8845uvPFGDRo0SI899phmzpxprWvOnDnq1auXxo0bpxYtWujZZ59Vhw4dNHfu3GIZBwBAyVHkkEUxAwCUFvv371d6errCw8OtaX5+fgoNDVVycrIkKTk5Wf7+/urYsaPVJjw8XJ6entq8ebPVpmvXrvL29rbaREREaM+ePfrjjz+sNuevx9nGuZ6CZGdnKysry+UGACj9bD0ni2IGAChJ0tPTJUmBgYEu0wMDA6156enpCggIcJlfoUIF1ahRw6VNQcs4fx2FtXHOL8jUqVPl5+dn3erXr1/UTQQAlEC2hiyKGQAAl2/ChAnKzMy0bgcOHHB3lwAANihXVxekmAFA+RIUFCRJysjIcJmekZFhzQsKCtLhw4dd5p89e1ZHjx51aVPQMs5fR2FtnPML4uPjI4fD4XIDAJR+toYsihkAoCQJDg5WUFCQVq9ebU3LysrS5s2bFRYWJkkKCwvTsWPHlJKSYrVZs2aN8vLyFBoaarX5+uuvdebMGatNUlKSmjVrpurVq1ttzl+Ps41zPQCA8sPWkEUxAwAUtxMnTig1NVWpqamSzp0fnJqaqrS0NHl4eGjMmDF67rnn9I9//EM7duzQAw88oLp166pv376SpBYtWqhXr156+OGHtWXLFm3YsEExMTEaNGiQ6tatK0m677775O3trREjRmjnzp1avHix5syZo9jYWKsfjz/+uFauXKkZM2Zo9+7dmjx5sr777jvFxMQU95AAANysyCGLYgYAKEm+++47tW/fXu3bt5ckxcbGqn379oqLi5MkPfnkkxo9erRGjhypm266SSdOnNDKlSvl6+trLePDDz9U8+bN1aNHD91xxx3q0qWLy8+G+Pn56csvv9T+/fsVEhKiJ554QnFxcS4/P3LzzTdr4cKFeuONN9S2bVstW7ZMn3zyiVq1alVMIwEAKCk8jDGmKA9Yt26dbr/99nzTo6KilJCQIGOMJk2apDfeeEPHjh1Tly5dNG/ePN1www1W26NHjyomJkafffaZPD091b9/f73yyiuqWrWq1Wb79u2Kjo7Wt99+q1q1amn06NEaP368yzqXLl2qiRMn6qefflLTpk01ffp03XHHHZe9LVlZWfLz81NmZuYVHzrY6KnEIrX/aVrkFa0HAMoSOz5/yyJ31CWJ2gQAkr21qcghqywhZAGAexCyCkbIAgD3sbM2laurCwIAAADAtVbB3R0AAADudbG9X+zlAoCiY08WAAAAANiIPVnFjG8LAQAAgLKNPVkAAAAAYCNCFgAAAADYiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQhYAAAAA2IiQBQAAAAA2ImQBAAAAgI0IWQAAAABgI0IWAAAAANiIkAUAAAAANiJkAQAAAICNCFkAAAAAYCNCFgAAAADYiJAFAAAAADaq4O4O4L8aPZVY4PSfpkUWc08AADiH2gQARceeLAAAAACwESELAAAAAGxEyAIAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARvwYMQAAKDJ+pBgACkfIKgUKK2QSxQwAAAAoaThcEAAAAABsRMgCAAAAABsRsgAAAADARpyTVcpx4jEAoCThPGIAYE8WAAAAANiKkAUAAAAANir1hwvGx8frpZdeUnp6utq2batXX31VnTp1cne33I7DCAHAfahNBaM2ASgvSnXIWrx4sWJjYzV//nyFhoZq9uzZioiI0J49exQQEODu7gEAyiFqU9FxHheAssbDGGPc3YkrFRoaqptuuklz586VJOXl5al+/foaPXq0nnrqqUs+PisrS35+fsrMzJTD4biiPlysMJQ2FDIAxcWOz9+S6mpqE3UpP2oTgOJiZ20qtXuycnJylJKSogkTJljTPD09FR4eruTk5AIfk52drezsbOt+ZmampHMDeqXysv+84seWNA3GLrVtWd9PibBtWQDKHufnbin+nq9ARa1N1KVLozYBKC521qZSG7KOHDmi3NxcBQYGukwPDAzU7t27C3zM1KlTNWXKlHzT69evf036WJ75zXZ3DwCUBsePH5efn5+7u2GbotYm6lLxojYBuBx21KZSG7KuxIQJExQbG2vdz8vL09GjR1WzZk15eHgUeXlZWVmqX7++Dhw4UOYOd7lcjAFjIDEGEmMgFW0MjDE6fvy46tatW0y9K5moS9cOY3EO43AO4/BfjMU5BY2DnbWp1IasWrVqycvLSxkZGS7TMzIyFBQUVOBjfHx85OPj4zLN39//qvvicDjK9YtUYgwkxkBiDCTGQLr8MShLe7CcilqbqEvXHmNxDuNwDuPwX4zFOReOg121qdT+Tpa3t7dCQkK0evVqa1peXp5Wr16tsLAwN/YMAFBeUZsAAFIp3pMlSbGxsYqKilLHjh3VqVMnzZ49WydPntTw4cPd3TUAQDlFbQIAlOqQNXDgQP3222+Ki4tTenq62rVrp5UrV+Y74fha8fHx0aRJk/Id6lGeMAaMgcQYSIyBxBg4ubM28Rz8F2NxDuNwDuPwX4zFOdd6HEr172QBAAAAQElTas/JAgAAAICSiJAFAAAAADYiZAEAAACAjQhZAAAAAGAjQtYVio+PV6NGjeTr66vQ0FBt2bLF3V26ZiZPniwPDw+XW/Pmza35p0+fVnR0tGrWrKmqVauqf//++X6Is7T5+uuvddddd6lu3bry8PDQJ5984jLfGKO4uDjVqVNHlSpVUnh4uPbu3evS5ujRoxoyZIgcDof8/f01YsQInThxohi34upcagyGDRuW73XRq1cvlzaleQymTp2qm266SdWqVVNAQID69u2rPXv2uLS5nNd+WlqaIiMjVblyZQUEBGjcuHE6e/ZscW7KFbucMejWrVu+18Ejjzzi0qY0j0FpU55qk1Q+65NEjTpfea9VTtSsc0pS3SJkXYHFixcrNjZWkyZN0tatW9W2bVtFRETo8OHD7u7aNXPjjTfq0KFD1u2bb76x5o0dO1afffaZli5dqvXr1+vgwYPq16+fG3t79U6ePKm2bdsqPj6+wPnTp0/XK6+8ovnz52vz5s2qUqWKIiIidPr0aavNkCFDtHPnTiUlJWnFihX6+uuvNXLkyOLahKt2qTGQpF69erm8Lj766COX+aV5DNavX6/o6Ght2rRJSUlJOnPmjHr27KmTJ09abS712s/NzVVkZKRycnK0ceNGvfvuu0pISFBcXJw7NqnILmcMJOnhhx92eR1Mnz7dmlfax6A0KY+1SSp/9UmiRp2vvNcqJ2rWOSWqbhkUWadOnUx0dLR1Pzc319StW9dMnTrVjb26diZNmmTatm1b4Lxjx46ZihUrmqVLl1rTfvjhByPJJCcnF1MPry1JZvny5db9vLw8ExQUZF566SVr2rFjx4yPj4/56KOPjDHG7Nq1y0gy3377rdXmiy++MB4eHubXX38ttr7b5cIxMMaYqKgo06dPn0IfU9bG4PDhw0aSWb9+vTHm8l77n3/+ufH09DTp6elWm9dee804HA6TnZ1dvBtggwvHwBhjbrvtNvP4448X+piyNgYlWXmrTcZQn4yhRp2PWvVf1Kxz3Fm32JNVRDk5OUpJSVF4eLg1zdPTU+Hh4UpOTnZjz66tvXv3qm7durr++us1ZMgQpaWlSZJSUlJ05swZl/Fo3ry5GjRoUGbHY//+/UpPT3fZZj8/P4WGhlrbnJycLH9/f3Xs2NFqEx4eLk9PT23evLnY+3ytrFu3TgEBAWrWrJlGjRql33//3ZpX1sYgMzNTklSjRg1Jl/faT05OVuvWrV1+hDYiIkJZWVnauXNnMfbeHheOgdOHH36oWrVqqVWrVpowYYL+/PNPa15ZG4OSqrzWJon6dCFqVH7lqVY5UbPOcWfdqnCVfS93jhw5otzcXJeBl6TAwEDt3r3bTb26tkJDQ5WQkKBmzZrp0KFDmjJlim699VZ9//33Sk9Pl7e3t/z9/V0eExgYqPT0dPd0+BpzbldBrwHnvPT0dAUEBLjMr1ChgmrUqFFmxqVXr17q16+fgoOD9eOPP+p///d/1bt3byUnJ8vLy6tMjUFeXp7GjBmjW265Ra1atZKky3rtp6enF/g6cc4rTQoaA0m677771LBhQ9WtW1fbt2/X+PHjtWfPHn388ceSytYYlGTlsTZJ1KeCUKNclada5UTNOsfddYuQhUvq3bu39f82bdooNDRUDRs21JIlS1SpUiU39gzuNGjQIOv/rVu3Vps2bdS4cWOtW7dOPXr0cGPP7BcdHa3vv//e5VyP8qawMTj/vIXWrVurTp066tGjh3788Uc1bty4uLuJcob6hEspT7XKiZp1jrvrFocLFlGtWrXk5eWV72osGRkZCgoKclOvipe/v79uuOEG7du3T0FBQcrJydGxY8dc2pTl8XBu18VeA0FBQflONj979qyOHj1aZsfl+uuvV61atbRv3z5JZWcMYmJitGLFCq1du1b16tWzpl/Oaz8oKKjA14lzXmlR2BgUJDQ0VJJcXgdlYQxKOmrTOeW9PknUqEspq7XKiZp1TkmoW4SsIvL29lZISIhWr15tTcvLy9Pq1asVFhbmxp4VnxMnTujHH39UnTp1FBISoooVK7qMx549e5SWllZmxyM4OFhBQUEu25yVlaXNmzdb2xwWFqZjx44pJSXFarNmzRrl5eVZb+ay5pdfftHvv/+uOnXqSCr9Y2CMUUxMjJYvX641a9YoODjYZf7lvPbDwsK0Y8cOlwKelJQkh8Ohli1bFs+GXIVLjUFBUlNTJcnldVCax6C0oDadU97rk0SNupSyVqucqFnnlKi6VeTLdMAsWrTI+Pj4mISEBLNr1y4zcuRI4+/v73IVkrLkiSeeMOvWrTP79+83GzZsMOHh4aZWrVrm8OHDxhhjHnnkEdOgQQOzZs0a891335mwsDATFhbm5l5fnePHj5tt27aZbdu2GUlm5syZZtu2bebnn382xhgzbdo04+/vbz799FOzfft206dPHxMcHGxOnTplLaNXr16mffv2ZvPmzeabb74xTZs2NYMHD3bXJhXZxcbg+PHj5m9/+5tJTk42+/fvN1999ZXp0KGDadq0qTl9+rS1jNI8BqNGjTJ+fn5m3bp15tChQ9btzz//tNpc6rV/9uxZ06pVK9OzZ0+TmppqVq5caWrXrm0mTJjgjk0qskuNwb59+8wzzzxjvvvuO7N//37z6aefmuuvv9507drVWkZpH4PSpLzVJmPKZ30yhhp1vvJeq5yoWeeUpLpFyLpCr776qmnQoIHx9vY2nTp1Mps2bXJ3l66ZgQMHmjp16hhvb29z3XXXmYEDB5p9+/ZZ80+dOmUeffRRU716dVO5cmVzzz33mEOHDrmxx1dv7dq1RlK+W1RUlDHm3CVyn376aRMYGGh8fHxMjx49zJ49e1yW8fvvv5vBgwebqlWrGofDYYYPH26OHz/uhq25Mhcbgz///NP07NnT1K5d21SsWNE0bNjQPPzww/n+mCvNY1DQtksyCxYssNpczmv/p59+Mr179zaVKlUytWrVMk888YQ5c+ZMMW/NlbnUGKSlpZmuXbuaGjVqGB8fH9OkSRMzbtw4k5mZ6bKc0jwGpU15qk3GlM/6ZAw16nzlvVY5UbPOKUl1y+P/dwgAAAAAYAPOyQIAAAAAGxGyAAAAAMBGhCwAAAAAsBEhCwAAAABsRMgCAAAAABsRsgAAAADARoQsAAAAALARIQsAAAAAbETIAkoYDw8PffLJJ5fdfvLkyWrXrt1F2wwbNkx9+/a9qn4BAMovahNQNIQsoIjuuusu9erVq8B5//znP+Xh4aHt27df8fIPHTqk3r17X/Hjr4UzZ85o/Pjxat26tapUqaK6devqgQce0MGDB93dNQCAymdtks6FuebNm6tKlSqqXr26wsPDtXnzZnd3CyBkAUU1YsQIJSUl6Zdffsk3b8GCBerYsaPatGlT5OXm5ORIkoKCguTj43PV/bTTn3/+qa1bt+rpp5/W1q1b9fHHH2vPnj26++673d01AIDKZ22SpBtuuEFz587Vjh079M0336hRo0bq2bOnfvvtN3d3DeUcIQsoojvvvFO1a9dWQkKCy/QTJ05o6dKlGjFihH7//XcNHjxY1113nSpXrqzWrVvro48+cmnfrVs3xcTEaMyYMapVq5YiIiIk5T8kY/z48brhhhtUuXJlXX/99Xr66ad15syZfP16/fXXVb9+fVWuXFkDBgxQZmZmoduQl5enqVOnKjg4WJUqVVLbtm21bNmyQtv7+fkpKSlJAwYMULNmzdS5c2fNnTtXKSkpSktLu4xRAwBcS+WxNknSfffdp/DwcF1//fW68cYbNXPmTGVlZV3VXjvADoQsoIgqVKigBx54QAkJCTLGWNOXLl2q3NxcDR48WKdPn1ZISIgSExP1/fffa+TIkRo6dKi2bNnisqx3331X3t7e2rBhg+bPn1/g+qpVq6aEhATt2rVLc+bM0ZtvvqlZs2a5tNm3b5+WLFmizz77TCtXrtS2bdv06KOPFroNU6dO1Xvvvaf58+dr586dGjt2rO6//36tX7/+sschMzNTHh4e8vf3v+zHAACuDWrTub1ub7zxhvz8/NS2bdvLegxwzRgARfbDDz8YSWbt2rXWtFtvvdXcf//9hT4mMjLSPPHEE9b92267zbRv3z5fO0lm+fLlhS7npZdeMiEhIdb9SZMmGS8vL/PLL79Y07744gvj6elpDh06ZIwxJioqyvTp08cYY8zp06dN5cqVzcaNG12WO2LECDN48OBC13u+U6dOmQ4dOpj77rvvstoDAK698lqbPvvsM1OlShXj4eFh6tata7Zs2XLR9kBxqODeiAeUTs2bN9fNN9+sd955R926ddO+ffv0z3/+U88884wkKTc3Vy+88IKWLFmiX3/9VTk5OcrOzlblypVdlhMSEnLJdS1evFivvPKKfvzxR504cUJnz56Vw+FwadOgQQNdd9111v2wsDDl5eVpz549CgoKcmm7b98+/fnnn/rLX/7iMj0nJ0ft27e/ZH/OnDmjAQMGyBij11577ZLtAQDFo7zWpttvv12pqak6cuSI3nzzTQ0YMECbN29WQEDAJbcDuFYIWcAVGjFihEaPHq34+HgtWLBAjRs31m233SZJeumllzRnzhzNnj3buiLfmDFjrBOInapUqXLRdSQnJ2vIkCGaMmWKIiIi5Ofnp0WLFmnGjBlX3O8TJ05IkhITE12Kn6RLntTsDFg///yz1qxZk6+gAgDcqzzWpipVqqhJkyZq0qSJOnfurKZNm+rtt9/WhAkTrrg/wNUiZAFXaMCAAXr88ce1cOFCvffeexo1apQ8PDwkSRs2bFCfPn10//33Szp3Mu+///1vtWzZskjr2Lhxoxo2bKi///3v1rSff/45X7u0tDQdPHhQdevWlSRt2rRJnp6eatasWb62LVu2lI+Pj9LS0qzCezmcAWvv3r1au3atatasWaRtAQBce+WtNhUkLy9P2dnZV7UM4GoRsoArVLVqVQ0cOFATJkxQVlaWhg0bZs1r2rSpli1bpo0bN6p69eqaOXOmMjIyilzImjZtqrS0NC1atEg33XSTEhMTtXz58nztfH19FRUVpZdffllZWVl67LHHNGDAgHyHY0jnTlb+29/+prFjxyovL09dunRRZmamNmzYIIfDoaioqHyPOXPmjO69915t3bpVK1asUG5urtLT0yVJNWrUkLe3d5G2CwBwbZSn2nTy5Ek9//zzuvvuu1WnTh0dOXJE8fHx+vXXX/XXv/61SNsE2I2rCwJXYcSIEfrjjz8UERFhfVMnSRMnTlSHDh0UERGhbt26KSgo6Ip+1f7uu+/W2LFjFRPz/9q7+6Cq7juP4x8evPh4wUduqBjZ1UapChUVb9tNTaVeE8zG1UzUtYYoWUeLrkCaKBvFJs0UR7ONGp8ym9lgd0J9yI62SsWyqOQBfAKZoBa32THBiBdMDFwlCsg9+0eG09yCiReO4sP7NXNnwu/3Pb/zO79x0E/Oub+zSLGxsSoqKtKKFSta1Q0ZMkTTpk3TY489pkmTJmnUqFHatGnTDcf91a9+pRUrVigrK0vDhw/X5MmTlZubq6ioqDbrz58/rz/84Q/69NNPFRsbqwceeMD8FBUV+X1dAIBb5375uykoKEgVFRWaPn26vvvd7+rxxx/X559/rvfee0/f+973/L4uwEoBhvG1fT4BAAAAAB3CnSwAAAAAsBAhCwAAAAAsdF9vfOH1elVVVaVevXqZO+8AAG49wzB0+fJlRUREKDCQ/98HALi33Nchq6qqSpGRkZ09DQC4b507d04DBw7s7GkAAGCp+zpk9erVS9JXf8nzUlUAuH08Ho8iIyPN38MAANxLOhSyVq1apYyMDC1ZskRr166VJF27dk3PPfectm3bpoaGBrlcLm3atEnh4eHmcZWVlVq4cKEOHjyonj17KikpSVlZWQoO/ut0Dh06pPT0dJ06dUqRkZFavny5z7seJGnjxo1as2aN3G63YmJi9Prrr2vcuHE3Pf+WRwTtdjshCwA6AY9qAwDuRe1+EP7YsWN64403NGrUKJ/2tLQ07dmzRzt37lRhYaGqqqo0bdo0s7+5uVmJiYlqbGxUUVGRtm7dquzsbGVmZpo1Z8+eVWJioh555BGVlZUpNTVVzz77rPbv32/WbN++Xenp6Vq5cqVKS0sVExMjl8ulmpqa9l4SAAAAAHRYu96TdeXKFY0ePVqbNm3SK6+8otjYWK1du1Z1dXXq37+/cnJy9OSTT0qSKioqNHz4cBUXF2v8+PHat2+fpkyZoqqqKvPu1pYtW7R06VJdvHhRNptNS5cuVW5urk6ePGmec+bMmaqtrVVeXp4kKT4+XmPHjtWGDRskfbWJRWRkpBYvXqxly5bd1HV4PB6Fhoaqrq6OO1kAcBvx+xcAcC9r152slJQUJSYmKiEhwae9pKRETU1NPu3Dhg3ToEGDVFxcLEkqLi7WyJEjfR4fdLlc8ng8OnXqlFnzt2O7XC5zjMbGRpWUlPjUBAYGKiEhwaxpS0NDgzwej88HAAAAAKzk93eytm3bptLSUh07dqxVn9vtls1mU1hYmE97eHi43G63WfP1gNXS39L3TTUej0dXr17VF198oebm5jZrKioqbjj3rKwsvfTSSzd3oQAAAADQDn7dyTp37pyWLFmit99+W127dr1Vc7plMjIyVFdXZ37OnTvX2VMCAAAAcI/xK2SVlJSopqZGo0ePVnBwsIKDg1VYWKj169crODhY4eHhamxsVG1trc9x1dXVcjgckiSHw6Hq6upW/S1931Rjt9vVrVs39evXT0FBQW3WtIzRlpCQEHMnQXYUBAAAAHAr+BWyJk6cqPLycpWVlZmfMWPGaPbs2eZ/d+nSRQUFBeYxZ86cUWVlpZxOpyTJ6XSqvLzcZxfA/Px82e12RUdHmzVfH6OlpmUMm82muLg4nxqv16uCggKzBgAAAAA6g1/fyerVq5dGjBjh09ajRw/17dvXbE9OTlZ6err69Okju92uxYsXy+l0avz48ZKkSZMmKTo6WnPmzNHq1avldru1fPlypaSkKCQkRJK0YMECbdiwQS+88ILmzZunAwcOaMeOHcrNzTXPm56erqSkJI0ZM0bjxo3T2rVrVV9fr7lz53ZoQQAAAACgIzr0MuK2vPbaawoMDNT06dN9XkbcIigoSHv37tXChQvldDrVo0cPJSUl6eWXXzZroqKilJubq7S0NK1bt04DBw7Um2++KZfLZdbMmDFDFy9eVGZmptxut2JjY5WXl9dqM4xbbfCy3DbbP16VeFvnAQAAAODO0K73ZN0rrHhPCyELAPzHe7IAAPeydr0nCwAAAADQNkIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhfwKWZs3b9aoUaNkt9tlt9vldDq1b98+s//atWtKSUlR37591bNnT02fPl3V1dU+Y1RWVioxMVHdu3fXgAED9Pzzz+v69es+NYcOHdLo0aMVEhKiIUOGKDs7u9VcNm7cqMGDB6tr166Kj4/X0aNH/bkUAAAAALgl/ApZAwcO1KpVq1RSUqLjx4/rJz/5iZ544gmdOnVKkpSWlqY9e/Zo586dKiwsVFVVlaZNm2Ye39zcrMTERDU2NqqoqEhbt25Vdna2MjMzzZqzZ88qMTFRjzzyiMrKypSamqpnn31W+/fvN2u2b9+u9PR0rVy5UqWlpYqJiZHL5VJNTU1H1wMAAAAAOiTAMAyjIwP06dNHa9as0ZNPPqn+/fsrJydHTz75pCSpoqJCw4cPV3FxscaPH699+/ZpypQpqqqqUnh4uCRpy5YtWrp0qS5evCibzaalS5cqNzdXJ0+eNM8xc+ZM1dbWKi8vT5IUHx+vsWPHasOGDZIkr9eryMhILV68WMuWLbvpuXs8HoWGhqqurk52u71d1z94WW6b7R+vSmzXeABwP7Di9y8AAHeqdn8nq7m5Wdu2bVN9fb2cTqdKSkrU1NSkhIQEs2bYsGEaNGiQiouLJUnFxcUaOXKkGbAkyeVyyePxmHfDiouLfcZoqWkZo7GxUSUlJT41gYGBSkhIMGtupKGhQR6Px+cDAAAAAFbyO2SVl5erZ8+eCgkJ0YIFC7Rr1y5FR0fL7XbLZrMpLCzMpz48PFxut1uS5Ha7fQJWS39L3zfVeDweXb16VZ999pmam5vbrGkZ40aysrIUGhpqfiIjI/29fAAAAAD4Rn6HrIceekhlZWU6cuSIFi5cqKSkJJ0+ffpWzM1yGRkZqqurMz/nzp3r7CkBAAAAuMcE+3uAzWbTkCFDJElxcXE6duyY1q1bpxkzZqixsVG1tbU+d7Oqq6vlcDgkSQ6Ho9UugC27D3695m93JKyurpbdble3bt0UFBSkoKCgNmtaxriRkJAQhYSE+HvJAAAAAHDTOvyeLK/Xq4aGBsXFxalLly4qKCgw+86cOaPKyko5nU5JktPpVHl5uc8ugPn5+bLb7YqOjjZrvj5GS03LGDabTXFxcT41Xq9XBQUFZg0AAAAAdBa/7mRlZGTo0Ucf1aBBg3T58mXl5OTo0KFD2r9/v0JDQ5WcnKz09HT16dNHdrtdixcvltPp1Pjx4yVJkyZNUnR0tObMmaPVq1fL7XZr+fLlSklJMe8wLViwQBs2bNALL7ygefPm6cCBA9qxY4dyc/+6i196erqSkpI0ZswYjRs3TmvXrlV9fb3mzp1r4dIAAAAAgP/8Clk1NTV6+umndeHCBYWGhmrUqFHav3+/fvrTn0qSXnvtNQUGBmr69OlqaGiQy+XSpk2bzOODgoK0d+9eLVy4UE6nUz169FBSUpJefvllsyYqKkq5ublKS0vTunXrNHDgQL355ptyuVxmzYwZM3Tx4kVlZmbK7XYrNjZWeXl5rTbDAAAAAIDbrcPvybqb8Z4sAOgcvCcLAHAv6/B3sgAAAAAAf0XIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsJBfISsrK0tjx45Vr169NGDAAE2dOlVnzpzxqbl27ZpSUlLUt29f9ezZU9OnT1d1dbVPTWVlpRITE9W9e3cNGDBAzz//vK5fv+5Tc+jQIY0ePVohISEaMmSIsrOzW81n48aNGjx4sLp27ar4+HgdPXrUn8sBAAAAAMv5FbIKCwuVkpKiw4cPKz8/X01NTZo0aZLq6+vNmrS0NO3Zs0c7d+5UYWGhqqqqNG3aNLO/ublZiYmJamxsVFFRkbZu3ars7GxlZmaaNWfPnlViYqIeeeQRlZWVKTU1Vc8++6z2799v1mzfvl3p6elauXKlSktLFRMTI5fLpZqamo6sBwAAAAB0SIBhGEZ7D7548aIGDBigwsJCPfzww6qrq1P//v2Vk5OjJ598UpJUUVGh4cOHq7i4WOPHj9e+ffs0ZcoUVVVVKTw8XJK0ZcsWLV26VBcvXpTNZtPSpUuVm5urkydPmueaOXOmamtrlZeXJ0mKj4/X2LFjtWHDBkmS1+tVZGSkFi9erGXLlt3U/D0ej0JDQ1VXVye73d6uNRi8LLfN9o9XJbZrPAC4H1jx+xcAgDtVh76TVVdXJ0nq06ePJKmkpERNTU1KSEgwa4YNG6ZBgwapuLhYklRcXKyRI0eaAUuSXC6XPB6PTp06ZdZ8fYyWmpYxGhsbVVJS4lMTGBiohIQEswYAAAAAOkNwew/0er1KTU3VD3/4Q40YMUKS5Ha7ZbPZFBYW5lMbHh4ut9tt1nw9YLX0t/R9U43H49HVq1f1xRdfqLm5uc2aioqKG865oaFBDQ0N5s8ej8ePKwYAAACAb9fukJWSkqKTJ0/q/ffft3I+t1RWVpZeeuml23IuHiMEAAAA7k/telxw0aJF2rt3rw4ePKiBAwea7Q6HQ42NjaqtrfWpr66ulsPhMGv+drfBlp+/rcZut6tbt27q16+fgoKC2qxpGaMtGRkZqqurMz/nzp3z78IBAAAA4Fv4FbIMw9CiRYu0a9cuHThwQFFRUT79cXFx6tKliwoKCsy2M2fOqLKyUk6nU5LkdDpVXl7uswtgfn6+7Ha7oqOjzZqvj9FS0zKGzWZTXFycT43X61VBQYFZ05aQkBDZ7XafDwAAAABYya/HBVNSUpSTk6Pf//736tWrl/kdqtDQUHXr1k2hoaFKTk5Wenq6+vTpI7vdrsWLF8vpdGr8+PGSpEmTJik6Olpz5szR6tWr5Xa7tXz5cqWkpCgkJESStGDBAm3YsEEvvPCC5s2bpwMHDmjHjh3Kzf3rI3jp6elKSkrSmDFjNG7cOK1du1b19fWaO3euVWsDAAAAAH7zK2Rt3rxZkjRhwgSf9rfeekvPPPOMJOm1115TYGCgpk+froaGBrlcLm3atMmsDQoK0t69e7Vw4UI5nU716NFDSUlJevnll82aqKgo5ebmKi0tTevWrdPAgQP15ptvyuVymTUzZszQxYsXlZmZKbfbrdjYWOXl5bXaDAMAAAAAbqcOvSfrbncr35N1I2x8AQC8JwsAcG/r0HuyAAAAAAC+CFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAW8jtkvfvuu3r88ccVERGhgIAA7d6926ffMAxlZmbqgQceULdu3ZSQkKC//OUvPjWXLl3S7NmzZbfbFRYWpuTkZF25csWn5sMPP9Q//MM/qGvXroqMjNTq1atbzWXnzp0aNmyYunbtqpEjR+qPf/yjv5cDAAAAAJYK9veA+vp6xcTEaN68eZo2bVqr/tWrV2v9+vXaunWroqKitGLFCrlcLp0+fVpdu3aVJM2ePVsXLlxQfn6+mpqaNHfuXM2fP185OTmSJI/Ho0mTJikhIUFbtmxReXm55s2bp7CwMM2fP1+SVFRUpFmzZikrK0tTpkxRTk6Opk6dqtLSUo0YMaIja3JLDV6We8O+j1cl3saZAAAAALgVAgzDMNp9cECAdu3apalTp0r66i5WRESEnnvuOf3iF7+QJNXV1Sk8PFzZ2dmaOXOm/vznPys6OlrHjh3TmDFjJEl5eXl67LHH9OmnnyoiIkKbN2/Wiy++KLfbLZvNJklatmyZdu/erYqKCknSjBkzVF9fr71795rzGT9+vGJjY7Vly5abmr/H41FoaKjq6upkt9vbtQbfFJr8RcgCcL+w4vcvAAB3Kku/k3X27Fm53W4lJCSYbaGhoYqPj1dxcbEkqbi4WGFhYWbAkqSEhAQFBgbqyJEjZs3DDz9sBixJcrlcOnPmjL744guz5uvnaalpOQ8AAAAAdAa/Hxf8Jm63W5IUHh7u0x4eHm72ud1uDRgwwHcSwcHq06ePT01UVFSrMVr6evfuLbfb/Y3naUtDQ4MaGhrMnz0ejz+XBwAAAADf6r7aXTArK0uhoaHmJzIysrOnBAAAAOAeY2nIcjgckqTq6mqf9urqarPP4XCopqbGp//69eu6dOmST01bY3z9HDeqaelvS0ZGhurq6szPuXPn/L1EAAAAAPhGloasqKgoORwOFRQUmG0ej0dHjhyR0+mUJDmdTtXW1qqkpMSsOXDggLxer+Lj482ad999V01NTWZNfn6+HnroIfXu3dus+fp5WmpaztOWkJAQ2e12nw8AAAAAWMnvkHXlyhWVlZWprKxM0lebXZSVlamyslIBAQFKTU3VK6+8oj/84Q8qLy/X008/rYiICHMHwuHDh2vy5Mn6l3/5Fx09elQffPCBFi1apJkzZyoiIkKS9M///M+y2WxKTk7WqVOntH37dq1bt07p6enmPJYsWaK8vDz9+7//uyoqKvTLX/5Sx48f16JFizq+KgAAAADQTn5vfHH8+HE98sgj5s8twScpKUnZ2dl64YUXVF9fr/nz56u2tlY/+tGPlJeXZ74jS5LefvttLVq0SBMnTlRgYKCmT5+u9evXm/2hoaH605/+pJSUFMXFxalfv37KzMw035ElST/4wQ+Uk5Oj5cuX69/+7d80dOhQ7d69+45+RxYAAACAe1+H3pN1t+M9WQDQOXhPFgDgXnZf7S4IAAAAALcaIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsFBwZ08AfzV4WW6b7R+vSrzNMwEAAADQXtzJAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwELBnT0BfLvBy3Jv2PfxqsTbOBMAAAAA34Y7WQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCF2F7zL3WjnQXYdBAAAADoHd7IAAAAAwEKELAAAAACw0F3/uODGjRu1Zs0aud1uxcTE6PXXX9e4ceM6e1qdjscIAQAAgM5xV9/J2r59u9LT07Vy5UqVlpYqJiZGLpdLNTU1nT01AAAAAPepAMMwjM6eRHvFx8dr7Nix2rBhgyTJ6/UqMjJSixcv1rJly771eI/Ho9DQUNXV1clut7drDje6Y3Q34i4XgNvFit+/AADcqe7axwUbGxtVUlKijIwMsy0wMFAJCQkqLi5u85iGhgY1NDSYP9fV1Un66i/79vI2fNnuY+80g9J2dur5T77k6tTzA7h9Wn7v3sX/nw8AgBu6a0PWZ599pubmZoWHh/u0h4eHq6Kios1jsrKy9NJLL7Vqj4yMvCVzhH9C13b2DADcbpcvX1ZoaGhnTwMAAEvdtSGrPTIyMpSenm7+7PV6denSJfXt21cBAQF+j+fxeBQZGalz587xuEs7sH7tx9p1DOvXMVasn2EYunz5siIiIiyeHQAAne+uDVn9+vVTUFCQqqurfdqrq6vlcDjaPCYkJEQhISE+bWFhYR2ei91u5x9qHcD6tR9r1zGsX8d0dP24gwUAuFfdtbsL2mw2xcXFqaCgwGzzer0qKCiQ0+nsxJkBAAAAuJ/dtXeyJCk9PV1JSUkaM2aMxo0bp7Vr16q+vl5z587t7KkBAAAAuE/d1SFrxowZunjxojIzM+V2uxUbG6u8vLxWm2HcKiEhIVq5cmWrRxBxc1i/9mPtOob16xjWDwCAb3ZXvycLAAAAAO40d+13sgAAAADgTkTIAgAAAAALEbIAAAAAwEKELAAAAACwECGrnTZu3KjBgwera9euio+P19GjRzt7SneEd999V48//rgiIiIUEBCg3bt3+/QbhqHMzEw98MAD6tatmxISEvSXv/zFp+bSpUuaPXu27Ha7wsLClJycrCtXrtzGq+gcWVlZGjt2rHr16qUBAwZo6tSpOnPmjE/NtWvXlJKSor59+6pnz56aPn16qxdyV1ZWKjExUd27d9eAAQP0/PPP6/r167fzUjrF5s2bNWrUKPMFuU6nU/v27TP7WTv/rFq1SgEBAUpNTTXbWEMAAG4OIasdtm/frvT0dK1cuVKlpaWKiYmRy+VSTU1NZ0+t09XX1ysmJkYbN25ss3/16tVav369tmzZoiNHjqhHjx5yuVy6du2aWTN79mydOnVK+fn52rt3r959913Nnz//dl1CpyksLFRKSooOHz6s/Px8NTU1adKkSaqvrzdr0tLStGfPHu3cuVOFhYWqqqrStGnTzP7m5mYlJiaqsbFRRUVF2rp1q7Kzs5WZmdkZl3RbDRw4UKtWrVJJSYmOHz+un/zkJ3riiSd06tQpSaydP44dO6Y33nhDo0aN8mlnDQEAuEkG/DZu3DgjJSXF/Lm5udmIiIgwsrKyOnFWdx5Jxq5du8yfvV6v4XA4jDVr1phttbW1RkhIiPG73/3OMAzDOH36tCHJOHbsmFmzb98+IyAgwDh//vxtm/udoKamxpBkFBYWGobx1Vp16dLF2Llzp1nz5z//2ZBkFBcXG4ZhGH/84x+NwMBAw+12mzWbN2827Ha70dDQcHsv4A7Qu3dv480332Tt/HD58mVj6NChRn5+vvHjH//YWLJkiWEY/PkDAMAf3MnyU2Njo0pKSpSQkGC2BQYGKiEhQcXFxZ04szvf2bNn5Xa7fdYuNDRU8fHx5toVFxcrLCxMY8aMMWsSEhIUGBioI0eO3PY5d6a6ujpJUp8+fSRJJSUlampq8lm/YcOGadCgQT7rN3LkSJ8XcrtcLnk8HvOOzv2gublZ27ZtU319vZxOJ2vnh5SUFCUmJvqslcSfPwAA/BHc2RO423z22Wdqbm72+UeEJIWHh6uioqKTZnV3cLvdktTm2rX0ud1uDRgwwKc/ODhYffr0MWvuB16vV6mpqfrhD3+oESNGSPpqbWw2m8LCwnxq/3b92lrflr57XXl5uZxOp65du6aePXtq165dio6OVllZGWt3E7Zt26bS0lIdO3asVR9//gAAuHmELOAOlJKSopMnT+r999/v7KncVR566CGVlZWprq5O77zzjpKSklRYWNjZ07ornDt3TkuWLFF+fr66du3a2dMBAOCuxuOCfurXr5+CgoJa7ahVXV0th8PRSbO6O7SszzetncPhaLWByPXr13Xp0qX7Zn0XLVqkvXv36uDBgxo4cKDZ7nA41NjYqNraWp/6v12/tta3pe9eZ7PZNGTIEMXFxSkrK0sxMTFat24da3cTSkpKVFNTo9GjRys4OFjBwcEqLCzU+vXrFRwcrPDwcNYQAICbRMjyk81mU1xcnAoKCsw2r9ergoICOZ3OTpzZnS8qKkoOh8Nn7Twej44cOWKundPpVG1trUpKSsyaAwcOyOv1Kj4+/rbP+XYyDEOLFi3Srl27dODAAUVFRfn0x8XFqUuXLj7rd+bMGVVWVvqsX3l5uU9Qzc/Pl91uV3R09O25kDuI1+tVQ0MDa3cTJk6cqPLycpWVlZmfMWPGaPbs2eZ/s4YAANykzt554260bds2IyQkxMjOzjZOnz5tzJ8/3wgLC/PZUet+dfnyZePEiRPGiRMnDEnGb37zG+PEiRPGJ598YhiGYaxatcoICwszfv/73xsffvih8cQTTxhRUVHG1atXzTEmT55sfP/73zeOHDlivP/++8bQoUONWbNmddYl3TYLFy40QkNDjUOHDhkXLlwwP19++aVZs2DBAmPQoEHGgQMHjOPHjxtOp9NwOp1m//Xr140RI0YYkyZNMsrKyoy8vDyjf//+RkZGRmdc0m21bNkyo7Cw0Dh79qzx4YcfGsuWLTMCAgKMP/3pT4ZhsHbt8fXdBQ2DNQQA4GYRstrp9ddfNwYNGmTYbDZj3LhxxuHDhzt7SneEgwcPGpJafZKSkgzD+Gob9xUrVhjh4eFGSEiIMXHiROPMmTM+Y3z++efGrFmzjJ49exp2u92YO3eucfny5U64mturrXWTZLz11ltmzdWrV42f//znRu/evY3u3bsb//RP/2RcuHDBZ5yPP/7YePTRR41u3boZ/fr1M5577jmjqanpNl/N7Tdv3jzjwQcfNGw2m9G/f39j4sSJZsAyDNauPf42ZLGGAADcnADDMIzOuYcGAAAAAPcevpMFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWcIcJCAjQ7t27b7r+l7/8pWJjY7+x5plnntHUqVM7NC8AAADcHEIW4KfHH39ckydPbrPvvffeU0BAgD788MN2j3/hwgU9+uij7T7+dliwYIECAgK0du3azp4KAADAHYeQBfgpOTlZ+fn5+vTTT1v1vfXWWxozZoxGjRrl97iNjY2SJIfDoZCQkA7P81bZtWuXDh8+rIiIiM6eCgAAwB2JkAX4acqUKerfv7+ys7N92q9cuaKdO3cqOTlZn3/+uWbNmqXvfOc76t69u0aOHKnf/e53PvUTJkzQokWLlJqaqn79+snlcklq/bjg0qVL9d3vflfdu3fX3/3d32nFihVqampqNa833nhDkZGR6t69u5566inV1dXd8Bq8Xq+ysrIUFRWlbt26KSYmRu+88863Xvv58+e1ePFivf322+rSpcu31gMAANyPCFmAn4KDg/X0008rOztbhmGY7Tt37lRzc7NmzZqla9euKS4uTrm5uTp58qTmz5+vOXPm6OjRoz5jbd26VTabTR988IG2bNnS5vl69eql7OxsnT59WuvWrdN//Md/6LXXXvOp+eijj7Rjxw7t2bNHeXl5OnHihH7+85/f8BqysrL029/+Vlu2bNGpU6eUlpamn/3sZyosLLzhMV6vV3PmzNHzzz+v733vezezVAAAAPelAOPr/0oEcFMqKio0fPhwHTx4UBMmTJAkPfzww3rwwQf1X//1X20eM2XKFA0bNkyvvvqqpK/uZHk8HpWWlvrUBQQEaNeuXTfcqOLVV1/Vtm3bdPz4cUlfbXzxyiuv6JNPPtF3vvMdSVJeXp4SExN1/vx5ORwOPfPMM6qtrdXu3bvV0NCgPn366H/+53/kdDrNcZ999ll9+eWXysnJafO8WVlZOnjwoPbv36+AgAANHjxYqampSk1NvdllAwAAuC8Ed/YEgLvRsGHD9IMf/ED/+Z//qQkTJuijjz7Se++9p5dfflmS1NzcrF//+tfasWOHzp8/r8bGRjU0NKh79+4+48TFxX3rubZv367169fr//7v/3TlyhVdv35ddrvdp2bQoEFmwJIkp9Mpr9erM2fOyOFw+NR+9NFH+vLLL/XTn/7Up72xsVHf//7325xDSUmJ1q1bp9LSUgUEBHzrnAEAAO5nPC4ItFNycrL++7//W5cvX9Zbb72lv//7v9ePf/xjSdKaNWu0bt06LV26VAcPHlRZWZlcLpe5uUWLHj16fOM5iouLNXv2bD322GPau3evTpw4oRdffLHVOP64cuWKJCk3N1dlZWXm5/Tp0zf8XtZ7772nmpoaDRo0SMHBwQoODtYnn3yi5557ToMHD273XAAAAO5F3MkC2umpp57SkiVLlJOTo9/+9rdauHCheZfngw8+0BNPPKGf/exnkr76PtP//u//Kjo62q9zFBUV6cEHH9SLL75otn3yySet6iorK1VVVWXu+Hf48GEFBgbqoYcealUbHR2tkJAQVVZWmqHw28yZM0cJCQk+bS6XS3PmzNHcuXP9uSQAAIB7HiELaKeePXtqxowZysjIkMfj0TPPPGP2DR06VO+8846KiorUu3dv/eY3v1F1dbXfIWvo0KGqrKzUtm3bNHbsWOXm5mrXrl2t6rp27aqkpCS9+uqr8ng8+td//Vc99dRTrR4VlL7aSOMXv/iF0tLS5PV69aMf/Uh1dXX64IMPZLfblZSU1OqYvn37qm/fvj5tXbp0kcPhaDPIAQAA3M94XBDogOTkZH3xxRdyuVw+741avny5Ro8eLZfLpQkTJsjhcNxwI4tv8o//+I9KS0vTokWLFBsbq6KiIq1YsaJV3ZAhQzRt2jQ99thjmjRpkkaNGqVNmzbdcNxf/epXWrFihbKysjR8+HBNnjxZubm5ioqK8nuOAAAA8MXuggAAAABgIe5kAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFvp/2VaUo+xQ8gcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Note how we are only plotting train and not test here. \n",
        "# Plotting histograms of the input variables before z-score normalization\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.suptitle('Histograms of input variables before z-score normalization')\n",
        "for i in range(5):\n",
        "    plt.subplot(3, 2, i+1)\n",
        "    plt.hist(x_train[:, i].cpu(), bins=50) # Must be converted to cpu() for plotting.\n",
        "    plt.xlabel(f'Variable {i}')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "QrN95284vExM",
        "outputId": "522f5d2e-ba54-48aa-a34d-8ef03a6b62a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary statistics of input variables before z-score normalization\n",
            "tensor([[6.6927e-05, 3.5973e+01, 6.3298e+00, 6.1996e+00, 3.8339e+00],\n",
            "        [4.0428e-06, 2.5052e+02, 6.8724e+00, 3.8580e+00, 8.9550e+00],\n",
            "        [1.2382e-06, 2.4635e+02, 6.8743e+00, 3.8543e+00, 8.9745e+00],\n",
            "        [8.8250e-06, 2.4121e+02, 6.8453e+00, 3.8405e+00, 8.9339e+00],\n",
            "        [1.6427e-05, 4.0075e+02, 1.2120e+01, 8.2927e+00, 1.3523e+01]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# print('Summary statistics of input variables before z-score normalization')\n",
        "# print(torch.stack([torch.min(x_train, dim=0).values,\n",
        "#                 torch.max(x_train, dim=0).values,\n",
        "#                 torch.mean(x_train, dim=0),\n",
        "#                 torch.median(x_train, dim=0).values,\n",
        "#                 torch.std(x_train, dim=0)], dim=1))\n",
        "\n",
        "# Computing summary statistics of the input variables before and after z-score normalization\n",
        "print('Summary statistics of input variables before z-score normalization')\n",
        "print(torch.stack([torch.min(x_train, dim=0).values, torch.max(x_train, dim=0).values, torch.nanmean(x_train, dim=0), torch.median(x_train, dim=0).values, torch.std(x_train, dim=0)], dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTEmkR1SUZh7"
      },
      "source": [
        "Perform z-score normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "kqUmp1VVvExN"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "yPOv6DxhUZh7"
      },
      "outputs": [],
      "source": [
        "if ZSCORE_NORMALIZATION:\n",
        "    \n",
        "    # # Computing the median of each input variable from the training set using torch.nanmedian function\n",
        "    # D_median = torch.nanmedian(x_train[:, 0])\n",
        "    # Sx_median = torch.nanmedian(x_train[:, 1])\n",
        "    # Sy_median = torch.nanmedian(x_train[:, 2])\n",
        "    # Sz_median = torch.nanmedian(x_train[:, 3])\n",
        "    # tau_median = torch.nanmedian(x_train[:, 4])\n",
        "\n",
        "    # # Computing the standard deviation of each input variable from the training set using torch.std function with a boolean mask to ignore nan values\n",
        "    # D_std = torch.std(x_train[~torch.isnan(x_train[:, 0]), 0])\n",
        "    # Sx_std = torch.std(x_train[~torch.isnan(x_train[:, 1]), 1])\n",
        "    # Sy_std = torch.std(x_train[~torch.isnan(x_train[:, 2]), 2])\n",
        "    # Sz_std = torch.std(x_train[~torch.isnan(x_train[:, 3]), 3])\n",
        "    # tau_std = torch.std(x_train[~torch.isnan(x_train[:, 4]), 4])\n",
        "\n",
        "\n",
        "    # # Applying z-score normalization to both train and test sets using the statistics from the training set\n",
        "    # x_train[:, 0] = torch.sub(x_train[:, 0], D_median).div(D_std)\n",
        "    # x_train[:, 1] = torch.sub(x_train[:, 1], Sx_median).div(Sx_std)\n",
        "    # x_train[:, 2] = torch.sub(x_train[:, 2], Sy_median).div(Sy_std)\n",
        "    # x_train[:, 3] = torch.sub(x_train[:, 3], Sz_median).div(Sz_std)\n",
        "    # x_train[:, 4] = torch.sub(x_train[:, 4], tau_median).div(tau_std)\n",
        "\n",
        "    # x_test[:, 0] = torch.sub(x_test[:, 0], D_median).div(D_std)\n",
        "    # x_test[:, 1] = torch.sub(x_test[:, 1], Sx_median).div(Sx_std)\n",
        "    # x_test[:, 2] = torch.sub(x_test[:, 2], Sy_median).div(Sy_std)\n",
        "    # x_test[:, 3] = torch.sub(x_test[:, 3], Sz_median).div(Sz_std)\n",
        "    # x_test[:, 4] = torch.sub(x_test[:, 4], tau_median).div(tau_std)\n",
        "\n",
        "    # Computing the mean and standard deviation of each column\n",
        "    mean = x_train.mean(dim=0)\n",
        "    std = x_train.std(dim=0)\n",
        "\n",
        "    # Applying z-score normalization\n",
        "    x_train = (x_train - mean) / std\n",
        "    # Use the same mean and std from the training data as we don't want test data leakage.\n",
        "    x_test = (x_test - mean) / std\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "boC-8KmXvExN",
        "outputId": "cb6af4dc-1ed3-459c-dec5-5a5f0e8cea43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "6J7rG-OevExN",
        "outputId": "42bb4c75-85d0-472c-fad1-a1511061cfe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.3518, 10.5083, 10.1694,  ...,  4.4721,  1.6649, 10.0924],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([80000, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.3518,  5.5407,  6.2987,  0.5088,  5.6678],\n",
              "        [10.5083,  2.1281,  8.8768,  5.0672, 10.4496],\n",
              "        [10.1694, 24.6210,  8.6734, 17.3371, 28.7775],\n",
              "        ...,\n",
              "        [ 4.4721,  2.5686,  0.6514,  7.2552,  7.7801],\n",
              "        [ 1.6649,  3.8329,  2.9365,  2.0393,  5.2449],\n",
              "        [10.0924,  7.4824,  5.1795,  0.5879, 12.0876]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 9.4826,  2.1303,  3.8089,  0.1353,  2.8137],\n",
              "        [ 3.2086,  0.2304,  0.0765,  1.0786,  4.0821],\n",
              "        [ 1.0799,  5.0950,  4.3277,  4.3998,  7.4208],\n",
              "        ...,\n",
              "        [11.7645, 38.2826, 11.3023, 34.4865, 48.7155],\n",
              "        [ 9.2215,  1.3869,  4.5133,  2.2089,  6.8695],\n",
              "        [11.9479, 25.2658, 21.7815, 19.5978, 31.0534]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "x_train[:, 0]\n",
        "x_train.shape\n",
        "x_train\n",
        "x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmdr204ZvExO"
      },
      "source": [
        "Plotting the histograms of the input data after normalization if z-score normalization was performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "yE_qe_eLvExO"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"last_expr_or_assign\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "bHw7bNaRvExO"
      },
      "outputs": [],
      "source": [
        "if ZSCORE_NORMALIZATION: \n",
        "    # Note how we are only plotting train and not test here.\n",
        "    # Plotting histograms of the input variables after z-score normalization\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.suptitle('Histograms of input variables after z-score normalization')\n",
        "    for i in range(5):\n",
        "        plt.subplot(3, 2, i+1)\n",
        "        plt.hist(x_train[:, i].cpu(), bins=50) # Must be convertedhere to cpu() for plotting.\n",
        "        plt.xlabel(f'Variable {i}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "5_7RTKmuvExO"
      },
      "outputs": [],
      "source": [
        "if ZSCORE_NORMALIZATION:\n",
        "    # print('Summary statistics of input variables after z-score normalization')\n",
        "    # print(torch.stack([torch.min(x_train, dim=0).values,\n",
        "    #                 torch.max(x_train, dim=0).values,\n",
        "    #                 torch.mean(x_train, dim=0),\n",
        "    #                 torch.median(x_train, dim=0).values,\n",
        "    #                 torch.std(x_train, dim=0)], dim=1))\n",
        "    # Computing summary statistics of the input variables after z-score normalization\n",
        "    print('Summary statistics of input variables after z-score normalization')\n",
        "    print(torch.stack([torch.min(x_train, dim=0).values, torch.max(x_train, dim=0).values, torch.mean(x_train, dim=0), torch.median(x_train, dim=0).values, torch.std(x_train, dim=0)], dim=1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E96p_MsOUZh9",
        "outputId": "4b95bad0-8f3a-4364-eed1-008e0ce2a5e3"
      },
      "source": [
        "Checking if our output is always positive by plotting a histogram of y_train and y_test tensors "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "vhyJwr4nvExO",
        "outputId": "ef941489-f5f1-4696-ee06-f63eec522c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(y_train.cpu().numpy(), bins=20) # must be cpu here.\n",
        "plt.xlabel(\"y_train\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.yscale(\"log\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(y_test.cpu().numpy(), bins=20) # must be cpu here\n",
        "plt.xlabel(\"y_test\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.yscale(\"log\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "FEgjk--AUZh9"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2b9GecHUZh9"
      },
      "source": [
        "## Defining the neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Iv8HA-ZXUZh-"
      },
      "outputs": [],
      "source": [
        "# Defining a class for the network\n",
        "class Net(nn.Module):\n",
        "    \"\"\"A class for creating a network with a\n",
        "    variable number of hidden layers and units.\n",
        "\n",
        "    Attributes:\n",
        "        n_layers (int): The number of hidden layers in the network.\n",
        "        n_units (list): A list of integers representing the number of units in each hidden layer.\n",
        "        hidden_activation (torch.nn.Module): The activation function for the hidden layers.\n",
        "        output_activation (torch.nn.Module): The activation function for the output layer.\n",
        "        layers (torch.nn.ModuleList): A list of linear layers in the network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_layers, n_units, hidden_activation, output_activation):\n",
        "        \"\"\"Initializes the network with the given hyperparameters.\n",
        "\n",
        "        Args:\n",
        "            n_layers (int): The number of hidden layers in the network.\n",
        "            n_units (list): A list of integers representing the number of units in each hidden layer.\n",
        "            hidden_activation (torch.nn.Module): The activation function for the hidden layers.\n",
        "            output_activation (torch.nn.Module): The activation function for the output layer.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.n_units = n_units\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.output_activation = output_activation\n",
        "\n",
        "        # Creating a list of linear layers with different numbers of units for each layer\n",
        "        self.layers = nn.ModuleList([nn.Linear(5, n_units[0])])\n",
        "        for i in range(1, n_layers):\n",
        "            self.layers.append(nn.Linear(n_units[i - 1], n_units[i]))\n",
        "        self.layers.append(nn.Linear(n_units[-1], 1))\n",
        "\n",
        "        # Adding some assertions to check that the input arguments are valid\n",
        "        assert isinstance(n_layers, int) and n_layers > 0, \"n_layers must be a positive integer\"\n",
        "        assert isinstance(n_units, list) and len(n_units) == n_layers, \"n_units must be a list of length n_layers\"\n",
        "        assert all(isinstance(n, int) and n > 0 for n in n_units), \"n_units must contain positive integers\"\n",
        "        assert isinstance(hidden_activation, nn.Module), \"hidden_activation must be a torch.nn.Module\"\n",
        "        assert isinstance(output_activation, nn.Module), \"output_activation must be a torch.nn.Module\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Performs a forward pass on the input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor of shape (batch_size, 5).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output tensor of shape (batch_size, 1).\n",
        "        \"\"\"\n",
        "        # Adding an assertion to check that the input tensor has the expected shape and type\n",
        "        assert isinstance(x, torch.Tensor), \"x must be a torch.Tensor\"\n",
        "        assert x.shape[1] == 5, \"x must have shape (batch_size, 5)\"\n",
        "\n",
        "        # Looping over the hidden layers and applying the linear transformation and the activation function\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = self.hidden_activation(layer(x))\n",
        "        # Applying the linear transformation and the activation function on the output layer\n",
        "        x = self.output_activation(self.layers[-1](x))\n",
        "\n",
        "        # Returning the output tensor\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GNvp55PUZh_"
      },
      "source": [
        "## Defining the model and search space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "9a1opluOUZh_"
      },
      "outputs": [],
      "source": [
        "# Defining a function to create a trial network and optimizer\n",
        "def create_model(trial, optimize):\n",
        "    \"\"\"Creates a trial network and optimizer based on the sampled hyperparameters.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): The trial object that contains the hyperparameters.\n",
        "        optimize (boolean): Whether to optimize the hyperparameters or to use predefined values.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple of (net, loss_fn, optimizer, batch_size, n_epochs,\n",
        "            scheduler, loss_name, optimizer_name, scheduler_name,\n",
        "            n_units, n_layers, hidden_activation, output_activation),\n",
        "            where net is the trial network,\n",
        "            loss_fn is the loss function,\n",
        "            optimizer is the optimizer,\n",
        "            batch_size is the batch size,\n",
        "            n_epochs is the number of epochs,\n",
        "            scheduler is the learning rate scheduler,\n",
        "            loss_name is the name of the loss function,\n",
        "            optimizer_name is the name of the optimizer,\n",
        "            scheduler_name is the name of the scheduler,\n",
        "            n_units is a list of integers representing\n",
        "            the number of units in each hidden layer,\n",
        "            n_layers is an integer representing the number of hidden layers in the network,\n",
        "            hidden_activation is a torch.nn.Module representing the activation function for the hidden layers,\n",
        "            output_activation is a torch.nn.Module representing the activation function for the output layer,\n",
        "            lr is the (initial) learning rate.\n",
        "    \"\"\"\n",
        "    # If optimize is True, sample the hyperparameters from the search space\n",
        "    if optimize:\n",
        "        # Sampling the hyperparameters from the search space\n",
        "        n_layers = trial.suggest_int(\"n_layers\", 2, 10)\n",
        "        n_units = [trial.suggest_int(f\"n_units_{i}\", 32, 2048) for i in range(n_layers)] \n",
        "        hidden_activation_name = trial.suggest_categorical(\n",
        "            #\"hidden_activation\", [\"ReLU\", \"LeakyReLU\", \"ELU\", \"Tanh\", \"Sigmoid\"]\n",
        "            #\"hidden_activation\", [\"ReLU\", \"LeakyReLU\"]\n",
        "            \"hidden_activation\", [\"ReLU\", \"LeakyReLU\", \"ELU\"]\n",
        "        )\n",
        "        output_activation_name = trial.suggest_categorical(\n",
        "            #\"output_activation\", [\"Linear\", \"ReLU\", \"Softplus\"]\n",
        "            # Assuming pressure cannot be negative, linear output activation is not an option.\n",
        "            #\"output_activation\", [\"ReLU\", \"Softplus\", \"Linear\"]\n",
        "            \"output_activation\", [\"ReLU\", \"Linear\"]\n",
        "        ) \n",
        "        loss_name = trial.suggest_categorical(\n",
        "            #\"loss\", [\"MSE\", \"MAE\", \"Huber\", \"LogCosh\"] \n",
        "            \"loss\", [\"MSE\", \"MAE\", \"Huber\"] \n",
        "        )\n",
        "        optimizer_name = trial.suggest_categorical(\n",
        "            \"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\", \"Adagrad\"] \n",
        "        )\n",
        "        lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2) \n",
        "\n",
        "        batch_size_list = [32, 48, 64, 96, 128, 256, 512, 1048]\n",
        "        batch_size = trial.suggest_categorical(\"batch_size\", batch_size_list)\n",
        "        #batch_size = trial.suggest_int(\"batch_size\", 16, 1048)\n",
        "        n_epochs = trial.suggest_int(\"n_epochs\", 100, 300) \n",
        "        scheduler_name = trial.suggest_categorical(\n",
        "            \"scheduler\",\n",
        "            # [\"None\", \"CosineAnnealingLR\", \"ReduceLROnPlateau\", \"StepLR\", \"ExponentialLR\"],\n",
        "            [\"CosineAnnealingLR\", \"ReduceLROnPlateau\", \"StepLR\"],\n",
        "        )\n",
        "\n",
        "    # If optimize is False, use the predefined values\n",
        "    else:\n",
        "        # Setting the hyperparameters to the predefined values\n",
        "        n_layers = N_LAYERS_NO_OPT\n",
        "        n_units = N_UNITS_NO_OPT\n",
        "        hidden_activation_name = HIDDEN_ACTIVATION_NAME_NO_OPT\n",
        "        output_activation_name = OUTPUT_ACTIVATION_NAME_NO_OPT\n",
        "        loss_name = LOSS_NAME_NO_OPT\n",
        "        optimizer_name = OPTIMIZER_NAME_NO_OPT\n",
        "        lr = LR_NO_OPT\n",
        "        batch_size = BATCH_SIZE_NO_OPT\n",
        "        n_epochs = N_EPOCHS_NO_OPT\n",
        "        scheduler_name = SCHEDULER_NAME_NO_OPT\n",
        "\n",
        "\n",
        "    # Creating the activation functions from their names\n",
        "    if hidden_activation_name == \"ReLU\":\n",
        "        hidden_activation = nn.ReLU()\n",
        "    elif hidden_activation_name == \"LeakyReLU\":\n",
        "        hidden_activation = nn.LeakyReLU() \n",
        "    elif hidden_activation_name == \"ELU\":\n",
        "        hidden_activation = nn.ELU() \n",
        "    elif hidden_activation_name == \"Tanh\":\n",
        "        hidden_activation = nn.Tanh()\n",
        "    else:\n",
        "        hidden_activation = nn.Sigmoid()\n",
        "\n",
        "    if output_activation_name == \"ReLU\":\n",
        "        output_activation = nn.ReLU()\n",
        "    elif output_activation_name == \"Softplus\":\n",
        "        output_activation = nn.Softplus()\n",
        "    else:\n",
        "        output_activation = nn.Identity()\n",
        "\n",
        "    # Creating the loss function from its name\n",
        "    if loss_name == \"MSE\":\n",
        "        loss_fn = nn.MSELoss()\n",
        "    elif loss_name == \"MAE\":\n",
        "        loss_fn = nn.L1Loss()\n",
        "    elif loss_name == \"Huber\":\n",
        "        loss_fn = nn.SmoothL1Loss() \n",
        "    else:\n",
        "        # Creating the log-cosh loss function\n",
        "        def log_cosh_loss(y_pred, y_true):\n",
        "            return torch.mean(torch.log(torch.cosh(y_pred - y_true)))\n",
        "            \n",
        "        loss_fn = log_cosh_loss\n",
        "\n",
        "    # Creating the network with the sampled hyperparameters\n",
        "    net = Net(\n",
        "        n_layers, n_units, hidden_activation, output_activation\n",
        "    ).to(device)\n",
        "\n",
        "    if optimize:\n",
        "        # Creating the optimizer from its name\n",
        "        if optimizer_name == \"SGD\":\n",
        "            # Added sampling the weight decay and momentum for SGD\n",
        "            weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)\n",
        "            momentum = trial.suggest_uniform(\"momentum\", 0.0, 0.99)\n",
        "            optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
        "        elif optimizer_name == \"Adam\":\n",
        "            # Added sampling the weight decay and beta parameters for Adam\n",
        "            weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)\n",
        "            beta1 = trial.suggest_uniform(\"beta1\", 0.9, 0.999)\n",
        "            beta2 = trial.suggest_uniform(\"beta2\", 0.999, 0.9999)\n",
        "            optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay, betas=(beta1, beta2))\n",
        "        elif optimizer_name == \"RMSprop\":\n",
        "            optimizer = optim.RMSprop(net.parameters(), lr=lr)\n",
        "        else:\n",
        "            # Added creating the Adagrad optimizer\n",
        "            optimizer = optim.Adagrad(net.parameters(), lr=lr)\n",
        "\n",
        "        # Creating the learning rate scheduler from its name\n",
        "        if scheduler_name == \"StepLR\":\n",
        "            step_size = trial.suggest_int(\"step_size\", 5, 15)\n",
        "            gamma = trial.suggest_uniform(\"gamma\", 0.1, 0.5)\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "        elif scheduler_name == \"ExponentialLR\":\n",
        "            gamma = trial.suggest_uniform(\"gamma\", 0.8, 0.99)\n",
        "            scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
        "        elif scheduler_name == \"CosineAnnealingLR\":\n",
        "            if n_epochs < 150:\n",
        "                t_max_fraction = trial.suggest_uniform('t_max_fraction', 0.1, 0.3)\n",
        "            elif n_epochs > 250:\n",
        "                t_max_fraction = trial.suggest_uniform('t_max_fraction', 0.05, 0.1)\n",
        "            else:\n",
        "                t_max_fraction = trial.suggest_uniform('t_max_fraction', 0.1, 0.2)\n",
        "\n",
        "            T_max = int(n_epochs * t_max_fraction)\n",
        "            eta_min = trial.suggest_loguniform(\"eta_min\", 1e-7, 1e-2)\n",
        "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n",
        "        elif scheduler_name == \"ReduceLROnPlateau\":\n",
        "            # Added sampling the factor, patience and threshold for ReduceLROnPlateau\n",
        "            factor = trial.suggest_uniform(\"factor\", 0.1, 0.5)\n",
        "            patience = trial.suggest_int(\"patience\", 5, 10)\n",
        "            threshold = trial.suggest_loguniform(\"threshold\", 1e-4, 1e-2)\n",
        "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                optimizer, mode=\"min\", factor=factor, patience=patience, threshold=threshold\n",
        "            )\n",
        "        # # Added using OneCycleLR scheduler as an option\n",
        "        # elif scheduler_name == \"OneCycleLR\":\n",
        "        #         # Added sampling the max_lr and pct_start for OneCycleLR\n",
        "        #         max_lr = trial.suggest_loguniform(\"max_lr\", lr, 10 * lr) \n",
        "        #         pct_start = trial.suggest_uniform(\"pct_start\", 0.1, 0.9)\n",
        "        #         scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "        #             optimizer,\n",
        "        #             max_lr=max_lr,\n",
        "        #             epochs=n_epochs,\n",
        "        #             steps_per_epoch=len(train_loader),\n",
        "        #             pct_start=pct_start,\n",
        "        #         )\n",
        "        else:\n",
        "            scheduler = None\n",
        "    else:\n",
        "        # Creating the optimizer from its name\n",
        "        if optimizer_name == \"SGD\":\n",
        "            optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "        elif optimizer_name == \"Adam\":\n",
        "            optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "        elif optimizer_name == \"RMSprop\":\n",
        "            optimizer = optim.RMSprop(net.parameters(), lr=lr)\n",
        "        else:\n",
        "            optimizer = optim.Adagrad(net.parameters(), lr=lr)\n",
        "\n",
        "        # Creating the learning rate scheduler from its name\n",
        "        if scheduler_name == \"StepLR\":\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "        elif scheduler_name == \"ExponentialLR\":\n",
        "            scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "        elif scheduler_name == \"CosineAnnealingLR\":\n",
        "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer)\n",
        "        elif scheduler_name == \"ReduceLROnPlateau\":\n",
        "            # Creating the ReduceLROnPlateau scheduler with a threshold value of 0.01\n",
        "            #scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            #    optimizer, mode=\"min\", factor=0.1, patience=10, threshold=0.01\n",
        "            #)\n",
        "            # Use Dieseldorst et al. settings and add to that a minimum lr.\n",
        "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                        optimizer, mode=\"min\", factor=0.18979341786654758, patience=11, threshold=0.0017197466122611932 #, min_lr=1e-6\n",
        "                    )\n",
        "        else:\n",
        "            scheduler = None\n",
        "\n",
        "    # Returning all variables needed for saving and loading\n",
        "    return net, loss_fn, optimizer, batch_size, n_epochs, scheduler, loss_name, optimizer_name, scheduler_name, n_units, n_layers, hidden_activation, output_activation, lr\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-czA7VvUZiD"
      },
      "source": [
        " ## The training and evaluation loop\n",
        "\n",
        " We first define a couple of functions used in the training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "aD6FQNmxUZiD"
      },
      "outputs": [],
      "source": [
        "# Defining a function that computes loss and metrics for a given batch\n",
        "def compute_loss_and_metrics(y_pred, y_true, loss_fn):\n",
        "    \"\"\"Computes loss and metrics for a given batch.\n",
        "\n",
        "    Args:\n",
        "        y_pred (torch.Tensor): The predicted pressure tensor of shape (batch_size, 1).\n",
        "        y_true (torch.Tensor): The true pressure tensor of shape (batch_size,).\n",
        "        loss_fn (torch.nn.Module or function): The loss function to use.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple of (loss, l1_norm), where loss is a scalar tensor,\n",
        "            l1_norm is L1 norm for relative error of pressure,\n",
        "            each being a scalar tensor.\n",
        "            linf_norm is Linf norm for relative error of pressure.\n",
        "    \"\"\"\n",
        "    # Reshaping the target tensor to match the input tensor\n",
        "    y_true = y_true.view(-1, 1)\n",
        "\n",
        "    # Computing the loss using the loss function\n",
        "    loss = loss_fn(y_pred, y_true)\n",
        "\n",
        "    # Computing the relative error of pressure\n",
        "    rel_error = torch.abs((y_pred - y_true) / y_true)\n",
        "\n",
        "    # Computing the L1 norm for the relative error of pressure\n",
        "    l1_norm = torch.mean(rel_error) \n",
        "    # Computing the Linf norm for the relative error of pressure\n",
        "    linf_norm = torch.max(rel_error) \n",
        "\n",
        "    # Returning the loss and metrics\n",
        "    return loss, l1_norm, linf_norm\n",
        "\n",
        "\n",
        "# Defining a function that updates the learning rate scheduler with validation loss if applicable\n",
        "def update_scheduler(scheduler, test_loss):\n",
        "    \"\"\"Updates the learning rate scheduler with validation loss if applicable.\n",
        "\n",
        "    Args:\n",
        "        scheduler (torch.optim.lr_scheduler._LRScheduler or None): The learning rate scheduler to use.\n",
        "        test_loss (float): The validation loss to use.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Checking if scheduler is not None\n",
        "    if scheduler is not None:\n",
        "        # Checking if scheduler is ReduceLROnPlateau\n",
        "        if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "            # Updating the scheduler with test_loss\n",
        "            scheduler.step(test_loss)\n",
        "        else:\n",
        "            # Updating the scheduler without test_loss\n",
        "            scheduler.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1nE662UUZiE"
      },
      "source": [
        "Now for the actual training and evaluation loop,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YAOjgKW3UZiF"
      },
      "outputs": [],
      "source": [
        "# Defining a function to train and evaluate a network\n",
        "def train_and_eval(net, loss_fn, optimizer, batch_size, n_epochs, scheduler, trial=None):\n",
        "    \"\"\"Trains and evaluates a network.\n",
        "\n",
        "    Args:\n",
        "        net (torch.nn.Module): The network to train and evaluate.\n",
        "        loss_fn (torch.nn.Module or function): The loss function.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer.\n",
        "        batch_size (int): The batch size.\n",
        "        n_epochs (int): The number of epochs.\n",
        "        scheduler (torch.optim.lr_scheduler._LRScheduler or None): The learning rate scheduler.\n",
        "    Returns:\n",
        "        tuple: A tuple of (train_losses, test_losses, train_metrics, test_metrics), where\n",
        "            train_losses is a list of training losses for each epoch,\n",
        "            test_losses is a list of validation losses for each epoch,\n",
        "            train_metrics is a list of dictionaries containing training metrics for each epoch,\n",
        "            test_metrics is a list of dictionaries containing validation metrics for each epoch.\n",
        "    \"\"\"\n",
        "    # Creating data loaders for train and test sets\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # Initializing lists to store the losses and metrics for each epoch\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_metrics = []\n",
        "    test_metrics = []\n",
        "\n",
        "    # Creating a SummaryWriter object to log data for tensorboard\n",
        "    writer = tbx.SummaryWriter()\n",
        "\n",
        "    # Looping over the epochs\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # Setting the network to training mode\n",
        "        net.train()\n",
        "\n",
        "        # Initializing variables to store the total loss and metrics for the train set\n",
        "        train_loss = 0.0\n",
        "        train_l1_norm = 0.0\n",
        "        train_linf_norm = 0.0\n",
        "\n",
        "        # Looping over the batches in the train set\n",
        "        for x_batch, y_batch in train_loader:\n",
        "\n",
        "            # Moving the batch tensors to the device\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            # Zeroing the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Performing a forward pass and computing the loss and metrics\n",
        "            y_pred = net(x_batch)\n",
        "            loss, l1_norm, linf_norm = compute_loss_and_metrics(\n",
        "                y_pred, y_batch, loss_fn\n",
        "            )\n",
        "\n",
        "\n",
        "            # Performing a backward pass and updating the weights\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Updating the total loss and metrics for the train set\n",
        "            train_loss += loss.item() * x_batch.size(0)\n",
        "            train_l1_norm += l1_norm.item() * x_batch.size(0)\n",
        "            train_linf_norm += linf_norm.item() * x_batch.size(0)\n",
        "\n",
        "        # Computing the average loss and metrics for the train set\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_l1_norm /= len(train_loader.dataset)\n",
        "        train_linf_norm /= len(train_loader.dataset)\n",
        "\n",
        "        # Appending the average loss and metrics for the train set to the lists\n",
        "        train_losses.append(train_loss)\n",
        "        train_metrics.append(\n",
        "            {\n",
        "                \"l1_norm\": train_l1_norm,\n",
        "                \"linf_norm\": train_linf_norm,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Logging the average loss and metrics for the train set to tensorboard\n",
        "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
        "        writer.add_scalar(\"L1 norm/train\", train_l1_norm, epoch)\n",
        "        writer.add_scalar(\"Linf norm/train\", train_linf_norm, epoch)\n",
        "\n",
        "        # Setting the network to evaluation mode\n",
        "        net.eval()\n",
        "\n",
        "        # Initializing variables to store the total loss and metrics for the test set\n",
        "        test_loss = 0.0\n",
        "        test_l1_norm = 0.0\n",
        "        test_linf_norm = 0.0\n",
        "\n",
        "        # Looping over the batches in the test set\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in test_loader:\n",
        "\n",
        "                # Moving the batch tensors to the device\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "\n",
        "                # Performing a forward pass and computing the loss and metrics\n",
        "                y_pred = net(x_batch)\n",
        "                loss, l1_norm, linf_norm = compute_loss_and_metrics(\n",
        "                    y_pred, y_batch, loss_fn\n",
        "                )\n",
        "\n",
        "\n",
        "                # Updating the total loss and metrics for the test set\n",
        "                test_loss += loss.item() * x_batch.size(0)\n",
        "                test_l1_norm += l1_norm.item() * x_batch.size(0)\n",
        "                test_linf_norm += linf_norm.item() * x_batch.size(0)\n",
        "\n",
        "        # Computing the average loss and metrics for the test set\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_l1_norm /= len(test_loader.dataset)\n",
        "        test_linf_norm /= len(test_loader.dataset)\n",
        "\n",
        "        # Appending the average loss and metrics for the test set to the lists\n",
        "        test_losses.append(test_loss)\n",
        "        test_metrics.append(\n",
        "            {\n",
        "                \"l1_norm\": test_l1_norm,\n",
        "                \"linf_norm\": test_linf_norm,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Logging the average loss and metrics for the test set to tensorboard\n",
        "        writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
        "        writer.add_scalar(\"L1 norm/test\", test_l1_norm, epoch)\n",
        "        writer.add_scalar(\"Linf norm/test\", test_linf_norm, epoch)\n",
        "\n",
        "        # Printing the average loss and metrics for both sets for this epoch\n",
        "        print(\n",
        "            f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, \"\n",
        "            f\"Train L1 Norm: {train_l1_norm:.4f}, Test L1 Norm: {test_l1_norm:.4f}, \"\n",
        "            f\"Train Linf Norm: {train_linf_norm:.4f}, Test Linf Norm: {test_linf_norm:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Updating the learning rate scheduler with validation loss if applicable\n",
        "        update_scheduler(scheduler, test_loss)\n",
        "\n",
        "        # Reporting the intermediate metric value to Optuna if trial is not None\n",
        "        if trial is not None:\n",
        "            trial.report(test_metrics[-1][\"l1_norm\"], epoch)\n",
        "\n",
        "            # Checking if the trial should be pruned based on the intermediate value if trial is not None\n",
        "            if trial.should_prune():\n",
        "                raise optuna.TrialPruned()\n",
        "\n",
        "    # Closing the SummaryWriter object\n",
        "    writer.close()\n",
        "\n",
        "    # Returning the losses and metrics lists\n",
        "    return train_losses, test_losses, train_metrics, test_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg9jz0SvUZiQ"
      },
      "source": [
        "## The objective function and hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "fmRncQPuUZiR"
      },
      "outputs": [],
      "source": [
        "# Defining an objective function for Optuna to minimize\n",
        "def objective(trial):\n",
        "    \"\"\"Defines an objective function for Optuna to minimize.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): The trial object that contains the hyperparameters.\n",
        "\n",
        "    Returns:\n",
        "        float: The validation L1 norm to minimize.\n",
        "    \"\"\"\n",
        "    # Creating a trial network and optimizer using the create_model function\n",
        "    net, \\\n",
        "    loss_fn, \\\n",
        "    optimizer, \\\n",
        "    batch_size, \\\n",
        "    n_epochs, \\\n",
        "    scheduler, \\\n",
        "    loss_name, \\\n",
        "    optimizer_name, \\\n",
        "    scheduler_name, \\\n",
        "    n_units, \\\n",
        "    n_layers, \\\n",
        "    hidden_activation, \\\n",
        "    output_activation, \\\n",
        "    lr = create_model(trial, optimize=True)\n",
        "\n",
        "    # Training and evaluating the network using the train_and_eval function\n",
        "    _, _, _, test_metrics = train_and_eval(\n",
        "        net, loss_fn, optimizer, batch_size, n_epochs, scheduler, trial\n",
        "    )\n",
        "\n",
        "    # Returning the last validation L1 norm as the objective value to minimize\n",
        "    return test_metrics[-1][\"l1_norm\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyES4NAyUZiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c2b037-1576-4242-c6eb-469f5dae952a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 10:10:53,985]\u001b[0m A new study created in memory with name: no-name-3df03303-8f92-4e38-9647-577ec730f4af\u001b[0m\n",
            "<ipython-input-60-82e2252adf92>:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
            "<ipython-input-60-82e2252adf92>:126: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)\n",
            "<ipython-input-60-82e2252adf92>:127: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  beta1 = trial.suggest_uniform(\"beta1\", 0.9, 0.999)\n",
            "<ipython-input-60-82e2252adf92>:128: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  beta2 = trial.suggest_uniform(\"beta2\", 0.999, 0.9999)\n",
            "<ipython-input-60-82e2252adf92>:157: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  factor = trial.suggest_uniform(\"factor\", 0.1, 0.5)\n",
            "<ipython-input-60-82e2252adf92>:159: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  threshold = trial.suggest_loguniform(\"threshold\", 1e-4, 1e-2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.4601, Test Loss: 0.0115, Train L1 Norm: 5.1690, Test L1 Norm: 0.5604, Train Linf Norm: 982.1550, Test Linf Norm: 76.0110\n",
            "Epoch 2: Train Loss: 0.0180, Test Loss: 0.0050, Train L1 Norm: 2.2571, Test L1 Norm: 0.4273, Train Linf Norm: 511.2994, Test Linf Norm: 60.4740\n",
            "Epoch 3: Train Loss: 0.0099, Test Loss: 0.0109, Train L1 Norm: 1.8841, Test L1 Norm: 0.3489, Train Linf Norm: 432.6934, Test Linf Norm: 48.0831\n",
            "Epoch 4: Train Loss: 0.0084, Test Loss: 0.0060, Train L1 Norm: 1.2891, Test L1 Norm: 0.2285, Train Linf Norm: 289.4369, Test Linf Norm: 31.5519\n",
            "Epoch 5: Train Loss: 0.0113, Test Loss: 0.0428, Train L1 Norm: 0.7127, Test L1 Norm: 0.1637, Train Linf Norm: 157.1471, Test Linf Norm: 17.2180\n",
            "Epoch 6: Train Loss: 0.0080, Test Loss: 0.0075, Train L1 Norm: 0.6151, Test L1 Norm: 0.1404, Train Linf Norm: 135.9592, Test Linf Norm: 16.5571\n",
            "Epoch 7: Train Loss: 0.0120, Test Loss: 0.0114, Train L1 Norm: 0.5475, Test L1 Norm: 0.1228, Train Linf Norm: 118.7434, Test Linf Norm: 14.5047\n",
            "Epoch 8: Train Loss: 0.0133, Test Loss: 0.0198, Train L1 Norm: 0.6206, Test L1 Norm: 0.1538, Train Linf Norm: 135.5323, Test Linf Norm: 19.1618\n",
            "Epoch 9: Train Loss: 0.0083, Test Loss: 0.0089, Train L1 Norm: 0.6333, Test L1 Norm: 0.1411, Train Linf Norm: 142.5372, Test Linf Norm: 17.8980\n",
            "Epoch 10: Train Loss: 0.0107, Test Loss: 0.0059, Train L1 Norm: 0.6913, Test L1 Norm: 0.1223, Train Linf Norm: 157.0573, Test Linf Norm: 15.9355\n",
            "Epoch 11: Train Loss: 0.0101, Test Loss: 0.0122, Train L1 Norm: 0.6605, Test L1 Norm: 0.1531, Train Linf Norm: 148.7287, Test Linf Norm: 19.3229\n",
            "Epoch 12: Train Loss: 0.0161, Test Loss: 0.0230, Train L1 Norm: 0.7397, Test L1 Norm: 0.1696, Train Linf Norm: 165.4044, Test Linf Norm: 21.3838\n",
            "Epoch 13: Train Loss: 0.0023, Test Loss: 0.0010, Train L1 Norm: 0.7515, Test L1 Norm: 0.1282, Train Linf Norm: 173.8437, Test Linf Norm: 18.9728\n",
            "Epoch 14: Train Loss: 0.0013, Test Loss: 0.0010, Train L1 Norm: 0.7209, Test L1 Norm: 0.1375, Train Linf Norm: 166.2046, Test Linf Norm: 20.9682\n",
            "Epoch 15: Train Loss: 0.0016, Test Loss: 0.0029, Train L1 Norm: 0.6930, Test L1 Norm: 0.1320, Train Linf Norm: 162.4377, Test Linf Norm: 19.2811\n",
            "Epoch 16: Train Loss: 0.0016, Test Loss: 0.0014, Train L1 Norm: 0.6478, Test L1 Norm: 0.1310, Train Linf Norm: 150.6074, Test Linf Norm: 19.6941\n",
            "Epoch 17: Train Loss: 0.0018, Test Loss: 0.0016, Train L1 Norm: 0.6778, Test L1 Norm: 0.1202, Train Linf Norm: 157.8849, Test Linf Norm: 18.0208\n",
            "Epoch 18: Train Loss: 0.0016, Test Loss: 0.0019, Train L1 Norm: 0.6388, Test L1 Norm: 0.1207, Train Linf Norm: 149.5416, Test Linf Norm: 18.2614\n",
            "Epoch 19: Train Loss: 0.0018, Test Loss: 0.0017, Train L1 Norm: 0.6221, Test L1 Norm: 0.1033, Train Linf Norm: 145.2763, Test Linf Norm: 15.2556\n",
            "Epoch 20: Train Loss: 0.0024, Test Loss: 0.0010, Train L1 Norm: 0.5889, Test L1 Norm: 0.1320, Train Linf Norm: 134.6207, Test Linf Norm: 20.4748\n",
            "Epoch 21: Train Loss: 0.0020, Test Loss: 0.0012, Train L1 Norm: 0.6209, Test L1 Norm: 0.1171, Train Linf Norm: 143.8746, Test Linf Norm: 17.6601\n",
            "Epoch 22: Train Loss: 0.0018, Test Loss: 0.0009, Train L1 Norm: 0.6151, Test L1 Norm: 0.1140, Train Linf Norm: 143.6662, Test Linf Norm: 16.9933\n",
            "Epoch 23: Train Loss: 0.0014, Test Loss: 0.0011, Train L1 Norm: 0.6174, Test L1 Norm: 0.1157, Train Linf Norm: 145.0780, Test Linf Norm: 17.3717\n",
            "Epoch 24: Train Loss: 0.0016, Test Loss: 0.0017, Train L1 Norm: 0.5880, Test L1 Norm: 0.1029, Train Linf Norm: 136.5928, Test Linf Norm: 14.9093\n",
            "Epoch 25: Train Loss: 0.0029, Test Loss: 0.0009, Train L1 Norm: 0.5891, Test L1 Norm: 0.0985, Train Linf Norm: 136.3264, Test Linf Norm: 14.9198\n",
            "Epoch 26: Train Loss: 0.0020, Test Loss: 0.0027, Train L1 Norm: 0.5857, Test L1 Norm: 0.1041, Train Linf Norm: 135.9325, Test Linf Norm: 15.3653\n",
            "Epoch 27: Train Loss: 0.0019, Test Loss: 0.0008, Train L1 Norm: 0.5416, Test L1 Norm: 0.1061, Train Linf Norm: 125.4783, Test Linf Norm: 16.4376\n",
            "Epoch 28: Train Loss: 0.0033, Test Loss: 0.0029, Train L1 Norm: 0.5313, Test L1 Norm: 0.1316, Train Linf Norm: 121.9388, Test Linf Norm: 18.8312\n",
            "Epoch 29: Train Loss: 0.0020, Test Loss: 0.0038, Train L1 Norm: 0.5878, Test L1 Norm: 0.1042, Train Linf Norm: 137.1845, Test Linf Norm: 14.0655\n",
            "Epoch 30: Train Loss: 0.0029, Test Loss: 0.0018, Train L1 Norm: 0.5676, Test L1 Norm: 0.0970, Train Linf Norm: 130.0131, Test Linf Norm: 14.5152\n",
            "Epoch 31: Train Loss: 0.0012, Test Loss: 0.0012, Train L1 Norm: 0.5536, Test L1 Norm: 0.0858, Train Linf Norm: 129.7413, Test Linf Norm: 12.1432\n",
            "Epoch 32: Train Loss: 0.0034, Test Loss: 0.0013, Train L1 Norm: 0.5474, Test L1 Norm: 0.1061, Train Linf Norm: 125.6220, Test Linf Norm: 15.4637\n",
            "Epoch 33: Train Loss: 0.0016, Test Loss: 0.0016, Train L1 Norm: 0.5789, Test L1 Norm: 0.0973, Train Linf Norm: 134.1421, Test Linf Norm: 14.1069\n",
            "Epoch 34: Train Loss: 0.0018, Test Loss: 0.0017, Train L1 Norm: 0.5632, Test L1 Norm: 0.1221, Train Linf Norm: 131.2514, Test Linf Norm: 17.5249\n",
            "Epoch 35: Train Loss: 0.0031, Test Loss: 0.0033, Train L1 Norm: 0.5700, Test L1 Norm: 0.1256, Train Linf Norm: 129.0914, Test Linf Norm: 17.6925\n",
            "Epoch 36: Train Loss: 0.0016, Test Loss: 0.0017, Train L1 Norm: 0.5413, Test L1 Norm: 0.1137, Train Linf Norm: 124.9284, Test Linf Norm: 17.2389\n",
            "Epoch 37: Train Loss: 0.0012, Test Loss: 0.0004, Train L1 Norm: 0.5645, Test L1 Norm: 0.0958, Train Linf Norm: 132.9793, Test Linf Norm: 15.0909\n",
            "Epoch 38: Train Loss: 0.0011, Test Loss: 0.0006, Train L1 Norm: 0.5764, Test L1 Norm: 0.1144, Train Linf Norm: 134.9983, Test Linf Norm: 18.1291\n",
            "Epoch 39: Train Loss: 0.0015, Test Loss: 0.0022, Train L1 Norm: 0.5962, Test L1 Norm: 0.0992, Train Linf Norm: 140.9173, Test Linf Norm: 14.9489\n",
            "Epoch 40: Train Loss: 0.0024, Test Loss: 0.0017, Train L1 Norm: 0.5180, Test L1 Norm: 0.0836, Train Linf Norm: 119.8215, Test Linf Norm: 11.7384\n",
            "Epoch 41: Train Loss: 0.0028, Test Loss: 0.0037, Train L1 Norm: 0.4615, Test L1 Norm: 0.0974, Train Linf Norm: 105.4386, Test Linf Norm: 12.1724\n",
            "Epoch 42: Train Loss: 0.0025, Test Loss: 0.0006, Train L1 Norm: 0.6303, Test L1 Norm: 0.0865, Train Linf Norm: 148.4410, Test Linf Norm: 12.9931\n",
            "Epoch 43: Train Loss: 0.0009, Test Loss: 0.0008, Train L1 Norm: 0.5099, Test L1 Norm: 0.0914, Train Linf Norm: 120.0848, Test Linf Norm: 13.8391\n",
            "Epoch 44: Train Loss: 0.0015, Test Loss: 0.0006, Train L1 Norm: 0.4940, Test L1 Norm: 0.0912, Train Linf Norm: 113.4012, Test Linf Norm: 14.2888\n",
            "Epoch 45: Train Loss: 0.0017, Test Loss: 0.0007, Train L1 Norm: 0.5209, Test L1 Norm: 0.1121, Train Linf Norm: 120.7393, Test Linf Norm: 16.4932\n",
            "Epoch 46: Train Loss: 0.0011, Test Loss: 0.0008, Train L1 Norm: 0.5684, Test L1 Norm: 0.0831, Train Linf Norm: 134.4032, Test Linf Norm: 11.7135\n",
            "Epoch 47: Train Loss: 0.0014, Test Loss: 0.0021, Train L1 Norm: 0.4700, Test L1 Norm: 0.0873, Train Linf Norm: 109.0895, Test Linf Norm: 11.2191\n",
            "Epoch 48: Train Loss: 0.0005, Test Loss: 0.0003, Train L1 Norm: 0.5044, Test L1 Norm: 0.0827, Train Linf Norm: 119.8188, Test Linf Norm: 13.1584\n",
            "Epoch 49: Train Loss: 0.0005, Test Loss: 0.0004, Train L1 Norm: 0.4529, Test L1 Norm: 0.0802, Train Linf Norm: 106.9014, Test Linf Norm: 12.4900\n",
            "Epoch 50: Train Loss: 0.0007, Test Loss: 0.0008, Train L1 Norm: 0.4529, Test L1 Norm: 0.0847, Train Linf Norm: 105.6379, Test Linf Norm: 13.2281\n",
            "Epoch 51: Train Loss: 0.0006, Test Loss: 0.0005, Train L1 Norm: 0.4496, Test L1 Norm: 0.0809, Train Linf Norm: 105.0859, Test Linf Norm: 11.9767\n",
            "Epoch 52: Train Loss: 0.0005, Test Loss: 0.0003, Train L1 Norm: 0.4529, Test L1 Norm: 0.0806, Train Linf Norm: 107.0700, Test Linf Norm: 12.8478\n",
            "Epoch 53: Train Loss: 0.0004, Test Loss: 0.0003, Train L1 Norm: 0.4433, Test L1 Norm: 0.0815, Train Linf Norm: 104.5273, Test Linf Norm: 12.8606\n",
            "Epoch 54: Train Loss: 0.0005, Test Loss: 0.0004, Train L1 Norm: 0.4584, Test L1 Norm: 0.0797, Train Linf Norm: 107.7332, Test Linf Norm: 12.6659\n",
            "Epoch 55: Train Loss: 0.0006, Test Loss: 0.0004, Train L1 Norm: 0.4366, Test L1 Norm: 0.0795, Train Linf Norm: 103.0927, Test Linf Norm: 12.4522\n",
            "Epoch 56: Train Loss: 0.0006, Test Loss: 0.0007, Train L1 Norm: 0.4162, Test L1 Norm: 0.0699, Train Linf Norm: 96.1670, Test Linf Norm: 10.4575\n",
            "Epoch 57: Train Loss: 0.0005, Test Loss: 0.0011, Train L1 Norm: 0.4360, Test L1 Norm: 0.0731, Train Linf Norm: 103.0473, Test Linf Norm: 10.6723\n",
            "Epoch 58: Train Loss: 0.0004, Test Loss: 0.0003, Train L1 Norm: 0.4472, Test L1 Norm: 0.0745, Train Linf Norm: 106.5880, Test Linf Norm: 11.9205\n",
            "Epoch 59: Train Loss: 0.0005, Test Loss: 0.0003, Train L1 Norm: 0.4247, Test L1 Norm: 0.0675, Train Linf Norm: 100.5548, Test Linf Norm: 10.3391\n",
            "Epoch 60: Train Loss: 0.0007, Test Loss: 0.0004, Train L1 Norm: 0.4081, Test L1 Norm: 0.0739, Train Linf Norm: 95.9322, Test Linf Norm: 11.7941\n",
            "Epoch 61: Train Loss: 0.0006, Test Loss: 0.0005, Train L1 Norm: 0.4185, Test L1 Norm: 0.0775, Train Linf Norm: 98.1832, Test Linf Norm: 12.2690\n",
            "Epoch 62: Train Loss: 0.0005, Test Loss: 0.0004, Train L1 Norm: 0.3743, Test L1 Norm: 0.0984, Train Linf Norm: 87.0969, Test Linf Norm: 15.3888\n",
            "Epoch 63: Train Loss: 0.0005, Test Loss: 0.0004, Train L1 Norm: 0.3723, Test L1 Norm: 0.0791, Train Linf Norm: 87.1112, Test Linf Norm: 12.7922\n",
            "Epoch 64: Train Loss: 0.0006, Test Loss: 0.0003, Train L1 Norm: 0.4435, Test L1 Norm: 0.0744, Train Linf Norm: 104.9191, Test Linf Norm: 11.9456\n",
            "Epoch 65: Train Loss: 0.0008, Test Loss: 0.0013, Train L1 Norm: 0.4047, Test L1 Norm: 0.0787, Train Linf Norm: 94.2310, Test Linf Norm: 11.6020\n",
            "Epoch 66: Train Loss: 0.0005, Test Loss: 0.0006, Train L1 Norm: 0.3734, Test L1 Norm: 0.0654, Train Linf Norm: 87.4221, Test Linf Norm: 9.7783\n",
            "Epoch 67: Train Loss: 0.0005, Test Loss: 0.0004, Train L1 Norm: 0.4230, Test L1 Norm: 0.0644, Train Linf Norm: 99.9237, Test Linf Norm: 10.0223\n",
            "Epoch 68: Train Loss: 0.0006, Test Loss: 0.0008, Train L1 Norm: 0.4085, Test L1 Norm: 0.0685, Train Linf Norm: 97.0173, Test Linf Norm: 9.7102\n",
            "Epoch 69: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.4149, Test L1 Norm: 0.0642, Train Linf Norm: 97.4156, Test Linf Norm: 10.1714\n",
            "Epoch 70: Train Loss: 0.0004, Test Loss: 0.0003, Train L1 Norm: 0.3765, Test L1 Norm: 0.0710, Train Linf Norm: 88.9451, Test Linf Norm: 11.5092\n",
            "Epoch 71: Train Loss: 0.0003, Test Loss: 0.0004, Train L1 Norm: 0.3753, Test L1 Norm: 0.0674, Train Linf Norm: 88.6200, Test Linf Norm: 10.7791\n",
            "Epoch 72: Train Loss: 0.0004, Test Loss: 0.0003, Train L1 Norm: 0.3589, Test L1 Norm: 0.0648, Train Linf Norm: 84.5615, Test Linf Norm: 10.3371\n",
            "Epoch 73: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3746, Test L1 Norm: 0.0667, Train Linf Norm: 88.9488, Test Linf Norm: 10.7544\n",
            "Epoch 74: Train Loss: 0.0003, Test Loss: 0.0004, Train L1 Norm: 0.3709, Test L1 Norm: 0.0669, Train Linf Norm: 87.7942, Test Linf Norm: 10.7304\n",
            "Epoch 75: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3743, Test L1 Norm: 0.0685, Train Linf Norm: 88.8878, Test Linf Norm: 11.1129\n",
            "Epoch 76: Train Loss: 0.0003, Test Loss: 0.0004, Train L1 Norm: 0.3743, Test L1 Norm: 0.0668, Train Linf Norm: 89.0013, Test Linf Norm: 10.6576\n",
            "Epoch 77: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3714, Test L1 Norm: 0.0633, Train Linf Norm: 88.2549, Test Linf Norm: 9.9980\n",
            "Epoch 78: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3661, Test L1 Norm: 0.0633, Train Linf Norm: 86.8305, Test Linf Norm: 10.0933\n",
            "Epoch 79: Train Loss: 0.0003, Test Loss: 0.0004, Train L1 Norm: 0.3570, Test L1 Norm: 0.0651, Train Linf Norm: 84.4309, Test Linf Norm: 10.2571\n",
            "Epoch 80: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3831, Test L1 Norm: 0.0683, Train Linf Norm: 91.5179, Test Linf Norm: 11.0082\n",
            "Epoch 81: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3705, Test L1 Norm: 0.0632, Train Linf Norm: 88.1811, Test Linf Norm: 9.9605\n",
            "Epoch 82: Train Loss: 0.0004, Test Loss: 0.0003, Train L1 Norm: 0.3599, Test L1 Norm: 0.0610, Train Linf Norm: 85.3315, Test Linf Norm: 9.4536\n",
            "Epoch 83: Train Loss: 0.0004, Test Loss: 0.0005, Train L1 Norm: 0.3749, Test L1 Norm: 0.0634, Train Linf Norm: 87.7101, Test Linf Norm: 9.9604\n",
            "Epoch 84: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3672, Test L1 Norm: 0.0640, Train Linf Norm: 86.9105, Test Linf Norm: 10.2067\n",
            "Epoch 85: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3659, Test L1 Norm: 0.0634, Train Linf Norm: 86.3222, Test Linf Norm: 10.1193\n",
            "Epoch 86: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0634, Train Linf Norm: 83.8796, Test Linf Norm: 10.1470\n",
            "Epoch 87: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3637, Test L1 Norm: 0.0629, Train Linf Norm: 86.1648, Test Linf Norm: 10.0014\n",
            "Epoch 88: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3613, Test L1 Norm: 0.0637, Train Linf Norm: 85.6295, Test Linf Norm: 10.2018\n",
            "Epoch 89: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3568, Test L1 Norm: 0.0648, Train Linf Norm: 84.4972, Test Linf Norm: 10.3324\n",
            "Epoch 90: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3629, Test L1 Norm: 0.0628, Train Linf Norm: 85.5986, Test Linf Norm: 9.9329\n",
            "Epoch 91: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3646, Test L1 Norm: 0.0620, Train Linf Norm: 86.4686, Test Linf Norm: 9.8703\n",
            "Epoch 92: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3607, Test L1 Norm: 0.0634, Train Linf Norm: 85.1861, Test Linf Norm: 10.1698\n",
            "Epoch 93: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3628, Test L1 Norm: 0.0628, Train Linf Norm: 85.5041, Test Linf Norm: 10.0280\n",
            "Epoch 94: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3594, Test L1 Norm: 0.0639, Train Linf Norm: 85.5197, Test Linf Norm: 10.2455\n",
            "Epoch 95: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3584, Test L1 Norm: 0.0623, Train Linf Norm: 84.3342, Test Linf Norm: 9.9492\n",
            "Epoch 96: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3601, Test L1 Norm: 0.0627, Train Linf Norm: 85.4716, Test Linf Norm: 10.0289\n",
            "Epoch 97: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3595, Test L1 Norm: 0.0632, Train Linf Norm: 84.9377, Test Linf Norm: 10.1177\n",
            "Epoch 98: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3582, Test L1 Norm: 0.0617, Train Linf Norm: 84.0104, Test Linf Norm: 9.7950\n",
            "Epoch 99: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3590, Test L1 Norm: 0.0629, Train Linf Norm: 85.3091, Test Linf Norm: 9.9909\n",
            "Epoch 100: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3533, Test L1 Norm: 0.0625, Train Linf Norm: 83.6583, Test Linf Norm: 9.9272\n",
            "Epoch 101: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3583, Test L1 Norm: 0.0625, Train Linf Norm: 84.2752, Test Linf Norm: 10.0037\n",
            "Epoch 102: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3563, Test L1 Norm: 0.0624, Train Linf Norm: 84.3073, Test Linf Norm: 9.9858\n",
            "Epoch 103: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3565, Test L1 Norm: 0.0621, Train Linf Norm: 84.4871, Test Linf Norm: 9.9069\n",
            "Epoch 104: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0623, Train Linf Norm: 84.3412, Test Linf Norm: 9.9492\n",
            "Epoch 105: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3560, Test L1 Norm: 0.0623, Train Linf Norm: 84.4922, Test Linf Norm: 9.9502\n",
            "Epoch 106: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3578, Test L1 Norm: 0.0622, Train Linf Norm: 85.2701, Test Linf Norm: 9.9404\n",
            "Epoch 107: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3582, Test L1 Norm: 0.0622, Train Linf Norm: 84.4367, Test Linf Norm: 9.9445\n",
            "Epoch 108: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3543, Test L1 Norm: 0.0621, Train Linf Norm: 83.6460, Test Linf Norm: 9.9157\n",
            "Epoch 109: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3564, Test L1 Norm: 0.0621, Train Linf Norm: 84.5389, Test Linf Norm: 9.9240\n",
            "Epoch 110: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3562, Test L1 Norm: 0.0623, Train Linf Norm: 84.4126, Test Linf Norm: 9.9628\n",
            "Epoch 111: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0623, Train Linf Norm: 83.9968, Test Linf Norm: 9.9729\n",
            "Epoch 112: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3583, Test L1 Norm: 0.0622, Train Linf Norm: 85.3834, Test Linf Norm: 9.9540\n",
            "Epoch 113: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0621, Train Linf Norm: 83.7910, Test Linf Norm: 9.9339\n",
            "Epoch 114: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3557, Test L1 Norm: 0.0622, Train Linf Norm: 84.5824, Test Linf Norm: 9.9505\n",
            "Epoch 115: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0621, Train Linf Norm: 84.6330, Test Linf Norm: 9.9259\n",
            "Epoch 116: Train Loss: 0.0003, Test Loss: 0.0003, Train L1 Norm: 0.3561, Test L1 Norm: 0.0621, Train Linf Norm: 84.3579, Test Linf Norm: 9.9206\n",
            "Epoch 117: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3559, Test L1 Norm: 0.0621, Train Linf Norm: 84.1794, Test Linf Norm: 9.9096\n",
            "Epoch 118: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3562, Test L1 Norm: 0.0621, Train Linf Norm: 84.6284, Test Linf Norm: 9.9189\n",
            "Epoch 119: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3565, Test L1 Norm: 0.0621, Train Linf Norm: 84.6434, Test Linf Norm: 9.9327\n",
            "Epoch 120: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0621, Train Linf Norm: 84.5128, Test Linf Norm: 9.9400\n",
            "Epoch 121: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3565, Test L1 Norm: 0.0621, Train Linf Norm: 84.3211, Test Linf Norm: 9.9236\n",
            "Epoch 122: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0621, Train Linf Norm: 83.7555, Test Linf Norm: 9.9301\n",
            "Epoch 123: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3563, Test L1 Norm: 0.0621, Train Linf Norm: 84.3917, Test Linf Norm: 9.9225\n",
            "Epoch 124: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3561, Test L1 Norm: 0.0621, Train Linf Norm: 84.1869, Test Linf Norm: 9.9320\n",
            "Epoch 125: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3563, Test L1 Norm: 0.0621, Train Linf Norm: 84.2039, Test Linf Norm: 9.9273\n",
            "Epoch 126: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3563, Test L1 Norm: 0.0621, Train Linf Norm: 84.4902, Test Linf Norm: 9.9297\n",
            "Epoch 127: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3564, Test L1 Norm: 0.0621, Train Linf Norm: 84.5962, Test Linf Norm: 9.9265\n",
            "Epoch 128: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3563, Test L1 Norm: 0.0621, Train Linf Norm: 83.7190, Test Linf Norm: 9.9286\n",
            "Epoch 129: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3564, Test L1 Norm: 0.0621, Train Linf Norm: 84.6383, Test Linf Norm: 9.9318\n",
            "Epoch 130: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3565, Test L1 Norm: 0.0621, Train Linf Norm: 84.5634, Test Linf Norm: 9.9316\n",
            "Epoch 131: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3564, Test L1 Norm: 0.0621, Train Linf Norm: 84.4727, Test Linf Norm: 9.9316\n",
            "Epoch 132: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3564, Test L1 Norm: 0.0621, Train Linf Norm: 84.7398, Test Linf Norm: 9.9346\n",
            "Epoch 133: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3565, Test L1 Norm: 0.0621, Train Linf Norm: 84.8284, Test Linf Norm: 9.9329\n",
            "Epoch 134: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3565, Test L1 Norm: 0.0621, Train Linf Norm: 84.7457, Test Linf Norm: 9.9345\n",
            "Epoch 135: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3565, Test L1 Norm: 0.0621, Train Linf Norm: 84.2741, Test Linf Norm: 9.9350\n",
            "Epoch 136: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0621, Train Linf Norm: 84.3993, Test Linf Norm: 9.9353\n",
            "Epoch 137: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0621, Train Linf Norm: 81.8911, Test Linf Norm: 9.9353\n",
            "Epoch 138: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0621, Train Linf Norm: 84.8225, Test Linf Norm: 9.9362\n",
            "Epoch 139: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0621, Train Linf Norm: 83.2752, Test Linf Norm: 9.9370\n",
            "Epoch 140: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0621, Train Linf Norm: 84.5524, Test Linf Norm: 9.9370\n",
            "Epoch 141: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0622, Train Linf Norm: 84.8682, Test Linf Norm: 9.9370\n",
            "Epoch 142: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0622, Train Linf Norm: 76.2169, Test Linf Norm: 9.9376\n",
            "Epoch 143: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3566, Test L1 Norm: 0.0622, Train Linf Norm: 84.5136, Test Linf Norm: 9.9391\n",
            "Epoch 144: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0622, Train Linf Norm: 83.9578, Test Linf Norm: 9.9391\n",
            "Epoch 145: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0622, Train Linf Norm: 84.0565, Test Linf Norm: 9.9394\n",
            "Epoch 146: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0622, Train Linf Norm: 84.1180, Test Linf Norm: 9.9397\n",
            "Epoch 147: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0622, Train Linf Norm: 84.8911, Test Linf Norm: 9.9400\n",
            "Epoch 148: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0622, Train Linf Norm: 85.0350, Test Linf Norm: 9.9402\n",
            "Epoch 149: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0622, Train Linf Norm: 84.0574, Test Linf Norm: 9.9406\n",
            "Epoch 150: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0622, Train Linf Norm: 83.7284, Test Linf Norm: 9.9409\n",
            "Epoch 151: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0622, Train Linf Norm: 84.7091, Test Linf Norm: 9.9412\n",
            "Epoch 152: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0622, Train Linf Norm: 83.6986, Test Linf Norm: 9.9414\n",
            "Epoch 153: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3567, Test L1 Norm: 0.0622, Train Linf Norm: 84.4941, Test Linf Norm: 9.9416\n",
            "Epoch 154: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3568, Test L1 Norm: 0.0622, Train Linf Norm: 82.9141, Test Linf Norm: 9.9419\n",
            "Epoch 155: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3568, Test L1 Norm: 0.0622, Train Linf Norm: 84.8044, Test Linf Norm: 9.9422\n",
            "Epoch 156: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3568, Test L1 Norm: 0.0622, Train Linf Norm: 84.7291, Test Linf Norm: 9.9425\n",
            "Epoch 157: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3568, Test L1 Norm: 0.0622, Train Linf Norm: 84.1278, Test Linf Norm: 9.9429\n",
            "Epoch 158: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3568, Test L1 Norm: 0.0622, Train Linf Norm: 84.0150, Test Linf Norm: 9.9432\n",
            "Epoch 159: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3568, Test L1 Norm: 0.0622, Train Linf Norm: 84.5272, Test Linf Norm: 9.9434\n",
            "Epoch 160: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3568, Test L1 Norm: 0.0622, Train Linf Norm: 83.9246, Test Linf Norm: 9.9437\n",
            "Epoch 161: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3568, Test L1 Norm: 0.0622, Train Linf Norm: 84.4579, Test Linf Norm: 9.9440\n",
            "Epoch 162: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3568, Test L1 Norm: 0.0622, Train Linf Norm: 84.3796, Test Linf Norm: 9.9443\n",
            "Epoch 163: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 84.1390, Test Linf Norm: 9.9448\n",
            "Epoch 164: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 84.4799, Test Linf Norm: 9.9449\n",
            "Epoch 165: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 84.1264, Test Linf Norm: 9.9452\n",
            "Epoch 166: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 84.4490, Test Linf Norm: 9.9456\n",
            "Epoch 167: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 81.8388, Test Linf Norm: 9.9459\n",
            "Epoch 168: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 84.6177, Test Linf Norm: 9.9461\n",
            "Epoch 169: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 84.9396, Test Linf Norm: 9.9466\n",
            "Epoch 170: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 84.3489, Test Linf Norm: 9.9469\n",
            "Epoch 171: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 84.0834, Test Linf Norm: 9.9471\n",
            "Epoch 172: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 84.8341, Test Linf Norm: 9.9474\n",
            "Epoch 173: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3569, Test L1 Norm: 0.0622, Train Linf Norm: 84.1148, Test Linf Norm: 9.9477\n",
            "Epoch 174: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3570, Test L1 Norm: 0.0622, Train Linf Norm: 84.9114, Test Linf Norm: 9.9481\n",
            "Epoch 175: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3570, Test L1 Norm: 0.0622, Train Linf Norm: 84.1524, Test Linf Norm: 9.9483\n",
            "Epoch 176: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3570, Test L1 Norm: 0.0622, Train Linf Norm: 84.7025, Test Linf Norm: 9.9487\n",
            "Epoch 177: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3570, Test L1 Norm: 0.0622, Train Linf Norm: 85.0062, Test Linf Norm: 9.9490\n",
            "Epoch 178: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3570, Test L1 Norm: 0.0622, Train Linf Norm: 84.5480, Test Linf Norm: 9.9493\n",
            "Epoch 179: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3570, Test L1 Norm: 0.0622, Train Linf Norm: 84.0181, Test Linf Norm: 9.9496\n",
            "Epoch 180: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3570, Test L1 Norm: 0.0622, Train Linf Norm: 84.9100, Test Linf Norm: 9.9500\n",
            "Epoch 181: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3570, Test L1 Norm: 0.0622, Train Linf Norm: 84.3292, Test Linf Norm: 9.9503\n",
            "Epoch 182: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3570, Test L1 Norm: 0.0622, Train Linf Norm: 83.6374, Test Linf Norm: 9.9506\n",
            "Epoch 183: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3571, Test L1 Norm: 0.0622, Train Linf Norm: 84.7060, Test Linf Norm: 9.9510\n",
            "Epoch 184: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3571, Test L1 Norm: 0.0622, Train Linf Norm: 84.2882, Test Linf Norm: 9.9512\n",
            "Epoch 185: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3571, Test L1 Norm: 0.0622, Train Linf Norm: 83.1991, Test Linf Norm: 9.9516\n",
            "Epoch 186: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3571, Test L1 Norm: 0.0622, Train Linf Norm: 83.9573, Test Linf Norm: 9.9520\n",
            "Epoch 187: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3571, Test L1 Norm: 0.0622, Train Linf Norm: 82.4380, Test Linf Norm: 9.9522\n",
            "Epoch 188: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3571, Test L1 Norm: 0.0622, Train Linf Norm: 84.3636, Test Linf Norm: 9.9524\n",
            "Epoch 189: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3571, Test L1 Norm: 0.0622, Train Linf Norm: 84.3464, Test Linf Norm: 9.9528\n",
            "Epoch 190: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3571, Test L1 Norm: 0.0622, Train Linf Norm: 84.6940, Test Linf Norm: 9.9530\n",
            "Epoch 191: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3571, Test L1 Norm: 0.0622, Train Linf Norm: 84.1552, Test Linf Norm: 9.9534\n",
            "Epoch 192: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0622, Train Linf Norm: 84.4622, Test Linf Norm: 9.9538\n",
            "Epoch 193: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0622, Train Linf Norm: 84.4318, Test Linf Norm: 9.9542\n",
            "Epoch 194: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0622, Train Linf Norm: 83.4577, Test Linf Norm: 9.9545\n",
            "Epoch 195: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0622, Train Linf Norm: 84.5602, Test Linf Norm: 9.9548\n",
            "Epoch 196: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0622, Train Linf Norm: 85.1283, Test Linf Norm: 9.9550\n",
            "Epoch 197: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0622, Train Linf Norm: 84.3475, Test Linf Norm: 9.9554\n",
            "Epoch 198: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0622, Train Linf Norm: 83.6965, Test Linf Norm: 9.9557\n",
            "Epoch 199: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0622, Train Linf Norm: 84.6188, Test Linf Norm: 9.9560\n",
            "Epoch 200: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0623, Train Linf Norm: 84.8621, Test Linf Norm: 9.9563\n",
            "Epoch 201: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3572, Test L1 Norm: 0.0623, Train Linf Norm: 84.9973, Test Linf Norm: 9.9566\n",
            "Epoch 202: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3573, Test L1 Norm: 0.0623, Train Linf Norm: 83.9564, Test Linf Norm: 9.9570\n",
            "Epoch 203: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3573, Test L1 Norm: 0.0623, Train Linf Norm: 85.2480, Test Linf Norm: 9.9572\n",
            "Epoch 204: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3573, Test L1 Norm: 0.0623, Train Linf Norm: 84.8085, Test Linf Norm: 9.9575\n",
            "Epoch 205: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3573, Test L1 Norm: 0.0623, Train Linf Norm: 84.6802, Test Linf Norm: 9.9579\n",
            "Epoch 206: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3573, Test L1 Norm: 0.0623, Train Linf Norm: 85.1687, Test Linf Norm: 9.9581\n",
            "Epoch 207: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3573, Test L1 Norm: 0.0623, Train Linf Norm: 84.8627, Test Linf Norm: 9.9585\n",
            "Epoch 208: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3573, Test L1 Norm: 0.0623, Train Linf Norm: 81.6810, Test Linf Norm: 9.9588\n",
            "Epoch 209: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3573, Test L1 Norm: 0.0623, Train Linf Norm: 84.8694, Test Linf Norm: 9.9592\n",
            "Epoch 210: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3573, Test L1 Norm: 0.0623, Train Linf Norm: 84.9638, Test Linf Norm: 9.9595\n",
            "Epoch 211: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3574, Test L1 Norm: 0.0623, Train Linf Norm: 84.9644, Test Linf Norm: 9.9597\n",
            "Epoch 212: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3574, Test L1 Norm: 0.0623, Train Linf Norm: 84.4632, Test Linf Norm: 9.9602\n",
            "Epoch 213: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3574, Test L1 Norm: 0.0623, Train Linf Norm: 84.8939, Test Linf Norm: 9.9603\n",
            "Epoch 214: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3574, Test L1 Norm: 0.0623, Train Linf Norm: 84.9357, Test Linf Norm: 9.9608\n",
            "Epoch 215: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3574, Test L1 Norm: 0.0623, Train Linf Norm: 84.3761, Test Linf Norm: 9.9611\n",
            "Epoch 216: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3574, Test L1 Norm: 0.0623, Train Linf Norm: 84.9143, Test Linf Norm: 9.9614\n",
            "Epoch 217: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3574, Test L1 Norm: 0.0623, Train Linf Norm: 84.1062, Test Linf Norm: 9.9617\n",
            "Epoch 218: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3574, Test L1 Norm: 0.0623, Train Linf Norm: 84.7534, Test Linf Norm: 9.9620\n",
            "Epoch 219: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3574, Test L1 Norm: 0.0623, Train Linf Norm: 84.8487, Test Linf Norm: 9.9625\n",
            "Epoch 220: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3574, Test L1 Norm: 0.0623, Train Linf Norm: 84.9593, Test Linf Norm: 9.9628\n",
            "Epoch 221: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3575, Test L1 Norm: 0.0623, Train Linf Norm: 83.4435, Test Linf Norm: 9.9631\n",
            "Epoch 222: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3575, Test L1 Norm: 0.0623, Train Linf Norm: 84.4098, Test Linf Norm: 9.9633\n",
            "Epoch 223: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3575, Test L1 Norm: 0.0623, Train Linf Norm: 84.9017, Test Linf Norm: 9.9636\n",
            "Epoch 224: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3575, Test L1 Norm: 0.0623, Train Linf Norm: 85.0986, Test Linf Norm: 9.9640\n",
            "Epoch 225: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3575, Test L1 Norm: 0.0623, Train Linf Norm: 84.6689, Test Linf Norm: 9.9643\n",
            "Epoch 226: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3575, Test L1 Norm: 0.0623, Train Linf Norm: 84.4489, Test Linf Norm: 9.9646\n",
            "Epoch 227: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3575, Test L1 Norm: 0.0623, Train Linf Norm: 84.8807, Test Linf Norm: 9.9649\n",
            "Epoch 228: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3575, Test L1 Norm: 0.0623, Train Linf Norm: 85.0174, Test Linf Norm: 9.9653\n",
            "Epoch 229: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3576, Test L1 Norm: 0.0623, Train Linf Norm: 84.5001, Test Linf Norm: 9.9657\n",
            "Epoch 230: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3576, Test L1 Norm: 0.0623, Train Linf Norm: 84.0557, Test Linf Norm: 9.9660\n",
            "Epoch 231: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3576, Test L1 Norm: 0.0623, Train Linf Norm: 84.7800, Test Linf Norm: 9.9663\n",
            "Epoch 232: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3576, Test L1 Norm: 0.0623, Train Linf Norm: 84.1573, Test Linf Norm: 9.9666\n",
            "Epoch 233: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3576, Test L1 Norm: 0.0623, Train Linf Norm: 84.1682, Test Linf Norm: 9.9670\n",
            "Epoch 234: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3576, Test L1 Norm: 0.0623, Train Linf Norm: 85.0979, Test Linf Norm: 9.9672\n",
            "Epoch 235: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3576, Test L1 Norm: 0.0623, Train Linf Norm: 84.8530, Test Linf Norm: 9.9676\n",
            "Epoch 236: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3576, Test L1 Norm: 0.0623, Train Linf Norm: 84.4067, Test Linf Norm: 9.9680\n",
            "Epoch 237: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3576, Test L1 Norm: 0.0623, Train Linf Norm: 84.7507, Test Linf Norm: 9.9683\n",
            "Epoch 238: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3576, Test L1 Norm: 0.0623, Train Linf Norm: 84.6052, Test Linf Norm: 9.9686\n",
            "Epoch 239: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3577, Test L1 Norm: 0.0623, Train Linf Norm: 84.7219, Test Linf Norm: 9.9690\n",
            "Epoch 240: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3577, Test L1 Norm: 0.0623, Train Linf Norm: 84.5672, Test Linf Norm: 9.9693\n",
            "Epoch 241: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3577, Test L1 Norm: 0.0623, Train Linf Norm: 84.3795, Test Linf Norm: 9.9697\n",
            "Epoch 242: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3577, Test L1 Norm: 0.0623, Train Linf Norm: 84.9160, Test Linf Norm: 9.9700\n",
            "Epoch 243: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3577, Test L1 Norm: 0.0623, Train Linf Norm: 84.7121, Test Linf Norm: 9.9702\n",
            "Epoch 244: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3577, Test L1 Norm: 0.0623, Train Linf Norm: 84.5037, Test Linf Norm: 9.9706\n",
            "Epoch 245: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3577, Test L1 Norm: 0.0623, Train Linf Norm: 84.8209, Test Linf Norm: 9.9709\n",
            "Epoch 246: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3577, Test L1 Norm: 0.0623, Train Linf Norm: 84.5596, Test Linf Norm: 9.9713\n",
            "Epoch 247: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3577, Test L1 Norm: 0.0623, Train Linf Norm: 84.3637, Test Linf Norm: 9.9715\n",
            "Epoch 248: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3578, Test L1 Norm: 0.0623, Train Linf Norm: 84.6472, Test Linf Norm: 9.9719\n",
            "Epoch 249: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3578, Test L1 Norm: 0.0623, Train Linf Norm: 84.6943, Test Linf Norm: 9.9722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 10:25:51,442]\u001b[0m Trial 0 finished with value: 0.062339425717294214 and parameters: {'n_layers': 9, 'n_units_0': 1656, 'n_units_1': 1582, 'n_units_2': 539, 'n_units_3': 452, 'n_units_4': 200, 'n_units_5': 1374, 'n_units_6': 1792, 'n_units_7': 1787, 'n_units_8': 474, 'hidden_activation': 'LeakyReLU', 'output_activation': 'Linear', 'loss': 'Huber', 'optimizer': 'Adam', 'lr': 0.003825285106667675, 'batch_size': 256, 'n_epochs': 250, 'scheduler': 'ReduceLROnPlateau', 'weight_decay': 0.0006540321056213948, 'beta1': 0.9738416778575902, 'beta2': 0.9995537136033149, 'factor': 0.21645743059262365, 'patience': 9, 'threshold': 0.002219756483586792}. Best is trial 0 with value: 0.062339425717294214.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 250: Train Loss: 0.0002, Test Loss: 0.0003, Train L1 Norm: 0.3578, Test L1 Norm: 0.0623, Train Linf Norm: 84.9343, Test Linf Norm: 9.9725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-82e2252adf92>:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)\n",
            "<ipython-input-60-82e2252adf92>:122: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  momentum = trial.suggest_uniform(\"momentum\", 0.0, 0.99)\n",
            "<ipython-input-60-82e2252adf92>:139: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  gamma = trial.suggest_uniform(\"gamma\", 0.1, 0.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.4697, Test Loss: 0.2696, Train L1 Norm: 0.9047, Test L1 Norm: 0.1318, Train Linf Norm: 41.7568, Test Linf Norm: 2.6736\n",
            "Epoch 2: Train Loss: 0.1740, Test Loss: 0.1165, Train L1 Norm: 0.3399, Test L1 Norm: 0.5152, Train Linf Norm: 15.5307, Test Linf Norm: 20.5868\n",
            "Epoch 3: Train Loss: 0.1487, Test Loss: 0.1192, Train L1 Norm: 1.4499, Test L1 Norm: 0.2152, Train Linf Norm: 87.2778, Test Linf Norm: 7.8948\n",
            "Epoch 4: Train Loss: 0.1330, Test Loss: 0.2813, Train L1 Norm: 0.2728, Test L1 Norm: 0.2199, Train Linf Norm: 12.5479, Test Linf Norm: 7.8287\n",
            "Epoch 5: Train Loss: 0.1085, Test Loss: 0.0615, Train L1 Norm: 0.1337, Test L1 Norm: 0.1786, Train Linf Norm: 4.2297, Test Linf Norm: 6.9598\n",
            "Epoch 6: Train Loss: 0.0937, Test Loss: 0.1095, Train L1 Norm: 0.1622, Test L1 Norm: 0.3911, Train Linf Norm: 6.0169, Test Linf Norm: 14.5270\n",
            "Epoch 7: Train Loss: 0.0974, Test Loss: 0.0915, Train L1 Norm: 0.7948, Test L1 Norm: 0.1597, Train Linf Norm: 46.7556, Test Linf Norm: 5.4363\n",
            "Epoch 8: Train Loss: 0.0856, Test Loss: 0.2472, Train L1 Norm: 0.3923, Test L1 Norm: 0.1375, Train Linf Norm: 21.5236, Test Linf Norm: 4.3016\n",
            "Epoch 9: Train Loss: 0.1046, Test Loss: 0.0488, Train L1 Norm: 0.5781, Test L1 Norm: 0.0561, Train Linf Norm: 32.6249, Test Linf Norm: 1.0086\n",
            "Epoch 10: Train Loss: 0.0819, Test Loss: 0.0352, Train L1 Norm: 0.1547, Test L1 Norm: 0.0459, Train Linf Norm: 6.1687, Test Linf Norm: 0.8502\n",
            "Epoch 11: Train Loss: 0.0842, Test Loss: 0.1121, Train L1 Norm: 0.3820, Test L1 Norm: 0.1103, Train Linf Norm: 20.3309, Test Linf Norm: 0.9804\n",
            "Epoch 12: Train Loss: 0.0763, Test Loss: 0.1755, Train L1 Norm: 0.1278, Test L1 Norm: 0.2651, Train Linf Norm: 4.5122, Test Linf Norm: 10.5880\n",
            "Epoch 13: Train Loss: 0.0689, Test Loss: 0.0615, Train L1 Norm: 0.1607, Test L1 Norm: 0.1434, Train Linf Norm: 6.9959, Test Linf Norm: 5.8497\n",
            "Epoch 14: Train Loss: 0.0279, Test Loss: 0.0259, Train L1 Norm: 0.0595, Test L1 Norm: 0.0267, Train Linf Norm: 2.2274, Test Linf Norm: 0.6453\n",
            "Epoch 15: Train Loss: 0.0266, Test Loss: 0.0295, Train L1 Norm: 0.2109, Test L1 Norm: 0.0411, Train Linf Norm: 11.9424, Test Linf Norm: 0.8148\n",
            "Epoch 16: Train Loss: 0.0244, Test Loss: 0.0177, Train L1 Norm: 0.1108, Test L1 Norm: 0.0228, Train Linf Norm: 5.6552, Test Linf Norm: 0.5545\n",
            "Epoch 17: Train Loss: 0.0273, Test Loss: 0.0128, Train L1 Norm: 0.0727, Test L1 Norm: 0.0227, Train Linf Norm: 3.0305, Test Linf Norm: 0.5590\n",
            "Epoch 18: Train Loss: 0.0246, Test Loss: 0.0250, Train L1 Norm: 0.0483, Test L1 Norm: 0.0230, Train Linf Norm: 1.6878, Test Linf Norm: 0.5866\n",
            "Epoch 19: Train Loss: 0.0278, Test Loss: 0.0208, Train L1 Norm: 0.2416, Test L1 Norm: 0.0273, Train Linf Norm: 14.0143, Test Linf Norm: 0.6222\n",
            "Epoch 20: Train Loss: 0.0232, Test Loss: 0.0137, Train L1 Norm: 0.1671, Test L1 Norm: 0.0501, Train Linf Norm: 9.2665, Test Linf Norm: 2.0132\n",
            "Epoch 21: Train Loss: 0.0245, Test Loss: 0.0435, Train L1 Norm: 0.1048, Test L1 Norm: 0.0499, Train Linf Norm: 5.2935, Test Linf Norm: 1.8063\n",
            "Epoch 22: Train Loss: 0.0272, Test Loss: 0.0151, Train L1 Norm: 0.0899, Test L1 Norm: 0.0295, Train Linf Norm: 4.2670, Test Linf Norm: 0.6835\n",
            "Epoch 23: Train Loss: 0.0235, Test Loss: 0.0192, Train L1 Norm: 0.0888, Test L1 Norm: 0.0215, Train Linf Norm: 4.3037, Test Linf Norm: 0.5376\n",
            "Epoch 24: Train Loss: 0.0250, Test Loss: 0.0144, Train L1 Norm: 0.0571, Test L1 Norm: 0.0212, Train Linf Norm: 2.3076, Test Linf Norm: 0.4915\n",
            "Epoch 25: Train Loss: 0.0216, Test Loss: 0.0102, Train L1 Norm: 0.1089, Test L1 Norm: 0.0183, Train Linf Norm: 5.7392, Test Linf Norm: 0.5669\n",
            "Epoch 26: Train Loss: 0.0246, Test Loss: 0.0121, Train L1 Norm: 0.0529, Test L1 Norm: 0.0228, Train Linf Norm: 2.0249, Test Linf Norm: 0.5230\n",
            "Epoch 27: Train Loss: 0.0106, Test Loss: 0.0079, Train L1 Norm: 0.0638, Test L1 Norm: 0.0212, Train Linf Norm: 3.3669, Test Linf Norm: 0.5683\n",
            "Epoch 28: Train Loss: 0.0112, Test Loss: 0.0069, Train L1 Norm: 0.0698, Test L1 Norm: 0.0160, Train Linf Norm: 3.7512, Test Linf Norm: 0.4391\n",
            "Epoch 29: Train Loss: 0.0089, Test Loss: 0.0094, Train L1 Norm: 0.1081, Test L1 Norm: 0.0150, Train Linf Norm: 6.2587, Test Linf Norm: 0.4084\n",
            "Epoch 30: Train Loss: 0.0093, Test Loss: 0.0110, Train L1 Norm: 0.0743, Test L1 Norm: 0.0284, Train Linf Norm: 4.1078, Test Linf Norm: 0.6599\n",
            "Epoch 31: Train Loss: 0.0113, Test Loss: 0.0254, Train L1 Norm: 0.1196, Test L1 Norm: 0.0413, Train Linf Norm: 6.9549, Test Linf Norm: 1.4719\n",
            "Epoch 32: Train Loss: 0.0092, Test Loss: 0.0073, Train L1 Norm: 0.0390, Test L1 Norm: 0.0185, Train Linf Norm: 1.7900, Test Linf Norm: 0.6534\n",
            "Epoch 33: Train Loss: 0.0093, Test Loss: 0.0137, Train L1 Norm: 0.0553, Test L1 Norm: 0.0193, Train Linf Norm: 2.8717, Test Linf Norm: 0.6468\n",
            "Epoch 34: Train Loss: 0.0097, Test Loss: 0.0128, Train L1 Norm: 0.0537, Test L1 Norm: 0.0182, Train Linf Norm: 2.7662, Test Linf Norm: 0.4980\n",
            "Epoch 35: Train Loss: 0.0100, Test Loss: 0.0093, Train L1 Norm: 0.0803, Test L1 Norm: 0.0157, Train Linf Norm: 4.4891, Test Linf Norm: 0.5231\n",
            "Epoch 36: Train Loss: 0.0086, Test Loss: 0.0073, Train L1 Norm: 0.0510, Test L1 Norm: 0.0165, Train Linf Norm: 2.6319, Test Linf Norm: 0.5535\n",
            "Epoch 37: Train Loss: 0.0086, Test Loss: 0.0094, Train L1 Norm: 0.1058, Test L1 Norm: 0.0222, Train Linf Norm: 6.1382, Test Linf Norm: 0.5747\n",
            "Epoch 38: Train Loss: 0.0086, Test Loss: 0.0076, Train L1 Norm: 0.0526, Test L1 Norm: 0.0198, Train Linf Norm: 2.7356, Test Linf Norm: 0.5250\n",
            "Epoch 39: Train Loss: 0.0084, Test Loss: 0.0125, Train L1 Norm: 0.0692, Test L1 Norm: 0.0172, Train Linf Norm: 3.8480, Test Linf Norm: 0.5817\n",
            "Epoch 40: Train Loss: 0.0052, Test Loss: 0.0069, Train L1 Norm: 0.0973, Test L1 Norm: 0.0138, Train Linf Norm: 5.7704, Test Linf Norm: 0.4085\n",
            "Epoch 41: Train Loss: 0.0053, Test Loss: 0.0044, Train L1 Norm: 0.0441, Test L1 Norm: 0.0117, Train Linf Norm: 2.3752, Test Linf Norm: 0.3791\n",
            "Epoch 42: Train Loss: 0.0049, Test Loss: 0.0048, Train L1 Norm: 0.0603, Test L1 Norm: 0.0134, Train Linf Norm: 3.4117, Test Linf Norm: 0.4525\n",
            "Epoch 43: Train Loss: 0.0050, Test Loss: 0.0044, Train L1 Norm: 0.0615, Test L1 Norm: 0.0173, Train Linf Norm: 3.4668, Test Linf Norm: 0.6719\n",
            "Epoch 44: Train Loss: 0.0051, Test Loss: 0.0045, Train L1 Norm: 0.0482, Test L1 Norm: 0.0123, Train Linf Norm: 2.6492, Test Linf Norm: 0.3923\n",
            "Epoch 45: Train Loss: 0.0049, Test Loss: 0.0067, Train L1 Norm: 0.0463, Test L1 Norm: 0.0137, Train Linf Norm: 2.5176, Test Linf Norm: 0.4133\n",
            "Epoch 46: Train Loss: 0.0049, Test Loss: 0.0048, Train L1 Norm: 0.0459, Test L1 Norm: 0.0117, Train Linf Norm: 2.4849, Test Linf Norm: 0.3396\n",
            "Epoch 47: Train Loss: 0.0050, Test Loss: 0.0062, Train L1 Norm: 0.0464, Test L1 Norm: 0.0164, Train Linf Norm: 2.5281, Test Linf Norm: 0.4614\n",
            "Epoch 48: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0557, Test L1 Norm: 0.0121, Train Linf Norm: 3.1241, Test Linf Norm: 0.4065\n",
            "Epoch 49: Train Loss: 0.0047, Test Loss: 0.0057, Train L1 Norm: 0.0660, Test L1 Norm: 0.0127, Train Linf Norm: 3.7904, Test Linf Norm: 0.4361\n",
            "Epoch 50: Train Loss: 0.0050, Test Loss: 0.0042, Train L1 Norm: 0.0414, Test L1 Norm: 0.0127, Train Linf Norm: 2.1941, Test Linf Norm: 0.4390\n",
            "Epoch 51: Train Loss: 0.0048, Test Loss: 0.0039, Train L1 Norm: 0.0352, Test L1 Norm: 0.0118, Train Linf Norm: 1.8237, Test Linf Norm: 0.4066\n",
            "Epoch 52: Train Loss: 0.0050, Test Loss: 0.0050, Train L1 Norm: 0.0850, Test L1 Norm: 0.0133, Train Linf Norm: 5.0079, Test Linf Norm: 0.4492\n",
            "Epoch 53: Train Loss: 0.0038, Test Loss: 0.0038, Train L1 Norm: 0.0495, Test L1 Norm: 0.0108, Train Linf Norm: 2.7774, Test Linf Norm: 0.3396\n",
            "Epoch 54: Train Loss: 0.0037, Test Loss: 0.0037, Train L1 Norm: 0.0562, Test L1 Norm: 0.0123, Train Linf Norm: 3.2141, Test Linf Norm: 0.4399\n",
            "Epoch 55: Train Loss: 0.0038, Test Loss: 0.0039, Train L1 Norm: 0.0686, Test L1 Norm: 0.0122, Train Linf Norm: 4.0105, Test Linf Norm: 0.4339\n",
            "Epoch 56: Train Loss: 0.0038, Test Loss: 0.0035, Train L1 Norm: 0.0627, Test L1 Norm: 0.0107, Train Linf Norm: 3.6159, Test Linf Norm: 0.3557\n",
            "Epoch 57: Train Loss: 0.0039, Test Loss: 0.0039, Train L1 Norm: 0.0645, Test L1 Norm: 0.0107, Train Linf Norm: 3.7473, Test Linf Norm: 0.3533\n",
            "Epoch 58: Train Loss: 0.0038, Test Loss: 0.0038, Train L1 Norm: 0.0406, Test L1 Norm: 0.0115, Train Linf Norm: 2.2101, Test Linf Norm: 0.3977\n",
            "Epoch 59: Train Loss: 0.0037, Test Loss: 0.0036, Train L1 Norm: 0.0642, Test L1 Norm: 0.0108, Train Linf Norm: 3.7295, Test Linf Norm: 0.3570\n",
            "Epoch 60: Train Loss: 0.0037, Test Loss: 0.0035, Train L1 Norm: 0.0514, Test L1 Norm: 0.0112, Train Linf Norm: 2.9146, Test Linf Norm: 0.3821\n",
            "Epoch 61: Train Loss: 0.0038, Test Loss: 0.0037, Train L1 Norm: 0.0509, Test L1 Norm: 0.0112, Train Linf Norm: 2.8773, Test Linf Norm: 0.3817\n",
            "Epoch 62: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0610, Test L1 Norm: 0.0105, Train Linf Norm: 3.5318, Test Linf Norm: 0.3404\n",
            "Epoch 63: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0450, Test L1 Norm: 0.0107, Train Linf Norm: 2.4899, Test Linf Norm: 0.3447\n",
            "Epoch 64: Train Loss: 0.0036, Test Loss: 0.0036, Train L1 Norm: 0.0540, Test L1 Norm: 0.0118, Train Linf Norm: 3.0766, Test Linf Norm: 0.4106\n",
            "Epoch 65: Train Loss: 0.0037, Test Loss: 0.0041, Train L1 Norm: 0.0386, Test L1 Norm: 0.0105, Train Linf Norm: 2.0843, Test Linf Norm: 0.3413\n",
            "Epoch 66: Train Loss: 0.0034, Test Loss: 0.0037, Train L1 Norm: 0.0524, Test L1 Norm: 0.0115, Train Linf Norm: 2.9725, Test Linf Norm: 0.4021\n",
            "Epoch 67: Train Loss: 0.0034, Test Loss: 0.0035, Train L1 Norm: 0.0549, Test L1 Norm: 0.0114, Train Linf Norm: 3.1505, Test Linf Norm: 0.3954\n",
            "Epoch 68: Train Loss: 0.0034, Test Loss: 0.0034, Train L1 Norm: 0.0489, Test L1 Norm: 0.0110, Train Linf Norm: 2.7603, Test Linf Norm: 0.3803\n",
            "Epoch 69: Train Loss: 0.0034, Test Loss: 0.0034, Train L1 Norm: 0.0540, Test L1 Norm: 0.0111, Train Linf Norm: 3.0871, Test Linf Norm: 0.3839\n",
            "Epoch 70: Train Loss: 0.0034, Test Loss: 0.0034, Train L1 Norm: 0.0592, Test L1 Norm: 0.0109, Train Linf Norm: 3.4328, Test Linf Norm: 0.3740\n",
            "Epoch 71: Train Loss: 0.0034, Test Loss: 0.0034, Train L1 Norm: 0.0511, Test L1 Norm: 0.0111, Train Linf Norm: 2.9055, Test Linf Norm: 0.3848\n",
            "Epoch 72: Train Loss: 0.0034, Test Loss: 0.0034, Train L1 Norm: 0.0590, Test L1 Norm: 0.0111, Train Linf Norm: 3.4054, Test Linf Norm: 0.3863\n",
            "Epoch 73: Train Loss: 0.0034, Test Loss: 0.0035, Train L1 Norm: 0.0534, Test L1 Norm: 0.0109, Train Linf Norm: 3.0572, Test Linf Norm: 0.3732\n",
            "Epoch 74: Train Loss: 0.0034, Test Loss: 0.0035, Train L1 Norm: 0.0497, Test L1 Norm: 0.0111, Train Linf Norm: 2.8223, Test Linf Norm: 0.3865\n",
            "Epoch 75: Train Loss: 0.0034, Test Loss: 0.0035, Train L1 Norm: 0.0537, Test L1 Norm: 0.0104, Train Linf Norm: 3.0734, Test Linf Norm: 0.3411\n",
            "Epoch 76: Train Loss: 0.0034, Test Loss: 0.0036, Train L1 Norm: 0.0398, Test L1 Norm: 0.0112, Train Linf Norm: 2.1869, Test Linf Norm: 0.3875\n",
            "Epoch 77: Train Loss: 0.0034, Test Loss: 0.0034, Train L1 Norm: 0.0575, Test L1 Norm: 0.0106, Train Linf Norm: 3.3181, Test Linf Norm: 0.3584\n",
            "Epoch 78: Train Loss: 0.0034, Test Loss: 0.0034, Train L1 Norm: 0.0578, Test L1 Norm: 0.0107, Train Linf Norm: 3.3417, Test Linf Norm: 0.3598\n",
            "Epoch 79: Train Loss: 0.0033, Test Loss: 0.0034, Train L1 Norm: 0.0507, Test L1 Norm: 0.0111, Train Linf Norm: 2.8857, Test Linf Norm: 0.3831\n",
            "Epoch 80: Train Loss: 0.0033, Test Loss: 0.0033, Train L1 Norm: 0.0499, Test L1 Norm: 0.0107, Train Linf Norm: 2.8290, Test Linf Norm: 0.3652\n",
            "Epoch 81: Train Loss: 0.0033, Test Loss: 0.0034, Train L1 Norm: 0.0528, Test L1 Norm: 0.0107, Train Linf Norm: 3.0272, Test Linf Norm: 0.3648\n",
            "Epoch 82: Train Loss: 0.0033, Test Loss: 0.0033, Train L1 Norm: 0.0581, Test L1 Norm: 0.0107, Train Linf Norm: 3.3586, Test Linf Norm: 0.3656\n",
            "Epoch 83: Train Loss: 0.0033, Test Loss: 0.0035, Train L1 Norm: 0.0501, Test L1 Norm: 0.0110, Train Linf Norm: 2.8461, Test Linf Norm: 0.3780\n",
            "Epoch 84: Train Loss: 0.0033, Test Loss: 0.0034, Train L1 Norm: 0.0539, Test L1 Norm: 0.0109, Train Linf Norm: 3.0834, Test Linf Norm: 0.3751\n",
            "Epoch 85: Train Loss: 0.0032, Test Loss: 0.0034, Train L1 Norm: 0.0540, Test L1 Norm: 0.0107, Train Linf Norm: 3.1006, Test Linf Norm: 0.3616\n",
            "Epoch 86: Train Loss: 0.0032, Test Loss: 0.0034, Train L1 Norm: 0.0550, Test L1 Norm: 0.0112, Train Linf Norm: 3.1648, Test Linf Norm: 0.3905\n",
            "Epoch 87: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0578, Test L1 Norm: 0.0116, Train Linf Norm: 3.3437, Test Linf Norm: 0.4140\n",
            "Epoch 88: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0517, Test L1 Norm: 0.0114, Train Linf Norm: 2.9477, Test Linf Norm: 0.4003\n",
            "Epoch 89: Train Loss: 0.0032, Test Loss: 0.0034, Train L1 Norm: 0.0514, Test L1 Norm: 0.0107, Train Linf Norm: 2.9288, Test Linf Norm: 0.3643\n",
            "Epoch 90: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0544, Test L1 Norm: 0.0110, Train Linf Norm: 3.1276, Test Linf Norm: 0.3814\n",
            "Epoch 91: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0562, Test L1 Norm: 0.0104, Train Linf Norm: 3.2462, Test Linf Norm: 0.3488\n",
            "Epoch 92: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0498, Test L1 Norm: 0.0109, Train Linf Norm: 2.8297, Test Linf Norm: 0.3735\n",
            "Epoch 93: Train Loss: 0.0032, Test Loss: 0.0034, Train L1 Norm: 0.0527, Test L1 Norm: 0.0107, Train Linf Norm: 3.0204, Test Linf Norm: 0.3651\n",
            "Epoch 94: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0554, Test L1 Norm: 0.0109, Train Linf Norm: 3.1878, Test Linf Norm: 0.3738\n",
            "Epoch 95: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0543, Test L1 Norm: 0.0107, Train Linf Norm: 3.1233, Test Linf Norm: 0.3636\n",
            "Epoch 96: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0527, Test L1 Norm: 0.0107, Train Linf Norm: 3.0140, Test Linf Norm: 0.3647\n",
            "Epoch 97: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0526, Test L1 Norm: 0.0109, Train Linf Norm: 3.0059, Test Linf Norm: 0.3767\n",
            "Epoch 98: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0538, Test L1 Norm: 0.0108, Train Linf Norm: 3.0893, Test Linf Norm: 0.3714\n",
            "Epoch 99: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0505, Test L1 Norm: 0.0108, Train Linf Norm: 2.8677, Test Linf Norm: 0.3721\n",
            "Epoch 100: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0513, Test L1 Norm: 0.0108, Train Linf Norm: 2.9222, Test Linf Norm: 0.3722\n",
            "Epoch 101: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0513, Test L1 Norm: 0.0110, Train Linf Norm: 2.9303, Test Linf Norm: 0.3822\n",
            "Epoch 102: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0506, Test L1 Norm: 0.0109, Train Linf Norm: 2.8879, Test Linf Norm: 0.3753\n",
            "Epoch 103: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0546, Test L1 Norm: 0.0109, Train Linf Norm: 3.1399, Test Linf Norm: 0.3748\n",
            "Epoch 104: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0516, Test L1 Norm: 0.0111, Train Linf Norm: 2.9503, Test Linf Norm: 0.3891\n",
            "Epoch 105: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0520, Test L1 Norm: 0.0109, Train Linf Norm: 2.9740, Test Linf Norm: 0.3754\n",
            "Epoch 106: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0535, Test L1 Norm: 0.0108, Train Linf Norm: 3.0679, Test Linf Norm: 0.3687\n",
            "Epoch 107: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0528, Test L1 Norm: 0.0109, Train Linf Norm: 3.0242, Test Linf Norm: 0.3762\n",
            "Epoch 108: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0523, Test L1 Norm: 0.0109, Train Linf Norm: 2.9935, Test Linf Norm: 0.3737\n",
            "Epoch 109: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0534, Test L1 Norm: 0.0108, Train Linf Norm: 3.0598, Test Linf Norm: 0.3714\n",
            "Epoch 110: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0526, Test L1 Norm: 0.0109, Train Linf Norm: 3.0028, Test Linf Norm: 0.3758\n",
            "Epoch 111: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0529, Test L1 Norm: 0.0108, Train Linf Norm: 3.0099, Test Linf Norm: 0.3713\n",
            "Epoch 112: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0517, Test L1 Norm: 0.0107, Train Linf Norm: 2.9554, Test Linf Norm: 0.3671\n",
            "Epoch 113: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0522, Test L1 Norm: 0.0108, Train Linf Norm: 2.9907, Test Linf Norm: 0.3728\n",
            "Epoch 114: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0522, Test L1 Norm: 0.0110, Train Linf Norm: 2.9769, Test Linf Norm: 0.3800\n",
            "Epoch 115: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0108, Train Linf Norm: 3.0051, Test Linf Norm: 0.3730\n",
            "Epoch 116: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0538, Test L1 Norm: 0.0108, Train Linf Norm: 3.0874, Test Linf Norm: 0.3716\n",
            "Epoch 117: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0527, Test L1 Norm: 0.0109, Train Linf Norm: 3.0193, Test Linf Norm: 0.3764\n",
            "Epoch 118: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0535, Test L1 Norm: 0.0109, Train Linf Norm: 3.0733, Test Linf Norm: 0.3755\n",
            "Epoch 119: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0522, Test L1 Norm: 0.0109, Train Linf Norm: 2.9857, Test Linf Norm: 0.3765\n",
            "Epoch 120: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0526, Test L1 Norm: 0.0108, Train Linf Norm: 3.0045, Test Linf Norm: 0.3713\n",
            "Epoch 121: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0521, Test L1 Norm: 0.0109, Train Linf Norm: 2.9825, Test Linf Norm: 0.3739\n",
            "Epoch 122: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0519, Test L1 Norm: 0.0109, Train Linf Norm: 2.9671, Test Linf Norm: 0.3749\n",
            "Epoch 123: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0527, Test L1 Norm: 0.0109, Train Linf Norm: 3.0149, Test Linf Norm: 0.3772\n",
            "Epoch 124: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0527, Test L1 Norm: 0.0109, Train Linf Norm: 3.0184, Test Linf Norm: 0.3751\n",
            "Epoch 125: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0521, Test L1 Norm: 0.0109, Train Linf Norm: 2.9880, Test Linf Norm: 0.3739\n",
            "Epoch 126: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9976, Test Linf Norm: 0.3743\n",
            "Epoch 127: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0521, Test L1 Norm: 0.0109, Train Linf Norm: 2.9661, Test Linf Norm: 0.3772\n",
            "Epoch 128: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0108, Train Linf Norm: 3.0075, Test Linf Norm: 0.3728\n",
            "Epoch 129: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0526, Test L1 Norm: 0.0108, Train Linf Norm: 3.0087, Test Linf Norm: 0.3734\n",
            "Epoch 130: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0525, Test L1 Norm: 0.0109, Train Linf Norm: 3.0048, Test Linf Norm: 0.3756\n",
            "Epoch 131: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0525, Test L1 Norm: 0.0109, Train Linf Norm: 3.0147, Test Linf Norm: 0.3749\n",
            "Epoch 132: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9917, Test Linf Norm: 0.3751\n",
            "Epoch 133: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9932, Test Linf Norm: 0.3743\n",
            "Epoch 134: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0522, Test L1 Norm: 0.0108, Train Linf Norm: 2.9885, Test Linf Norm: 0.3736\n",
            "Epoch 135: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9994, Test Linf Norm: 0.3740\n",
            "Epoch 136: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9921, Test Linf Norm: 0.3753\n",
            "Epoch 137: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9986, Test Linf Norm: 0.3738\n",
            "Epoch 138: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0522, Test L1 Norm: 0.0109, Train Linf Norm: 2.9783, Test Linf Norm: 0.3745\n",
            "Epoch 139: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0523, Test L1 Norm: 0.0108, Train Linf Norm: 2.9869, Test Linf Norm: 0.3737\n",
            "Epoch 140: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9842, Test Linf Norm: 0.3742\n",
            "Epoch 141: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0523, Test L1 Norm: 0.0108, Train Linf Norm: 2.9917, Test Linf Norm: 0.3735\n",
            "Epoch 142: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0523, Test L1 Norm: 0.0109, Train Linf Norm: 2.9893, Test Linf Norm: 0.3740\n",
            "Epoch 143: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0010, Test Linf Norm: 0.3741\n",
            "Epoch 144: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9969, Test Linf Norm: 0.3741\n",
            "Epoch 145: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9994, Test Linf Norm: 0.3741\n",
            "Epoch 146: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9905, Test Linf Norm: 0.3742\n",
            "Epoch 147: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0025, Test Linf Norm: 0.3742\n",
            "Epoch 148: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9911, Test Linf Norm: 0.3741\n",
            "Epoch 149: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0015, Test Linf Norm: 0.3741\n",
            "Epoch 150: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9877, Test Linf Norm: 0.3741\n",
            "Epoch 151: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9998, Test Linf Norm: 0.3741\n",
            "Epoch 152: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9951, Test Linf Norm: 0.3741\n",
            "Epoch 153: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0050, Test Linf Norm: 0.3741\n",
            "Epoch 154: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0523, Test L1 Norm: 0.0109, Train Linf Norm: 2.9919, Test Linf Norm: 0.3741\n",
            "Epoch 155: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9950, Test Linf Norm: 0.3741\n",
            "Epoch 156: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9928, Test Linf Norm: 0.3741\n",
            "Epoch 157: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9908, Test Linf Norm: 0.3741\n",
            "Epoch 158: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0007, Test Linf Norm: 0.3741\n",
            "Epoch 159: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0023, Test Linf Norm: 0.3741\n",
            "Epoch 160: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9834, Test Linf Norm: 0.3741\n",
            "Epoch 161: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9997, Test Linf Norm: 0.3741\n",
            "Epoch 162: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9900, Test Linf Norm: 0.3741\n",
            "Epoch 163: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9955, Test Linf Norm: 0.3741\n",
            "Epoch 164: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9981, Test Linf Norm: 0.3741\n",
            "Epoch 165: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0005, Test Linf Norm: 0.3741\n",
            "Epoch 166: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0007, Test Linf Norm: 0.3741\n",
            "Epoch 167: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0021, Test Linf Norm: 0.3741\n",
            "Epoch 168: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9908, Test Linf Norm: 0.3741\n",
            "Epoch 169: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9915, Test Linf Norm: 0.3741\n",
            "Epoch 170: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9865, Test Linf Norm: 0.3741\n",
            "Epoch 171: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0002, Test Linf Norm: 0.3741\n",
            "Epoch 172: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9954, Test Linf Norm: 0.3741\n",
            "Epoch 173: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9943, Test Linf Norm: 0.3741\n",
            "Epoch 174: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9911, Test Linf Norm: 0.3741\n",
            "Epoch 175: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0003, Test Linf Norm: 0.3741\n",
            "Epoch 176: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0002, Test Linf Norm: 0.3741\n",
            "Epoch 177: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9989, Test Linf Norm: 0.3741\n",
            "Epoch 178: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0043, Test Linf Norm: 0.3741\n",
            "Epoch 179: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9998, Test Linf Norm: 0.3741\n",
            "Epoch 180: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9930, Test Linf Norm: 0.3741\n",
            "Epoch 181: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0047, Test Linf Norm: 0.3741\n",
            "Epoch 182: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9953, Test Linf Norm: 0.3741\n",
            "Epoch 183: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9890, Test Linf Norm: 0.3741\n",
            "Epoch 184: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9926, Test Linf Norm: 0.3741\n",
            "Epoch 185: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9967, Test Linf Norm: 0.3741\n",
            "Epoch 186: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9996, Test Linf Norm: 0.3741\n",
            "Epoch 187: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9974, Test Linf Norm: 0.3741\n",
            "Epoch 188: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9961, Test Linf Norm: 0.3741\n",
            "Epoch 189: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9956, Test Linf Norm: 0.3741\n",
            "Epoch 190: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0006, Test Linf Norm: 0.3741\n",
            "Epoch 191: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0043, Test Linf Norm: 0.3741\n",
            "Epoch 192: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9958, Test Linf Norm: 0.3741\n",
            "Epoch 193: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0004, Test Linf Norm: 0.3741\n",
            "Epoch 194: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9948, Test Linf Norm: 0.3741\n",
            "Epoch 195: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9951, Test Linf Norm: 0.3741\n",
            "Epoch 196: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9904, Test Linf Norm: 0.3741\n",
            "Epoch 197: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9969, Test Linf Norm: 0.3741\n",
            "Epoch 198: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9958, Test Linf Norm: 0.3741\n",
            "Epoch 199: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9989, Test Linf Norm: 0.3741\n",
            "Epoch 200: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9984, Test Linf Norm: 0.3741\n",
            "Epoch 201: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0010, Test Linf Norm: 0.3741\n",
            "Epoch 202: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9854, Test Linf Norm: 0.3741\n",
            "Epoch 203: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9997, Test Linf Norm: 0.3741\n",
            "Epoch 204: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9932, Test Linf Norm: 0.3741\n",
            "Epoch 205: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9895, Test Linf Norm: 0.3741\n",
            "Epoch 206: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9905, Test Linf Norm: 0.3741\n",
            "Epoch 207: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0003, Test Linf Norm: 0.3741\n",
            "Epoch 208: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9997, Test Linf Norm: 0.3741\n",
            "Epoch 209: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9948, Test Linf Norm: 0.3741\n",
            "Epoch 210: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9943, Test Linf Norm: 0.3741\n",
            "Epoch 211: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9997, Test Linf Norm: 0.3741\n",
            "Epoch 212: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9978, Test Linf Norm: 0.3741\n",
            "Epoch 213: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9974, Test Linf Norm: 0.3741\n",
            "Epoch 214: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9916, Test Linf Norm: 0.3741\n",
            "Epoch 215: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9975, Test Linf Norm: 0.3741\n",
            "Epoch 216: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9933, Test Linf Norm: 0.3741\n",
            "Epoch 217: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9944, Test Linf Norm: 0.3741\n",
            "Epoch 218: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0010, Test Linf Norm: 0.3741\n",
            "Epoch 219: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9913, Test Linf Norm: 0.3741\n",
            "Epoch 220: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9928, Test Linf Norm: 0.3741\n",
            "Epoch 221: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9964, Test Linf Norm: 0.3741\n",
            "Epoch 222: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9983, Test Linf Norm: 0.3741\n",
            "Epoch 223: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9926, Test Linf Norm: 0.3741\n",
            "Epoch 224: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0052, Test Linf Norm: 0.3741\n",
            "Epoch 225: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9946, Test Linf Norm: 0.3741\n",
            "Epoch 226: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9991, Test Linf Norm: 0.3741\n",
            "Epoch 227: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9931, Test Linf Norm: 0.3741\n",
            "Epoch 228: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9939, Test Linf Norm: 0.3741\n",
            "Epoch 229: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9960, Test Linf Norm: 0.3741\n",
            "Epoch 230: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9986, Test Linf Norm: 0.3741\n",
            "Epoch 231: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9917, Test Linf Norm: 0.3741\n",
            "Epoch 232: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9851, Test Linf Norm: 0.3741\n",
            "Epoch 233: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9969, Test Linf Norm: 0.3741\n",
            "Epoch 234: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0006, Test Linf Norm: 0.3741\n",
            "Epoch 235: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9892, Test Linf Norm: 0.3741\n",
            "Epoch 236: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9912, Test Linf Norm: 0.3741\n",
            "Epoch 237: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9895, Test Linf Norm: 0.3741\n",
            "Epoch 238: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9967, Test Linf Norm: 0.3741\n",
            "Epoch 239: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9952, Test Linf Norm: 0.3741\n",
            "Epoch 240: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9955, Test Linf Norm: 0.3741\n",
            "Epoch 241: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0023, Test Linf Norm: 0.3741\n",
            "Epoch 242: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9906, Test Linf Norm: 0.3741\n",
            "Epoch 243: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9908, Test Linf Norm: 0.3741\n",
            "Epoch 244: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9972, Test Linf Norm: 0.3741\n",
            "Epoch 245: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9942, Test Linf Norm: 0.3741\n",
            "Epoch 246: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0012, Test Linf Norm: 0.3741\n",
            "Epoch 247: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9990, Test Linf Norm: 0.3741\n",
            "Epoch 248: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9878, Test Linf Norm: 0.3741\n",
            "Epoch 249: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9917, Test Linf Norm: 0.3741\n",
            "Epoch 250: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9972, Test Linf Norm: 0.3741\n",
            "Epoch 251: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9949, Test Linf Norm: 0.3741\n",
            "Epoch 252: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9953, Test Linf Norm: 0.3741\n",
            "Epoch 253: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9963, Test Linf Norm: 0.3741\n",
            "Epoch 254: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9996, Test Linf Norm: 0.3741\n",
            "Epoch 255: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9926, Test Linf Norm: 0.3741\n",
            "Epoch 256: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0007, Test Linf Norm: 0.3741\n",
            "Epoch 257: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9902, Test Linf Norm: 0.3741\n",
            "Epoch 258: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9955, Test Linf Norm: 0.3741\n",
            "Epoch 259: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9932, Test Linf Norm: 0.3741\n",
            "Epoch 260: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9903, Test Linf Norm: 0.3741\n",
            "Epoch 261: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9969, Test Linf Norm: 0.3741\n",
            "Epoch 262: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9895, Test Linf Norm: 0.3741\n",
            "Epoch 263: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9978, Test Linf Norm: 0.3741\n",
            "Epoch 264: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9962, Test Linf Norm: 0.3741\n",
            "Epoch 265: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9908, Test Linf Norm: 0.3741\n",
            "Epoch 266: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9914, Test Linf Norm: 0.3741\n",
            "Epoch 267: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9965, Test Linf Norm: 0.3741\n",
            "Epoch 268: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0023, Test Linf Norm: 0.3741\n",
            "Epoch 269: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9950, Test Linf Norm: 0.3741\n",
            "Epoch 270: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 2.9957, Test Linf Norm: 0.3741\n",
            "Epoch 271: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0023, Test Linf Norm: 0.3741\n",
            "Epoch 272: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0035, Test Linf Norm: 0.3741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 10:56:17,959]\u001b[0m Trial 1 finished with value: 0.010856217047572135 and parameters: {'n_layers': 9, 'n_units_0': 1378, 'n_units_1': 505, 'n_units_2': 1722, 'n_units_3': 1609, 'n_units_4': 769, 'n_units_5': 1505, 'n_units_6': 1342, 'n_units_7': 365, 'n_units_8': 453, 'hidden_activation': 'ELU', 'output_activation': 'ReLU', 'loss': 'MAE', 'optimizer': 'SGD', 'lr': 0.0013895717266126568, 'batch_size': 64, 'n_epochs': 273, 'scheduler': 'StepLR', 'weight_decay': 2.6265949818456017e-05, 'momentum': 0.9602481067705522, 'step_size': 13, 'gamma': 0.33826327630942976}. Best is trial 1 with value: 0.010856217047572135.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 273: Train Loss: 0.0032, Test Loss: 0.0033, Train L1 Norm: 0.0524, Test L1 Norm: 0.0109, Train Linf Norm: 3.0015, Test Linf Norm: 0.3741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-82e2252adf92>:146: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t_max_fraction = trial.suggest_uniform('t_max_fraction', 0.1, 0.3)\n",
            "<ipython-input-60-82e2252adf92>:153: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  eta_min = trial.suggest_loguniform(\"eta_min\", 1e-7, 1e-2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 21.5733, Test Loss: 20.6405, Train L1 Norm: 1.0298, Test L1 Norm: 1.0000, Train Linf Norm: 1.4136, Test Linf Norm: 1.0000\n",
            "Epoch 2: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 3: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 4: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 5: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 6: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 7: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 8: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 9: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 10: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 11: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 12: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 13: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 14: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 15: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 16: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 17: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 18: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 19: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 20: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 21: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 22: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 23: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 24: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 25: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 26: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 27: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 28: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 29: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 30: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 31: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 32: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 33: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 34: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 35: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 36: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 37: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 38: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 39: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 40: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 41: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 42: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 43: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 44: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 45: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 46: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 47: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 48: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 49: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 50: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 51: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 52: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 53: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 54: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 55: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 56: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 57: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 58: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 59: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 60: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 61: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 62: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 63: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 64: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 65: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 66: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 67: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 68: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 69: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 70: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 71: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 72: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 73: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 74: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 75: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 76: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 77: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 78: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 79: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 80: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 81: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 82: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 83: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 84: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 85: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 86: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 87: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 88: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 89: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 90: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 91: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 92: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 93: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 94: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 95: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 96: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 97: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 98: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 99: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 100: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:03:59,635]\u001b[0m Trial 2 finished with value: 1.0 and parameters: {'n_layers': 3, 'n_units_0': 1440, 'n_units_1': 942, 'n_units_2': 1678, 'hidden_activation': 'ELU', 'output_activation': 'ReLU', 'loss': 'MSE', 'optimizer': 'RMSprop', 'lr': 0.000397640798416855, 'batch_size': 48, 'n_epochs': 101, 'scheduler': 'CosineAnnealingLR', 't_max_fraction': 0.197308096783115, 'eta_min': 1.6084206450967412e-07}. Best is trial 1 with value: 0.010856217047572135.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101: Train Loss: 20.4332, Test Loss: 20.6405, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-82e2252adf92>:148: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t_max_fraction = trial.suggest_uniform('t_max_fraction', 0.05, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.1077, Test Loss: 0.4744, Train L1 Norm: 0.7701, Test L1 Norm: 0.2220, Train Linf Norm: 163.1533, Test Linf Norm: 3.7753\n",
            "Epoch 2: Train Loss: 0.4829, Test Loss: 0.3968, Train L1 Norm: 0.2447, Test L1 Norm: 0.2022, Train Linf Norm: 16.1633, Test Linf Norm: 16.9126\n",
            "Epoch 3: Train Loss: 0.3636, Test Loss: 0.3188, Train L1 Norm: 0.2280, Test L1 Norm: 0.1598, Train Linf Norm: 47.4198, Test Linf Norm: 1.1181\n",
            "Epoch 4: Train Loss: 0.2912, Test Loss: 0.2677, Train L1 Norm: 0.1838, Test L1 Norm: 0.1585, Train Linf Norm: 31.1877, Test Linf Norm: 15.3643\n",
            "Epoch 5: Train Loss: 0.2384, Test Loss: 0.2675, Train L1 Norm: 0.1845, Test L1 Norm: 0.1318, Train Linf Norm: 55.2816, Test Linf Norm: 1.0556\n",
            "Epoch 6: Train Loss: 0.2036, Test Loss: 0.1927, Train L1 Norm: 0.1447, Test L1 Norm: 0.1193, Train Linf Norm: 29.0416, Test Linf Norm: 12.8257\n",
            "Epoch 7: Train Loss: 0.1726, Test Loss: 0.1628, Train L1 Norm: 0.1361, Test L1 Norm: 0.0916, Train Linf Norm: 34.6952, Test Linf Norm: 1.1322\n",
            "Epoch 8: Train Loss: 0.1471, Test Loss: 0.1329, Train L1 Norm: 0.1445, Test L1 Norm: 0.1004, Train Linf Norm: 52.5144, Test Linf Norm: 12.7691\n",
            "Epoch 9: Train Loss: 0.1216, Test Loss: 0.1102, Train L1 Norm: 0.1049, Test L1 Norm: 0.0641, Train Linf Norm: 27.6055, Test Linf Norm: 1.8059\n",
            "Epoch 10: Train Loss: 0.1001, Test Loss: 0.0865, Train L1 Norm: 0.0978, Test L1 Norm: 0.0732, Train Linf Norm: 34.9286, Test Linf Norm: 9.8544\n",
            "Epoch 11: Train Loss: 0.0826, Test Loss: 0.0743, Train L1 Norm: 0.0850, Test L1 Norm: 0.0471, Train Linf Norm: 31.1201, Test Linf Norm: 1.8703\n",
            "Epoch 12: Train Loss: 0.0660, Test Loss: 0.0991, Train L1 Norm: 0.0732, Test L1 Norm: 0.0557, Train Linf Norm: 29.2693, Test Linf Norm: 1.2987\n",
            "Epoch 13: Train Loss: 0.0577, Test Loss: 0.0582, Train L1 Norm: 0.0627, Test L1 Norm: 0.0432, Train Linf Norm: 22.8966, Test Linf Norm: 4.3454\n",
            "Epoch 14: Train Loss: 0.0537, Test Loss: 0.0529, Train L1 Norm: 0.0646, Test L1 Norm: 0.0377, Train Linf Norm: 27.7291, Test Linf Norm: 1.8552\n",
            "Epoch 15: Train Loss: 0.0513, Test Loss: 0.0503, Train L1 Norm: 0.0607, Test L1 Norm: 0.0364, Train Linf Norm: 24.4332, Test Linf Norm: 2.3666\n",
            "Epoch 16: Train Loss: 0.0497, Test Loss: 0.0490, Train L1 Norm: 0.0586, Test L1 Norm: 0.0357, Train Linf Norm: 23.4826, Test Linf Norm: 2.1287\n",
            "Epoch 17: Train Loss: 0.0486, Test Loss: 0.0485, Train L1 Norm: 0.0587, Test L1 Norm: 0.0355, Train Linf Norm: 24.3209, Test Linf Norm: 2.0950\n",
            "Epoch 18: Train Loss: 0.0478, Test Loss: 0.0479, Train L1 Norm: 0.0563, Test L1 Norm: 0.0350, Train Linf Norm: 21.2652, Test Linf Norm: 2.1576\n",
            "Epoch 19: Train Loss: 0.0472, Test Loss: 0.0470, Train L1 Norm: 0.0560, Test L1 Norm: 0.0348, Train Linf Norm: 22.4111, Test Linf Norm: 2.1145\n",
            "Epoch 20: Train Loss: 0.0467, Test Loss: 0.0465, Train L1 Norm: 0.0558, Test L1 Norm: 0.0344, Train Linf Norm: 22.4628, Test Linf Norm: 2.1501\n",
            "Epoch 21: Train Loss: 0.0463, Test Loss: 0.0463, Train L1 Norm: 0.0555, Test L1 Norm: 0.0341, Train Linf Norm: 22.6102, Test Linf Norm: 2.0354\n",
            "Epoch 22: Train Loss: 0.0458, Test Loss: 0.0458, Train L1 Norm: 0.0540, Test L1 Norm: 0.0342, Train Linf Norm: 21.1454, Test Linf Norm: 2.2821\n",
            "Epoch 23: Train Loss: 0.0452, Test Loss: 0.0451, Train L1 Norm: 0.0537, Test L1 Norm: 0.0334, Train Linf Norm: 21.4486, Test Linf Norm: 2.1895\n",
            "Epoch 24: Train Loss: 0.0446, Test Loss: 0.0442, Train L1 Norm: 0.0533, Test L1 Norm: 0.0329, Train Linf Norm: 21.1156, Test Linf Norm: 2.1193\n",
            "Epoch 25: Train Loss: 0.0440, Test Loss: 0.0458, Train L1 Norm: 0.0527, Test L1 Norm: 0.0332, Train Linf Norm: 20.7574, Test Linf Norm: 1.5495\n",
            "Epoch 26: Train Loss: 0.0531, Test Loss: 0.0460, Train L1 Norm: 0.0602, Test L1 Norm: 0.0347, Train Linf Norm: 23.6210, Test Linf Norm: 2.5386\n",
            "Epoch 27: Train Loss: 0.0655, Test Loss: 0.0616, Train L1 Norm: 0.0569, Test L1 Norm: 0.0413, Train Linf Norm: 13.7136, Test Linf Norm: 1.1822\n",
            "Epoch 28: Train Loss: 0.0772, Test Loss: 0.0652, Train L1 Norm: 0.0725, Test L1 Norm: 0.0491, Train Linf Norm: 23.2924, Test Linf Norm: 5.0027\n",
            "Epoch 29: Train Loss: 0.0882, Test Loss: 0.0968, Train L1 Norm: 0.0786, Test L1 Norm: 0.0574, Train Linf Norm: 24.5255, Test Linf Norm: 1.0291\n",
            "Epoch 30: Train Loss: 0.0965, Test Loss: 0.0821, Train L1 Norm: 0.0849, Test L1 Norm: 0.0547, Train Linf Norm: 26.4681, Test Linf Norm: 5.0285\n",
            "Epoch 31: Train Loss: 0.1035, Test Loss: 0.0972, Train L1 Norm: 0.0859, Test L1 Norm: 0.0600, Train Linf Norm: 24.0236, Test Linf Norm: 1.0000\n",
            "Epoch 32: Train Loss: 0.1080, Test Loss: 0.0961, Train L1 Norm: 0.0784, Test L1 Norm: 0.0634, Train Linf Norm: 14.7285, Test Linf Norm: 5.9843\n",
            "Epoch 33: Train Loss: 0.1115, Test Loss: 0.1332, Train L1 Norm: 0.0787, Test L1 Norm: 0.0689, Train Linf Norm: 13.1337, Test Linf Norm: 1.0000\n",
            "Epoch 34: Train Loss: 0.1150, Test Loss: 0.0891, Train L1 Norm: 0.0823, Test L1 Norm: 0.0611, Train Linf Norm: 14.2579, Test Linf Norm: 5.9217\n",
            "Epoch 35: Train Loss: 0.1170, Test Loss: 0.1304, Train L1 Norm: 0.0808, Test L1 Norm: 0.0707, Train Linf Norm: 13.6226, Test Linf Norm: 1.0000\n",
            "Epoch 36: Train Loss: 0.1171, Test Loss: 0.0833, Train L1 Norm: 0.0789, Test L1 Norm: 0.0517, Train Linf Norm: 11.2348, Test Linf Norm: 4.4767\n",
            "Epoch 37: Train Loss: 0.1148, Test Loss: 0.1348, Train L1 Norm: 0.0773, Test L1 Norm: 0.0695, Train Linf Norm: 10.9089, Test Linf Norm: 1.0000\n",
            "Epoch 38: Train Loss: 0.1129, Test Loss: 0.1109, Train L1 Norm: 0.0793, Test L1 Norm: 0.0676, Train Linf Norm: 13.5388, Test Linf Norm: 6.6382\n",
            "Epoch 39: Train Loss: 0.1088, Test Loss: 0.1012, Train L1 Norm: 0.0887, Test L1 Norm: 0.0603, Train Linf Norm: 26.3106, Test Linf Norm: 1.0000\n",
            "Epoch 40: Train Loss: 0.1039, Test Loss: 0.1154, Train L1 Norm: 0.0728, Test L1 Norm: 0.0670, Train Linf Norm: 12.1032, Test Linf Norm: 6.2565\n",
            "Epoch 41: Train Loss: 0.0997, Test Loss: 0.1160, Train L1 Norm: 0.0674, Test L1 Norm: 0.0621, Train Linf Norm: 8.1947, Test Linf Norm: 1.0191\n",
            "Epoch 42: Train Loss: 0.0932, Test Loss: 0.0907, Train L1 Norm: 0.0789, Test L1 Norm: 0.0618, Train Linf Norm: 24.1384, Test Linf Norm: 6.4434\n",
            "Epoch 43: Train Loss: 0.0867, Test Loss: 0.1005, Train L1 Norm: 0.0669, Test L1 Norm: 0.0540, Train Linf Norm: 14.6983, Test Linf Norm: 1.0549\n",
            "Epoch 44: Train Loss: 0.0771, Test Loss: 0.0828, Train L1 Norm: 0.0717, Test L1 Norm: 0.0538, Train Linf Norm: 24.9238, Test Linf Norm: 5.1734\n",
            "Epoch 45: Train Loss: 0.0690, Test Loss: 0.0545, Train L1 Norm: 0.0660, Test L1 Norm: 0.0381, Train Linf Norm: 23.4491, Test Linf Norm: 1.0771\n",
            "Epoch 46: Train Loss: 0.0598, Test Loss: 0.0599, Train L1 Norm: 0.0512, Test L1 Norm: 0.0389, Train Linf Norm: 12.6738, Test Linf Norm: 3.1530\n",
            "Epoch 47: Train Loss: 0.0506, Test Loss: 0.0589, Train L1 Norm: 0.0477, Test L1 Norm: 0.0368, Train Linf Norm: 14.3309, Test Linf Norm: 1.1923\n",
            "Epoch 48: Train Loss: 0.0424, Test Loss: 0.0403, Train L1 Norm: 0.0449, Test L1 Norm: 0.0292, Train Linf Norm: 14.9529, Test Linf Norm: 1.6063\n",
            "Epoch 49: Train Loss: 0.0381, Test Loss: 0.0379, Train L1 Norm: 0.0456, Test L1 Norm: 0.0280, Train Linf Norm: 17.4107, Test Linf Norm: 1.8341\n",
            "Epoch 50: Train Loss: 0.0367, Test Loss: 0.0373, Train L1 Norm: 0.0429, Test L1 Norm: 0.0279, Train Linf Norm: 15.9148, Test Linf Norm: 1.5786\n",
            "Epoch 51: Train Loss: 0.0362, Test Loss: 0.0365, Train L1 Norm: 0.0433, Test L1 Norm: 0.0273, Train Linf Norm: 16.7554, Test Linf Norm: 1.7918\n",
            "Epoch 52: Train Loss: 0.0354, Test Loss: 0.0362, Train L1 Norm: 0.0424, Test L1 Norm: 0.0274, Train Linf Norm: 16.3238, Test Linf Norm: 1.7010\n",
            "Epoch 53: Train Loss: 0.0350, Test Loss: 0.0353, Train L1 Norm: 0.0412, Test L1 Norm: 0.0269, Train Linf Norm: 15.1359, Test Linf Norm: 1.7487\n",
            "Epoch 54: Train Loss: 0.0347, Test Loss: 0.0351, Train L1 Norm: 0.0418, Test L1 Norm: 0.0270, Train Linf Norm: 15.9870, Test Linf Norm: 1.6911\n",
            "Epoch 55: Train Loss: 0.0345, Test Loss: 0.0349, Train L1 Norm: 0.0416, Test L1 Norm: 0.0269, Train Linf Norm: 15.9695, Test Linf Norm: 1.7371\n",
            "Epoch 56: Train Loss: 0.0343, Test Loss: 0.0348, Train L1 Norm: 0.0414, Test L1 Norm: 0.0269, Train Linf Norm: 15.3207, Test Linf Norm: 1.7028\n",
            "Epoch 57: Train Loss: 0.0342, Test Loss: 0.0346, Train L1 Norm: 0.0409, Test L1 Norm: 0.0268, Train Linf Norm: 15.1771, Test Linf Norm: 1.7379\n",
            "Epoch 58: Train Loss: 0.0340, Test Loss: 0.0345, Train L1 Norm: 0.0410, Test L1 Norm: 0.0268, Train Linf Norm: 15.1795, Test Linf Norm: 1.7060\n",
            "Epoch 59: Train Loss: 0.0339, Test Loss: 0.0345, Train L1 Norm: 0.0410, Test L1 Norm: 0.0268, Train Linf Norm: 15.4739, Test Linf Norm: 1.7367\n",
            "Epoch 60: Train Loss: 0.0338, Test Loss: 0.0343, Train L1 Norm: 0.0407, Test L1 Norm: 0.0267, Train Linf Norm: 15.2379, Test Linf Norm: 1.6978\n",
            "Epoch 61: Train Loss: 0.0337, Test Loss: 0.0347, Train L1 Norm: 0.0407, Test L1 Norm: 0.0267, Train Linf Norm: 15.3436, Test Linf Norm: 1.6829\n",
            "Epoch 62: Train Loss: 0.0335, Test Loss: 0.0341, Train L1 Norm: 0.0406, Test L1 Norm: 0.0266, Train Linf Norm: 15.4323, Test Linf Norm: 1.6793\n",
            "Epoch 63: Train Loss: 0.0333, Test Loss: 0.0338, Train L1 Norm: 0.0404, Test L1 Norm: 0.0265, Train Linf Norm: 15.2232, Test Linf Norm: 1.6888\n",
            "Epoch 64: Train Loss: 0.0331, Test Loss: 0.0334, Train L1 Norm: 0.0406, Test L1 Norm: 0.0263, Train Linf Norm: 15.3856, Test Linf Norm: 1.7279\n",
            "Epoch 65: Train Loss: 0.0329, Test Loss: 0.0340, Train L1 Norm: 0.0398, Test L1 Norm: 0.0265, Train Linf Norm: 14.7377, Test Linf Norm: 1.6019\n",
            "Epoch 66: Train Loss: 0.0334, Test Loss: 0.0338, Train L1 Norm: 0.0383, Test L1 Norm: 0.0267, Train Linf Norm: 12.8104, Test Linf Norm: 1.9750\n",
            "Epoch 67: Train Loss: 0.0445, Test Loss: 0.0467, Train L1 Norm: 0.0428, Test L1 Norm: 0.0317, Train Linf Norm: 11.7632, Test Linf Norm: 1.1865\n",
            "Epoch 68: Train Loss: 0.0528, Test Loss: 0.0546, Train L1 Norm: 0.0469, Test L1 Norm: 0.0371, Train Linf Norm: 11.5825, Test Linf Norm: 3.0886\n",
            "Epoch 69: Train Loss: 0.0609, Test Loss: 0.0828, Train L1 Norm: 0.0577, Test L1 Norm: 0.0468, Train Linf Norm: 18.0986, Test Linf Norm: 1.0228\n",
            "Epoch 70: Train Loss: 0.0676, Test Loss: 0.0598, Train L1 Norm: 0.0480, Test L1 Norm: 0.0384, Train Linf Norm: 5.2809, Test Linf Norm: 2.9658\n",
            "Epoch 71: Train Loss: 0.0722, Test Loss: 0.0719, Train L1 Norm: 0.0507, Test L1 Norm: 0.0455, Train Linf Norm: 4.8735, Test Linf Norm: 1.0218\n",
            "Epoch 72: Train Loss: 0.0763, Test Loss: 0.0695, Train L1 Norm: 0.0690, Test L1 Norm: 0.0429, Train Linf Norm: 22.6490, Test Linf Norm: 3.5941\n",
            "Epoch 73: Train Loss: 0.0792, Test Loss: 0.0866, Train L1 Norm: 0.0562, Test L1 Norm: 0.0495, Train Linf Norm: 7.1971, Test Linf Norm: 1.0164\n",
            "Epoch 74: Train Loss: 0.0815, Test Loss: 0.0807, Train L1 Norm: 0.0690, Test L1 Norm: 0.0494, Train Linf Norm: 20.3315, Test Linf Norm: 4.2094\n",
            "Epoch 75: Train Loss: 0.0825, Test Loss: 0.0809, Train L1 Norm: 0.0659, Test L1 Norm: 0.0494, Train Linf Norm: 16.5905, Test Linf Norm: 1.0152\n",
            "Epoch 76: Train Loss: 0.0817, Test Loss: 0.0614, Train L1 Norm: 0.0583, Test L1 Norm: 0.0432, Train Linf Norm: 8.9700, Test Linf Norm: 4.2667\n",
            "Epoch 77: Train Loss: 0.0803, Test Loss: 0.0767, Train L1 Norm: 0.0528, Test L1 Norm: 0.0486, Train Linf Norm: 4.4370, Test Linf Norm: 1.0043\n",
            "Epoch 78: Train Loss: 0.0775, Test Loss: 0.0806, Train L1 Norm: 0.0523, Test L1 Norm: 0.0538, Train Linf Norm: 5.0781, Test Linf Norm: 5.5028\n",
            "Epoch 79: Train Loss: 0.0743, Test Loss: 0.0864, Train L1 Norm: 0.0526, Test L1 Norm: 0.0488, Train Linf Norm: 6.9221, Test Linf Norm: 1.0237\n",
            "Epoch 80: Train Loss: 0.0712, Test Loss: 0.0734, Train L1 Norm: 0.0614, Test L1 Norm: 0.0484, Train Linf Norm: 17.8018, Test Linf Norm: 4.7910\n",
            "Epoch 81: Train Loss: 0.0661, Test Loss: 0.0614, Train L1 Norm: 0.0567, Test L1 Norm: 0.0386, Train Linf Norm: 15.5620, Test Linf Norm: 1.0734\n",
            "Epoch 82: Train Loss: 0.0588, Test Loss: 0.0506, Train L1 Norm: 0.0574, Test L1 Norm: 0.0354, Train Linf Norm: 19.7619, Test Linf Norm: 3.2482\n",
            "Epoch 83: Train Loss: 0.0529, Test Loss: 0.0534, Train L1 Norm: 0.0501, Test L1 Norm: 0.0359, Train Linf Norm: 15.4178, Test Linf Norm: 1.0624\n",
            "Epoch 84: Train Loss: 0.0462, Test Loss: 0.0407, Train L1 Norm: 0.0476, Test L1 Norm: 0.0293, Train Linf Norm: 16.9307, Test Linf Norm: 2.3646\n",
            "Epoch 85: Train Loss: 0.0399, Test Loss: 0.0354, Train L1 Norm: 0.0426, Test L1 Norm: 0.0273, Train Linf Norm: 14.8256, Test Linf Norm: 1.2761\n",
            "Epoch 86: Train Loss: 0.0320, Test Loss: 0.0344, Train L1 Norm: 0.0374, Test L1 Norm: 0.0254, Train Linf Norm: 12.9418, Test Linf Norm: 1.7542\n",
            "Epoch 87: Train Loss: 0.0310, Test Loss: 0.0309, Train L1 Norm: 0.0355, Test L1 Norm: 0.0246, Train Linf Norm: 11.7762, Test Linf Norm: 1.5556\n",
            "Epoch 88: Train Loss: 0.0299, Test Loss: 0.0322, Train L1 Norm: 0.0355, Test L1 Norm: 0.0252, Train Linf Norm: 12.6111, Test Linf Norm: 1.3990\n",
            "Epoch 89: Train Loss: 0.0295, Test Loss: 0.0298, Train L1 Norm: 0.0359, Test L1 Norm: 0.0237, Train Linf Norm: 13.1564, Test Linf Norm: 1.5919\n",
            "Epoch 90: Train Loss: 0.0291, Test Loss: 0.0295, Train L1 Norm: 0.0352, Test L1 Norm: 0.0236, Train Linf Norm: 12.2585, Test Linf Norm: 1.5842\n",
            "Epoch 91: Train Loss: 0.0289, Test Loss: 0.0296, Train L1 Norm: 0.0345, Test L1 Norm: 0.0238, Train Linf Norm: 11.7538, Test Linf Norm: 1.5379\n",
            "Epoch 92: Train Loss: 0.0287, Test Loss: 0.0293, Train L1 Norm: 0.0344, Test L1 Norm: 0.0235, Train Linf Norm: 11.8035, Test Linf Norm: 1.5842\n",
            "Epoch 93: Train Loss: 0.0286, Test Loss: 0.0292, Train L1 Norm: 0.0340, Test L1 Norm: 0.0234, Train Linf Norm: 11.5845, Test Linf Norm: 1.5664\n",
            "Epoch 94: Train Loss: 0.0285, Test Loss: 0.0291, Train L1 Norm: 0.0340, Test L1 Norm: 0.0233, Train Linf Norm: 11.2670, Test Linf Norm: 1.5955\n",
            "Epoch 95: Train Loss: 0.0284, Test Loss: 0.0291, Train L1 Norm: 0.0343, Test L1 Norm: 0.0233, Train Linf Norm: 11.7049, Test Linf Norm: 1.5688\n",
            "Epoch 96: Train Loss: 0.0283, Test Loss: 0.0289, Train L1 Norm: 0.0342, Test L1 Norm: 0.0233, Train Linf Norm: 11.6175, Test Linf Norm: 1.5711\n",
            "Epoch 97: Train Loss: 0.0283, Test Loss: 0.0289, Train L1 Norm: 0.0338, Test L1 Norm: 0.0232, Train Linf Norm: 11.4200, Test Linf Norm: 1.5874\n",
            "Epoch 98: Train Loss: 0.0282, Test Loss: 0.0288, Train L1 Norm: 0.0341, Test L1 Norm: 0.0233, Train Linf Norm: 11.9300, Test Linf Norm: 1.5732\n",
            "Epoch 99: Train Loss: 0.0281, Test Loss: 0.0288, Train L1 Norm: 0.0334, Test L1 Norm: 0.0232, Train Linf Norm: 11.0124, Test Linf Norm: 1.5958\n",
            "Epoch 100: Train Loss: 0.0281, Test Loss: 0.0287, Train L1 Norm: 0.0340, Test L1 Norm: 0.0232, Train Linf Norm: 11.8292, Test Linf Norm: 1.5756\n",
            "Epoch 101: Train Loss: 0.0279, Test Loss: 0.0285, Train L1 Norm: 0.0337, Test L1 Norm: 0.0232, Train Linf Norm: 11.5121, Test Linf Norm: 1.5406\n",
            "Epoch 102: Train Loss: 0.0279, Test Loss: 0.0283, Train L1 Norm: 0.0334, Test L1 Norm: 0.0232, Train Linf Norm: 10.9038, Test Linf Norm: 1.5967\n",
            "Epoch 103: Train Loss: 0.0277, Test Loss: 0.0294, Train L1 Norm: 0.0345, Test L1 Norm: 0.0233, Train Linf Norm: 12.1321, Test Linf Norm: 1.5109\n",
            "Epoch 104: Train Loss: 0.0280, Test Loss: 0.0279, Train L1 Norm: 0.0328, Test L1 Norm: 0.0228, Train Linf Norm: 10.6569, Test Linf Norm: 1.5415\n",
            "Epoch 105: Train Loss: 0.0319, Test Loss: 0.0296, Train L1 Norm: 0.0337, Test L1 Norm: 0.0235, Train Linf Norm: 9.6439, Test Linf Norm: 1.6532\n",
            "Epoch 106: Train Loss: 0.0389, Test Loss: 0.0390, Train L1 Norm: 0.0367, Test L1 Norm: 0.0280, Train Linf Norm: 9.1673, Test Linf Norm: 1.0988\n",
            "Epoch 107: Train Loss: 0.0462, Test Loss: 0.0468, Train L1 Norm: 0.0400, Test L1 Norm: 0.0313, Train Linf Norm: 8.8289, Test Linf Norm: 2.6191\n",
            "Epoch 108: Train Loss: 0.0521, Test Loss: 0.0591, Train L1 Norm: 0.0405, Test L1 Norm: 0.0369, Train Linf Norm: 6.1696, Test Linf Norm: 1.0401\n",
            "Epoch 109: Train Loss: 0.0571, Test Loss: 0.0481, Train L1 Norm: 0.0530, Test L1 Norm: 0.0355, Train Linf Norm: 16.1587, Test Linf Norm: 3.4060\n",
            "Epoch 110: Train Loss: 0.0612, Test Loss: 0.0640, Train L1 Norm: 0.0455, Test L1 Norm: 0.0408, Train Linf Norm: 6.3892, Test Linf Norm: 1.0187\n",
            "Epoch 111: Train Loss: 0.0637, Test Loss: 0.0589, Train L1 Norm: 0.0544, Test L1 Norm: 0.0377, Train Linf Norm: 14.8181, Test Linf Norm: 3.1678\n",
            "Epoch 112: Train Loss: 0.0661, Test Loss: 0.0597, Train L1 Norm: 0.0475, Test L1 Norm: 0.0396, Train Linf Norm: 6.3571, Test Linf Norm: 1.0173\n",
            "Epoch 113: Train Loss: 0.0667, Test Loss: 0.0753, Train L1 Norm: 0.0585, Test L1 Norm: 0.0448, Train Linf Norm: 17.3672, Test Linf Norm: 4.1568\n",
            "Epoch 114: Train Loss: 0.0680, Test Loss: 0.0687, Train L1 Norm: 0.0581, Test L1 Norm: 0.0416, Train Linf Norm: 16.1062, Test Linf Norm: 1.0190\n",
            "Epoch 115: Train Loss: 0.0674, Test Loss: 0.0634, Train L1 Norm: 0.0466, Test L1 Norm: 0.0437, Train Linf Norm: 4.2130, Test Linf Norm: 4.5739\n",
            "Epoch 116: Train Loss: 0.0655, Test Loss: 0.0890, Train L1 Norm: 0.0458, Test L1 Norm: 0.0491, Train Linf Norm: 5.1337, Test Linf Norm: 1.0000\n",
            "Epoch 117: Train Loss: 0.0635, Test Loss: 0.0654, Train L1 Norm: 0.0460, Test L1 Norm: 0.0416, Train Linf Norm: 5.7238, Test Linf Norm: 4.0055\n",
            "Epoch 118: Train Loss: 0.0593, Test Loss: 0.0499, Train L1 Norm: 0.0538, Test L1 Norm: 0.0339, Train Linf Norm: 16.2778, Test Linf Norm: 1.0377\n",
            "Epoch 119: Train Loss: 0.0554, Test Loss: 0.0577, Train L1 Norm: 0.0508, Test L1 Norm: 0.0402, Train Linf Norm: 15.2863, Test Linf Norm: 4.5026\n",
            "Epoch 120: Train Loss: 0.0507, Test Loss: 0.0615, Train L1 Norm: 0.0476, Test L1 Norm: 0.0370, Train Linf Norm: 14.6882, Test Linf Norm: 1.0370\n",
            "Epoch 121: Train Loss: 0.0454, Test Loss: 0.0355, Train L1 Norm: 0.0377, Test L1 Norm: 0.0282, Train Linf Norm: 7.0764, Test Linf Norm: 2.8559\n",
            "Epoch 122: Train Loss: 0.0393, Test Loss: 0.0379, Train L1 Norm: 0.0350, Test L1 Norm: 0.0276, Train Linf Norm: 7.5349, Test Linf Norm: 1.1065\n",
            "Epoch 123: Train Loss: 0.0332, Test Loss: 0.0303, Train L1 Norm: 0.0322, Test L1 Norm: 0.0229, Train Linf Norm: 7.7918, Test Linf Norm: 1.6994\n",
            "Epoch 124: Train Loss: 0.0277, Test Loss: 0.0274, Train L1 Norm: 0.0295, Test L1 Norm: 0.0219, Train Linf Norm: 7.9905, Test Linf Norm: 1.6274\n",
            "Epoch 125: Train Loss: 0.0263, Test Loss: 0.0265, Train L1 Norm: 0.0303, Test L1 Norm: 0.0215, Train Linf Norm: 9.5291, Test Linf Norm: 1.4431\n",
            "Epoch 126: Train Loss: 0.0259, Test Loss: 0.0264, Train L1 Norm: 0.0310, Test L1 Norm: 0.0215, Train Linf Norm: 10.4263, Test Linf Norm: 1.5486\n",
            "Epoch 127: Train Loss: 0.0256, Test Loss: 0.0263, Train L1 Norm: 0.0300, Test L1 Norm: 0.0214, Train Linf Norm: 9.4006, Test Linf Norm: 1.3819\n",
            "Epoch 128: Train Loss: 0.0254, Test Loss: 0.0260, Train L1 Norm: 0.0299, Test L1 Norm: 0.0214, Train Linf Norm: 9.4330, Test Linf Norm: 1.4342\n",
            "Epoch 129: Train Loss: 0.0252, Test Loss: 0.0259, Train L1 Norm: 0.0299, Test L1 Norm: 0.0214, Train Linf Norm: 9.5475, Test Linf Norm: 1.5496\n",
            "Epoch 130: Train Loss: 0.0251, Test Loss: 0.0258, Train L1 Norm: 0.0300, Test L1 Norm: 0.0213, Train Linf Norm: 9.6653, Test Linf Norm: 1.4604\n",
            "Epoch 131: Train Loss: 0.0250, Test Loss: 0.0257, Train L1 Norm: 0.0300, Test L1 Norm: 0.0211, Train Linf Norm: 9.8076, Test Linf Norm: 1.4128\n",
            "Epoch 132: Train Loss: 0.0250, Test Loss: 0.0256, Train L1 Norm: 0.0301, Test L1 Norm: 0.0212, Train Linf Norm: 9.7359, Test Linf Norm: 1.4456\n",
            "Epoch 133: Train Loss: 0.0249, Test Loss: 0.0256, Train L1 Norm: 0.0297, Test L1 Norm: 0.0212, Train Linf Norm: 9.4386, Test Linf Norm: 1.4135\n",
            "Epoch 134: Train Loss: 0.0249, Test Loss: 0.0257, Train L1 Norm: 0.0298, Test L1 Norm: 0.0212, Train Linf Norm: 9.6562, Test Linf Norm: 1.4100\n",
            "Epoch 135: Train Loss: 0.0248, Test Loss: 0.0256, Train L1 Norm: 0.0298, Test L1 Norm: 0.0211, Train Linf Norm: 9.5768, Test Linf Norm: 1.4205\n",
            "Epoch 136: Train Loss: 0.0248, Test Loss: 0.0255, Train L1 Norm: 0.0299, Test L1 Norm: 0.0211, Train Linf Norm: 9.7999, Test Linf Norm: 1.4217\n",
            "Epoch 137: Train Loss: 0.0247, Test Loss: 0.0254, Train L1 Norm: 0.0298, Test L1 Norm: 0.0211, Train Linf Norm: 9.7264, Test Linf Norm: 1.4319\n",
            "Epoch 138: Train Loss: 0.0247, Test Loss: 0.0254, Train L1 Norm: 0.0295, Test L1 Norm: 0.0210, Train Linf Norm: 9.3987, Test Linf Norm: 1.4388\n",
            "Epoch 139: Train Loss: 0.0246, Test Loss: 0.0253, Train L1 Norm: 0.0297, Test L1 Norm: 0.0209, Train Linf Norm: 9.7568, Test Linf Norm: 1.3931\n",
            "Epoch 140: Train Loss: 0.0245, Test Loss: 0.0252, Train L1 Norm: 0.0291, Test L1 Norm: 0.0210, Train Linf Norm: 8.9458, Test Linf Norm: 1.3202\n",
            "Epoch 141: Train Loss: 0.0245, Test Loss: 0.0253, Train L1 Norm: 0.0300, Test L1 Norm: 0.0210, Train Linf Norm: 10.0015, Test Linf Norm: 1.3241\n",
            "Epoch 142: Train Loss: 0.0244, Test Loss: 0.0251, Train L1 Norm: 0.0291, Test L1 Norm: 0.0209, Train Linf Norm: 9.1111, Test Linf Norm: 1.5336\n",
            "Epoch 143: Train Loss: 0.0266, Test Loss: 0.0296, Train L1 Norm: 0.0299, Test L1 Norm: 0.0238, Train Linf Norm: 8.9498, Test Linf Norm: 1.0641\n",
            "Epoch 144: Train Loss: 0.0329, Test Loss: 0.0353, Train L1 Norm: 0.0309, Test L1 Norm: 0.0256, Train Linf Norm: 6.6208, Test Linf Norm: 2.1335\n",
            "Epoch 145: Train Loss: 0.0389, Test Loss: 0.0332, Train L1 Norm: 0.0400, Test L1 Norm: 0.0251, Train Linf Norm: 12.9246, Test Linf Norm: 1.0527\n",
            "Epoch 146: Train Loss: 0.0438, Test Loss: 0.0470, Train L1 Norm: 0.0436, Test L1 Norm: 0.0321, Train Linf Norm: 13.7075, Test Linf Norm: 2.9101\n",
            "Epoch 147: Train Loss: 0.0485, Test Loss: 0.0498, Train L1 Norm: 0.0395, Test L1 Norm: 0.0313, Train Linf Norm: 7.3291, Test Linf Norm: 1.0413\n",
            "Epoch 148: Train Loss: 0.0519, Test Loss: 0.0437, Train L1 Norm: 0.0524, Test L1 Norm: 0.0301, Train Linf Norm: 18.3854, Test Linf Norm: 2.6662\n",
            "Epoch 149: Train Loss: 0.0547, Test Loss: 0.0619, Train L1 Norm: 0.0486, Test L1 Norm: 0.0373, Train Linf Norm: 13.7658, Test Linf Norm: 1.0227\n",
            "Epoch 150: Train Loss: 0.0574, Test Loss: 0.0474, Train L1 Norm: 0.0442, Test L1 Norm: 0.0337, Train Linf Norm: 6.9933, Test Linf Norm: 3.3157\n",
            "Epoch 151: Train Loss: 0.0586, Test Loss: 0.0686, Train L1 Norm: 0.0437, Test L1 Norm: 0.0387, Train Linf Norm: 6.5018, Test Linf Norm: 1.0208\n",
            "Epoch 152: Train Loss: 0.0589, Test Loss: 0.0511, Train L1 Norm: 0.0447, Test L1 Norm: 0.0363, Train Linf Norm: 6.4028, Test Linf Norm: 3.7424\n",
            "Epoch 153: Train Loss: 0.0576, Test Loss: 0.0727, Train L1 Norm: 0.0426, Test L1 Norm: 0.0401, Train Linf Norm: 5.7184, Test Linf Norm: 1.0086\n",
            "Epoch 154: Train Loss: 0.0568, Test Loss: 0.0538, Train L1 Norm: 0.0520, Test L1 Norm: 0.0391, Train Linf Norm: 15.8441, Test Linf Norm: 4.4472\n",
            "Epoch 155: Train Loss: 0.0556, Test Loss: 0.0557, Train L1 Norm: 0.0426, Test L1 Norm: 0.0353, Train Linf Norm: 7.4659, Test Linf Norm: 1.0040\n",
            "Epoch 156: Train Loss: 0.0521, Test Loss: 0.0480, Train L1 Norm: 0.0407, Test L1 Norm: 0.0362, Train Linf Norm: 7.4540, Test Linf Norm: 4.2279\n",
            "Epoch 157: Train Loss: 0.0491, Test Loss: 0.0508, Train L1 Norm: 0.0390, Test L1 Norm: 0.0333, Train Linf Norm: 7.0681, Test Linf Norm: 1.0136\n",
            "Epoch 158: Train Loss: 0.0444, Test Loss: 0.0391, Train L1 Norm: 0.0363, Test L1 Norm: 0.0293, Train Linf Norm: 6.6174, Test Linf Norm: 3.0933\n",
            "Epoch 159: Train Loss: 0.0406, Test Loss: 0.0364, Train L1 Norm: 0.0340, Test L1 Norm: 0.0261, Train Linf Norm: 6.1623, Test Linf Norm: 1.0379\n",
            "Epoch 160: Train Loss: 0.0341, Test Loss: 0.0352, Train L1 Norm: 0.0370, Test L1 Norm: 0.0263, Train Linf Norm: 12.8355, Test Linf Norm: 2.5516\n",
            "Epoch 161: Train Loss: 0.0293, Test Loss: 0.0255, Train L1 Norm: 0.0292, Test L1 Norm: 0.0205, Train Linf Norm: 7.1961, Test Linf Norm: 1.3408\n",
            "Epoch 162: Train Loss: 0.0247, Test Loss: 0.0268, Train L1 Norm: 0.0294, Test L1 Norm: 0.0212, Train Linf Norm: 9.8876, Test Linf Norm: 1.7302\n",
            "Epoch 163: Train Loss: 0.0241, Test Loss: 0.0240, Train L1 Norm: 0.0283, Test L1 Norm: 0.0200, Train Linf Norm: 9.0015, Test Linf Norm: 1.4429\n",
            "Epoch 164: Train Loss: 0.0232, Test Loss: 0.0238, Train L1 Norm: 0.0289, Test L1 Norm: 0.0200, Train Linf Norm: 10.1243, Test Linf Norm: 1.5123\n",
            "Epoch 165: Train Loss: 0.0230, Test Loss: 0.0236, Train L1 Norm: 0.0278, Test L1 Norm: 0.0198, Train Linf Norm: 8.9272, Test Linf Norm: 1.3642\n",
            "Epoch 166: Train Loss: 0.0228, Test Loss: 0.0235, Train L1 Norm: 0.0286, Test L1 Norm: 0.0198, Train Linf Norm: 9.8758, Test Linf Norm: 1.4267\n",
            "Epoch 167: Train Loss: 0.0227, Test Loss: 0.0235, Train L1 Norm: 0.0280, Test L1 Norm: 0.0199, Train Linf Norm: 9.3567, Test Linf Norm: 1.3385\n",
            "Epoch 168: Train Loss: 0.0226, Test Loss: 0.0235, Train L1 Norm: 0.0283, Test L1 Norm: 0.0198, Train Linf Norm: 9.6018, Test Linf Norm: 1.4484\n",
            "Epoch 169: Train Loss: 0.0226, Test Loss: 0.0234, Train L1 Norm: 0.0283, Test L1 Norm: 0.0197, Train Linf Norm: 9.7841, Test Linf Norm: 1.3977\n",
            "Epoch 170: Train Loss: 0.0225, Test Loss: 0.0233, Train L1 Norm: 0.0280, Test L1 Norm: 0.0198, Train Linf Norm: 9.4957, Test Linf Norm: 1.4425\n",
            "Epoch 171: Train Loss: 0.0225, Test Loss: 0.0233, Train L1 Norm: 0.0283, Test L1 Norm: 0.0197, Train Linf Norm: 9.8259, Test Linf Norm: 1.4145\n",
            "Epoch 172: Train Loss: 0.0225, Test Loss: 0.0233, Train L1 Norm: 0.0280, Test L1 Norm: 0.0197, Train Linf Norm: 9.3254, Test Linf Norm: 1.4197\n",
            "Epoch 173: Train Loss: 0.0224, Test Loss: 0.0233, Train L1 Norm: 0.0280, Test L1 Norm: 0.0197, Train Linf Norm: 9.4356, Test Linf Norm: 1.3895\n",
            "Epoch 174: Train Loss: 0.0224, Test Loss: 0.0232, Train L1 Norm: 0.0281, Test L1 Norm: 0.0197, Train Linf Norm: 9.5956, Test Linf Norm: 1.3911\n",
            "Epoch 175: Train Loss: 0.0224, Test Loss: 0.0233, Train L1 Norm: 0.0277, Test L1 Norm: 0.0196, Train Linf Norm: 9.2559, Test Linf Norm: 1.3997\n",
            "Epoch 176: Train Loss: 0.0224, Test Loss: 0.0233, Train L1 Norm: 0.0280, Test L1 Norm: 0.0197, Train Linf Norm: 9.3343, Test Linf Norm: 1.3736\n",
            "Epoch 177: Train Loss: 0.0223, Test Loss: 0.0232, Train L1 Norm: 0.0273, Test L1 Norm: 0.0197, Train Linf Norm: 8.8879, Test Linf Norm: 1.3068\n",
            "Epoch 178: Train Loss: 0.0222, Test Loss: 0.0230, Train L1 Norm: 0.0276, Test L1 Norm: 0.0197, Train Linf Norm: 9.1568, Test Linf Norm: 1.4463\n",
            "Epoch 179: Train Loss: 0.0222, Test Loss: 0.0230, Train L1 Norm: 0.0277, Test L1 Norm: 0.0196, Train Linf Norm: 9.2865, Test Linf Norm: 1.3046\n",
            "Epoch 180: Train Loss: 0.0223, Test Loss: 0.0230, Train L1 Norm: 0.0277, Test L1 Norm: 0.0195, Train Linf Norm: 9.1471, Test Linf Norm: 1.4597\n",
            "Epoch 181: Train Loss: 0.0231, Test Loss: 0.0247, Train L1 Norm: 0.0279, Test L1 Norm: 0.0200, Train Linf Norm: 9.0116, Test Linf Norm: 1.2850\n",
            "Epoch 182: Train Loss: 0.0281, Test Loss: 0.0331, Train L1 Norm: 0.0329, Test L1 Norm: 0.0244, Train Linf Norm: 11.6500, Test Linf Norm: 2.1175\n",
            "Epoch 183: Train Loss: 0.0345, Test Loss: 0.0384, Train L1 Norm: 0.0319, Test L1 Norm: 0.0266, Train Linf Norm: 7.0812, Test Linf Norm: 1.0242\n",
            "Epoch 184: Train Loss: 0.0390, Test Loss: 0.0298, Train L1 Norm: 0.0325, Test L1 Norm: 0.0255, Train Linf Norm: 5.5396, Test Linf Norm: 2.7876\n",
            "Epoch 185: Train Loss: 0.0429, Test Loss: 0.0491, Train L1 Norm: 0.0405, Test L1 Norm: 0.0300, Train Linf Norm: 11.6867, Test Linf Norm: 1.0211\n",
            "Epoch 186: Train Loss: 0.0468, Test Loss: 0.0375, Train L1 Norm: 0.0377, Test L1 Norm: 0.0270, Train Linf Norm: 6.4429, Test Linf Norm: 2.4194\n",
            "Epoch 187: Train Loss: 0.0494, Test Loss: 0.0504, Train L1 Norm: 0.0374, Test L1 Norm: 0.0307, Train Linf Norm: 5.3014, Test Linf Norm: 1.0148\n",
            "Epoch 188: Train Loss: 0.0515, Test Loss: 0.0554, Train L1 Norm: 0.0419, Test L1 Norm: 0.0348, Train Linf Norm: 8.0287, Test Linf Norm: 3.2772\n",
            "Epoch 189: Train Loss: 0.0525, Test Loss: 0.0615, Train L1 Norm: 0.0481, Test L1 Norm: 0.0399, Train Linf Norm: 14.5588, Test Linf Norm: 1.0000\n",
            "Epoch 190: Train Loss: 0.0531, Test Loss: 0.0444, Train L1 Norm: 0.0489, Test L1 Norm: 0.0330, Train Linf Norm: 14.1927, Test Linf Norm: 3.4634\n",
            "Epoch 191: Train Loss: 0.0527, Test Loss: 0.0542, Train L1 Norm: 0.0406, Test L1 Norm: 0.0337, Train Linf Norm: 6.2817, Test Linf Norm: 1.0015\n",
            "Epoch 192: Train Loss: 0.0518, Test Loss: 0.0486, Train L1 Norm: 0.0482, Test L1 Norm: 0.0322, Train Linf Norm: 15.4650, Test Linf Norm: 3.2869\n",
            "Epoch 193: Train Loss: 0.0500, Test Loss: 0.0650, Train L1 Norm: 0.0405, Test L1 Norm: 0.0384, Train Linf Norm: 8.0201, Test Linf Norm: 1.0010\n",
            "Epoch 194: Train Loss: 0.0479, Test Loss: 0.0446, Train L1 Norm: 0.0365, Test L1 Norm: 0.0321, Train Linf Norm: 5.5076, Test Linf Norm: 3.3391\n",
            "Epoch 195: Train Loss: 0.0441, Test Loss: 0.0504, Train L1 Norm: 0.0411, Test L1 Norm: 0.0315, Train Linf Norm: 12.0998, Test Linf Norm: 1.0160\n",
            "Epoch 196: Train Loss: 0.0415, Test Loss: 0.0377, Train L1 Norm: 0.0349, Test L1 Norm: 0.0264, Train Linf Norm: 7.3746, Test Linf Norm: 2.4393\n",
            "Epoch 197: Train Loss: 0.0365, Test Loss: 0.0351, Train L1 Norm: 0.0318, Test L1 Norm: 0.0256, Train Linf Norm: 6.5299, Test Linf Norm: 1.0315\n",
            "Epoch 198: Train Loss: 0.0316, Test Loss: 0.0356, Train L1 Norm: 0.0315, Test L1 Norm: 0.0247, Train Linf Norm: 8.4701, Test Linf Norm: 2.2647\n",
            "Epoch 199: Train Loss: 0.0274, Test Loss: 0.0309, Train L1 Norm: 0.0285, Test L1 Norm: 0.0224, Train Linf Norm: 8.0891, Test Linf Norm: 1.0879\n",
            "Epoch 200: Train Loss: 0.0231, Test Loss: 0.0256, Train L1 Norm: 0.0291, Test L1 Norm: 0.0202, Train Linf Norm: 10.8875, Test Linf Norm: 1.1917\n",
            "Epoch 201: Train Loss: 0.0218, Test Loss: 0.0221, Train L1 Norm: 0.0278, Test L1 Norm: 0.0189, Train Linf Norm: 10.1062, Test Linf Norm: 1.3207\n",
            "Epoch 202: Train Loss: 0.0213, Test Loss: 0.0219, Train L1 Norm: 0.0267, Test L1 Norm: 0.0189, Train Linf Norm: 9.1807, Test Linf Norm: 1.3677\n",
            "Epoch 203: Train Loss: 0.0212, Test Loss: 0.0232, Train L1 Norm: 0.0275, Test L1 Norm: 0.0191, Train Linf Norm: 10.1314, Test Linf Norm: 1.2262\n",
            "Epoch 204: Train Loss: 0.0210, Test Loss: 0.0220, Train L1 Norm: 0.0272, Test L1 Norm: 0.0188, Train Linf Norm: 9.8389, Test Linf Norm: 1.2405\n",
            "Epoch 205: Train Loss: 0.0209, Test Loss: 0.0217, Train L1 Norm: 0.0272, Test L1 Norm: 0.0186, Train Linf Norm: 9.9062, Test Linf Norm: 1.2985\n",
            "Epoch 206: Train Loss: 0.0209, Test Loss: 0.0222, Train L1 Norm: 0.0272, Test L1 Norm: 0.0187, Train Linf Norm: 9.9051, Test Linf Norm: 1.2503\n",
            "Epoch 207: Train Loss: 0.0208, Test Loss: 0.0216, Train L1 Norm: 0.0271, Test L1 Norm: 0.0186, Train Linf Norm: 9.8189, Test Linf Norm: 1.3938\n",
            "Epoch 208: Train Loss: 0.0208, Test Loss: 0.0216, Train L1 Norm: 0.0270, Test L1 Norm: 0.0187, Train Linf Norm: 9.6997, Test Linf Norm: 1.3703\n",
            "Epoch 209: Train Loss: 0.0208, Test Loss: 0.0216, Train L1 Norm: 0.0272, Test L1 Norm: 0.0186, Train Linf Norm: 9.9184, Test Linf Norm: 1.2959\n",
            "Epoch 210: Train Loss: 0.0207, Test Loss: 0.0216, Train L1 Norm: 0.0269, Test L1 Norm: 0.0186, Train Linf Norm: 9.7138, Test Linf Norm: 1.3344\n",
            "Epoch 211: Train Loss: 0.0207, Test Loss: 0.0215, Train L1 Norm: 0.0270, Test L1 Norm: 0.0186, Train Linf Norm: 9.8137, Test Linf Norm: 1.3432\n",
            "Epoch 212: Train Loss: 0.0207, Test Loss: 0.0215, Train L1 Norm: 0.0271, Test L1 Norm: 0.0186, Train Linf Norm: 9.6928, Test Linf Norm: 1.3599\n",
            "Epoch 213: Train Loss: 0.0207, Test Loss: 0.0215, Train L1 Norm: 0.0271, Test L1 Norm: 0.0186, Train Linf Norm: 9.9485, Test Linf Norm: 1.3801\n",
            "Epoch 214: Train Loss: 0.0206, Test Loss: 0.0215, Train L1 Norm: 0.0267, Test L1 Norm: 0.0186, Train Linf Norm: 9.4554, Test Linf Norm: 1.3764\n",
            "Epoch 215: Train Loss: 0.0206, Test Loss: 0.0214, Train L1 Norm: 0.0267, Test L1 Norm: 0.0184, Train Linf Norm: 9.5140, Test Linf Norm: 1.3924\n",
            "Epoch 216: Train Loss: 0.0206, Test Loss: 0.0214, Train L1 Norm: 0.0269, Test L1 Norm: 0.0185, Train Linf Norm: 9.6479, Test Linf Norm: 1.4088\n",
            "Epoch 217: Train Loss: 0.0206, Test Loss: 0.0214, Train L1 Norm: 0.0272, Test L1 Norm: 0.0184, Train Linf Norm: 9.9965, Test Linf Norm: 1.3867\n",
            "Epoch 218: Train Loss: 0.0205, Test Loss: 0.0214, Train L1 Norm: 0.0263, Test L1 Norm: 0.0184, Train Linf Norm: 9.0197, Test Linf Norm: 1.2703\n",
            "Epoch 219: Train Loss: 0.0207, Test Loss: 0.0231, Train L1 Norm: 0.0262, Test L1 Norm: 0.0188, Train Linf Norm: 8.7847, Test Linf Norm: 1.2711\n",
            "Epoch 220: Train Loss: 0.0251, Test Loss: 0.0274, Train L1 Norm: 0.0298, Test L1 Norm: 0.0208, Train Linf Norm: 10.4890, Test Linf Norm: 1.7414\n",
            "Epoch 221: Train Loss: 0.0302, Test Loss: 0.0366, Train L1 Norm: 0.0337, Test L1 Norm: 0.0256, Train Linf Norm: 11.5893, Test Linf Norm: 1.0171\n",
            "Epoch 222: Train Loss: 0.0356, Test Loss: 0.0327, Train L1 Norm: 0.0312, Test L1 Norm: 0.0237, Train Linf Norm: 6.3584, Test Linf Norm: 2.0779\n",
            "Epoch 223: Train Loss: 0.0392, Test Loss: 0.0416, Train L1 Norm: 0.0315, Test L1 Norm: 0.0275, Train Linf Norm: 4.7933, Test Linf Norm: 1.0058\n",
            "Epoch 224: Train Loss: 0.0421, Test Loss: 0.0425, Train L1 Norm: 0.0340, Test L1 Norm: 0.0278, Train Linf Norm: 5.6839, Test Linf Norm: 2.6313\n",
            "Epoch 225: Train Loss: 0.0450, Test Loss: 0.0471, Train L1 Norm: 0.0334, Test L1 Norm: 0.0301, Train Linf Norm: 3.6773, Test Linf Norm: 1.0023\n",
            "Epoch 226: Train Loss: 0.0468, Test Loss: 0.0510, Train L1 Norm: 0.0366, Test L1 Norm: 0.0340, Train Linf Norm: 6.0489, Test Linf Norm: 3.4272\n",
            "Epoch 227: Train Loss: 0.0482, Test Loss: 0.0578, Train L1 Norm: 0.0450, Test L1 Norm: 0.0354, Train Linf Norm: 14.2511, Test Linf Norm: 1.0000\n",
            "Epoch 228: Train Loss: 0.0489, Test Loss: 0.0436, Train L1 Norm: 0.0464, Test L1 Norm: 0.0334, Train Linf Norm: 15.2807, Test Linf Norm: 3.9982\n",
            "Epoch 229: Train Loss: 0.0485, Test Loss: 0.0566, Train L1 Norm: 0.0369, Test L1 Norm: 0.0326, Train Linf Norm: 4.8169, Test Linf Norm: 1.0035\n",
            "Epoch 230: Train Loss: 0.0477, Test Loss: 0.0427, Train L1 Norm: 0.0365, Test L1 Norm: 0.0302, Train Linf Norm: 5.7516, Test Linf Norm: 3.2320\n",
            "Epoch 231: Train Loss: 0.0464, Test Loss: 0.0569, Train L1 Norm: 0.0356, Test L1 Norm: 0.0337, Train Linf Norm: 5.1299, Test Linf Norm: 1.0000\n",
            "Epoch 232: Train Loss: 0.0440, Test Loss: 0.0387, Train L1 Norm: 0.0439, Test L1 Norm: 0.0276, Train Linf Norm: 14.8394, Test Linf Norm: 2.7235\n",
            "Epoch 233: Train Loss: 0.0410, Test Loss: 0.0436, Train L1 Norm: 0.0346, Test L1 Norm: 0.0277, Train Linf Norm: 7.3450, Test Linf Norm: 1.0053\n",
            "Epoch 234: Train Loss: 0.0371, Test Loss: 0.0334, Train L1 Norm: 0.0319, Test L1 Norm: 0.0260, Train Linf Norm: 6.5184, Test Linf Norm: 2.8405\n",
            "Epoch 235: Train Loss: 0.0335, Test Loss: 0.0288, Train L1 Norm: 0.0351, Test L1 Norm: 0.0220, Train Linf Norm: 5.9833, Test Linf Norm: 1.0736\n",
            "Epoch 236: Train Loss: 0.0295, Test Loss: 0.0314, Train L1 Norm: 0.0332, Test L1 Norm: 0.0222, Train Linf Norm: 11.9315, Test Linf Norm: 1.8766\n",
            "Epoch 237: Train Loss: 0.0241, Test Loss: 0.0283, Train L1 Norm: 0.0299, Test L1 Norm: 0.0214, Train Linf Norm: 11.3792, Test Linf Norm: 1.0208\n",
            "Epoch 238: Train Loss: 0.0215, Test Loss: 0.0207, Train L1 Norm: 0.0266, Test L1 Norm: 0.0179, Train Linf Norm: 9.2283, Test Linf Norm: 1.2144\n",
            "Epoch 239: Train Loss: 0.0201, Test Loss: 0.0207, Train L1 Norm: 0.0258, Test L1 Norm: 0.0178, Train Linf Norm: 9.1240, Test Linf Norm: 1.3977\n",
            "Epoch 240: Train Loss: 0.0199, Test Loss: 0.0207, Train L1 Norm: 0.0255, Test L1 Norm: 0.0177, Train Linf Norm: 8.9622, Test Linf Norm: 1.4322\n",
            "Epoch 241: Train Loss: 0.0197, Test Loss: 0.0205, Train L1 Norm: 0.0257, Test L1 Norm: 0.0175, Train Linf Norm: 9.3185, Test Linf Norm: 1.2740\n",
            "Epoch 242: Train Loss: 0.0196, Test Loss: 0.0203, Train L1 Norm: 0.0263, Test L1 Norm: 0.0176, Train Linf Norm: 9.9434, Test Linf Norm: 1.3708\n",
            "Epoch 243: Train Loss: 0.0195, Test Loss: 0.0205, Train L1 Norm: 0.0260, Test L1 Norm: 0.0178, Train Linf Norm: 9.7196, Test Linf Norm: 1.2706\n",
            "Epoch 244: Train Loss: 0.0195, Test Loss: 0.0204, Train L1 Norm: 0.0253, Test L1 Norm: 0.0175, Train Linf Norm: 8.9378, Test Linf Norm: 1.2932\n",
            "Epoch 245: Train Loss: 0.0194, Test Loss: 0.0202, Train L1 Norm: 0.0257, Test L1 Norm: 0.0176, Train Linf Norm: 9.5062, Test Linf Norm: 1.3135\n",
            "Epoch 246: Train Loss: 0.0194, Test Loss: 0.0202, Train L1 Norm: 0.0254, Test L1 Norm: 0.0174, Train Linf Norm: 9.1836, Test Linf Norm: 1.2964\n",
            "Epoch 247: Train Loss: 0.0194, Test Loss: 0.0202, Train L1 Norm: 0.0256, Test L1 Norm: 0.0175, Train Linf Norm: 9.3189, Test Linf Norm: 1.2990\n",
            "Epoch 248: Train Loss: 0.0194, Test Loss: 0.0202, Train L1 Norm: 0.0255, Test L1 Norm: 0.0175, Train Linf Norm: 9.3023, Test Linf Norm: 1.2929\n",
            "Epoch 249: Train Loss: 0.0193, Test Loss: 0.0202, Train L1 Norm: 0.0255, Test L1 Norm: 0.0175, Train Linf Norm: 9.3446, Test Linf Norm: 1.2704\n",
            "Epoch 250: Train Loss: 0.0193, Test Loss: 0.0202, Train L1 Norm: 0.0257, Test L1 Norm: 0.0175, Train Linf Norm: 9.5797, Test Linf Norm: 1.2881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:08:13,542]\u001b[0m Trial 3 finished with value: 0.017426438264548778 and parameters: {'n_layers': 2, 'n_units_0': 181, 'n_units_1': 1552, 'hidden_activation': 'LeakyReLU', 'output_activation': 'ReLU', 'loss': 'MAE', 'optimizer': 'Adagrad', 'lr': 0.002332732546961667, 'batch_size': 1048, 'n_epochs': 251, 'scheduler': 'CosineAnnealingLR', 't_max_fraction': 0.07805311496038014, 'eta_min': 0.00019455713537453316}. Best is trial 1 with value: 0.010856217047572135.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 251: Train Loss: 0.0193, Test Loss: 0.0202, Train L1 Norm: 0.0256, Test L1 Norm: 0.0174, Train Linf Norm: 9.3031, Test Linf Norm: 1.2581\n",
            "Epoch 1: Train Loss: 0.7307, Test Loss: 0.2685, Train L1 Norm: 2.6758, Test L1 Norm: 0.3149, Train Linf Norm: 142.7409, Test Linf Norm: 10.5755\n",
            "Epoch 2: Train Loss: 0.2464, Test Loss: 0.1421, Train L1 Norm: 0.8985, Test L1 Norm: 0.2177, Train Linf Norm: 48.9314, Test Linf Norm: 7.7479\n",
            "Epoch 3: Train Loss: 0.2019, Test Loss: 0.1756, Train L1 Norm: 0.6227, Test L1 Norm: 0.1479, Train Linf Norm: 33.1338, Test Linf Norm: 4.7899\n",
            "Epoch 4: Train Loss: 0.1761, Test Loss: 0.1015, Train L1 Norm: 0.4997, Test L1 Norm: 0.1100, Train Linf Norm: 26.1969, Test Linf Norm: 3.6865\n",
            "Epoch 5: Train Loss: 0.1567, Test Loss: 0.1343, Train L1 Norm: 0.4838, Test L1 Norm: 0.1025, Train Linf Norm: 25.8996, Test Linf Norm: 2.9970\n",
            "Epoch 6: Train Loss: 0.1455, Test Loss: 0.0783, Train L1 Norm: 0.4590, Test L1 Norm: 0.0860, Train Linf Norm: 24.7615, Test Linf Norm: 2.8094\n",
            "Epoch 7: Train Loss: 0.1348, Test Loss: 0.1004, Train L1 Norm: 0.3533, Test L1 Norm: 0.1109, Train Linf Norm: 18.2974, Test Linf Norm: 3.5885\n",
            "Epoch 8: Train Loss: 0.1274, Test Loss: 0.0902, Train L1 Norm: 0.3247, Test L1 Norm: 0.1062, Train Linf Norm: 16.7890, Test Linf Norm: 3.4271\n",
            "Epoch 9: Train Loss: 0.1219, Test Loss: 0.1098, Train L1 Norm: 0.3573, Test L1 Norm: 0.1153, Train Linf Norm: 19.1100, Test Linf Norm: 3.5460\n",
            "Epoch 10: Train Loss: 0.1187, Test Loss: 0.0843, Train L1 Norm: 0.2982, Test L1 Norm: 0.0871, Train Linf Norm: 15.4639, Test Linf Norm: 2.7242\n",
            "Epoch 11: Train Loss: 0.1138, Test Loss: 0.1662, Train L1 Norm: 0.2587, Test L1 Norm: 0.1246, Train Linf Norm: 13.0926, Test Linf Norm: 3.3127\n",
            "Epoch 12: Train Loss: 0.1102, Test Loss: 0.1409, Train L1 Norm: 0.2711, Test L1 Norm: 0.1119, Train Linf Norm: 13.8199, Test Linf Norm: 3.0930\n",
            "Epoch 13: Train Loss: 0.1071, Test Loss: 0.1058, Train L1 Norm: 0.2752, Test L1 Norm: 0.0659, Train Linf Norm: 14.4245, Test Linf Norm: 1.7583\n",
            "Epoch 14: Train Loss: 0.1029, Test Loss: 0.0861, Train L1 Norm: 0.2623, Test L1 Norm: 0.0747, Train Linf Norm: 13.7448, Test Linf Norm: 2.2270\n",
            "Epoch 15: Train Loss: 0.0998, Test Loss: 0.1139, Train L1 Norm: 0.2420, Test L1 Norm: 0.0639, Train Linf Norm: 12.5490, Test Linf Norm: 1.4637\n",
            "Epoch 16: Train Loss: 0.0257, Test Loss: 0.0224, Train L1 Norm: 0.1499, Test L1 Norm: 0.0383, Train Linf Norm: 8.2407, Test Linf Norm: 1.2932\n",
            "Epoch 17: Train Loss: 0.0210, Test Loss: 0.0212, Train L1 Norm: 0.1315, Test L1 Norm: 0.0351, Train Linf Norm: 7.2059, Test Linf Norm: 1.1509\n",
            "Epoch 18: Train Loss: 0.0193, Test Loss: 0.0172, Train L1 Norm: 0.1290, Test L1 Norm: 0.0337, Train Linf Norm: 7.0208, Test Linf Norm: 1.1367\n",
            "Epoch 19: Train Loss: 0.0183, Test Loss: 0.0190, Train L1 Norm: 0.1307, Test L1 Norm: 0.0344, Train Linf Norm: 7.2555, Test Linf Norm: 1.1582\n",
            "Epoch 20: Train Loss: 0.0176, Test Loss: 0.0166, Train L1 Norm: 0.1280, Test L1 Norm: 0.0325, Train Linf Norm: 7.0786, Test Linf Norm: 1.1083\n",
            "Epoch 21: Train Loss: 0.0168, Test Loss: 0.0172, Train L1 Norm: 0.1275, Test L1 Norm: 0.0335, Train Linf Norm: 7.0840, Test Linf Norm: 1.1460\n",
            "Epoch 22: Train Loss: 0.0165, Test Loss: 0.0156, Train L1 Norm: 0.1198, Test L1 Norm: 0.0325, Train Linf Norm: 6.6323, Test Linf Norm: 1.1265\n",
            "Epoch 23: Train Loss: 0.0164, Test Loss: 0.0142, Train L1 Norm: 0.1244, Test L1 Norm: 0.0313, Train Linf Norm: 6.9366, Test Linf Norm: 1.0953\n",
            "Epoch 24: Train Loss: 0.0160, Test Loss: 0.0128, Train L1 Norm: 0.1228, Test L1 Norm: 0.0297, Train Linf Norm: 6.8344, Test Linf Norm: 1.0322\n",
            "Epoch 25: Train Loss: 0.0161, Test Loss: 0.0139, Train L1 Norm: 0.1194, Test L1 Norm: 0.0312, Train Linf Norm: 6.6030, Test Linf Norm: 1.0963\n",
            "Epoch 26: Train Loss: 0.0158, Test Loss: 0.0126, Train L1 Norm: 0.1178, Test L1 Norm: 0.0286, Train Linf Norm: 6.5377, Test Linf Norm: 1.0067\n",
            "Epoch 27: Train Loss: 0.0159, Test Loss: 0.0139, Train L1 Norm: 0.1139, Test L1 Norm: 0.0290, Train Linf Norm: 6.2826, Test Linf Norm: 1.0011\n",
            "Epoch 28: Train Loss: 0.0158, Test Loss: 0.0154, Train L1 Norm: 0.1097, Test L1 Norm: 0.0278, Train Linf Norm: 6.0622, Test Linf Norm: 0.9326\n",
            "Epoch 29: Train Loss: 0.0159, Test Loss: 0.0109, Train L1 Norm: 0.1106, Test L1 Norm: 0.0266, Train Linf Norm: 6.1303, Test Linf Norm: 0.9319\n",
            "Epoch 30: Train Loss: 0.0157, Test Loss: 0.0120, Train L1 Norm: 0.1105, Test L1 Norm: 0.0266, Train Linf Norm: 6.1089, Test Linf Norm: 0.9295\n",
            "Epoch 31: Train Loss: 0.0158, Test Loss: 0.0153, Train L1 Norm: 0.1057, Test L1 Norm: 0.0289, Train Linf Norm: 5.5969, Test Linf Norm: 0.9995\n",
            "Epoch 32: Train Loss: 0.0158, Test Loss: 0.0139, Train L1 Norm: 0.1058, Test L1 Norm: 0.0279, Train Linf Norm: 5.8358, Test Linf Norm: 0.9671\n",
            "Epoch 33: Train Loss: 0.0158, Test Loss: 0.0151, Train L1 Norm: 0.1056, Test L1 Norm: 0.0264, Train Linf Norm: 5.8570, Test Linf Norm: 0.8815\n",
            "Epoch 34: Train Loss: 0.0159, Test Loss: 0.0318, Train L1 Norm: 0.1039, Test L1 Norm: 0.0303, Train Linf Norm: 5.7409, Test Linf Norm: 0.8181\n",
            "Epoch 35: Train Loss: 0.0158, Test Loss: 0.0218, Train L1 Norm: 0.1000, Test L1 Norm: 0.0306, Train Linf Norm: 5.4589, Test Linf Norm: 1.0003\n",
            "Epoch 36: Train Loss: 0.0156, Test Loss: 0.0171, Train L1 Norm: 0.0982, Test L1 Norm: 0.0260, Train Linf Norm: 5.3998, Test Linf Norm: 0.8506\n",
            "Epoch 37: Train Loss: 0.0159, Test Loss: 0.0180, Train L1 Norm: 0.0968, Test L1 Norm: 0.0291, Train Linf Norm: 5.3091, Test Linf Norm: 0.9789\n",
            "Epoch 38: Train Loss: 0.0157, Test Loss: 0.0126, Train L1 Norm: 0.1009, Test L1 Norm: 0.0246, Train Linf Norm: 5.5786, Test Linf Norm: 0.8411\n",
            "Epoch 39: Train Loss: 0.0090, Test Loss: 0.0090, Train L1 Norm: 0.0943, Test L1 Norm: 0.0241, Train Linf Norm: 5.2872, Test Linf Norm: 0.8597\n",
            "Epoch 40: Train Loss: 0.0089, Test Loss: 0.0090, Train L1 Norm: 0.0937, Test L1 Norm: 0.0239, Train Linf Norm: 5.2552, Test Linf Norm: 0.8493\n",
            "Epoch 41: Train Loss: 0.0088, Test Loss: 0.0089, Train L1 Norm: 0.0921, Test L1 Norm: 0.0240, Train Linf Norm: 5.1669, Test Linf Norm: 0.8543\n",
            "Epoch 42: Train Loss: 0.0088, Test Loss: 0.0090, Train L1 Norm: 0.0922, Test L1 Norm: 0.0237, Train Linf Norm: 5.1625, Test Linf Norm: 0.8397\n",
            "Epoch 43: Train Loss: 0.0088, Test Loss: 0.0088, Train L1 Norm: 0.0911, Test L1 Norm: 0.0238, Train Linf Norm: 5.0257, Test Linf Norm: 0.8465\n",
            "Epoch 44: Train Loss: 0.0087, Test Loss: 0.0088, Train L1 Norm: 0.0906, Test L1 Norm: 0.0237, Train Linf Norm: 5.0805, Test Linf Norm: 0.8420\n",
            "Epoch 45: Train Loss: 0.0087, Test Loss: 0.0087, Train L1 Norm: 0.0907, Test L1 Norm: 0.0236, Train Linf Norm: 5.0398, Test Linf Norm: 0.8384\n",
            "Epoch 46: Train Loss: 0.0086, Test Loss: 0.0088, Train L1 Norm: 0.0910, Test L1 Norm: 0.0235, Train Linf Norm: 5.0846, Test Linf Norm: 0.8297\n",
            "Epoch 47: Train Loss: 0.0086, Test Loss: 0.0087, Train L1 Norm: 0.0907, Test L1 Norm: 0.0235, Train Linf Norm: 5.0774, Test Linf Norm: 0.8356\n",
            "Epoch 48: Train Loss: 0.0086, Test Loss: 0.0087, Train L1 Norm: 0.0897, Test L1 Norm: 0.0237, Train Linf Norm: 5.0088, Test Linf Norm: 0.8419\n",
            "Epoch 49: Train Loss: 0.0085, Test Loss: 0.0089, Train L1 Norm: 0.0904, Test L1 Norm: 0.0239, Train Linf Norm: 5.0618, Test Linf Norm: 0.8475\n",
            "Epoch 50: Train Loss: 0.0085, Test Loss: 0.0087, Train L1 Norm: 0.0892, Test L1 Norm: 0.0236, Train Linf Norm: 4.9749, Test Linf Norm: 0.8386\n",
            "Epoch 51: Train Loss: 0.0085, Test Loss: 0.0092, Train L1 Norm: 0.0895, Test L1 Norm: 0.0233, Train Linf Norm: 5.0093, Test Linf Norm: 0.8208\n",
            "Epoch 52: Train Loss: 0.0084, Test Loss: 0.0085, Train L1 Norm: 0.0892, Test L1 Norm: 0.0233, Train Linf Norm: 4.9948, Test Linf Norm: 0.8245\n",
            "Epoch 53: Train Loss: 0.0084, Test Loss: 0.0084, Train L1 Norm: 0.0890, Test L1 Norm: 0.0232, Train Linf Norm: 5.0008, Test Linf Norm: 0.8238\n",
            "Epoch 54: Train Loss: 0.0084, Test Loss: 0.0086, Train L1 Norm: 0.0886, Test L1 Norm: 0.0232, Train Linf Norm: 4.9231, Test Linf Norm: 0.8191\n",
            "Epoch 55: Train Loss: 0.0084, Test Loss: 0.0085, Train L1 Norm: 0.0884, Test L1 Norm: 0.0232, Train Linf Norm: 4.9332, Test Linf Norm: 0.8206\n",
            "Epoch 56: Train Loss: 0.0083, Test Loss: 0.0083, Train L1 Norm: 0.0875, Test L1 Norm: 0.0232, Train Linf Norm: 4.8885, Test Linf Norm: 0.8246\n",
            "Epoch 57: Train Loss: 0.0083, Test Loss: 0.0084, Train L1 Norm: 0.0876, Test L1 Norm: 0.0233, Train Linf Norm: 4.9075, Test Linf Norm: 0.8274\n",
            "Epoch 58: Train Loss: 0.0083, Test Loss: 0.0083, Train L1 Norm: 0.0874, Test L1 Norm: 0.0231, Train Linf Norm: 4.8766, Test Linf Norm: 0.8177\n",
            "Epoch 59: Train Loss: 0.0082, Test Loss: 0.0083, Train L1 Norm: 0.0863, Test L1 Norm: 0.0230, Train Linf Norm: 4.8083, Test Linf Norm: 0.8136\n",
            "Epoch 60: Train Loss: 0.0082, Test Loss: 0.0082, Train L1 Norm: 0.0867, Test L1 Norm: 0.0229, Train Linf Norm: 4.8354, Test Linf Norm: 0.8101\n",
            "Epoch 61: Train Loss: 0.0082, Test Loss: 0.0082, Train L1 Norm: 0.0860, Test L1 Norm: 0.0229, Train Linf Norm: 4.7957, Test Linf Norm: 0.8082\n",
            "Epoch 62: Train Loss: 0.0082, Test Loss: 0.0082, Train L1 Norm: 0.0856, Test L1 Norm: 0.0228, Train Linf Norm: 4.7892, Test Linf Norm: 0.8057\n",
            "Epoch 63: Train Loss: 0.0081, Test Loss: 0.0082, Train L1 Norm: 0.0854, Test L1 Norm: 0.0228, Train Linf Norm: 4.7586, Test Linf Norm: 0.8047\n",
            "Epoch 64: Train Loss: 0.0081, Test Loss: 0.0082, Train L1 Norm: 0.0857, Test L1 Norm: 0.0228, Train Linf Norm: 4.7942, Test Linf Norm: 0.8031\n",
            "Epoch 65: Train Loss: 0.0081, Test Loss: 0.0081, Train L1 Norm: 0.0847, Test L1 Norm: 0.0226, Train Linf Norm: 4.7154, Test Linf Norm: 0.7982\n",
            "Epoch 66: Train Loss: 0.0081, Test Loss: 0.0081, Train L1 Norm: 0.0848, Test L1 Norm: 0.0227, Train Linf Norm: 4.7231, Test Linf Norm: 0.8030\n",
            "Epoch 67: Train Loss: 0.0080, Test Loss: 0.0084, Train L1 Norm: 0.0840, Test L1 Norm: 0.0226, Train Linf Norm: 4.6755, Test Linf Norm: 0.7936\n",
            "Epoch 68: Train Loss: 0.0080, Test Loss: 0.0081, Train L1 Norm: 0.0848, Test L1 Norm: 0.0226, Train Linf Norm: 4.7439, Test Linf Norm: 0.7960\n",
            "Epoch 69: Train Loss: 0.0080, Test Loss: 0.0080, Train L1 Norm: 0.0835, Test L1 Norm: 0.0225, Train Linf Norm: 4.6268, Test Linf Norm: 0.7950\n",
            "Epoch 70: Train Loss: 0.0079, Test Loss: 0.0080, Train L1 Norm: 0.0834, Test L1 Norm: 0.0226, Train Linf Norm: 4.6449, Test Linf Norm: 0.7976\n",
            "Epoch 71: Train Loss: 0.0079, Test Loss: 0.0080, Train L1 Norm: 0.0832, Test L1 Norm: 0.0224, Train Linf Norm: 4.6404, Test Linf Norm: 0.7909\n",
            "Epoch 72: Train Loss: 0.0079, Test Loss: 0.0080, Train L1 Norm: 0.0829, Test L1 Norm: 0.0224, Train Linf Norm: 4.5398, Test Linf Norm: 0.7875\n",
            "Epoch 73: Train Loss: 0.0079, Test Loss: 0.0079, Train L1 Norm: 0.0829, Test L1 Norm: 0.0223, Train Linf Norm: 4.6286, Test Linf Norm: 0.7846\n",
            "Epoch 74: Train Loss: 0.0079, Test Loss: 0.0079, Train L1 Norm: 0.0820, Test L1 Norm: 0.0223, Train Linf Norm: 4.5274, Test Linf Norm: 0.7848\n",
            "Epoch 75: Train Loss: 0.0078, Test Loss: 0.0081, Train L1 Norm: 0.0821, Test L1 Norm: 0.0222, Train Linf Norm: 4.5670, Test Linf Norm: 0.7801\n",
            "Epoch 76: Train Loss: 0.0078, Test Loss: 0.0079, Train L1 Norm: 0.0822, Test L1 Norm: 0.0222, Train Linf Norm: 4.5532, Test Linf Norm: 0.7797\n",
            "Epoch 77: Train Loss: 0.0078, Test Loss: 0.0079, Train L1 Norm: 0.0823, Test L1 Norm: 0.0222, Train Linf Norm: 4.5737, Test Linf Norm: 0.7837\n",
            "Epoch 78: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0806, Test L1 Norm: 0.0221, Train Linf Norm: 4.4719, Test Linf Norm: 0.7773\n",
            "Epoch 79: Train Loss: 0.0077, Test Loss: 0.0079, Train L1 Norm: 0.0808, Test L1 Norm: 0.0222, Train Linf Norm: 4.4958, Test Linf Norm: 0.7838\n",
            "Epoch 80: Train Loss: 0.0077, Test Loss: 0.0080, Train L1 Norm: 0.0812, Test L1 Norm: 0.0222, Train Linf Norm: 4.5219, Test Linf Norm: 0.7823\n",
            "Epoch 81: Train Loss: 0.0077, Test Loss: 0.0078, Train L1 Norm: 0.0805, Test L1 Norm: 0.0220, Train Linf Norm: 4.4812, Test Linf Norm: 0.7737\n",
            "Epoch 82: Train Loss: 0.0077, Test Loss: 0.0078, Train L1 Norm: 0.0802, Test L1 Norm: 0.0220, Train Linf Norm: 4.4619, Test Linf Norm: 0.7728\n",
            "Epoch 83: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0799, Test L1 Norm: 0.0220, Train Linf Norm: 4.4260, Test Linf Norm: 0.7749\n",
            "Epoch 84: Train Loss: 0.0076, Test Loss: 0.0078, Train L1 Norm: 0.0802, Test L1 Norm: 0.0218, Train Linf Norm: 4.4625, Test Linf Norm: 0.7646\n",
            "Epoch 85: Train Loss: 0.0076, Test Loss: 0.0078, Train L1 Norm: 0.0794, Test L1 Norm: 0.0217, Train Linf Norm: 4.4105, Test Linf Norm: 0.7603\n",
            "Epoch 86: Train Loss: 0.0076, Test Loss: 0.0077, Train L1 Norm: 0.0791, Test L1 Norm: 0.0219, Train Linf Norm: 4.3897, Test Linf Norm: 0.7676\n",
            "Epoch 87: Train Loss: 0.0076, Test Loss: 0.0077, Train L1 Norm: 0.0792, Test L1 Norm: 0.0218, Train Linf Norm: 4.4099, Test Linf Norm: 0.7648\n",
            "Epoch 88: Train Loss: 0.0076, Test Loss: 0.0077, Train L1 Norm: 0.0791, Test L1 Norm: 0.0218, Train Linf Norm: 4.3935, Test Linf Norm: 0.7654\n",
            "Epoch 89: Train Loss: 0.0075, Test Loss: 0.0077, Train L1 Norm: 0.0788, Test L1 Norm: 0.0216, Train Linf Norm: 4.3657, Test Linf Norm: 0.7525\n",
            "Epoch 90: Train Loss: 0.0075, Test Loss: 0.0077, Train L1 Norm: 0.0787, Test L1 Norm: 0.0216, Train Linf Norm: 4.3660, Test Linf Norm: 0.7563\n",
            "Epoch 91: Train Loss: 0.0075, Test Loss: 0.0077, Train L1 Norm: 0.0784, Test L1 Norm: 0.0218, Train Linf Norm: 4.3245, Test Linf Norm: 0.7665\n",
            "Epoch 92: Train Loss: 0.0075, Test Loss: 0.0076, Train L1 Norm: 0.0786, Test L1 Norm: 0.0215, Train Linf Norm: 4.3617, Test Linf Norm: 0.7541\n",
            "Epoch 93: Train Loss: 0.0075, Test Loss: 0.0075, Train L1 Norm: 0.0783, Test L1 Norm: 0.0217, Train Linf Norm: 4.3121, Test Linf Norm: 0.7613\n",
            "Epoch 94: Train Loss: 0.0074, Test Loss: 0.0076, Train L1 Norm: 0.0778, Test L1 Norm: 0.0216, Train Linf Norm: 4.3124, Test Linf Norm: 0.7566\n",
            "Epoch 95: Train Loss: 0.0074, Test Loss: 0.0075, Train L1 Norm: 0.0781, Test L1 Norm: 0.0215, Train Linf Norm: 4.3273, Test Linf Norm: 0.7523\n",
            "Epoch 96: Train Loss: 0.0074, Test Loss: 0.0077, Train L1 Norm: 0.0776, Test L1 Norm: 0.0214, Train Linf Norm: 4.2948, Test Linf Norm: 0.7481\n",
            "Epoch 97: Train Loss: 0.0074, Test Loss: 0.0075, Train L1 Norm: 0.0771, Test L1 Norm: 0.0215, Train Linf Norm: 4.2751, Test Linf Norm: 0.7517\n",
            "Epoch 98: Train Loss: 0.0074, Test Loss: 0.0075, Train L1 Norm: 0.0771, Test L1 Norm: 0.0214, Train Linf Norm: 4.2690, Test Linf Norm: 0.7491\n",
            "Epoch 99: Train Loss: 0.0073, Test Loss: 0.0075, Train L1 Norm: 0.0770, Test L1 Norm: 0.0214, Train Linf Norm: 4.2358, Test Linf Norm: 0.7497\n",
            "Epoch 100: Train Loss: 0.0073, Test Loss: 0.0075, Train L1 Norm: 0.0768, Test L1 Norm: 0.0213, Train Linf Norm: 4.2310, Test Linf Norm: 0.7467\n",
            "Epoch 101: Train Loss: 0.0073, Test Loss: 0.0074, Train L1 Norm: 0.0769, Test L1 Norm: 0.0212, Train Linf Norm: 4.2580, Test Linf Norm: 0.7416\n",
            "Epoch 102: Train Loss: 0.0073, Test Loss: 0.0074, Train L1 Norm: 0.0761, Test L1 Norm: 0.0213, Train Linf Norm: 4.1868, Test Linf Norm: 0.7446\n",
            "Epoch 103: Train Loss: 0.0073, Test Loss: 0.0074, Train L1 Norm: 0.0760, Test L1 Norm: 0.0213, Train Linf Norm: 4.2054, Test Linf Norm: 0.7469\n",
            "Epoch 104: Train Loss: 0.0072, Test Loss: 0.0074, Train L1 Norm: 0.0766, Test L1 Norm: 0.0211, Train Linf Norm: 4.2476, Test Linf Norm: 0.7360\n",
            "Epoch 105: Train Loss: 0.0072, Test Loss: 0.0074, Train L1 Norm: 0.0755, Test L1 Norm: 0.0212, Train Linf Norm: 4.1915, Test Linf Norm: 0.7416\n",
            "Epoch 106: Train Loss: 0.0072, Test Loss: 0.0077, Train L1 Norm: 0.0758, Test L1 Norm: 0.0211, Train Linf Norm: 4.1791, Test Linf Norm: 0.7333\n",
            "Epoch 107: Train Loss: 0.0072, Test Loss: 0.0073, Train L1 Norm: 0.0756, Test L1 Norm: 0.0211, Train Linf Norm: 4.1898, Test Linf Norm: 0.7374\n",
            "Epoch 108: Train Loss: 0.0072, Test Loss: 0.0073, Train L1 Norm: 0.0752, Test L1 Norm: 0.0211, Train Linf Norm: 4.1581, Test Linf Norm: 0.7378\n",
            "Epoch 109: Train Loss: 0.0072, Test Loss: 0.0073, Train L1 Norm: 0.0752, Test L1 Norm: 0.0211, Train Linf Norm: 4.1481, Test Linf Norm: 0.7399\n",
            "Epoch 110: Train Loss: 0.0072, Test Loss: 0.0074, Train L1 Norm: 0.0751, Test L1 Norm: 0.0213, Train Linf Norm: 4.1470, Test Linf Norm: 0.7441\n",
            "Epoch 111: Train Loss: 0.0071, Test Loss: 0.0073, Train L1 Norm: 0.0754, Test L1 Norm: 0.0211, Train Linf Norm: 4.1773, Test Linf Norm: 0.7393\n",
            "Epoch 112: Train Loss: 0.0071, Test Loss: 0.0074, Train L1 Norm: 0.0747, Test L1 Norm: 0.0210, Train Linf Norm: 4.1269, Test Linf Norm: 0.7300\n",
            "Epoch 113: Train Loss: 0.0071, Test Loss: 0.0072, Train L1 Norm: 0.0750, Test L1 Norm: 0.0209, Train Linf Norm: 4.1425, Test Linf Norm: 0.7297\n",
            "Epoch 114: Train Loss: 0.0071, Test Loss: 0.0077, Train L1 Norm: 0.0746, Test L1 Norm: 0.0209, Train Linf Norm: 4.1177, Test Linf Norm: 0.7228\n",
            "Epoch 115: Train Loss: 0.0071, Test Loss: 0.0072, Train L1 Norm: 0.0749, Test L1 Norm: 0.0208, Train Linf Norm: 4.1238, Test Linf Norm: 0.7256\n",
            "Epoch 116: Train Loss: 0.0071, Test Loss: 0.0072, Train L1 Norm: 0.0742, Test L1 Norm: 0.0209, Train Linf Norm: 4.1082, Test Linf Norm: 0.7303\n",
            "Epoch 117: Train Loss: 0.0071, Test Loss: 0.0073, Train L1 Norm: 0.0739, Test L1 Norm: 0.0208, Train Linf Norm: 4.1010, Test Linf Norm: 0.7256\n",
            "Epoch 118: Train Loss: 0.0070, Test Loss: 0.0072, Train L1 Norm: 0.0740, Test L1 Norm: 0.0209, Train Linf Norm: 4.0888, Test Linf Norm: 0.7322\n",
            "Epoch 119: Train Loss: 0.0070, Test Loss: 0.0074, Train L1 Norm: 0.0741, Test L1 Norm: 0.0210, Train Linf Norm: 4.0798, Test Linf Norm: 0.7333\n",
            "Epoch 120: Train Loss: 0.0070, Test Loss: 0.0072, Train L1 Norm: 0.0735, Test L1 Norm: 0.0209, Train Linf Norm: 4.0786, Test Linf Norm: 0.7291\n",
            "Epoch 121: Train Loss: 0.0070, Test Loss: 0.0071, Train L1 Norm: 0.0735, Test L1 Norm: 0.0208, Train Linf Norm: 4.0829, Test Linf Norm: 0.7248\n",
            "Epoch 122: Train Loss: 0.0070, Test Loss: 0.0073, Train L1 Norm: 0.0734, Test L1 Norm: 0.0209, Train Linf Norm: 4.0687, Test Linf Norm: 0.7300\n",
            "Epoch 123: Train Loss: 0.0070, Test Loss: 0.0071, Train L1 Norm: 0.0735, Test L1 Norm: 0.0208, Train Linf Norm: 4.0762, Test Linf Norm: 0.7287\n",
            "Epoch 124: Train Loss: 0.0070, Test Loss: 0.0071, Train L1 Norm: 0.0733, Test L1 Norm: 0.0207, Train Linf Norm: 4.0640, Test Linf Norm: 0.7213\n",
            "Epoch 125: Train Loss: 0.0070, Test Loss: 0.0072, Train L1 Norm: 0.0730, Test L1 Norm: 0.0208, Train Linf Norm: 4.0225, Test Linf Norm: 0.7275\n",
            "Epoch 126: Train Loss: 0.0069, Test Loss: 0.0071, Train L1 Norm: 0.0738, Test L1 Norm: 0.0206, Train Linf Norm: 4.0906, Test Linf Norm: 0.7147\n",
            "Epoch 127: Train Loss: 0.0069, Test Loss: 0.0073, Train L1 Norm: 0.0727, Test L1 Norm: 0.0208, Train Linf Norm: 3.9979, Test Linf Norm: 0.7263\n",
            "Epoch 128: Train Loss: 0.0069, Test Loss: 0.0071, Train L1 Norm: 0.0730, Test L1 Norm: 0.0207, Train Linf Norm: 4.0445, Test Linf Norm: 0.7208\n",
            "Epoch 129: Train Loss: 0.0069, Test Loss: 0.0071, Train L1 Norm: 0.0728, Test L1 Norm: 0.0206, Train Linf Norm: 4.0358, Test Linf Norm: 0.7187\n",
            "Epoch 130: Train Loss: 0.0069, Test Loss: 0.0070, Train L1 Norm: 0.0722, Test L1 Norm: 0.0205, Train Linf Norm: 4.0085, Test Linf Norm: 0.7157\n",
            "Epoch 131: Train Loss: 0.0068, Test Loss: 0.0072, Train L1 Norm: 0.0727, Test L1 Norm: 0.0205, Train Linf Norm: 4.0217, Test Linf Norm: 0.7109\n",
            "Epoch 132: Train Loss: 0.0068, Test Loss: 0.0070, Train L1 Norm: 0.0722, Test L1 Norm: 0.0205, Train Linf Norm: 3.9698, Test Linf Norm: 0.7161\n",
            "Epoch 133: Train Loss: 0.0068, Test Loss: 0.0070, Train L1 Norm: 0.0726, Test L1 Norm: 0.0204, Train Linf Norm: 4.0055, Test Linf Norm: 0.7113\n",
            "Epoch 134: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0722, Test L1 Norm: 0.0204, Train Linf Norm: 3.9800, Test Linf Norm: 0.7095\n",
            "Epoch 135: Train Loss: 0.0068, Test Loss: 0.0071, Train L1 Norm: 0.0719, Test L1 Norm: 0.0205, Train Linf Norm: 3.9659, Test Linf Norm: 0.7148\n",
            "Epoch 136: Train Loss: 0.0068, Test Loss: 0.0070, Train L1 Norm: 0.0721, Test L1 Norm: 0.0204, Train Linf Norm: 3.9961, Test Linf Norm: 0.7095\n",
            "Epoch 137: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0719, Test L1 Norm: 0.0205, Train Linf Norm: 3.9779, Test Linf Norm: 0.7157\n",
            "Epoch 138: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0720, Test L1 Norm: 0.0204, Train Linf Norm: 3.9878, Test Linf Norm: 0.7113\n",
            "Epoch 139: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0714, Test L1 Norm: 0.0203, Train Linf Norm: 3.9398, Test Linf Norm: 0.7035\n",
            "Epoch 140: Train Loss: 0.0067, Test Loss: 0.0069, Train L1 Norm: 0.0717, Test L1 Norm: 0.0203, Train Linf Norm: 3.9821, Test Linf Norm: 0.7074\n",
            "Epoch 141: Train Loss: 0.0067, Test Loss: 0.0070, Train L1 Norm: 0.0712, Test L1 Norm: 0.0203, Train Linf Norm: 3.9429, Test Linf Norm: 0.7038\n",
            "Epoch 142: Train Loss: 0.0067, Test Loss: 0.0070, Train L1 Norm: 0.0710, Test L1 Norm: 0.0204, Train Linf Norm: 3.9305, Test Linf Norm: 0.7102\n",
            "Epoch 143: Train Loss: 0.0067, Test Loss: 0.0068, Train L1 Norm: 0.0710, Test L1 Norm: 0.0203, Train Linf Norm: 3.9189, Test Linf Norm: 0.7054\n",
            "Epoch 144: Train Loss: 0.0067, Test Loss: 0.0070, Train L1 Norm: 0.0715, Test L1 Norm: 0.0203, Train Linf Norm: 3.9617, Test Linf Norm: 0.7080\n",
            "Epoch 145: Train Loss: 0.0067, Test Loss: 0.0069, Train L1 Norm: 0.0711, Test L1 Norm: 0.0202, Train Linf Norm: 3.8652, Test Linf Norm: 0.7019\n",
            "Epoch 146: Train Loss: 0.0067, Test Loss: 0.0071, Train L1 Norm: 0.0713, Test L1 Norm: 0.0204, Train Linf Norm: 3.9506, Test Linf Norm: 0.7087\n",
            "Epoch 147: Train Loss: 0.0066, Test Loss: 0.0069, Train L1 Norm: 0.0709, Test L1 Norm: 0.0201, Train Linf Norm: 3.9299, Test Linf Norm: 0.6996\n",
            "Epoch 148: Train Loss: 0.0066, Test Loss: 0.0068, Train L1 Norm: 0.0713, Test L1 Norm: 0.0202, Train Linf Norm: 3.9303, Test Linf Norm: 0.7039\n",
            "Epoch 149: Train Loss: 0.0066, Test Loss: 0.0075, Train L1 Norm: 0.0703, Test L1 Norm: 0.0201, Train Linf Norm: 3.8660, Test Linf Norm: 0.6927\n",
            "Epoch 150: Train Loss: 0.0066, Test Loss: 0.0069, Train L1 Norm: 0.0706, Test L1 Norm: 0.0203, Train Linf Norm: 3.8805, Test Linf Norm: 0.7080\n",
            "Epoch 151: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0711, Test L1 Norm: 0.0200, Train Linf Norm: 3.9392, Test Linf Norm: 0.6973\n",
            "Epoch 152: Train Loss: 0.0066, Test Loss: 0.0068, Train L1 Norm: 0.0703, Test L1 Norm: 0.0200, Train Linf Norm: 3.8814, Test Linf Norm: 0.6956\n",
            "Epoch 153: Train Loss: 0.0066, Test Loss: 0.0068, Train L1 Norm: 0.0704, Test L1 Norm: 0.0200, Train Linf Norm: 3.9160, Test Linf Norm: 0.6931\n",
            "Epoch 154: Train Loss: 0.0066, Test Loss: 0.0071, Train L1 Norm: 0.0707, Test L1 Norm: 0.0200, Train Linf Norm: 3.8965, Test Linf Norm: 0.6938\n",
            "Epoch 155: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0699, Test L1 Norm: 0.0201, Train Linf Norm: 3.8278, Test Linf Norm: 0.6989\n",
            "Epoch 156: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0703, Test L1 Norm: 0.0200, Train Linf Norm: 3.8674, Test Linf Norm: 0.6968\n",
            "Epoch 157: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0703, Test L1 Norm: 0.0201, Train Linf Norm: 3.9010, Test Linf Norm: 0.7015\n",
            "Epoch 158: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0702, Test L1 Norm: 0.0199, Train Linf Norm: 3.8720, Test Linf Norm: 0.6923\n",
            "Epoch 159: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0706, Test L1 Norm: 0.0199, Train Linf Norm: 3.9105, Test Linf Norm: 0.6943\n",
            "Epoch 160: Train Loss: 0.0065, Test Loss: 0.0069, Train L1 Norm: 0.0696, Test L1 Norm: 0.0199, Train Linf Norm: 3.8333, Test Linf Norm: 0.6901\n",
            "Epoch 161: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0698, Test L1 Norm: 0.0198, Train Linf Norm: 3.8674, Test Linf Norm: 0.6902\n",
            "Epoch 162: Train Loss: 0.0065, Test Loss: 0.0066, Train L1 Norm: 0.0704, Test L1 Norm: 0.0199, Train Linf Norm: 3.8980, Test Linf Norm: 0.6927\n",
            "Epoch 163: Train Loss: 0.0065, Test Loss: 0.0069, Train L1 Norm: 0.0700, Test L1 Norm: 0.0198, Train Linf Norm: 3.8736, Test Linf Norm: 0.6875\n",
            "Epoch 164: Train Loss: 0.0065, Test Loss: 0.0071, Train L1 Norm: 0.0699, Test L1 Norm: 0.0198, Train Linf Norm: 3.8748, Test Linf Norm: 0.6852\n",
            "Epoch 165: Train Loss: 0.0064, Test Loss: 0.0075, Train L1 Norm: 0.0697, Test L1 Norm: 0.0199, Train Linf Norm: 3.8608, Test Linf Norm: 0.6843\n",
            "Epoch 166: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0695, Test L1 Norm: 0.0197, Train Linf Norm: 3.8600, Test Linf Norm: 0.6860\n",
            "Epoch 167: Train Loss: 0.0064, Test Loss: 0.0069, Train L1 Norm: 0.0691, Test L1 Norm: 0.0198, Train Linf Norm: 3.8160, Test Linf Norm: 0.6876\n",
            "Epoch 168: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0700, Test L1 Norm: 0.0198, Train Linf Norm: 3.8705, Test Linf Norm: 0.6934\n",
            "Epoch 169: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0695, Test L1 Norm: 0.0198, Train Linf Norm: 3.8445, Test Linf Norm: 0.6913\n",
            "Epoch 170: Train Loss: 0.0064, Test Loss: 0.0071, Train L1 Norm: 0.0694, Test L1 Norm: 0.0197, Train Linf Norm: 3.8203, Test Linf Norm: 0.6850\n",
            "Epoch 171: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0697, Test L1 Norm: 0.0198, Train Linf Norm: 3.8356, Test Linf Norm: 0.6937\n",
            "Epoch 172: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0694, Test L1 Norm: 0.0198, Train Linf Norm: 3.8333, Test Linf Norm: 0.6954\n",
            "Epoch 173: Train Loss: 0.0064, Test Loss: 0.0067, Train L1 Norm: 0.0697, Test L1 Norm: 0.0196, Train Linf Norm: 3.8623, Test Linf Norm: 0.6825\n",
            "Epoch 174: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0695, Test L1 Norm: 0.0196, Train Linf Norm: 3.8592, Test Linf Norm: 0.6858\n",
            "Epoch 175: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0693, Test L1 Norm: 0.0197, Train Linf Norm: 3.8065, Test Linf Norm: 0.6861\n",
            "Epoch 176: Train Loss: 0.0063, Test Loss: 0.0068, Train L1 Norm: 0.0690, Test L1 Norm: 0.0198, Train Linf Norm: 3.8255, Test Linf Norm: 0.6884\n",
            "Epoch 177: Train Loss: 0.0063, Test Loss: 0.0071, Train L1 Norm: 0.0690, Test L1 Norm: 0.0199, Train Linf Norm: 3.8233, Test Linf Norm: 0.6943\n",
            "Epoch 178: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0689, Test L1 Norm: 0.0197, Train Linf Norm: 3.7938, Test Linf Norm: 0.6886\n",
            "Epoch 179: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0691, Test L1 Norm: 0.0195, Train Linf Norm: 3.8285, Test Linf Norm: 0.6808\n",
            "Epoch 180: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0689, Test L1 Norm: 0.0195, Train Linf Norm: 3.8118, Test Linf Norm: 0.6804\n",
            "Epoch 181: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0690, Test L1 Norm: 0.0197, Train Linf Norm: 3.8089, Test Linf Norm: 0.6878\n",
            "Epoch 182: Train Loss: 0.0063, Test Loss: 0.0067, Train L1 Norm: 0.0685, Test L1 Norm: 0.0197, Train Linf Norm: 3.8082, Test Linf Norm: 0.6862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:22:01,208]\u001b[0m Trial 4 finished with value: 0.019624560501798987 and parameters: {'n_layers': 4, 'n_units_0': 1512, 'n_units_1': 1143, 'n_units_2': 1383, 'n_units_3': 1615, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'SGD', 'lr': 0.00031419318134790814, 'batch_size': 64, 'n_epochs': 183, 'scheduler': 'ReduceLROnPlateau', 'weight_decay': 0.0025473229454551142, 'momentum': 0.14236635016540547, 'factor': 0.1384288303206113, 'patience': 8, 'threshold': 0.000658889442530093}. Best is trial 1 with value: 0.010856217047572135.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 183: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0689, Test L1 Norm: 0.0196, Train Linf Norm: 3.8115, Test Linf Norm: 0.6865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:22:05,506]\u001b[0m Trial 5 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 20.8521, Test Loss: 20.6405, Train L1 Norm: 1.1669, Test L1 Norm: 1.0000, Train Linf Norm: 10.3071, Test Linf Norm: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:22:08,349]\u001b[0m Trial 6 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 3.3922, Test Loss: 3.4125, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:22:10,027]\u001b[0m Trial 7 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 15960097.3575, Test Loss: 1.4813, Train L1 Norm: 12835110.6786, Test L1 Norm: 0.7530, Train Linf Norm: 1086395343.4044, Test Linf Norm: 55.1998\n",
            "Epoch 1: Train Loss: 0.2104, Test Loss: 0.1207, Train L1 Norm: 0.3182, Test L1 Norm: 0.0788, Train Linf Norm: 25.0165, Test Linf Norm: 3.5311\n",
            "Epoch 2: Train Loss: 0.1005, Test Loss: 0.1469, Train L1 Norm: 0.1988, Test L1 Norm: 0.0730, Train Linf Norm: 18.8889, Test Linf Norm: 2.0958\n",
            "Epoch 3: Train Loss: 0.0793, Test Loss: 0.1036, Train L1 Norm: 0.1376, Test L1 Norm: 0.0619, Train Linf Norm: 12.5298, Test Linf Norm: 2.5246\n",
            "Epoch 4: Train Loss: 0.0688, Test Loss: 0.0260, Train L1 Norm: 0.1235, Test L1 Norm: 0.0260, Train Linf Norm: 11.5329, Test Linf Norm: 1.5245\n",
            "Epoch 5: Train Loss: 0.0628, Test Loss: 0.0425, Train L1 Norm: 0.1015, Test L1 Norm: 0.0292, Train Linf Norm: 9.0835, Test Linf Norm: 1.5225\n",
            "Epoch 6: Train Loss: 0.0596, Test Loss: 0.0458, Train L1 Norm: 0.1064, Test L1 Norm: 0.0316, Train Linf Norm: 9.9411, Test Linf Norm: 1.0293\n",
            "Epoch 7: Train Loss: 0.0505, Test Loss: 0.0865, Train L1 Norm: 0.0957, Test L1 Norm: 0.0442, Train Linf Norm: 9.0561, Test Linf Norm: 1.3742\n",
            "Epoch 8: Train Loss: 0.0569, Test Loss: 0.0668, Train L1 Norm: 0.0945, Test L1 Norm: 0.0411, Train Linf Norm: 8.6258, Test Linf Norm: 1.8259\n",
            "Epoch 9: Train Loss: 0.0541, Test Loss: 0.0225, Train L1 Norm: 0.1086, Test L1 Norm: 0.0252, Train Linf Norm: 10.5747, Test Linf Norm: 1.6929\n",
            "Epoch 10: Train Loss: 0.0495, Test Loss: 0.0347, Train L1 Norm: 0.1361, Test L1 Norm: 0.0418, Train Linf Norm: 14.3572, Test Linf Norm: 2.3529\n",
            "Epoch 11: Train Loss: 0.0447, Test Loss: 0.0420, Train L1 Norm: 0.1193, Test L1 Norm: 0.0377, Train Linf Norm: 12.2566, Test Linf Norm: 2.1347\n",
            "Epoch 12: Train Loss: 0.0189, Test Loss: 0.0152, Train L1 Norm: 0.0886, Test L1 Norm: 0.0203, Train Linf Norm: 9.8240, Test Linf Norm: 1.4261\n",
            "Epoch 13: Train Loss: 0.0178, Test Loss: 0.0191, Train L1 Norm: 0.0862, Test L1 Norm: 0.0196, Train Linf Norm: 9.5398, Test Linf Norm: 1.0273\n",
            "Epoch 14: Train Loss: 0.0193, Test Loss: 0.0138, Train L1 Norm: 0.0769, Test L1 Norm: 0.0174, Train Linf Norm: 8.4435, Test Linf Norm: 1.1952\n",
            "Epoch 15: Train Loss: 0.0187, Test Loss: 0.0146, Train L1 Norm: 0.0646, Test L1 Norm: 0.0172, Train Linf Norm: 6.9477, Test Linf Norm: 1.1641\n",
            "Epoch 16: Train Loss: 0.0179, Test Loss: 0.0171, Train L1 Norm: 0.0610, Test L1 Norm: 0.0164, Train Linf Norm: 6.5281, Test Linf Norm: 0.8715\n",
            "Epoch 17: Train Loss: 0.0182, Test Loss: 0.0265, Train L1 Norm: 0.0561, Test L1 Norm: 0.0208, Train Linf Norm: 5.8921, Test Linf Norm: 1.0418\n",
            "Epoch 18: Train Loss: 0.0187, Test Loss: 0.0210, Train L1 Norm: 0.0498, Test L1 Norm: 0.0163, Train Linf Norm: 5.0595, Test Linf Norm: 0.7201\n",
            "Epoch 19: Train Loss: 0.0207, Test Loss: 0.0160, Train L1 Norm: 0.0518, Test L1 Norm: 0.0149, Train Linf Norm: 5.1637, Test Linf Norm: 0.7858\n",
            "Epoch 20: Train Loss: 0.0197, Test Loss: 0.0194, Train L1 Norm: 0.0462, Test L1 Norm: 0.0141, Train Linf Norm: 4.5784, Test Linf Norm: 0.7719\n",
            "Epoch 21: Train Loss: 0.0189, Test Loss: 0.0156, Train L1 Norm: 0.0487, Test L1 Norm: 0.0136, Train Linf Norm: 4.9732, Test Linf Norm: 0.7377\n",
            "Epoch 22: Train Loss: 0.0188, Test Loss: 0.0170, Train L1 Norm: 0.0427, Test L1 Norm: 0.0145, Train Linf Norm: 4.2145, Test Linf Norm: 0.6421\n",
            "Epoch 23: Train Loss: 0.0118, Test Loss: 0.0117, Train L1 Norm: 0.0335, Test L1 Norm: 0.0118, Train Linf Norm: 3.3695, Test Linf Norm: 0.6951\n",
            "Epoch 24: Train Loss: 0.0113, Test Loss: 0.0109, Train L1 Norm: 0.0328, Test L1 Norm: 0.0111, Train Linf Norm: 3.2921, Test Linf Norm: 0.6158\n",
            "Epoch 25: Train Loss: 0.0115, Test Loss: 0.0148, Train L1 Norm: 0.0349, Test L1 Norm: 0.0116, Train Linf Norm: 3.5921, Test Linf Norm: 0.5531\n",
            "Epoch 26: Train Loss: 0.0112, Test Loss: 0.0113, Train L1 Norm: 0.0320, Test L1 Norm: 0.0110, Train Linf Norm: 3.2398, Test Linf Norm: 0.6003\n",
            "Epoch 27: Train Loss: 0.0112, Test Loss: 0.0111, Train L1 Norm: 0.0313, Test L1 Norm: 0.0104, Train Linf Norm: 3.1742, Test Linf Norm: 0.5380\n",
            "Epoch 28: Train Loss: 0.0114, Test Loss: 0.0109, Train L1 Norm: 0.0281, Test L1 Norm: 0.0117, Train Linf Norm: 2.7403, Test Linf Norm: 0.6942\n",
            "Epoch 29: Train Loss: 0.0116, Test Loss: 0.0101, Train L1 Norm: 0.0253, Test L1 Norm: 0.0110, Train Linf Norm: 2.3714, Test Linf Norm: 0.6626\n",
            "Epoch 30: Train Loss: 0.0110, Test Loss: 0.0109, Train L1 Norm: 0.0290, Test L1 Norm: 0.0111, Train Linf Norm: 2.8994, Test Linf Norm: 0.6235\n",
            "Epoch 31: Train Loss: 0.0112, Test Loss: 0.0104, Train L1 Norm: 0.0241, Test L1 Norm: 0.0102, Train Linf Norm: 2.2500, Test Linf Norm: 0.5825\n",
            "Epoch 32: Train Loss: 0.0110, Test Loss: 0.0110, Train L1 Norm: 0.0256, Test L1 Norm: 0.0115, Train Linf Norm: 2.4398, Test Linf Norm: 0.6577\n",
            "Epoch 33: Train Loss: 0.0114, Test Loss: 0.0104, Train L1 Norm: 0.0238, Test L1 Norm: 0.0104, Train Linf Norm: 2.2233, Test Linf Norm: 0.5907\n",
            "Epoch 34: Train Loss: 0.0094, Test Loss: 0.0102, Train L1 Norm: 0.0211, Test L1 Norm: 0.0100, Train Linf Norm: 1.9580, Test Linf Norm: 0.5564\n",
            "Epoch 35: Train Loss: 0.0094, Test Loss: 0.0092, Train L1 Norm: 0.0219, Test L1 Norm: 0.0094, Train Linf Norm: 2.0622, Test Linf Norm: 0.5193\n",
            "Epoch 36: Train Loss: 0.0094, Test Loss: 0.0095, Train L1 Norm: 0.0185, Test L1 Norm: 0.0098, Train Linf Norm: 1.6466, Test Linf Norm: 0.5593\n",
            "Epoch 37: Train Loss: 0.0093, Test Loss: 0.0095, Train L1 Norm: 0.0211, Test L1 Norm: 0.0093, Train Linf Norm: 1.9828, Test Linf Norm: 0.5004\n",
            "Epoch 38: Train Loss: 0.0094, Test Loss: 0.0093, Train L1 Norm: 0.0183, Test L1 Norm: 0.0092, Train Linf Norm: 1.6425, Test Linf Norm: 0.5001\n",
            "Epoch 39: Train Loss: 0.0094, Test Loss: 0.0094, Train L1 Norm: 0.0189, Test L1 Norm: 0.0092, Train Linf Norm: 1.7088, Test Linf Norm: 0.4980\n",
            "Epoch 40: Train Loss: 0.0092, Test Loss: 0.0093, Train L1 Norm: 0.0156, Test L1 Norm: 0.0094, Train Linf Norm: 1.2930, Test Linf Norm: 0.4721\n",
            "Epoch 41: Train Loss: 0.0093, Test Loss: 0.0095, Train L1 Norm: 0.0176, Test L1 Norm: 0.0095, Train Linf Norm: 1.5488, Test Linf Norm: 0.5210\n",
            "Epoch 42: Train Loss: 0.0093, Test Loss: 0.0091, Train L1 Norm: 0.0175, Test L1 Norm: 0.0090, Train Linf Norm: 1.5175, Test Linf Norm: 0.4885\n",
            "Epoch 43: Train Loss: 0.0092, Test Loss: 0.0090, Train L1 Norm: 0.0171, Test L1 Norm: 0.0094, Train Linf Norm: 1.4800, Test Linf Norm: 0.5262\n",
            "Epoch 44: Train Loss: 0.0091, Test Loss: 0.0095, Train L1 Norm: 0.0166, Test L1 Norm: 0.0094, Train Linf Norm: 1.4415, Test Linf Norm: 0.5064\n",
            "Epoch 45: Train Loss: 0.0086, Test Loss: 0.0088, Train L1 Norm: 0.0163, Test L1 Norm: 0.0089, Train Linf Norm: 1.4305, Test Linf Norm: 0.4949\n",
            "Epoch 46: Train Loss: 0.0087, Test Loss: 0.0088, Train L1 Norm: 0.0161, Test L1 Norm: 0.0090, Train Linf Norm: 1.3914, Test Linf Norm: 0.5040\n",
            "Epoch 47: Train Loss: 0.0087, Test Loss: 0.0089, Train L1 Norm: 0.0158, Test L1 Norm: 0.0089, Train Linf Norm: 1.3649, Test Linf Norm: 0.4885\n",
            "Epoch 48: Train Loss: 0.0086, Test Loss: 0.0088, Train L1 Norm: 0.0149, Test L1 Norm: 0.0089, Train Linf Norm: 1.2472, Test Linf Norm: 0.5029\n",
            "Epoch 49: Train Loss: 0.0087, Test Loss: 0.0088, Train L1 Norm: 0.0160, Test L1 Norm: 0.0088, Train Linf Norm: 1.3669, Test Linf Norm: 0.4861\n",
            "Epoch 50: Train Loss: 0.0086, Test Loss: 0.0088, Train L1 Norm: 0.0161, Test L1 Norm: 0.0088, Train Linf Norm: 1.4034, Test Linf Norm: 0.4804\n",
            "Epoch 51: Train Loss: 0.0086, Test Loss: 0.0088, Train L1 Norm: 0.0155, Test L1 Norm: 0.0088, Train Linf Norm: 1.3225, Test Linf Norm: 0.4768\n",
            "Epoch 52: Train Loss: 0.0087, Test Loss: 0.0087, Train L1 Norm: 0.0164, Test L1 Norm: 0.0090, Train Linf Norm: 1.4390, Test Linf Norm: 0.5145\n",
            "Epoch 53: Train Loss: 0.0086, Test Loss: 0.0088, Train L1 Norm: 0.0158, Test L1 Norm: 0.0086, Train Linf Norm: 1.3399, Test Linf Norm: 0.4628\n",
            "Epoch 54: Train Loss: 0.0086, Test Loss: 0.0087, Train L1 Norm: 0.0159, Test L1 Norm: 0.0087, Train Linf Norm: 1.3703, Test Linf Norm: 0.4791\n",
            "Epoch 55: Train Loss: 0.0086, Test Loss: 0.0095, Train L1 Norm: 0.0152, Test L1 Norm: 0.0088, Train Linf Norm: 1.2877, Test Linf Norm: 0.4658\n",
            "Epoch 56: Train Loss: 0.0084, Test Loss: 0.0087, Train L1 Norm: 0.0154, Test L1 Norm: 0.0087, Train Linf Norm: 1.3368, Test Linf Norm: 0.4783\n",
            "Epoch 57: Train Loss: 0.0084, Test Loss: 0.0086, Train L1 Norm: 0.0149, Test L1 Norm: 0.0087, Train Linf Norm: 1.2636, Test Linf Norm: 0.4787\n",
            "Epoch 58: Train Loss: 0.0084, Test Loss: 0.0086, Train L1 Norm: 0.0147, Test L1 Norm: 0.0087, Train Linf Norm: 1.2446, Test Linf Norm: 0.4841\n",
            "Epoch 59: Train Loss: 0.0084, Test Loss: 0.0086, Train L1 Norm: 0.0141, Test L1 Norm: 0.0087, Train Linf Norm: 1.1642, Test Linf Norm: 0.4767\n",
            "Epoch 60: Train Loss: 0.0084, Test Loss: 0.0089, Train L1 Norm: 0.0149, Test L1 Norm: 0.0087, Train Linf Norm: 1.2674, Test Linf Norm: 0.4804\n",
            "Epoch 61: Train Loss: 0.0084, Test Loss: 0.0088, Train L1 Norm: 0.0144, Test L1 Norm: 0.0087, Train Linf Norm: 1.1938, Test Linf Norm: 0.4816\n",
            "Epoch 62: Train Loss: 0.0084, Test Loss: 0.0087, Train L1 Norm: 0.0146, Test L1 Norm: 0.0087, Train Linf Norm: 1.2113, Test Linf Norm: 0.4846\n",
            "Epoch 63: Train Loss: 0.0084, Test Loss: 0.0086, Train L1 Norm: 0.0140, Test L1 Norm: 0.0086, Train Linf Norm: 1.1454, Test Linf Norm: 0.4773\n",
            "Epoch 64: Train Loss: 0.0084, Test Loss: 0.0086, Train L1 Norm: 0.0143, Test L1 Norm: 0.0087, Train Linf Norm: 1.1996, Test Linf Norm: 0.4841\n",
            "Epoch 65: Train Loss: 0.0084, Test Loss: 0.0086, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.1933, Test Linf Norm: 0.4793\n",
            "Epoch 66: Train Loss: 0.0084, Test Loss: 0.0087, Train L1 Norm: 0.0140, Test L1 Norm: 0.0087, Train Linf Norm: 1.1480, Test Linf Norm: 0.4773\n",
            "Epoch 67: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1742, Test Linf Norm: 0.4767\n",
            "Epoch 68: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.2008, Test Linf Norm: 0.4770\n",
            "Epoch 69: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1863, Test Linf Norm: 0.4784\n",
            "Epoch 70: Train Loss: 0.0083, Test Loss: 0.0087, Train L1 Norm: 0.0142, Test L1 Norm: 0.0087, Train Linf Norm: 1.1867, Test Linf Norm: 0.4797\n",
            "Epoch 71: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.1869, Test Linf Norm: 0.4788\n",
            "Epoch 72: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0140, Test L1 Norm: 0.0086, Train Linf Norm: 1.1541, Test Linf Norm: 0.4790\n",
            "Epoch 73: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.2002, Test Linf Norm: 0.4762\n",
            "Epoch 74: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1835, Test Linf Norm: 0.4781\n",
            "Epoch 75: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0144, Test L1 Norm: 0.0086, Train Linf Norm: 1.2086, Test Linf Norm: 0.4797\n",
            "Epoch 76: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1905, Test Linf Norm: 0.4805\n",
            "Epoch 77: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1849, Test Linf Norm: 0.4791\n",
            "Epoch 78: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0141, Test L1 Norm: 0.0086, Train Linf Norm: 1.1755, Test Linf Norm: 0.4776\n",
            "Epoch 79: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1845, Test Linf Norm: 0.4791\n",
            "Epoch 80: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1850, Test Linf Norm: 0.4787\n",
            "Epoch 81: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.1926, Test Linf Norm: 0.4784\n",
            "Epoch 82: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.1906, Test Linf Norm: 0.4762\n",
            "Epoch 83: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1708, Test Linf Norm: 0.4779\n",
            "Epoch 84: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1833, Test Linf Norm: 0.4779\n",
            "Epoch 85: Train Loss: 0.0083, Test Loss: 0.0086, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1972, Test Linf Norm: 0.4773\n",
            "Epoch 86: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.1983, Test Linf Norm: 0.4777\n",
            "Epoch 87: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.1844, Test Linf Norm: 0.4776\n",
            "Epoch 88: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1938, Test Linf Norm: 0.4782\n",
            "Epoch 89: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.1914, Test Linf Norm: 0.4779\n",
            "Epoch 90: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.2048, Test Linf Norm: 0.4775\n",
            "Epoch 91: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1995, Test Linf Norm: 0.4774\n",
            "Epoch 92: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1823, Test Linf Norm: 0.4782\n",
            "Epoch 93: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.1880, Test Linf Norm: 0.4776\n",
            "Epoch 94: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.2017, Test Linf Norm: 0.4777\n",
            "Epoch 95: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.2045, Test Linf Norm: 0.4776\n",
            "Epoch 96: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1963, Test Linf Norm: 0.4777\n",
            "Epoch 97: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1776, Test Linf Norm: 0.4783\n",
            "Epoch 98: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.2006, Test Linf Norm: 0.4780\n",
            "Epoch 99: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.1945, Test Linf Norm: 0.4776\n",
            "Epoch 100: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1802, Test Linf Norm: 0.4775\n",
            "Epoch 101: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1748, Test Linf Norm: 0.4777\n",
            "Epoch 102: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1890, Test Linf Norm: 0.4776\n",
            "Epoch 103: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1806, Test Linf Norm: 0.4776\n",
            "Epoch 104: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1863, Test Linf Norm: 0.4778\n",
            "Epoch 105: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1825, Test Linf Norm: 0.4777\n",
            "Epoch 106: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1898, Test Linf Norm: 0.4778\n",
            "Epoch 107: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1602, Test Linf Norm: 0.4776\n",
            "Epoch 108: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1852, Test Linf Norm: 0.4778\n",
            "Epoch 109: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1918, Test Linf Norm: 0.4777\n",
            "Epoch 110: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1919, Test Linf Norm: 0.4780\n",
            "Epoch 111: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0143, Test L1 Norm: 0.0086, Train Linf Norm: 1.1963, Test Linf Norm: 0.4778\n",
            "Epoch 112: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1947, Test Linf Norm: 0.4777\n",
            "Epoch 113: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1953, Test Linf Norm: 0.4777\n",
            "Epoch 114: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1836, Test Linf Norm: 0.4777\n",
            "Epoch 115: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1950, Test Linf Norm: 0.4777\n",
            "Epoch 116: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1927, Test Linf Norm: 0.4777\n",
            "Epoch 117: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1889, Test Linf Norm: 0.4777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:26:21,770]\u001b[0m Trial 8 finished with value: 0.008597097944840789 and parameters: {'n_layers': 3, 'n_units_0': 835, 'n_units_1': 510, 'n_units_2': 483, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.000755828981696378, 'batch_size': 128, 'n_epochs': 118, 'scheduler': 'StepLR', 'weight_decay': 0.00676298958869246, 'beta1': 0.9117983750408882, 'beta2': 0.9995540948602418, 'step_size': 11, 'gamma': 0.2884579487623973}. Best is trial 8 with value: 0.008597097944840789.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 118: Train Loss: 0.0083, Test Loss: 0.0085, Train L1 Norm: 0.0142, Test L1 Norm: 0.0086, Train Linf Norm: 1.1801, Test Linf Norm: 0.4777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:26:30,556]\u001b[0m Trial 9 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 7.7819, Test Loss: 0.0096, Train L1 Norm: 258.2122, Test L1 Norm: 0.5150, Train Linf Norm: 12195.2365, Test Linf Norm: 18.1258\n",
            "Epoch 1: Train Loss: 0.2178, Test Loss: 0.2348, Train L1 Norm: 0.8348, Test L1 Norm: 0.1777, Train Linf Norm: 87.3402, Test Linf Norm: 9.8989\n",
            "Epoch 2: Train Loss: 0.1239, Test Loss: 0.0674, Train L1 Norm: 0.7375, Test L1 Norm: 0.1546, Train Linf Norm: 83.3704, Test Linf Norm: 12.4252\n",
            "Epoch 3: Train Loss: 0.0788, Test Loss: 0.1067, Train L1 Norm: 0.6847, Test L1 Norm: 0.1547, Train Linf Norm: 78.8519, Test Linf Norm: 11.5594\n",
            "Epoch 4: Train Loss: 0.0729, Test Loss: 0.0893, Train L1 Norm: 0.7514, Test L1 Norm: 0.1408, Train Linf Norm: 88.8810, Test Linf Norm: 10.6474\n",
            "Epoch 5: Train Loss: 0.0731, Test Loss: 0.0394, Train L1 Norm: 0.5949, Test L1 Norm: 0.1015, Train Linf Norm: 68.8827, Test Linf Norm: 8.4033\n",
            "Epoch 6: Train Loss: 0.0602, Test Loss: 0.0313, Train L1 Norm: 0.4798, Test L1 Norm: 0.0807, Train Linf Norm: 54.5989, Test Linf Norm: 6.4198\n",
            "Epoch 7: Train Loss: 0.0633, Test Loss: 0.1123, Train L1 Norm: 0.4698, Test L1 Norm: 0.1044, Train Linf Norm: 54.5398, Test Linf Norm: 6.3821\n",
            "Epoch 8: Train Loss: 0.0661, Test Loss: 0.0222, Train L1 Norm: 0.4146, Test L1 Norm: 0.0716, Train Linf Norm: 47.6691, Test Linf Norm: 6.0017\n",
            "Epoch 9: Train Loss: 0.0531, Test Loss: 0.0871, Train L1 Norm: 0.3579, Test L1 Norm: 0.0927, Train Linf Norm: 41.3142, Test Linf Norm: 6.1218\n",
            "Epoch 10: Train Loss: 0.0451, Test Loss: 0.0360, Train L1 Norm: 0.3363, Test L1 Norm: 0.0651, Train Linf Norm: 38.5780, Test Linf Norm: 5.1674\n",
            "Epoch 11: Train Loss: 0.0224, Test Loss: 0.0200, Train L1 Norm: 0.2777, Test L1 Norm: 0.0523, Train Linf Norm: 32.6179, Test Linf Norm: 4.3513\n",
            "Epoch 12: Train Loss: 0.0259, Test Loss: 0.0412, Train L1 Norm: 0.2412, Test L1 Norm: 0.0508, Train Linf Norm: 28.2427, Test Linf Norm: 3.6964\n",
            "Epoch 13: Train Loss: 0.0267, Test Loss: 0.0774, Train L1 Norm: 0.2233, Test L1 Norm: 0.0718, Train Linf Norm: 26.0645, Test Linf Norm: 4.3169\n",
            "Epoch 14: Train Loss: 0.0251, Test Loss: 0.0200, Train L1 Norm: 0.2160, Test L1 Norm: 0.0434, Train Linf Norm: 25.2072, Test Linf Norm: 3.4670\n",
            "Epoch 15: Train Loss: 0.0288, Test Loss: 0.0199, Train L1 Norm: 0.2113, Test L1 Norm: 0.0369, Train Linf Norm: 24.4579, Test Linf Norm: 2.9304\n",
            "Epoch 16: Train Loss: 0.0241, Test Loss: 0.0144, Train L1 Norm: 0.1794, Test L1 Norm: 0.0356, Train Linf Norm: 20.8618, Test Linf Norm: 2.9261\n",
            "Epoch 17: Train Loss: 0.0283, Test Loss: 0.0197, Train L1 Norm: 0.1684, Test L1 Norm: 0.0344, Train Linf Norm: 19.1742, Test Linf Norm: 2.6956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:27:29,778]\u001b[0m Trial 10 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss: 0.0251, Test Loss: 0.0384, Train L1 Norm: 0.1534, Test L1 Norm: 0.0351, Train Linf Norm: 17.5188, Test Linf Norm: 2.3005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:27:32,896]\u001b[0m Trial 11 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 3.3922, Test Loss: 3.4125, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 1: Train Loss: 0.3407, Test Loss: 0.1161, Train L1 Norm: 0.7970, Test L1 Norm: 0.0916, Train Linf Norm: 19.5262, Test Linf Norm: 1.2214\n",
            "Epoch 2: Train Loss: 0.1345, Test Loss: 0.0679, Train L1 Norm: 0.4856, Test L1 Norm: 0.0920, Train Linf Norm: 13.4478, Test Linf Norm: 1.8177\n",
            "Epoch 3: Train Loss: 0.1022, Test Loss: 0.1438, Train L1 Norm: 0.5587, Test L1 Norm: 0.1193, Train Linf Norm: 16.1796, Test Linf Norm: 1.8141\n",
            "Epoch 4: Train Loss: 0.0856, Test Loss: 0.1127, Train L1 Norm: 0.2977, Test L1 Norm: 0.1536, Train Linf Norm: 7.9866, Test Linf Norm: 2.5147\n",
            "Epoch 5: Train Loss: 0.0858, Test Loss: 0.0723, Train L1 Norm: 0.3605, Test L1 Norm: 0.0804, Train Linf Norm: 10.0180, Test Linf Norm: 1.2199\n",
            "Epoch 6: Train Loss: 0.0902, Test Loss: 0.1032, Train L1 Norm: 0.4677, Test L1 Norm: 0.1033, Train Linf Norm: 13.5154, Test Linf Norm: 1.9335\n",
            "Epoch 7: Train Loss: 0.0650, Test Loss: 0.0309, Train L1 Norm: 0.3486, Test L1 Norm: 0.0626, Train Linf Norm: 9.8592, Test Linf Norm: 1.3697\n",
            "Epoch 8: Train Loss: 0.0771, Test Loss: 0.0450, Train L1 Norm: 0.3462, Test L1 Norm: 0.0698, Train Linf Norm: 9.7551, Test Linf Norm: 1.2304\n",
            "Epoch 9: Train Loss: 0.0623, Test Loss: 0.1267, Train L1 Norm: 0.2235, Test L1 Norm: 0.2022, Train Linf Norm: 6.0067, Test Linf Norm: 4.4433\n",
            "Epoch 10: Train Loss: 0.0530, Test Loss: 0.0451, Train L1 Norm: 0.2452, Test L1 Norm: 0.1438, Train Linf Norm: 6.7135, Test Linf Norm: 3.6049\n",
            "Epoch 11: Train Loss: 0.0554, Test Loss: 0.0263, Train L1 Norm: 0.4778, Test L1 Norm: 0.0549, Train Linf Norm: 14.1899, Test Linf Norm: 1.0239\n",
            "Epoch 12: Train Loss: 0.0453, Test Loss: 0.0453, Train L1 Norm: 0.1965, Test L1 Norm: 0.0481, Train Linf Norm: 5.4463, Test Linf Norm: 0.8312\n",
            "Epoch 13: Train Loss: 0.0586, Test Loss: 0.0448, Train L1 Norm: 0.3195, Test L1 Norm: 0.1767, Train Linf Norm: 9.0940, Test Linf Norm: 3.8844\n",
            "Epoch 14: Train Loss: 0.0208, Test Loss: 0.0121, Train L1 Norm: 0.1550, Test L1 Norm: 0.0338, Train Linf Norm: 4.4768, Test Linf Norm: 0.7474\n",
            "Epoch 15: Train Loss: 0.0179, Test Loss: 0.0164, Train L1 Norm: 0.1849, Test L1 Norm: 0.0431, Train Linf Norm: 5.4882, Test Linf Norm: 0.9710\n",
            "Epoch 16: Train Loss: 0.0194, Test Loss: 0.0277, Train L1 Norm: 0.1959, Test L1 Norm: 0.0321, Train Linf Norm: 5.7859, Test Linf Norm: 0.6404\n",
            "Epoch 17: Train Loss: 0.0210, Test Loss: 0.0289, Train L1 Norm: 0.2036, Test L1 Norm: 0.0539, Train Linf Norm: 6.0214, Test Linf Norm: 0.9501\n",
            "Epoch 18: Train Loss: 0.0199, Test Loss: 0.0160, Train L1 Norm: 0.1031, Test L1 Norm: 0.0399, Train Linf Norm: 2.8505, Test Linf Norm: 0.9443\n",
            "Epoch 19: Train Loss: 0.0215, Test Loss: 0.0181, Train L1 Norm: 0.1288, Test L1 Norm: 0.0341, Train Linf Norm: 3.6592, Test Linf Norm: 0.7314\n",
            "Epoch 20: Train Loss: 0.0194, Test Loss: 0.0184, Train L1 Norm: 0.2397, Test L1 Norm: 0.0313, Train Linf Norm: 7.2465, Test Linf Norm: 0.6223\n",
            "Epoch 21: Train Loss: 0.0186, Test Loss: 0.0153, Train L1 Norm: 0.1161, Test L1 Norm: 0.0386, Train Linf Norm: 3.3001, Test Linf Norm: 0.8351\n",
            "Epoch 22: Train Loss: 0.0214, Test Loss: 0.0112, Train L1 Norm: 0.2038, Test L1 Norm: 0.0277, Train Linf Norm: 6.0732, Test Linf Norm: 0.6174\n",
            "Epoch 23: Train Loss: 0.0186, Test Loss: 0.0260, Train L1 Norm: 0.0757, Test L1 Norm: 0.0656, Train Linf Norm: 1.9896, Test Linf Norm: 1.4307\n",
            "Epoch 24: Train Loss: 0.0160, Test Loss: 0.0111, Train L1 Norm: 0.0911, Test L1 Norm: 0.0325, Train Linf Norm: 2.5372, Test Linf Norm: 0.6835\n",
            "Epoch 25: Train Loss: 0.0181, Test Loss: 0.0266, Train L1 Norm: 0.1816, Test L1 Norm: 0.0363, Train Linf Norm: 5.4077, Test Linf Norm: 0.6961\n",
            "Epoch 26: Train Loss: 0.0179, Test Loss: 0.0182, Train L1 Norm: 0.1914, Test L1 Norm: 0.0269, Train Linf Norm: 5.7252, Test Linf Norm: 0.5614\n",
            "Epoch 27: Train Loss: 0.0089, Test Loss: 0.0155, Train L1 Norm: 0.1503, Test L1 Norm: 0.0285, Train Linf Norm: 4.5587, Test Linf Norm: 0.5841\n",
            "Epoch 28: Train Loss: 0.0088, Test Loss: 0.0074, Train L1 Norm: 0.1402, Test L1 Norm: 0.0243, Train Linf Norm: 4.2090, Test Linf Norm: 0.5608\n",
            "Epoch 29: Train Loss: 0.0089, Test Loss: 0.0069, Train L1 Norm: 0.0752, Test L1 Norm: 0.0229, Train Linf Norm: 2.1513, Test Linf Norm: 0.5252\n",
            "Epoch 30: Train Loss: 0.0087, Test Loss: 0.0109, Train L1 Norm: 0.1347, Test L1 Norm: 0.0242, Train Linf Norm: 4.0495, Test Linf Norm: 0.5471\n",
            "Epoch 31: Train Loss: 0.0086, Test Loss: 0.0066, Train L1 Norm: 0.0848, Test L1 Norm: 0.0233, Train Linf Norm: 2.4673, Test Linf Norm: 0.5439\n",
            "Epoch 32: Train Loss: 0.0091, Test Loss: 0.0111, Train L1 Norm: 0.1117, Test L1 Norm: 0.0241, Train Linf Norm: 3.3304, Test Linf Norm: 0.5394\n",
            "Epoch 33: Train Loss: 0.0080, Test Loss: 0.0057, Train L1 Norm: 0.1136, Test L1 Norm: 0.0237, Train Linf Norm: 3.3949, Test Linf Norm: 0.5506\n",
            "Epoch 34: Train Loss: 0.0081, Test Loss: 0.0167, Train L1 Norm: 0.0706, Test L1 Norm: 0.0286, Train Linf Norm: 2.0221, Test Linf Norm: 0.6203\n",
            "Epoch 35: Train Loss: 0.0079, Test Loss: 0.0069, Train L1 Norm: 0.1000, Test L1 Norm: 0.0218, Train Linf Norm: 2.9684, Test Linf Norm: 0.4901\n",
            "Epoch 36: Train Loss: 0.0079, Test Loss: 0.0058, Train L1 Norm: 0.0998, Test L1 Norm: 0.0229, Train Linf Norm: 2.9474, Test Linf Norm: 0.5151\n",
            "Epoch 37: Train Loss: 0.0079, Test Loss: 0.0083, Train L1 Norm: 0.0618, Test L1 Norm: 0.0230, Train Linf Norm: 1.7434, Test Linf Norm: 0.5318\n",
            "Epoch 38: Train Loss: 0.0078, Test Loss: 0.0125, Train L1 Norm: 0.0823, Test L1 Norm: 0.0266, Train Linf Norm: 2.3996, Test Linf Norm: 0.5827\n",
            "Epoch 39: Train Loss: 0.0083, Test Loss: 0.0156, Train L1 Norm: 0.1091, Test L1 Norm: 0.0238, Train Linf Norm: 3.2592, Test Linf Norm: 0.5244\n",
            "Epoch 40: Train Loss: 0.0057, Test Loss: 0.0113, Train L1 Norm: 0.1081, Test L1 Norm: 0.0216, Train Linf Norm: 3.2643, Test Linf Norm: 0.4815\n",
            "Epoch 41: Train Loss: 0.0056, Test Loss: 0.0059, Train L1 Norm: 0.0843, Test L1 Norm: 0.0211, Train Linf Norm: 2.4993, Test Linf Norm: 0.4950\n",
            "Epoch 42: Train Loss: 0.0051, Test Loss: 0.0052, Train L1 Norm: 0.0950, Test L1 Norm: 0.0205, Train Linf Norm: 2.8429, Test Linf Norm: 0.4810\n",
            "Epoch 43: Train Loss: 0.0054, Test Loss: 0.0051, Train L1 Norm: 0.1007, Test L1 Norm: 0.0219, Train Linf Norm: 3.0228, Test Linf Norm: 0.4970\n",
            "Epoch 44: Train Loss: 0.0052, Test Loss: 0.0047, Train L1 Norm: 0.0920, Test L1 Norm: 0.0215, Train Linf Norm: 2.7531, Test Linf Norm: 0.5120\n",
            "Epoch 45: Train Loss: 0.0053, Test Loss: 0.0062, Train L1 Norm: 0.1025, Test L1 Norm: 0.0206, Train Linf Norm: 3.0866, Test Linf Norm: 0.4785\n",
            "Epoch 46: Train Loss: 0.0052, Test Loss: 0.0047, Train L1 Norm: 0.0846, Test L1 Norm: 0.0207, Train Linf Norm: 2.5167, Test Linf Norm: 0.4852\n",
            "Epoch 47: Train Loss: 0.0051, Test Loss: 0.0046, Train L1 Norm: 0.0831, Test L1 Norm: 0.0205, Train Linf Norm: 2.4575, Test Linf Norm: 0.4873\n",
            "Epoch 48: Train Loss: 0.0049, Test Loss: 0.0044, Train L1 Norm: 0.0997, Test L1 Norm: 0.0204, Train Linf Norm: 2.9988, Test Linf Norm: 0.4852\n",
            "Epoch 49: Train Loss: 0.0051, Test Loss: 0.0047, Train L1 Norm: 0.0992, Test L1 Norm: 0.0206, Train Linf Norm: 2.9807, Test Linf Norm: 0.4876\n",
            "Epoch 50: Train Loss: 0.0052, Test Loss: 0.0073, Train L1 Norm: 0.0967, Test L1 Norm: 0.0210, Train Linf Norm: 2.9046, Test Linf Norm: 0.4842\n",
            "Epoch 51: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.1147, Test L1 Norm: 0.0206, Train Linf Norm: 3.4817, Test Linf Norm: 0.4880\n",
            "Epoch 52: Train Loss: 0.0050, Test Loss: 0.0046, Train L1 Norm: 0.0889, Test L1 Norm: 0.0196, Train Linf Norm: 2.6618, Test Linf Norm: 0.4595\n",
            "Epoch 53: Train Loss: 0.0044, Test Loss: 0.0043, Train L1 Norm: 0.0932, Test L1 Norm: 0.0204, Train Linf Norm: 2.7932, Test Linf Norm: 0.4856\n",
            "Epoch 54: Train Loss: 0.0043, Test Loss: 0.0048, Train L1 Norm: 0.0916, Test L1 Norm: 0.0201, Train Linf Norm: 2.7265, Test Linf Norm: 0.4747\n",
            "Epoch 55: Train Loss: 0.0043, Test Loss: 0.0042, Train L1 Norm: 0.0921, Test L1 Norm: 0.0201, Train Linf Norm: 2.7544, Test Linf Norm: 0.4786\n",
            "Epoch 56: Train Loss: 0.0043, Test Loss: 0.0043, Train L1 Norm: 0.0928, Test L1 Norm: 0.0200, Train Linf Norm: 2.7940, Test Linf Norm: 0.4753\n",
            "Epoch 57: Train Loss: 0.0044, Test Loss: 0.0044, Train L1 Norm: 0.0964, Test L1 Norm: 0.0198, Train Linf Norm: 2.9045, Test Linf Norm: 0.4685\n",
            "Epoch 58: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0909, Test L1 Norm: 0.0198, Train Linf Norm: 2.7273, Test Linf Norm: 0.4687\n",
            "Epoch 59: Train Loss: 0.0044, Test Loss: 0.0043, Train L1 Norm: 0.0809, Test L1 Norm: 0.0199, Train Linf Norm: 2.4127, Test Linf Norm: 0.4739\n",
            "Epoch 60: Train Loss: 0.0043, Test Loss: 0.0044, Train L1 Norm: 0.0884, Test L1 Norm: 0.0197, Train Linf Norm: 2.6433, Test Linf Norm: 0.4652\n",
            "Epoch 61: Train Loss: 0.0043, Test Loss: 0.0043, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6862, Test Linf Norm: 0.4618\n",
            "Epoch 62: Train Loss: 0.0043, Test Loss: 0.0042, Train L1 Norm: 0.0830, Test L1 Norm: 0.0192, Train Linf Norm: 2.4784, Test Linf Norm: 0.4525\n",
            "Epoch 63: Train Loss: 0.0042, Test Loss: 0.0042, Train L1 Norm: 0.0898, Test L1 Norm: 0.0197, Train Linf Norm: 2.6970, Test Linf Norm: 0.4684\n",
            "Epoch 64: Train Loss: 0.0043, Test Loss: 0.0042, Train L1 Norm: 0.0936, Test L1 Norm: 0.0197, Train Linf Norm: 2.8161, Test Linf Norm: 0.4692\n",
            "Epoch 65: Train Loss: 0.0043, Test Loss: 0.0050, Train L1 Norm: 0.0856, Test L1 Norm: 0.0196, Train Linf Norm: 2.5620, Test Linf Norm: 0.4614\n",
            "Epoch 66: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0922, Test L1 Norm: 0.0198, Train Linf Norm: 2.7788, Test Linf Norm: 0.4703\n",
            "Epoch 67: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0880, Test L1 Norm: 0.0197, Train Linf Norm: 2.6384, Test Linf Norm: 0.4686\n",
            "Epoch 68: Train Loss: 0.0041, Test Loss: 0.0041, Train L1 Norm: 0.0881, Test L1 Norm: 0.0196, Train Linf Norm: 2.6400, Test Linf Norm: 0.4669\n",
            "Epoch 69: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0912, Test L1 Norm: 0.0198, Train Linf Norm: 2.7408, Test Linf Norm: 0.4709\n",
            "Epoch 70: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0889, Test L1 Norm: 0.0197, Train Linf Norm: 2.6740, Test Linf Norm: 0.4699\n",
            "Epoch 71: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0959, Test L1 Norm: 0.0196, Train Linf Norm: 2.8910, Test Linf Norm: 0.4656\n",
            "Epoch 72: Train Loss: 0.0040, Test Loss: 0.0043, Train L1 Norm: 0.0934, Test L1 Norm: 0.0197, Train Linf Norm: 2.8147, Test Linf Norm: 0.4672\n",
            "Epoch 73: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0899, Test L1 Norm: 0.0195, Train Linf Norm: 2.7017, Test Linf Norm: 0.4645\n",
            "Epoch 74: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0910, Test L1 Norm: 0.0197, Train Linf Norm: 2.7420, Test Linf Norm: 0.4691\n",
            "Epoch 75: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0894, Test L1 Norm: 0.0196, Train Linf Norm: 2.6861, Test Linf Norm: 0.4658\n",
            "Epoch 76: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0899, Test L1 Norm: 0.0196, Train Linf Norm: 2.7023, Test Linf Norm: 0.4665\n",
            "Epoch 77: Train Loss: 0.0040, Test Loss: 0.0043, Train L1 Norm: 0.0875, Test L1 Norm: 0.0196, Train Linf Norm: 2.6263, Test Linf Norm: 0.4659\n",
            "Epoch 78: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0930, Test L1 Norm: 0.0194, Train Linf Norm: 2.8080, Test Linf Norm: 0.4602\n",
            "Epoch 79: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0860, Test L1 Norm: 0.0195, Train Linf Norm: 2.5820, Test Linf Norm: 0.4645\n",
            "Epoch 80: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0889, Test L1 Norm: 0.0196, Train Linf Norm: 2.6747, Test Linf Norm: 0.4667\n",
            "Epoch 81: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0880, Test L1 Norm: 0.0196, Train Linf Norm: 2.6408, Test Linf Norm: 0.4668\n",
            "Epoch 82: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0904, Test L1 Norm: 0.0196, Train Linf Norm: 2.7230, Test Linf Norm: 0.4667\n",
            "Epoch 83: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0881, Test L1 Norm: 0.0197, Train Linf Norm: 2.6414, Test Linf Norm: 0.4686\n",
            "Epoch 84: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0904, Test L1 Norm: 0.0196, Train Linf Norm: 2.7195, Test Linf Norm: 0.4673\n",
            "Epoch 85: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0895, Test L1 Norm: 0.0196, Train Linf Norm: 2.6933, Test Linf Norm: 0.4668\n",
            "Epoch 86: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0916, Test L1 Norm: 0.0196, Train Linf Norm: 2.7583, Test Linf Norm: 0.4670\n",
            "Epoch 87: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0905, Test L1 Norm: 0.0196, Train Linf Norm: 2.7229, Test Linf Norm: 0.4662\n",
            "Epoch 88: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0894, Test L1 Norm: 0.0196, Train Linf Norm: 2.6864, Test Linf Norm: 0.4673\n",
            "Epoch 89: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0916, Test L1 Norm: 0.0196, Train Linf Norm: 2.7623, Test Linf Norm: 0.4663\n",
            "Epoch 90: Train Loss: 0.0040, Test Loss: 0.0041, Train L1 Norm: 0.0896, Test L1 Norm: 0.0196, Train Linf Norm: 2.6998, Test Linf Norm: 0.4648\n",
            "Epoch 91: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0910, Test L1 Norm: 0.0195, Train Linf Norm: 2.7325, Test Linf Norm: 0.4653\n",
            "Epoch 92: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0196, Train Linf Norm: 2.6962, Test Linf Norm: 0.4656\n",
            "Epoch 93: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0900, Test L1 Norm: 0.0196, Train Linf Norm: 2.7028, Test Linf Norm: 0.4658\n",
            "Epoch 94: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0903, Test L1 Norm: 0.0195, Train Linf Norm: 2.7175, Test Linf Norm: 0.4648\n",
            "Epoch 95: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0902, Test L1 Norm: 0.0196, Train Linf Norm: 2.7135, Test Linf Norm: 0.4659\n",
            "Epoch 96: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0908, Test L1 Norm: 0.0195, Train Linf Norm: 2.7347, Test Linf Norm: 0.4653\n",
            "Epoch 97: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0907, Test L1 Norm: 0.0195, Train Linf Norm: 2.7315, Test Linf Norm: 0.4652\n",
            "Epoch 98: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0885, Test L1 Norm: 0.0196, Train Linf Norm: 2.6611, Test Linf Norm: 0.4659\n",
            "Epoch 99: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0893, Test L1 Norm: 0.0195, Train Linf Norm: 2.6783, Test Linf Norm: 0.4654\n",
            "Epoch 100: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7010, Test Linf Norm: 0.4651\n",
            "Epoch 101: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0899, Test L1 Norm: 0.0196, Train Linf Norm: 2.6983, Test Linf Norm: 0.4659\n",
            "Epoch 102: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0901, Test L1 Norm: 0.0195, Train Linf Norm: 2.7061, Test Linf Norm: 0.4655\n",
            "Epoch 103: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0896, Test L1 Norm: 0.0196, Train Linf Norm: 2.6986, Test Linf Norm: 0.4663\n",
            "Epoch 104: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0899, Test L1 Norm: 0.0196, Train Linf Norm: 2.6985, Test Linf Norm: 0.4658\n",
            "Epoch 105: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0897, Test L1 Norm: 0.0195, Train Linf Norm: 2.7027, Test Linf Norm: 0.4653\n",
            "Epoch 106: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0899, Test L1 Norm: 0.0195, Train Linf Norm: 2.7054, Test Linf Norm: 0.4653\n",
            "Epoch 107: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0895, Test L1 Norm: 0.0195, Train Linf Norm: 2.6910, Test Linf Norm: 0.4654\n",
            "Epoch 108: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0899, Test L1 Norm: 0.0195, Train Linf Norm: 2.7039, Test Linf Norm: 0.4655\n",
            "Epoch 109: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0196, Train Linf Norm: 2.7018, Test Linf Norm: 0.4657\n",
            "Epoch 110: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0900, Test L1 Norm: 0.0195, Train Linf Norm: 2.7094, Test Linf Norm: 0.4655\n",
            "Epoch 111: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0896, Test L1 Norm: 0.0195, Train Linf Norm: 2.6923, Test Linf Norm: 0.4651\n",
            "Epoch 112: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0897, Test L1 Norm: 0.0195, Train Linf Norm: 2.6899, Test Linf Norm: 0.4655\n",
            "Epoch 113: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0900, Test L1 Norm: 0.0195, Train Linf Norm: 2.6973, Test Linf Norm: 0.4654\n",
            "Epoch 114: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7061, Test Linf Norm: 0.4654\n",
            "Epoch 115: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0897, Test L1 Norm: 0.0195, Train Linf Norm: 2.6958, Test Linf Norm: 0.4653\n",
            "Epoch 116: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0899, Test L1 Norm: 0.0195, Train Linf Norm: 2.6931, Test Linf Norm: 0.4652\n",
            "Epoch 117: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0899, Test L1 Norm: 0.0195, Train Linf Norm: 2.7070, Test Linf Norm: 0.4652\n",
            "Epoch 118: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0899, Test L1 Norm: 0.0195, Train Linf Norm: 2.7052, Test Linf Norm: 0.4654\n",
            "Epoch 119: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6958, Test Linf Norm: 0.4653\n",
            "Epoch 120: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6947, Test Linf Norm: 0.4654\n",
            "Epoch 121: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0899, Test L1 Norm: 0.0195, Train Linf Norm: 2.7060, Test Linf Norm: 0.4653\n",
            "Epoch 122: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7010, Test Linf Norm: 0.4653\n",
            "Epoch 123: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0900, Test L1 Norm: 0.0195, Train Linf Norm: 2.7033, Test Linf Norm: 0.4653\n",
            "Epoch 124: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7008, Test Linf Norm: 0.4653\n",
            "Epoch 125: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7043, Test Linf Norm: 0.4653\n",
            "Epoch 126: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7074, Test Linf Norm: 0.4653\n",
            "Epoch 127: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0897, Test L1 Norm: 0.0195, Train Linf Norm: 2.7023, Test Linf Norm: 0.4653\n",
            "Epoch 128: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0897, Test L1 Norm: 0.0195, Train Linf Norm: 2.6978, Test Linf Norm: 0.4652\n",
            "Epoch 129: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7027, Test Linf Norm: 0.4653\n",
            "Epoch 130: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7027, Test Linf Norm: 0.4653\n",
            "Epoch 131: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0897, Test L1 Norm: 0.0195, Train Linf Norm: 2.6950, Test Linf Norm: 0.4653\n",
            "Epoch 132: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6983, Test Linf Norm: 0.4653\n",
            "Epoch 133: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6974, Test Linf Norm: 0.4653\n",
            "Epoch 134: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7040, Test Linf Norm: 0.4653\n",
            "Epoch 135: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6992, Test Linf Norm: 0.4653\n",
            "Epoch 136: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6965, Test Linf Norm: 0.4653\n",
            "Epoch 137: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6951, Test Linf Norm: 0.4653\n",
            "Epoch 138: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7016, Test Linf Norm: 0.4653\n",
            "Epoch 139: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6984, Test Linf Norm: 0.4653\n",
            "Epoch 140: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6988, Test Linf Norm: 0.4653\n",
            "Epoch 141: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6875, Test Linf Norm: 0.4653\n",
            "Epoch 142: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7019, Test Linf Norm: 0.4653\n",
            "Epoch 143: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6991, Test Linf Norm: 0.4653\n",
            "Epoch 144: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6933, Test Linf Norm: 0.4653\n",
            "Epoch 145: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7010, Test Linf Norm: 0.4653\n",
            "Epoch 146: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6980, Test Linf Norm: 0.4653\n",
            "Epoch 147: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6993, Test Linf Norm: 0.4653\n",
            "Epoch 148: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6913, Test Linf Norm: 0.4653\n",
            "Epoch 149: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7026, Test Linf Norm: 0.4653\n",
            "Epoch 150: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7028, Test Linf Norm: 0.4653\n",
            "Epoch 151: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7014, Test Linf Norm: 0.4653\n",
            "Epoch 152: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7045, Test Linf Norm: 0.4653\n",
            "Epoch 153: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6935, Test Linf Norm: 0.4653\n",
            "Epoch 154: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6974, Test Linf Norm: 0.4653\n",
            "Epoch 155: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6966, Test Linf Norm: 0.4653\n",
            "Epoch 156: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7009, Test Linf Norm: 0.4653\n",
            "Epoch 157: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6998, Test Linf Norm: 0.4653\n",
            "Epoch 158: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6975, Test Linf Norm: 0.4653\n",
            "Epoch 159: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7040, Test Linf Norm: 0.4653\n",
            "Epoch 160: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6991, Test Linf Norm: 0.4653\n",
            "Epoch 161: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7034, Test Linf Norm: 0.4653\n",
            "Epoch 162: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7084, Test Linf Norm: 0.4653\n",
            "Epoch 163: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7014, Test Linf Norm: 0.4653\n",
            "Epoch 164: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6947, Test Linf Norm: 0.4653\n",
            "Epoch 165: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6991, Test Linf Norm: 0.4653\n",
            "Epoch 166: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7057, Test Linf Norm: 0.4653\n",
            "Epoch 167: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7026, Test Linf Norm: 0.4653\n",
            "Epoch 168: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7006, Test Linf Norm: 0.4653\n",
            "Epoch 169: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7001, Test Linf Norm: 0.4653\n",
            "Epoch 170: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7065, Test Linf Norm: 0.4653\n",
            "Epoch 171: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6851, Test Linf Norm: 0.4653\n",
            "Epoch 172: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7022, Test Linf Norm: 0.4653\n",
            "Epoch 173: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6826, Test Linf Norm: 0.4653\n",
            "Epoch 174: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7036, Test Linf Norm: 0.4653\n",
            "Epoch 175: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6966, Test Linf Norm: 0.4653\n",
            "Epoch 176: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6981, Test Linf Norm: 0.4653\n",
            "Epoch 177: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7002, Test Linf Norm: 0.4653\n",
            "Epoch 178: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6945, Test Linf Norm: 0.4653\n",
            "Epoch 179: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6962, Test Linf Norm: 0.4653\n",
            "Epoch 180: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6976, Test Linf Norm: 0.4653\n",
            "Epoch 181: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7035, Test Linf Norm: 0.4653\n",
            "Epoch 182: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7008, Test Linf Norm: 0.4653\n",
            "Epoch 183: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6994, Test Linf Norm: 0.4653\n",
            "Epoch 184: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7028, Test Linf Norm: 0.4653\n",
            "Epoch 185: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6988, Test Linf Norm: 0.4653\n",
            "Epoch 186: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6991, Test Linf Norm: 0.4653\n",
            "Epoch 187: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6996, Test Linf Norm: 0.4653\n",
            "Epoch 188: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6992, Test Linf Norm: 0.4653\n",
            "Epoch 189: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7042, Test Linf Norm: 0.4653\n",
            "Epoch 190: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7036, Test Linf Norm: 0.4653\n",
            "Epoch 191: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6983, Test Linf Norm: 0.4653\n",
            "Epoch 192: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7027, Test Linf Norm: 0.4653\n",
            "Epoch 193: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6997, Test Linf Norm: 0.4653\n",
            "Epoch 194: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7005, Test Linf Norm: 0.4653\n",
            "Epoch 195: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6990, Test Linf Norm: 0.4653\n",
            "Epoch 196: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6903, Test Linf Norm: 0.4653\n",
            "Epoch 197: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7029, Test Linf Norm: 0.4653\n",
            "Epoch 198: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6949, Test Linf Norm: 0.4653\n",
            "Epoch 199: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6946, Test Linf Norm: 0.4653\n",
            "Epoch 200: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.6964, Test Linf Norm: 0.4653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:56:53,458]\u001b[0m Trial 12 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 201: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0898, Test L1 Norm: 0.0195, Train Linf Norm: 2.7035, Test Linf Norm: 0.4653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:57:00,091]\u001b[0m Trial 13 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.7388, Test Loss: 0.3083, Train L1 Norm: 2.1122, Test L1 Norm: 0.3208, Train Linf Norm: 107.7624, Test Linf Norm: 10.4101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:57:03,282]\u001b[0m Trial 14 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.9220, Test Loss: 0.1986, Train L1 Norm: 4.3755, Test L1 Norm: 0.5895, Train Linf Norm: 465.5698, Test Linf Norm: 44.1225\n",
            "Epoch 1: Train Loss: 1.3260, Test Loss: 0.0119, Train L1 Norm: 0.9307, Test L1 Norm: 0.1228, Train Linf Norm: 49.3591, Test Linf Norm: 4.9931\n",
            "Epoch 2: Train Loss: 0.0604, Test Loss: 0.0884, Train L1 Norm: 0.7828, Test L1 Norm: 0.1593, Train Linf Norm: 45.1783, Test Linf Norm: 5.6623\n",
            "Epoch 3: Train Loss: 0.0620, Test Loss: 0.0123, Train L1 Norm: 0.5760, Test L1 Norm: 0.1360, Train Linf Norm: 32.3851, Test Linf Norm: 5.9325\n",
            "Epoch 4: Train Loss: 0.0909, Test Loss: 0.0069, Train L1 Norm: 0.6361, Test L1 Norm: 0.0663, Train Linf Norm: 36.2586, Test Linf Norm: 1.2790\n",
            "Epoch 5: Train Loss: 0.0325, Test Loss: 0.9117, Train L1 Norm: 0.5921, Test L1 Norm: 0.2974, Train Linf Norm: 34.5015, Test Linf Norm: 6.5321\n",
            "Epoch 6: Train Loss: 0.0384, Test Loss: 0.0045, Train L1 Norm: 1.0391, Test L1 Norm: 0.1592, Train Linf Norm: 62.4966, Test Linf Norm: 7.7500\n",
            "Epoch 7: Train Loss: 0.0342, Test Loss: 0.0195, Train L1 Norm: 0.6683, Test L1 Norm: 0.1308, Train Linf Norm: 38.7336, Test Linf Norm: 4.9172\n",
            "Epoch 8: Train Loss: 0.0499, Test Loss: 0.0030, Train L1 Norm: 0.6139, Test L1 Norm: 0.0972, Train Linf Norm: 34.8541, Test Linf Norm: 4.0793\n",
            "Epoch 9: Train Loss: 0.0319, Test Loss: 0.0057, Train L1 Norm: 2.7716, Test L1 Norm: 0.0999, Train Linf Norm: 173.8178, Test Linf Norm: 3.6508\n",
            "Epoch 10: Train Loss: 0.0233, Test Loss: 0.0302, Train L1 Norm: 0.3923, Test L1 Norm: 0.1060, Train Linf Norm: 21.7505, Test Linf Norm: 3.5628\n",
            "Epoch 11: Train Loss: 0.0375, Test Loss: 0.0075, Train L1 Norm: 0.5355, Test L1 Norm: 0.0830, Train Linf Norm: 30.5643, Test Linf Norm: 1.8541\n",
            "Epoch 12: Train Loss: 0.0129, Test Loss: 0.0010, Train L1 Norm: 0.4091, Test L1 Norm: 0.0696, Train Linf Norm: 23.5278, Test Linf Norm: 3.0229\n",
            "Epoch 13: Train Loss: 0.0120, Test Loss: 0.0564, Train L1 Norm: 0.2520, Test L1 Norm: 0.1386, Train Linf Norm: 13.7269, Test Linf Norm: 4.2306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:58:40,060]\u001b[0m Trial 15 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss: 0.0296, Test Loss: 0.0062, Train L1 Norm: 0.3875, Test L1 Norm: 0.0672, Train Linf Norm: 21.2010, Test Linf Norm: 2.5342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:58:43,050]\u001b[0m Trial 16 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 3.4130, Test Loss: 3.4125, Train L1 Norm: 1.2901, Test L1 Norm: 1.0000, Train Linf Norm: 41.7586, Test Linf Norm: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:58:44,555]\u001b[0m Trial 17 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.9761, Test Loss: 0.6715, Train L1 Norm: 5.6628, Test L1 Norm: 0.4519, Train Linf Norm: 2377.3779, Test Linf Norm: 38.5399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 11:58:46,915]\u001b[0m Trial 18 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 242630574.6158, Test Loss: 12.0401, Train L1 Norm: 785.2584, Test L1 Norm: 3.0541, Train Linf Norm: 107177.6755, Test Linf Norm: 785.9413\n",
            "Epoch 1: Train Loss: 0.1447, Test Loss: 0.0224, Train L1 Norm: 1.1612, Test L1 Norm: 0.1764, Train Linf Norm: 31.9283, Test Linf Norm: 3.8050\n",
            "Epoch 2: Train Loss: 0.0327, Test Loss: 0.0067, Train L1 Norm: 0.6177, Test L1 Norm: 0.1324, Train Linf Norm: 17.5689, Test Linf Norm: 2.6067\n",
            "Epoch 3: Train Loss: 0.0239, Test Loss: 0.0591, Train L1 Norm: 0.3572, Test L1 Norm: 0.1145, Train Linf Norm: 9.6043, Test Linf Norm: 1.9095\n",
            "Epoch 4: Train Loss: 0.0242, Test Loss: 0.0027, Train L1 Norm: 0.2789, Test L1 Norm: 0.0719, Train Linf Norm: 7.2063, Test Linf Norm: 1.3124\n",
            "Epoch 5: Train Loss: 0.0221, Test Loss: 0.0037, Train L1 Norm: 0.2227, Test L1 Norm: 0.0763, Train Linf Norm: 5.5302, Test Linf Norm: 1.4077\n",
            "Epoch 6: Train Loss: 0.0233, Test Loss: 0.0120, Train L1 Norm: 0.2549, Test L1 Norm: 0.0928, Train Linf Norm: 6.5450, Test Linf Norm: 1.7844\n",
            "Epoch 7: Train Loss: 0.0238, Test Loss: 0.0042, Train L1 Norm: 0.2819, Test L1 Norm: 0.0679, Train Linf Norm: 7.3634, Test Linf Norm: 1.2797\n",
            "Epoch 8: Train Loss: 0.0251, Test Loss: 0.0573, Train L1 Norm: 0.3264, Test L1 Norm: 0.1138, Train Linf Norm: 8.7712, Test Linf Norm: 1.1641\n",
            "Epoch 9: Train Loss: 0.0284, Test Loss: 0.0209, Train L1 Norm: 0.3755, Test L1 Norm: 0.1305, Train Linf Norm: 10.2929, Test Linf Norm: 2.3886\n",
            "Epoch 10: Train Loss: 0.0295, Test Loss: 0.0046, Train L1 Norm: 0.3653, Test L1 Norm: 0.1102, Train Linf Norm: 9.8513, Test Linf Norm: 2.3801\n",
            "Epoch 11: Train Loss: 0.0294, Test Loss: 0.0023, Train L1 Norm: 0.4261, Test L1 Norm: 0.0926, Train Linf Norm: 11.7916, Test Linf Norm: 2.1137\n",
            "Epoch 12: Train Loss: 0.0312, Test Loss: 0.0290, Train L1 Norm: 0.4950, Test L1 Norm: 0.1467, Train Linf Norm: 13.8959, Test Linf Norm: 2.9444\n",
            "Epoch 13: Train Loss: 0.0317, Test Loss: 0.0043, Train L1 Norm: 0.6029, Test L1 Norm: 0.1236, Train Linf Norm: 17.2494, Test Linf Norm: 2.9225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:00:14,930]\u001b[0m Trial 19 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss: 0.0348, Test Loss: 0.0057, Train L1 Norm: 0.6564, Test L1 Norm: 0.1557, Train Linf Norm: 18.9518, Test Linf Norm: 3.7160\n",
            "Epoch 1: Train Loss: 0.6340, Test Loss: 0.5499, Train L1 Norm: 1.0917, Test L1 Norm: 0.2648, Train Linf Norm: 94.7029, Test Linf Norm: 6.8874\n",
            "Epoch 2: Train Loss: 0.2729, Test Loss: 0.1492, Train L1 Norm: 0.2196, Test L1 Norm: 0.0897, Train Linf Norm: 10.9728, Test Linf Norm: 2.3508\n",
            "Epoch 3: Train Loss: 0.2205, Test Loss: 0.2081, Train L1 Norm: 0.1615, Test L1 Norm: 0.0938, Train Linf Norm: 7.3374, Test Linf Norm: 1.1681\n",
            "Epoch 4: Train Loss: 0.1917, Test Loss: 0.2979, Train L1 Norm: 0.1418, Test L1 Norm: 0.1160, Train Linf Norm: 6.9967, Test Linf Norm: 2.7591\n",
            "Epoch 5: Train Loss: 0.1820, Test Loss: 0.0613, Train L1 Norm: 0.1506, Test L1 Norm: 0.0565, Train Linf Norm: 8.6564, Test Linf Norm: 2.2429\n",
            "Epoch 6: Train Loss: 0.1699, Test Loss: 0.2136, Train L1 Norm: 0.1196, Test L1 Norm: 0.0903, Train Linf Norm: 5.4180, Test Linf Norm: 1.6650\n",
            "Epoch 7: Train Loss: 0.1546, Test Loss: 0.3722, Train L1 Norm: 0.1384, Test L1 Norm: 0.1690, Train Linf Norm: 8.7580, Test Linf Norm: 3.3604\n",
            "Epoch 8: Train Loss: 0.1477, Test Loss: 0.3448, Train L1 Norm: 0.0963, Test L1 Norm: 0.1339, Train Linf Norm: 3.7236, Test Linf Norm: 2.0461\n",
            "Epoch 9: Train Loss: 0.1620, Test Loss: 0.0613, Train L1 Norm: 0.1108, Test L1 Norm: 0.0527, Train Linf Norm: 5.2584, Test Linf Norm: 2.1253\n",
            "Epoch 10: Train Loss: 0.1325, Test Loss: 0.0576, Train L1 Norm: 0.1299, Test L1 Norm: 0.0449, Train Linf Norm: 9.0110, Test Linf Norm: 1.7761\n",
            "Epoch 11: Train Loss: 0.1253, Test Loss: 0.0512, Train L1 Norm: 0.1083, Test L1 Norm: 0.0371, Train Linf Norm: 6.6064, Test Linf Norm: 1.1006\n",
            "Epoch 12: Train Loss: 0.1311, Test Loss: 0.1066, Train L1 Norm: 0.1063, Test L1 Norm: 0.0575, Train Linf Norm: 6.2695, Test Linf Norm: 1.2374\n",
            "Epoch 13: Train Loss: 0.0405, Test Loss: 0.0242, Train L1 Norm: 0.0674, Test L1 Norm: 0.0327, Train Linf Norm: 5.0242, Test Linf Norm: 1.2818\n",
            "Epoch 14: Train Loss: 0.0400, Test Loss: 0.0242, Train L1 Norm: 0.0572, Test L1 Norm: 0.0303, Train Linf Norm: 3.7052, Test Linf Norm: 1.1630\n",
            "Epoch 15: Train Loss: 0.0473, Test Loss: 0.0374, Train L1 Norm: 0.0623, Test L1 Norm: 0.0354, Train Linf Norm: 4.2509, Test Linf Norm: 1.2102\n",
            "Epoch 16: Train Loss: 0.0450, Test Loss: 0.1180, Train L1 Norm: 0.0660, Test L1 Norm: 0.0485, Train Linf Norm: 4.8941, Test Linf Norm: 0.8123\n",
            "Epoch 17: Train Loss: 0.0464, Test Loss: 0.0196, Train L1 Norm: 0.0650, Test L1 Norm: 0.0272, Train Linf Norm: 4.8262, Test Linf Norm: 1.0710\n",
            "Epoch 18: Train Loss: 0.0465, Test Loss: 0.0301, Train L1 Norm: 0.0569, Test L1 Norm: 0.0259, Train Linf Norm: 3.7730, Test Linf Norm: 0.8251\n",
            "Epoch 19: Train Loss: 0.0457, Test Loss: 0.0325, Train L1 Norm: 0.0594, Test L1 Norm: 0.0277, Train Linf Norm: 4.2403, Test Linf Norm: 0.7017\n",
            "Epoch 20: Train Loss: 0.0454, Test Loss: 0.0261, Train L1 Norm: 0.0651, Test L1 Norm: 0.0277, Train Linf Norm: 5.0158, Test Linf Norm: 0.9737\n",
            "Epoch 21: Train Loss: 0.0464, Test Loss: 0.0299, Train L1 Norm: 0.0619, Test L1 Norm: 0.0270, Train Linf Norm: 4.5597, Test Linf Norm: 0.9013\n",
            "Epoch 22: Train Loss: 0.0476, Test Loss: 0.0332, Train L1 Norm: 0.0605, Test L1 Norm: 0.0253, Train Linf Norm: 4.4075, Test Linf Norm: 0.6462\n",
            "Epoch 23: Train Loss: 0.0440, Test Loss: 0.0187, Train L1 Norm: 0.0605, Test L1 Norm: 0.0220, Train Linf Norm: 4.5632, Test Linf Norm: 0.7552\n",
            "Epoch 24: Train Loss: 0.0486, Test Loss: 0.0758, Train L1 Norm: 0.0759, Test L1 Norm: 0.0444, Train Linf Norm: 6.3737, Test Linf Norm: 0.7277\n",
            "Epoch 25: Train Loss: 0.0168, Test Loss: 0.0142, Train L1 Norm: 0.0509, Test L1 Norm: 0.0218, Train Linf Norm: 4.4596, Test Linf Norm: 0.8279\n",
            "Epoch 26: Train Loss: 0.0154, Test Loss: 0.0131, Train L1 Norm: 0.0461, Test L1 Norm: 0.0199, Train Linf Norm: 3.8617, Test Linf Norm: 0.7366\n",
            "Epoch 27: Train Loss: 0.0157, Test Loss: 0.0139, Train L1 Norm: 0.0472, Test L1 Norm: 0.0200, Train Linf Norm: 4.0074, Test Linf Norm: 0.7257\n",
            "Epoch 28: Train Loss: 0.0152, Test Loss: 0.0125, Train L1 Norm: 0.0462, Test L1 Norm: 0.0198, Train Linf Norm: 3.9114, Test Linf Norm: 0.6942\n",
            "Epoch 29: Train Loss: 0.0160, Test Loss: 0.0138, Train L1 Norm: 0.0478, Test L1 Norm: 0.0198, Train Linf Norm: 4.1042, Test Linf Norm: 0.7193\n",
            "Epoch 30: Train Loss: 0.0156, Test Loss: 0.0215, Train L1 Norm: 0.0493, Test L1 Norm: 0.0222, Train Linf Norm: 4.3522, Test Linf Norm: 0.7935\n",
            "Epoch 31: Train Loss: 0.0161, Test Loss: 0.0132, Train L1 Norm: 0.0485, Test L1 Norm: 0.0194, Train Linf Norm: 4.2541, Test Linf Norm: 0.7307\n",
            "Epoch 32: Train Loss: 0.0155, Test Loss: 0.0153, Train L1 Norm: 0.0461, Test L1 Norm: 0.0190, Train Linf Norm: 3.9820, Test Linf Norm: 0.7200\n",
            "Epoch 33: Train Loss: 0.0156, Test Loss: 0.0136, Train L1 Norm: 0.0479, Test L1 Norm: 0.0179, Train Linf Norm: 4.2340, Test Linf Norm: 0.6314\n",
            "Epoch 34: Train Loss: 0.0172, Test Loss: 0.0108, Train L1 Norm: 0.0496, Test L1 Norm: 0.0167, Train Linf Norm: 4.4247, Test Linf Norm: 0.6006\n",
            "Epoch 35: Train Loss: 0.0162, Test Loss: 0.0196, Train L1 Norm: 0.0510, Test L1 Norm: 0.0195, Train Linf Norm: 4.6480, Test Linf Norm: 0.6625\n",
            "Epoch 36: Train Loss: 0.0157, Test Loss: 0.0141, Train L1 Norm: 0.0532, Test L1 Norm: 0.0181, Train Linf Norm: 4.9334, Test Linf Norm: 0.6527\n",
            "Epoch 37: Train Loss: 0.0101, Test Loss: 0.0095, Train L1 Norm: 0.0465, Test L1 Norm: 0.0168, Train Linf Norm: 4.2775, Test Linf Norm: 0.6523\n",
            "Epoch 38: Train Loss: 0.0099, Test Loss: 0.0099, Train L1 Norm: 0.0464, Test L1 Norm: 0.0167, Train Linf Norm: 4.3001, Test Linf Norm: 0.6399\n",
            "Epoch 39: Train Loss: 0.0099, Test Loss: 0.0091, Train L1 Norm: 0.0455, Test L1 Norm: 0.0164, Train Linf Norm: 4.1759, Test Linf Norm: 0.6295\n",
            "Epoch 40: Train Loss: 0.0097, Test Loss: 0.0094, Train L1 Norm: 0.0464, Test L1 Norm: 0.0164, Train Linf Norm: 4.3015, Test Linf Norm: 0.6183\n",
            "Epoch 41: Train Loss: 0.0097, Test Loss: 0.0100, Train L1 Norm: 0.0452, Test L1 Norm: 0.0163, Train Linf Norm: 4.1684, Test Linf Norm: 0.6037\n",
            "Epoch 42: Train Loss: 0.0096, Test Loss: 0.0089, Train L1 Norm: 0.0453, Test L1 Norm: 0.0164, Train Linf Norm: 4.1936, Test Linf Norm: 0.6371\n",
            "Epoch 43: Train Loss: 0.0095, Test Loss: 0.0086, Train L1 Norm: 0.0465, Test L1 Norm: 0.0161, Train Linf Norm: 4.3360, Test Linf Norm: 0.6171\n",
            "Epoch 44: Train Loss: 0.0094, Test Loss: 0.0097, Train L1 Norm: 0.0460, Test L1 Norm: 0.0161, Train Linf Norm: 4.2799, Test Linf Norm: 0.5958\n",
            "Epoch 45: Train Loss: 0.0094, Test Loss: 0.0125, Train L1 Norm: 0.0491, Test L1 Norm: 0.0172, Train Linf Norm: 4.7154, Test Linf Norm: 0.6340\n",
            "Epoch 46: Train Loss: 0.0092, Test Loss: 0.0087, Train L1 Norm: 0.0453, Test L1 Norm: 0.0160, Train Linf Norm: 4.1492, Test Linf Norm: 0.6082\n",
            "Epoch 47: Train Loss: 0.0092, Test Loss: 0.0099, Train L1 Norm: 0.0451, Test L1 Norm: 0.0165, Train Linf Norm: 4.1428, Test Linf Norm: 0.6184\n",
            "Epoch 48: Train Loss: 0.0090, Test Loss: 0.0088, Train L1 Norm: 0.0462, Test L1 Norm: 0.0159, Train Linf Norm: 4.3549, Test Linf Norm: 0.6068\n",
            "Epoch 49: Train Loss: 0.0085, Test Loss: 0.0090, Train L1 Norm: 0.0464, Test L1 Norm: 0.0158, Train Linf Norm: 4.3829, Test Linf Norm: 0.5986\n",
            "Epoch 50: Train Loss: 0.0084, Test Loss: 0.0082, Train L1 Norm: 0.0476, Test L1 Norm: 0.0156, Train Linf Norm: 4.5534, Test Linf Norm: 0.6017\n",
            "Epoch 51: Train Loss: 0.0084, Test Loss: 0.0084, Train L1 Norm: 0.0453, Test L1 Norm: 0.0158, Train Linf Norm: 4.2462, Test Linf Norm: 0.6066\n",
            "Epoch 52: Train Loss: 0.0084, Test Loss: 0.0082, Train L1 Norm: 0.0455, Test L1 Norm: 0.0156, Train Linf Norm: 4.3116, Test Linf Norm: 0.5919\n",
            "Epoch 53: Train Loss: 0.0083, Test Loss: 0.0082, Train L1 Norm: 0.0454, Test L1 Norm: 0.0156, Train Linf Norm: 4.2875, Test Linf Norm: 0.5927\n",
            "Epoch 54: Train Loss: 0.0083, Test Loss: 0.0082, Train L1 Norm: 0.0458, Test L1 Norm: 0.0157, Train Linf Norm: 4.3465, Test Linf Norm: 0.5994\n",
            "Epoch 55: Train Loss: 0.0083, Test Loss: 0.0081, Train L1 Norm: 0.0455, Test L1 Norm: 0.0154, Train Linf Norm: 4.3090, Test Linf Norm: 0.5869\n",
            "Epoch 56: Train Loss: 0.0083, Test Loss: 0.0081, Train L1 Norm: 0.0456, Test L1 Norm: 0.0156, Train Linf Norm: 4.2889, Test Linf Norm: 0.5933\n",
            "Epoch 57: Train Loss: 0.0083, Test Loss: 0.0081, Train L1 Norm: 0.0460, Test L1 Norm: 0.0155, Train Linf Norm: 4.3776, Test Linf Norm: 0.5895\n",
            "Epoch 58: Train Loss: 0.0082, Test Loss: 0.0080, Train L1 Norm: 0.0459, Test L1 Norm: 0.0154, Train Linf Norm: 4.3558, Test Linf Norm: 0.5802\n",
            "Epoch 59: Train Loss: 0.0081, Test Loss: 0.0080, Train L1 Norm: 0.0468, Test L1 Norm: 0.0154, Train Linf Norm: 4.4825, Test Linf Norm: 0.5882\n",
            "Epoch 60: Train Loss: 0.0082, Test Loss: 0.0080, Train L1 Norm: 0.0453, Test L1 Norm: 0.0152, Train Linf Norm: 4.2951, Test Linf Norm: 0.5709\n",
            "Epoch 61: Train Loss: 0.0080, Test Loss: 0.0080, Train L1 Norm: 0.0455, Test L1 Norm: 0.0154, Train Linf Norm: 4.3309, Test Linf Norm: 0.5948\n",
            "Epoch 62: Train Loss: 0.0080, Test Loss: 0.0079, Train L1 Norm: 0.0454, Test L1 Norm: 0.0154, Train Linf Norm: 4.2937, Test Linf Norm: 0.5901\n",
            "Epoch 63: Train Loss: 0.0080, Test Loss: 0.0079, Train L1 Norm: 0.0459, Test L1 Norm: 0.0153, Train Linf Norm: 4.3835, Test Linf Norm: 0.5860\n",
            "Epoch 64: Train Loss: 0.0079, Test Loss: 0.0079, Train L1 Norm: 0.0455, Test L1 Norm: 0.0153, Train Linf Norm: 4.3330, Test Linf Norm: 0.5906\n",
            "Epoch 65: Train Loss: 0.0079, Test Loss: 0.0079, Train L1 Norm: 0.0455, Test L1 Norm: 0.0153, Train Linf Norm: 4.3382, Test Linf Norm: 0.5857\n",
            "Epoch 66: Train Loss: 0.0079, Test Loss: 0.0079, Train L1 Norm: 0.0454, Test L1 Norm: 0.0153, Train Linf Norm: 4.3247, Test Linf Norm: 0.5870\n",
            "Epoch 67: Train Loss: 0.0079, Test Loss: 0.0078, Train L1 Norm: 0.0455, Test L1 Norm: 0.0153, Train Linf Norm: 4.3485, Test Linf Norm: 0.5830\n",
            "Epoch 68: Train Loss: 0.0079, Test Loss: 0.0078, Train L1 Norm: 0.0457, Test L1 Norm: 0.0152, Train Linf Norm: 4.3622, Test Linf Norm: 0.5811\n",
            "Epoch 69: Train Loss: 0.0079, Test Loss: 0.0078, Train L1 Norm: 0.0456, Test L1 Norm: 0.0152, Train Linf Norm: 4.3482, Test Linf Norm: 0.5834\n",
            "Epoch 70: Train Loss: 0.0079, Test Loss: 0.0078, Train L1 Norm: 0.0457, Test L1 Norm: 0.0152, Train Linf Norm: 4.3475, Test Linf Norm: 0.5776\n",
            "Epoch 71: Train Loss: 0.0079, Test Loss: 0.0078, Train L1 Norm: 0.0455, Test L1 Norm: 0.0153, Train Linf Norm: 4.3443, Test Linf Norm: 0.5879\n",
            "Epoch 72: Train Loss: 0.0079, Test Loss: 0.0079, Train L1 Norm: 0.0457, Test L1 Norm: 0.0153, Train Linf Norm: 4.3528, Test Linf Norm: 0.5857\n",
            "Epoch 73: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0454, Test L1 Norm: 0.0152, Train Linf Norm: 4.3287, Test Linf Norm: 0.5868\n",
            "Epoch 74: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0454, Test L1 Norm: 0.0152, Train Linf Norm: 4.3306, Test Linf Norm: 0.5856\n",
            "Epoch 75: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3321, Test Linf Norm: 0.5841\n",
            "Epoch 76: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0454, Test L1 Norm: 0.0152, Train Linf Norm: 4.3341, Test Linf Norm: 0.5865\n",
            "Epoch 77: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0454, Test L1 Norm: 0.0152, Train Linf Norm: 4.3266, Test Linf Norm: 0.5819\n",
            "Epoch 78: Train Loss: 0.0078, Test Loss: 0.0079, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3528, Test Linf Norm: 0.5785\n",
            "Epoch 79: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0454, Test L1 Norm: 0.0152, Train Linf Norm: 4.3450, Test Linf Norm: 0.5813\n",
            "Epoch 80: Train Loss: 0.0078, Test Loss: 0.0079, Train L1 Norm: 0.0454, Test L1 Norm: 0.0153, Train Linf Norm: 4.3524, Test Linf Norm: 0.5885\n",
            "Epoch 81: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3491, Test Linf Norm: 0.5788\n",
            "Epoch 82: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3454, Test Linf Norm: 0.5846\n",
            "Epoch 83: Train Loss: 0.0078, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3512, Test Linf Norm: 0.5821\n",
            "Epoch 84: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0460, Test L1 Norm: 0.0152, Train Linf Norm: 4.4183, Test Linf Norm: 0.5876\n",
            "Epoch 85: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0456, Test L1 Norm: 0.0152, Train Linf Norm: 4.3763, Test Linf Norm: 0.5838\n",
            "Epoch 86: Train Loss: 0.0078, Test Loss: 0.0077, Train L1 Norm: 0.0456, Test L1 Norm: 0.0152, Train Linf Norm: 4.3553, Test Linf Norm: 0.5853\n",
            "Epoch 87: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3470, Test Linf Norm: 0.5838\n",
            "Epoch 88: Train Loss: 0.0078, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3481, Test Linf Norm: 0.5835\n",
            "Epoch 89: Train Loss: 0.0078, Test Loss: 0.0077, Train L1 Norm: 0.0456, Test L1 Norm: 0.0152, Train Linf Norm: 4.3533, Test Linf Norm: 0.5852\n",
            "Epoch 90: Train Loss: 0.0078, Test Loss: 0.0077, Train L1 Norm: 0.0456, Test L1 Norm: 0.0152, Train Linf Norm: 4.3589, Test Linf Norm: 0.5843\n",
            "Epoch 91: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3467, Test Linf Norm: 0.5838\n",
            "Epoch 92: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3465, Test Linf Norm: 0.5841\n",
            "Epoch 93: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3580, Test Linf Norm: 0.5848\n",
            "Epoch 94: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3506, Test Linf Norm: 0.5838\n",
            "Epoch 95: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0454, Test L1 Norm: 0.0152, Train Linf Norm: 4.3438, Test Linf Norm: 0.5849\n",
            "Epoch 96: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0456, Test L1 Norm: 0.0152, Train Linf Norm: 4.3459, Test Linf Norm: 0.5812\n",
            "Epoch 97: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0454, Test L1 Norm: 0.0152, Train Linf Norm: 4.3247, Test Linf Norm: 0.5834\n",
            "Epoch 98: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3426, Test Linf Norm: 0.5832\n",
            "Epoch 99: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3180, Test Linf Norm: 0.5823\n",
            "Epoch 100: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3534, Test Linf Norm: 0.5840\n",
            "Epoch 101: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3519, Test Linf Norm: 0.5833\n",
            "Epoch 102: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3614, Test Linf Norm: 0.5840\n",
            "Epoch 103: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3349, Test Linf Norm: 0.5828\n",
            "Epoch 104: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3570, Test Linf Norm: 0.5824\n",
            "Epoch 105: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3278, Test Linf Norm: 0.5835\n",
            "Epoch 106: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3450, Test Linf Norm: 0.5830\n",
            "Epoch 107: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3413, Test Linf Norm: 0.5836\n",
            "Epoch 108: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3579, Test Linf Norm: 0.5822\n",
            "Epoch 109: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3641, Test Linf Norm: 0.5830\n",
            "Epoch 110: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3477, Test Linf Norm: 0.5837\n",
            "Epoch 111: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3573, Test Linf Norm: 0.5835\n",
            "Epoch 112: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3490, Test Linf Norm: 0.5836\n",
            "Epoch 113: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3517, Test Linf Norm: 0.5836\n",
            "Epoch 114: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3503, Test Linf Norm: 0.5834\n",
            "Epoch 115: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3469, Test Linf Norm: 0.5835\n",
            "Epoch 116: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3446, Test Linf Norm: 0.5833\n",
            "Epoch 117: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.2944, Test Linf Norm: 0.5833\n",
            "Epoch 118: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3514, Test Linf Norm: 0.5833\n",
            "Epoch 119: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3364, Test Linf Norm: 0.5832\n",
            "Epoch 120: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3571, Test Linf Norm: 0.5835\n",
            "Epoch 121: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3538, Test Linf Norm: 0.5837\n",
            "Epoch 122: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3519, Test Linf Norm: 0.5834\n",
            "Epoch 123: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3432, Test Linf Norm: 0.5836\n",
            "Epoch 124: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3644, Test Linf Norm: 0.5834\n",
            "Epoch 125: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3495, Test Linf Norm: 0.5834\n",
            "Epoch 126: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3356, Test Linf Norm: 0.5834\n",
            "Epoch 127: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3478, Test Linf Norm: 0.5833\n",
            "Epoch 128: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3531, Test Linf Norm: 0.5833\n",
            "Epoch 129: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3608, Test Linf Norm: 0.5834\n",
            "Epoch 130: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3421, Test Linf Norm: 0.5834\n",
            "Epoch 131: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3462, Test Linf Norm: 0.5833\n",
            "Epoch 132: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3557, Test Linf Norm: 0.5830\n",
            "Epoch 133: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3399, Test Linf Norm: 0.5832\n",
            "Epoch 134: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3413, Test Linf Norm: 0.5832\n",
            "Epoch 135: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3591, Test Linf Norm: 0.5833\n",
            "Epoch 136: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3447, Test Linf Norm: 0.5833\n",
            "Epoch 137: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3494, Test Linf Norm: 0.5833\n",
            "Epoch 138: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3513, Test Linf Norm: 0.5833\n",
            "Epoch 139: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3524, Test Linf Norm: 0.5833\n",
            "Epoch 140: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3432, Test Linf Norm: 0.5833\n",
            "Epoch 141: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3237, Test Linf Norm: 0.5833\n",
            "Epoch 142: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3169, Test Linf Norm: 0.5833\n",
            "Epoch 143: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3487, Test Linf Norm: 0.5833\n",
            "Epoch 144: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3386, Test Linf Norm: 0.5833\n",
            "Epoch 145: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3475, Test Linf Norm: 0.5833\n",
            "Epoch 146: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3407, Test Linf Norm: 0.5833\n",
            "Epoch 147: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3466, Test Linf Norm: 0.5833\n",
            "Epoch 148: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3633, Test Linf Norm: 0.5833\n",
            "Epoch 149: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3431, Test Linf Norm: 0.5833\n",
            "Epoch 150: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3499, Test Linf Norm: 0.5833\n",
            "Epoch 151: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3587, Test Linf Norm: 0.5833\n",
            "Epoch 152: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3533, Test Linf Norm: 0.5833\n",
            "Epoch 153: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3422, Test Linf Norm: 0.5833\n",
            "Epoch 154: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3444, Test Linf Norm: 0.5833\n",
            "Epoch 155: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3501, Test Linf Norm: 0.5833\n",
            "Epoch 156: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3495, Test Linf Norm: 0.5833\n",
            "Epoch 157: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3550, Test Linf Norm: 0.5833\n",
            "Epoch 158: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3275, Test Linf Norm: 0.5833\n",
            "Epoch 159: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3438, Test Linf Norm: 0.5833\n",
            "Epoch 160: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3512, Test Linf Norm: 0.5833\n",
            "Epoch 161: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3475, Test Linf Norm: 0.5833\n",
            "Epoch 162: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3459, Test Linf Norm: 0.5833\n",
            "Epoch 163: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3522, Test Linf Norm: 0.5833\n",
            "Epoch 164: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3387, Test Linf Norm: 0.5833\n",
            "Epoch 165: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3393, Test Linf Norm: 0.5833\n",
            "Epoch 166: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3338, Test Linf Norm: 0.5833\n",
            "Epoch 167: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3517, Test Linf Norm: 0.5833\n",
            "Epoch 168: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3462, Test Linf Norm: 0.5833\n",
            "Epoch 169: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3466, Test Linf Norm: 0.5833\n",
            "Epoch 170: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3572, Test Linf Norm: 0.5833\n",
            "Epoch 171: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3532, Test Linf Norm: 0.5833\n",
            "Epoch 172: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3441, Test Linf Norm: 0.5833\n",
            "Epoch 173: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3422, Test Linf Norm: 0.5833\n",
            "Epoch 174: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3356, Test Linf Norm: 0.5833\n",
            "Epoch 175: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3660, Test Linf Norm: 0.5833\n",
            "Epoch 176: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3547, Test Linf Norm: 0.5833\n",
            "Epoch 177: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3458, Test Linf Norm: 0.5833\n",
            "Epoch 178: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3296, Test Linf Norm: 0.5833\n",
            "Epoch 179: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3597, Test Linf Norm: 0.5833\n",
            "Epoch 180: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3247, Test Linf Norm: 0.5833\n",
            "Epoch 181: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3561, Test Linf Norm: 0.5833\n",
            "Epoch 182: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3495, Test Linf Norm: 0.5833\n",
            "Epoch 183: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3049, Test Linf Norm: 0.5833\n",
            "Epoch 184: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3558, Test Linf Norm: 0.5833\n",
            "Epoch 185: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3334, Test Linf Norm: 0.5833\n",
            "Epoch 186: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3509, Test Linf Norm: 0.5833\n",
            "Epoch 187: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3370, Test Linf Norm: 0.5833\n",
            "Epoch 188: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3608, Test Linf Norm: 0.5833\n",
            "Epoch 189: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3272, Test Linf Norm: 0.5833\n",
            "Epoch 190: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3499, Test Linf Norm: 0.5833\n",
            "Epoch 191: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3341, Test Linf Norm: 0.5833\n",
            "Epoch 192: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3617, Test Linf Norm: 0.5833\n",
            "Epoch 193: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3631, Test Linf Norm: 0.5833\n",
            "Epoch 194: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3204, Test Linf Norm: 0.5833\n",
            "Epoch 195: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3638, Test Linf Norm: 0.5833\n",
            "Epoch 196: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3490, Test Linf Norm: 0.5833\n",
            "Epoch 197: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3502, Test Linf Norm: 0.5833\n",
            "Epoch 198: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3410, Test Linf Norm: 0.5833\n",
            "Epoch 199: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3443, Test Linf Norm: 0.5833\n",
            "Epoch 200: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3495, Test Linf Norm: 0.5833\n",
            "Epoch 201: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3460, Test Linf Norm: 0.5833\n",
            "Epoch 202: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3431, Test Linf Norm: 0.5833\n",
            "Epoch 203: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3380, Test Linf Norm: 0.5833\n",
            "Epoch 204: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3435, Test Linf Norm: 0.5833\n",
            "Epoch 205: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3439, Test Linf Norm: 0.5833\n",
            "Epoch 206: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3478, Test Linf Norm: 0.5833\n",
            "Epoch 207: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3615, Test Linf Norm: 0.5833\n",
            "Epoch 208: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3632, Test Linf Norm: 0.5833\n",
            "Epoch 209: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3508, Test Linf Norm: 0.5833\n",
            "Epoch 210: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3471, Test Linf Norm: 0.5833\n",
            "Epoch 211: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3317, Test Linf Norm: 0.5833\n",
            "Epoch 212: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3222, Test Linf Norm: 0.5833\n",
            "Epoch 213: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3559, Test Linf Norm: 0.5833\n",
            "Epoch 214: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3552, Test Linf Norm: 0.5833\n",
            "Epoch 215: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3521, Test Linf Norm: 0.5833\n",
            "Epoch 216: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3505, Test Linf Norm: 0.5833\n",
            "Epoch 217: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3075, Test Linf Norm: 0.5833\n",
            "Epoch 218: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3447, Test Linf Norm: 0.5833\n",
            "Epoch 219: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3341, Test Linf Norm: 0.5833\n",
            "Epoch 220: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3543, Test Linf Norm: 0.5833\n",
            "Epoch 221: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3489, Test Linf Norm: 0.5833\n",
            "Epoch 222: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3421, Test Linf Norm: 0.5833\n",
            "Epoch 223: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3410, Test Linf Norm: 0.5833\n",
            "Epoch 224: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3666, Test Linf Norm: 0.5833\n",
            "Epoch 225: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3406, Test Linf Norm: 0.5833\n",
            "Epoch 226: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3461, Test Linf Norm: 0.5833\n",
            "Epoch 227: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3485, Test Linf Norm: 0.5833\n",
            "Epoch 228: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3465, Test Linf Norm: 0.5833\n",
            "Epoch 229: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3256, Test Linf Norm: 0.5833\n",
            "Epoch 230: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3430, Test Linf Norm: 0.5833\n",
            "Epoch 231: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3399, Test Linf Norm: 0.5833\n",
            "Epoch 232: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3340, Test Linf Norm: 0.5833\n",
            "Epoch 233: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3483, Test Linf Norm: 0.5833\n",
            "Epoch 234: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3328, Test Linf Norm: 0.5833\n",
            "Epoch 235: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3465, Test Linf Norm: 0.5833\n",
            "Epoch 236: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3397, Test Linf Norm: 0.5833\n",
            "Epoch 237: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3307, Test Linf Norm: 0.5833\n",
            "Epoch 238: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3519, Test Linf Norm: 0.5833\n",
            "Epoch 239: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3546, Test Linf Norm: 0.5833\n",
            "Epoch 240: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3328, Test Linf Norm: 0.5833\n",
            "Epoch 241: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3565, Test Linf Norm: 0.5833\n",
            "Epoch 242: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3439, Test Linf Norm: 0.5833\n",
            "Epoch 243: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3430, Test Linf Norm: 0.5833\n",
            "Epoch 244: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3542, Test Linf Norm: 0.5833\n",
            "Epoch 245: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3463, Test Linf Norm: 0.5833\n",
            "Epoch 246: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3501, Test Linf Norm: 0.5833\n",
            "Epoch 247: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3045, Test Linf Norm: 0.5833\n",
            "Epoch 248: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3446, Test Linf Norm: 0.5833\n",
            "Epoch 249: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3496, Test Linf Norm: 0.5833\n",
            "Epoch 250: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3481, Test Linf Norm: 0.5833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:10:03,233]\u001b[0m Trial 20 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 251: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0455, Test L1 Norm: 0.0152, Train Linf Norm: 4.3466, Test Linf Norm: 0.5833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:10:04,170]\u001b[0m Trial 21 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.9771, Test Loss: 0.5597, Train L1 Norm: 0.7595, Test L1 Norm: 0.3089, Train Linf Norm: 193.0876, Test Linf Norm: 24.1362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-82e2252adf92>:150: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  t_max_fraction = trial.suggest_uniform('t_max_fraction', 0.1, 0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.0065, Test Loss: 0.4911, Train L1 Norm: 0.9475, Test L1 Norm: 0.1945, Train Linf Norm: 351.9762, Test Linf Norm: 8.7973\n",
            "Epoch 2: Train Loss: 0.4030, Test Loss: 0.2569, Train L1 Norm: 0.3177, Test L1 Norm: 0.1933, Train Linf Norm: 111.2717, Test Linf Norm: 22.7953\n",
            "Epoch 3: Train Loss: 0.2950, Test Loss: 0.3077, Train L1 Norm: 0.2466, Test L1 Norm: 0.1194, Train Linf Norm: 87.9834, Test Linf Norm: 1.9802\n",
            "Epoch 4: Train Loss: 0.2375, Test Loss: 0.1583, Train L1 Norm: 0.2033, Test L1 Norm: 0.1364, Train Linf Norm: 78.3317, Test Linf Norm: 17.2682\n",
            "Epoch 5: Train Loss: 0.1959, Test Loss: 0.2199, Train L1 Norm: 0.1829, Test L1 Norm: 0.0826, Train Linf Norm: 71.2510, Test Linf Norm: 1.3885\n",
            "Epoch 6: Train Loss: 0.1686, Test Loss: 0.1618, Train L1 Norm: 0.1340, Test L1 Norm: 0.1160, Train Linf Norm: 47.7716, Test Linf Norm: 13.8015\n",
            "Epoch 7: Train Loss: 0.1449, Test Loss: 0.1615, Train L1 Norm: 0.1043, Test L1 Norm: 0.0661, Train Linf Norm: 24.2699, Test Linf Norm: 1.0024\n",
            "Epoch 8: Train Loss: 0.1267, Test Loss: 0.1134, Train L1 Norm: 0.1005, Test L1 Norm: 0.0751, Train Linf Norm: 32.8867, Test Linf Norm: 8.0896\n",
            "Epoch 9: Train Loss: 0.1085, Test Loss: 0.1468, Train L1 Norm: 0.0887, Test L1 Norm: 0.0638, Train Linf Norm: 30.3830, Test Linf Norm: 1.0000\n",
            "Epoch 10: Train Loss: 0.0932, Test Loss: 0.0729, Train L1 Norm: 0.0872, Test L1 Norm: 0.0506, Train Linf Norm: 36.5695, Test Linf Norm: 5.4896\n",
            "Epoch 11: Train Loss: 0.0802, Test Loss: 0.0896, Train L1 Norm: 0.0798, Test L1 Norm: 0.0405, Train Linf Norm: 36.0016, Test Linf Norm: 1.0000\n",
            "Epoch 12: Train Loss: 0.0671, Test Loss: 0.0676, Train L1 Norm: 0.0669, Test L1 Norm: 0.0469, Train Linf Norm: 29.5940, Test Linf Norm: 4.6016\n",
            "Epoch 13: Train Loss: 0.0576, Test Loss: 0.0422, Train L1 Norm: 0.0524, Test L1 Norm: 0.0253, Train Linf Norm: 19.5637, Test Linf Norm: 1.0664\n",
            "Epoch 14: Train Loss: 0.0474, Test Loss: 0.0465, Train L1 Norm: 0.0556, Test L1 Norm: 0.0330, Train Linf Norm: 27.8037, Test Linf Norm: 3.4946\n",
            "Epoch 15: Train Loss: 0.0371, Test Loss: 0.0468, Train L1 Norm: 0.0600, Test L1 Norm: 0.0259, Train Linf Norm: 36.9687, Test Linf Norm: 1.0544\n",
            "Epoch 16: Train Loss: 0.0303, Test Loss: 0.0384, Train L1 Norm: 0.0442, Test L1 Norm: 0.0240, Train Linf Norm: 23.8336, Test Linf Norm: 1.0000\n",
            "Epoch 17: Train Loss: 0.0279, Test Loss: 0.0268, Train L1 Norm: 0.0429, Test L1 Norm: 0.0201, Train Linf Norm: 23.3675, Test Linf Norm: 1.2311\n",
            "Epoch 18: Train Loss: 0.0259, Test Loss: 0.0253, Train L1 Norm: 0.0414, Test L1 Norm: 0.0198, Train Linf Norm: 22.7902, Test Linf Norm: 1.3712\n",
            "Epoch 19: Train Loss: 0.0250, Test Loss: 0.0257, Train L1 Norm: 0.0392, Test L1 Norm: 0.0196, Train Linf Norm: 20.7258, Test Linf Norm: 1.4068\n",
            "Epoch 20: Train Loss: 0.0244, Test Loss: 0.0243, Train L1 Norm: 0.0388, Test L1 Norm: 0.0192, Train Linf Norm: 20.5833, Test Linf Norm: 1.3565\n",
            "Epoch 21: Train Loss: 0.0241, Test Loss: 0.0241, Train L1 Norm: 0.0390, Test L1 Norm: 0.0191, Train Linf Norm: 21.5065, Test Linf Norm: 1.3606\n",
            "Epoch 22: Train Loss: 0.0239, Test Loss: 0.0239, Train L1 Norm: 0.0387, Test L1 Norm: 0.0190, Train Linf Norm: 21.0642, Test Linf Norm: 1.3612\n",
            "Epoch 23: Train Loss: 0.0238, Test Loss: 0.0239, Train L1 Norm: 0.0384, Test L1 Norm: 0.0190, Train Linf Norm: 20.8183, Test Linf Norm: 1.3690\n",
            "Epoch 24: Train Loss: 0.0238, Test Loss: 0.0239, Train L1 Norm: 0.0384, Test L1 Norm: 0.0190, Train Linf Norm: 21.0755, Test Linf Norm: 1.3753\n",
            "Epoch 25: Train Loss: 0.0238, Test Loss: 0.0239, Train L1 Norm: 0.0386, Test L1 Norm: 0.0190, Train Linf Norm: 20.9794, Test Linf Norm: 1.3809\n",
            "Epoch 26: Train Loss: 0.0237, Test Loss: 0.0237, Train L1 Norm: 0.0386, Test L1 Norm: 0.0190, Train Linf Norm: 21.0265, Test Linf Norm: 1.3819\n",
            "Epoch 27: Train Loss: 0.0236, Test Loss: 0.0238, Train L1 Norm: 0.0387, Test L1 Norm: 0.0189, Train Linf Norm: 21.1321, Test Linf Norm: 1.3541\n",
            "Epoch 28: Train Loss: 0.0234, Test Loss: 0.0232, Train L1 Norm: 0.0385, Test L1 Norm: 0.0187, Train Linf Norm: 20.7329, Test Linf Norm: 1.4420\n",
            "Epoch 29: Train Loss: 0.0231, Test Loss: 0.0228, Train L1 Norm: 0.0375, Test L1 Norm: 0.0185, Train Linf Norm: 20.0190, Test Linf Norm: 1.3306\n",
            "Epoch 30: Train Loss: 0.0229, Test Loss: 0.0230, Train L1 Norm: 0.0379, Test L1 Norm: 0.0181, Train Linf Norm: 20.6712, Test Linf Norm: 1.4121\n",
            "Epoch 31: Train Loss: 0.0278, Test Loss: 0.0289, Train L1 Norm: 0.0390, Test L1 Norm: 0.0211, Train Linf Norm: 19.5790, Test Linf Norm: 1.6951\n",
            "Epoch 32: Train Loss: 0.0367, Test Loss: 0.0367, Train L1 Norm: 0.0432, Test L1 Norm: 0.0228, Train Linf Norm: 20.1311, Test Linf Norm: 1.0537\n",
            "Epoch 33: Train Loss: 0.0440, Test Loss: 0.0426, Train L1 Norm: 0.0513, Test L1 Norm: 0.0274, Train Linf Norm: 25.6858, Test Linf Norm: 2.2784\n",
            "Epoch 34: Train Loss: 0.0508, Test Loss: 0.0619, Train L1 Norm: 0.0442, Test L1 Norm: 0.0321, Train Linf Norm: 14.8985, Test Linf Norm: 1.0000\n",
            "Epoch 35: Train Loss: 0.0566, Test Loss: 0.0441, Train L1 Norm: 0.0563, Test L1 Norm: 0.0294, Train Linf Norm: 24.0085, Test Linf Norm: 2.8410\n",
            "Epoch 36: Train Loss: 0.0610, Test Loss: 0.0508, Train L1 Norm: 0.0494, Test L1 Norm: 0.0322, Train Linf Norm: 14.4728, Test Linf Norm: 1.0000\n",
            "Epoch 37: Train Loss: 0.0658, Test Loss: 0.0523, Train L1 Norm: 0.0562, Test L1 Norm: 0.0358, Train Linf Norm: 20.2491, Test Linf Norm: 3.7274\n",
            "Epoch 38: Train Loss: 0.0694, Test Loss: 0.0848, Train L1 Norm: 0.0523, Test L1 Norm: 0.0373, Train Linf Norm: 13.8457, Test Linf Norm: 1.0000\n",
            "Epoch 39: Train Loss: 0.0726, Test Loss: 0.0803, Train L1 Norm: 0.0648, Test L1 Norm: 0.0489, Train Linf Norm: 25.4940, Test Linf Norm: 4.8191\n",
            "Epoch 40: Train Loss: 0.0758, Test Loss: 0.0779, Train L1 Norm: 0.0691, Test L1 Norm: 0.0386, Train Linf Norm: 28.0736, Test Linf Norm: 1.0000\n",
            "Epoch 41: Train Loss: 0.0766, Test Loss: 0.0632, Train L1 Norm: 0.0718, Test L1 Norm: 0.0451, Train Linf Norm: 29.3913, Test Linf Norm: 5.4194\n",
            "Epoch 42: Train Loss: 0.0778, Test Loss: 0.0762, Train L1 Norm: 0.0708, Test L1 Norm: 0.0378, Train Linf Norm: 28.7849, Test Linf Norm: 1.0000\n",
            "Epoch 43: Train Loss: 0.0789, Test Loss: 0.0700, Train L1 Norm: 0.0674, Test L1 Norm: 0.0455, Train Linf Norm: 25.1229, Test Linf Norm: 4.4709\n",
            "Epoch 44: Train Loss: 0.0791, Test Loss: 0.0803, Train L1 Norm: 0.0708, Test L1 Norm: 0.0396, Train Linf Norm: 27.9640, Test Linf Norm: 1.0000\n",
            "Epoch 45: Train Loss: 0.0783, Test Loss: 0.0558, Train L1 Norm: 0.0673, Test L1 Norm: 0.0404, Train Linf Norm: 24.4190, Test Linf Norm: 4.9810\n",
            "Epoch 46: Train Loss: 0.0775, Test Loss: 0.0883, Train L1 Norm: 0.0543, Test L1 Norm: 0.0403, Train Linf Norm: 12.0354, Test Linf Norm: 1.0000\n",
            "Epoch 47: Train Loss: 0.0762, Test Loss: 0.0760, Train L1 Norm: 0.0513, Test L1 Norm: 0.0542, Train Linf Norm: 8.6047, Test Linf Norm: 6.6958\n",
            "Epoch 48: Train Loss: 0.0730, Test Loss: 0.0795, Train L1 Norm: 0.0643, Test L1 Norm: 0.0371, Train Linf Norm: 25.3069, Test Linf Norm: 1.0000\n",
            "Epoch 49: Train Loss: 0.0710, Test Loss: 0.0518, Train L1 Norm: 0.0604, Test L1 Norm: 0.0374, Train Linf Norm: 22.6139, Test Linf Norm: 4.0926\n",
            "Epoch 50: Train Loss: 0.0679, Test Loss: 0.0757, Train L1 Norm: 0.0589, Test L1 Norm: 0.0352, Train Linf Norm: 22.0183, Test Linf Norm: 1.0000\n",
            "Epoch 51: Train Loss: 0.0638, Test Loss: 0.0538, Train L1 Norm: 0.0459, Test L1 Norm: 0.0335, Train Linf Norm: 11.0632, Test Linf Norm: 3.4864\n",
            "Epoch 52: Train Loss: 0.0601, Test Loss: 0.0721, Train L1 Norm: 0.0493, Test L1 Norm: 0.0328, Train Linf Norm: 17.0566, Test Linf Norm: 1.0000\n",
            "Epoch 53: Train Loss: 0.0549, Test Loss: 0.0453, Train L1 Norm: 0.0483, Test L1 Norm: 0.0321, Train Linf Norm: 18.1755, Test Linf Norm: 4.2821\n",
            "Epoch 54: Train Loss: 0.0509, Test Loss: 0.0559, Train L1 Norm: 0.0517, Test L1 Norm: 0.0315, Train Linf Norm: 23.6375, Test Linf Norm: 1.0000\n",
            "Epoch 55: Train Loss: 0.0458, Test Loss: 0.0461, Train L1 Norm: 0.0394, Test L1 Norm: 0.0275, Train Linf Norm: 13.6190, Test Linf Norm: 3.2381\n",
            "Epoch 56: Train Loss: 0.0409, Test Loss: 0.0438, Train L1 Norm: 0.0438, Test L1 Norm: 0.0228, Train Linf Norm: 21.0029, Test Linf Norm: 1.2269\n",
            "Epoch 57: Train Loss: 0.0357, Test Loss: 0.0277, Train L1 Norm: 0.0354, Test L1 Norm: 0.0209, Train Linf Norm: 14.3623, Test Linf Norm: 2.3354\n",
            "Epoch 58: Train Loss: 0.0299, Test Loss: 0.0319, Train L1 Norm: 0.0349, Test L1 Norm: 0.0193, Train Linf Norm: 16.5991, Test Linf Norm: 1.2385\n",
            "Epoch 59: Train Loss: 0.0261, Test Loss: 0.0265, Train L1 Norm: 0.0294, Test L1 Norm: 0.0193, Train Linf Norm: 12.6355, Test Linf Norm: 2.3160\n",
            "Epoch 60: Train Loss: 0.0211, Test Loss: 0.0208, Train L1 Norm: 0.0296, Test L1 Norm: 0.0159, Train Linf Norm: 14.5757, Test Linf Norm: 1.6751\n",
            "Epoch 61: Train Loss: 0.0197, Test Loss: 0.0196, Train L1 Norm: 0.0290, Test L1 Norm: 0.0155, Train Linf Norm: 14.2293, Test Linf Norm: 1.4065\n",
            "Epoch 62: Train Loss: 0.0189, Test Loss: 0.0188, Train L1 Norm: 0.0280, Test L1 Norm: 0.0151, Train Linf Norm: 13.9655, Test Linf Norm: 1.2969\n",
            "Epoch 63: Train Loss: 0.0184, Test Loss: 0.0184, Train L1 Norm: 0.0280, Test L1 Norm: 0.0150, Train Linf Norm: 14.2536, Test Linf Norm: 1.3286\n",
            "Epoch 64: Train Loss: 0.0181, Test Loss: 0.0182, Train L1 Norm: 0.0275, Test L1 Norm: 0.0149, Train Linf Norm: 13.2617, Test Linf Norm: 1.3328\n",
            "Epoch 65: Train Loss: 0.0179, Test Loss: 0.0182, Train L1 Norm: 0.0277, Test L1 Norm: 0.0149, Train Linf Norm: 14.0797, Test Linf Norm: 1.3527\n",
            "Epoch 66: Train Loss: 0.0178, Test Loss: 0.0180, Train L1 Norm: 0.0275, Test L1 Norm: 0.0148, Train Linf Norm: 13.7372, Test Linf Norm: 1.3208\n",
            "Epoch 67: Train Loss: 0.0177, Test Loss: 0.0179, Train L1 Norm: 0.0273, Test L1 Norm: 0.0148, Train Linf Norm: 13.7704, Test Linf Norm: 1.3168\n",
            "Epoch 68: Train Loss: 0.0176, Test Loss: 0.0179, Train L1 Norm: 0.0273, Test L1 Norm: 0.0147, Train Linf Norm: 13.0098, Test Linf Norm: 1.3233\n",
            "Epoch 69: Train Loss: 0.0176, Test Loss: 0.0179, Train L1 Norm: 0.0273, Test L1 Norm: 0.0147, Train Linf Norm: 13.2640, Test Linf Norm: 1.3324\n",
            "Epoch 70: Train Loss: 0.0176, Test Loss: 0.0179, Train L1 Norm: 0.0273, Test L1 Norm: 0.0147, Train Linf Norm: 13.2202, Test Linf Norm: 1.3332\n",
            "Epoch 71: Train Loss: 0.0176, Test Loss: 0.0178, Train L1 Norm: 0.0273, Test L1 Norm: 0.0147, Train Linf Norm: 13.8797, Test Linf Norm: 1.3346\n",
            "Epoch 72: Train Loss: 0.0176, Test Loss: 0.0179, Train L1 Norm: 0.0273, Test L1 Norm: 0.0147, Train Linf Norm: 13.9258, Test Linf Norm: 1.3266\n",
            "Epoch 73: Train Loss: 0.0175, Test Loss: 0.0178, Train L1 Norm: 0.0274, Test L1 Norm: 0.0147, Train Linf Norm: 13.8983, Test Linf Norm: 1.3159\n",
            "Epoch 74: Train Loss: 0.0175, Test Loss: 0.0177, Train L1 Norm: 0.0273, Test L1 Norm: 0.0147, Train Linf Norm: 13.7198, Test Linf Norm: 1.3255\n",
            "Epoch 75: Train Loss: 0.0174, Test Loss: 0.0177, Train L1 Norm: 0.0270, Test L1 Norm: 0.0147, Train Linf Norm: 13.0291, Test Linf Norm: 1.3520\n",
            "Epoch 76: Train Loss: 0.0173, Test Loss: 0.0177, Train L1 Norm: 0.0269, Test L1 Norm: 0.0146, Train Linf Norm: 13.3876, Test Linf Norm: 1.3033\n",
            "Epoch 77: Train Loss: 0.0172, Test Loss: 0.0199, Train L1 Norm: 0.0272, Test L1 Norm: 0.0154, Train Linf Norm: 13.9272, Test Linf Norm: 1.2202\n",
            "Epoch 78: Train Loss: 0.0171, Test Loss: 0.0176, Train L1 Norm: 0.0273, Test L1 Norm: 0.0145, Train Linf Norm: 14.0613, Test Linf Norm: 1.3123\n",
            "Epoch 79: Train Loss: 0.0210, Test Loss: 0.0236, Train L1 Norm: 0.0291, Test L1 Norm: 0.0165, Train Linf Norm: 14.5239, Test Linf Norm: 1.1585\n",
            "Epoch 80: Train Loss: 0.0262, Test Loss: 0.0230, Train L1 Norm: 0.0276, Test L1 Norm: 0.0170, Train Linf Norm: 10.2863, Test Linf Norm: 1.6754\n",
            "Epoch 81: Train Loss: 0.0313, Test Loss: 0.0286, Train L1 Norm: 0.0399, Test L1 Norm: 0.0177, Train Linf Norm: 18.4692, Test Linf Norm: 1.1277\n",
            "Epoch 82: Train Loss: 0.0361, Test Loss: 0.0341, Train L1 Norm: 0.0393, Test L1 Norm: 0.0224, Train Linf Norm: 18.0128, Test Linf Norm: 2.5915\n",
            "Epoch 83: Train Loss: 0.0399, Test Loss: 0.0367, Train L1 Norm: 0.0323, Test L1 Norm: 0.0220, Train Linf Norm: 9.2437, Test Linf Norm: 1.0506\n",
            "Epoch 84: Train Loss: 0.0437, Test Loss: 0.0318, Train L1 Norm: 0.0413, Test L1 Norm: 0.0229, Train Linf Norm: 16.2775, Test Linf Norm: 2.4591\n",
            "Epoch 85: Train Loss: 0.0470, Test Loss: 0.0503, Train L1 Norm: 0.0442, Test L1 Norm: 0.0257, Train Linf Norm: 17.8544, Test Linf Norm: 1.0717\n",
            "Epoch 86: Train Loss: 0.0494, Test Loss: 0.0444, Train L1 Norm: 0.0493, Test L1 Norm: 0.0289, Train Linf Norm: 21.9422, Test Linf Norm: 2.9708\n",
            "Epoch 87: Train Loss: 0.0515, Test Loss: 0.0435, Train L1 Norm: 0.0406, Test L1 Norm: 0.0274, Train Linf Norm: 11.2180, Test Linf Norm: 1.0000\n",
            "Epoch 88: Train Loss: 0.0532, Test Loss: 0.0405, Train L1 Norm: 0.0392, Test L1 Norm: 0.0303, Train Linf Norm: 8.9749, Test Linf Norm: 3.8735\n",
            "Epoch 89: Train Loss: 0.0543, Test Loss: 0.0601, Train L1 Norm: 0.0385, Test L1 Norm: 0.0296, Train Linf Norm: 8.2298, Test Linf Norm: 1.0542\n",
            "Epoch 90: Train Loss: 0.0556, Test Loss: 0.0590, Train L1 Norm: 0.0390, Test L1 Norm: 0.0322, Train Linf Norm: 7.9855, Test Linf Norm: 2.6406\n",
            "Epoch 91: Train Loss: 0.0561, Test Loss: 0.0568, Train L1 Norm: 0.0401, Test L1 Norm: 0.0289, Train Linf Norm: 9.1524, Test Linf Norm: 1.0050\n",
            "Epoch 92: Train Loss: 0.0554, Test Loss: 0.0542, Train L1 Norm: 0.0373, Test L1 Norm: 0.0327, Train Linf Norm: 6.9209, Test Linf Norm: 3.4260\n",
            "Epoch 93: Train Loss: 0.0546, Test Loss: 0.0554, Train L1 Norm: 0.0496, Test L1 Norm: 0.0291, Train Linf Norm: 19.8292, Test Linf Norm: 1.0000\n",
            "Epoch 94: Train Loss: 0.0536, Test Loss: 0.0425, Train L1 Norm: 0.0456, Test L1 Norm: 0.0310, Train Linf Norm: 16.1410, Test Linf Norm: 4.2013\n",
            "Epoch 95: Train Loss: 0.0515, Test Loss: 0.0587, Train L1 Norm: 0.0441, Test L1 Norm: 0.0319, Train Linf Norm: 15.8788, Test Linf Norm: 1.0000\n",
            "Epoch 96: Train Loss: 0.0501, Test Loss: 0.0460, Train L1 Norm: 0.0347, Test L1 Norm: 0.0306, Train Linf Norm: 6.4603, Test Linf Norm: 3.3392\n",
            "Epoch 97: Train Loss: 0.0474, Test Loss: 0.0533, Train L1 Norm: 0.0336, Test L1 Norm: 0.0282, Train Linf Norm: 7.3715, Test Linf Norm: 1.0000\n",
            "Epoch 98: Train Loss: 0.0446, Test Loss: 0.0354, Train L1 Norm: 0.0393, Test L1 Norm: 0.0227, Train Linf Norm: 14.3464, Test Linf Norm: 2.2285\n",
            "Epoch 99: Train Loss: 0.0420, Test Loss: 0.0438, Train L1 Norm: 0.0290, Test L1 Norm: 0.0227, Train Linf Norm: 5.0253, Test Linf Norm: 1.1816\n",
            "Epoch 100: Train Loss: 0.0379, Test Loss: 0.0393, Train L1 Norm: 0.0282, Test L1 Norm: 0.0234, Train Linf Norm: 6.4952, Test Linf Norm: 2.3876\n",
            "Epoch 101: Train Loss: 0.0346, Test Loss: 0.0322, Train L1 Norm: 0.0285, Test L1 Norm: 0.0186, Train Linf Norm: 7.9392, Test Linf Norm: 1.1952\n",
            "Epoch 102: Train Loss: 0.0308, Test Loss: 0.0249, Train L1 Norm: 0.0327, Test L1 Norm: 0.0171, Train Linf Norm: 14.0223, Test Linf Norm: 1.9170\n",
            "Epoch 103: Train Loss: 0.0266, Test Loss: 0.0274, Train L1 Norm: 0.0260, Test L1 Norm: 0.0179, Train Linf Norm: 9.5868, Test Linf Norm: 1.2095\n",
            "Epoch 104: Train Loss: 0.0232, Test Loss: 0.0229, Train L1 Norm: 0.0251, Test L1 Norm: 0.0165, Train Linf Norm: 10.3420, Test Linf Norm: 1.9738\n",
            "Epoch 105: Train Loss: 0.0183, Test Loss: 0.0187, Train L1 Norm: 0.0230, Test L1 Norm: 0.0143, Train Linf Norm: 9.7399, Test Linf Norm: 1.5068\n",
            "Epoch 106: Train Loss: 0.0166, Test Loss: 0.0186, Train L1 Norm: 0.0232, Test L1 Norm: 0.0141, Train Linf Norm: 9.9630, Test Linf Norm: 1.4101\n",
            "Epoch 107: Train Loss: 0.0160, Test Loss: 0.0172, Train L1 Norm: 0.0223, Test L1 Norm: 0.0135, Train Linf Norm: 10.1251, Test Linf Norm: 1.2564\n",
            "Epoch 108: Train Loss: 0.0157, Test Loss: 0.0159, Train L1 Norm: 0.0216, Test L1 Norm: 0.0131, Train Linf Norm: 9.5789, Test Linf Norm: 1.2303\n",
            "Epoch 109: Train Loss: 0.0154, Test Loss: 0.0159, Train L1 Norm: 0.0221, Test L1 Norm: 0.0131, Train Linf Norm: 10.1976, Test Linf Norm: 1.2588\n",
            "Epoch 110: Train Loss: 0.0152, Test Loss: 0.0155, Train L1 Norm: 0.0214, Test L1 Norm: 0.0130, Train Linf Norm: 9.5164, Test Linf Norm: 1.2277\n",
            "Epoch 111: Train Loss: 0.0151, Test Loss: 0.0154, Train L1 Norm: 0.0218, Test L1 Norm: 0.0129, Train Linf Norm: 10.1003, Test Linf Norm: 1.2381\n",
            "Epoch 112: Train Loss: 0.0150, Test Loss: 0.0153, Train L1 Norm: 0.0215, Test L1 Norm: 0.0129, Train Linf Norm: 9.8520, Test Linf Norm: 1.2149\n",
            "Epoch 113: Train Loss: 0.0150, Test Loss: 0.0153, Train L1 Norm: 0.0215, Test L1 Norm: 0.0129, Train Linf Norm: 9.3837, Test Linf Norm: 1.2181\n",
            "Epoch 114: Train Loss: 0.0149, Test Loss: 0.0153, Train L1 Norm: 0.0214, Test L1 Norm: 0.0129, Train Linf Norm: 9.6518, Test Linf Norm: 1.2327\n",
            "Epoch 115: Train Loss: 0.0149, Test Loss: 0.0153, Train L1 Norm: 0.0215, Test L1 Norm: 0.0129, Train Linf Norm: 9.7727, Test Linf Norm: 1.2348\n",
            "Epoch 116: Train Loss: 0.0149, Test Loss: 0.0153, Train L1 Norm: 0.0215, Test L1 Norm: 0.0129, Train Linf Norm: 9.7952, Test Linf Norm: 1.2350\n",
            "Epoch 117: Train Loss: 0.0149, Test Loss: 0.0153, Train L1 Norm: 0.0215, Test L1 Norm: 0.0129, Train Linf Norm: 9.8181, Test Linf Norm: 1.2353\n",
            "Epoch 118: Train Loss: 0.0149, Test Loss: 0.0153, Train L1 Norm: 0.0214, Test L1 Norm: 0.0129, Train Linf Norm: 9.8489, Test Linf Norm: 1.2336\n",
            "Epoch 119: Train Loss: 0.0149, Test Loss: 0.0152, Train L1 Norm: 0.0215, Test L1 Norm: 0.0129, Train Linf Norm: 9.8354, Test Linf Norm: 1.2257\n",
            "Epoch 120: Train Loss: 0.0149, Test Loss: 0.0152, Train L1 Norm: 0.0215, Test L1 Norm: 0.0128, Train Linf Norm: 9.8695, Test Linf Norm: 1.2581\n",
            "Epoch 121: Train Loss: 0.0148, Test Loss: 0.0152, Train L1 Norm: 0.0215, Test L1 Norm: 0.0129, Train Linf Norm: 9.9469, Test Linf Norm: 1.2697\n",
            "Epoch 122: Train Loss: 0.0148, Test Loss: 0.0151, Train L1 Norm: 0.0213, Test L1 Norm: 0.0128, Train Linf Norm: 8.6299, Test Linf Norm: 1.2126\n",
            "Epoch 123: Train Loss: 0.0147, Test Loss: 0.0154, Train L1 Norm: 0.0216, Test L1 Norm: 0.0129, Train Linf Norm: 10.1890, Test Linf Norm: 1.3164\n",
            "Epoch 124: Train Loss: 0.0146, Test Loss: 0.0149, Train L1 Norm: 0.0212, Test L1 Norm: 0.0127, Train Linf Norm: 9.6282, Test Linf Norm: 1.2199\n",
            "Epoch 125: Train Loss: 0.0151, Test Loss: 0.0154, Train L1 Norm: 0.0205, Test L1 Norm: 0.0129, Train Linf Norm: 8.8131, Test Linf Norm: 1.1592\n",
            "Epoch 126: Train Loss: 0.0183, Test Loss: 0.0176, Train L1 Norm: 0.0215, Test L1 Norm: 0.0139, Train Linf Norm: 8.7287, Test Linf Norm: 1.1556\n",
            "Epoch 127: Train Loss: 0.0234, Test Loss: 0.0244, Train L1 Norm: 0.0277, Test L1 Norm: 0.0160, Train Linf Norm: 12.8546, Test Linf Norm: 1.5882\n",
            "Epoch 128: Train Loss: 0.0272, Test Loss: 0.0234, Train L1 Norm: 0.0273, Test L1 Norm: 0.0162, Train Linf Norm: 10.6704, Test Linf Norm: 1.0806\n",
            "Epoch 129: Train Loss: 0.0309, Test Loss: 0.0337, Train L1 Norm: 0.0298, Test L1 Norm: 0.0224, Train Linf Norm: 11.5828, Test Linf Norm: 2.4298\n",
            "Epoch 130: Train Loss: 0.0336, Test Loss: 0.0335, Train L1 Norm: 0.0326, Test L1 Norm: 0.0207, Train Linf Norm: 13.1041, Test Linf Norm: 1.0337\n",
            "Epoch 131: Train Loss: 0.0373, Test Loss: 0.0276, Train L1 Norm: 0.0343, Test L1 Norm: 0.0191, Train Linf Norm: 12.6304, Test Linf Norm: 2.1133\n",
            "Epoch 132: Train Loss: 0.0393, Test Loss: 0.0373, Train L1 Norm: 0.0379, Test L1 Norm: 0.0238, Train Linf Norm: 15.2585, Test Linf Norm: 1.0000\n",
            "Epoch 133: Train Loss: 0.0413, Test Loss: 0.0339, Train L1 Norm: 0.0365, Test L1 Norm: 0.0224, Train Linf Norm: 12.4644, Test Linf Norm: 2.4798\n",
            "Epoch 134: Train Loss: 0.0429, Test Loss: 0.0556, Train L1 Norm: 0.0289, Test L1 Norm: 0.0271, Train Linf Norm: 4.6529, Test Linf Norm: 1.0471\n",
            "Epoch 135: Train Loss: 0.0447, Test Loss: 0.0354, Train L1 Norm: 0.0375, Test L1 Norm: 0.0227, Train Linf Norm: 12.1106, Test Linf Norm: 2.3111\n",
            "Epoch 136: Train Loss: 0.0453, Test Loss: 0.0601, Train L1 Norm: 0.0381, Test L1 Norm: 0.0301, Train Linf Norm: 12.5200, Test Linf Norm: 1.0000\n",
            "Epoch 137: Train Loss: 0.0460, Test Loss: 0.0360, Train L1 Norm: 0.0347, Test L1 Norm: 0.0228, Train Linf Norm: 8.3878, Test Linf Norm: 3.1542\n",
            "Epoch 138: Train Loss: 0.0459, Test Loss: 0.0476, Train L1 Norm: 0.0328, Test L1 Norm: 0.0252, Train Linf Norm: 5.2817, Test Linf Norm: 1.0345\n",
            "Epoch 139: Train Loss: 0.0453, Test Loss: 0.0397, Train L1 Norm: 0.0315, Test L1 Norm: 0.0233, Train Linf Norm: 6.1614, Test Linf Norm: 2.2405\n",
            "Epoch 140: Train Loss: 0.0447, Test Loss: 0.0384, Train L1 Norm: 0.0406, Test L1 Norm: 0.0200, Train Linf Norm: 15.6206, Test Linf Norm: 1.1945\n",
            "Epoch 141: Train Loss: 0.0438, Test Loss: 0.0334, Train L1 Norm: 0.0401, Test L1 Norm: 0.0210, Train Linf Norm: 15.8647, Test Linf Norm: 2.2027\n",
            "Epoch 142: Train Loss: 0.0413, Test Loss: 0.0420, Train L1 Norm: 0.0408, Test L1 Norm: 0.0216, Train Linf Norm: 17.7875, Test Linf Norm: 1.0747\n",
            "Epoch 143: Train Loss: 0.0399, Test Loss: 0.0341, Train L1 Norm: 0.0284, Test L1 Norm: 0.0246, Train Linf Norm: 5.4285, Test Linf Norm: 3.4336\n",
            "Epoch 144: Train Loss: 0.0377, Test Loss: 0.0384, Train L1 Norm: 0.0329, Test L1 Norm: 0.0231, Train Linf Norm: 11.7319, Test Linf Norm: 1.0596\n",
            "Epoch 145: Train Loss: 0.0355, Test Loss: 0.0345, Train L1 Norm: 0.0242, Test L1 Norm: 0.0207, Train Linf Norm: 4.3589, Test Linf Norm: 2.1626\n",
            "Epoch 146: Train Loss: 0.0323, Test Loss: 0.0365, Train L1 Norm: 0.0289, Test L1 Norm: 0.0213, Train Linf Norm: 10.1223, Test Linf Norm: 1.1219\n",
            "Epoch 147: Train Loss: 0.0294, Test Loss: 0.0277, Train L1 Norm: 0.0282, Test L1 Norm: 0.0173, Train Linf Norm: 10.8848, Test Linf Norm: 2.1774\n",
            "Epoch 148: Train Loss: 0.0259, Test Loss: 0.0286, Train L1 Norm: 0.0252, Test L1 Norm: 0.0174, Train Linf Norm: 9.5952, Test Linf Norm: 1.1648\n",
            "Epoch 149: Train Loss: 0.0227, Test Loss: 0.0269, Train L1 Norm: 0.0241, Test L1 Norm: 0.0165, Train Linf Norm: 10.1447, Test Linf Norm: 1.9660\n",
            "Epoch 150: Train Loss: 0.0195, Test Loss: 0.0223, Train L1 Norm: 0.0221, Test L1 Norm: 0.0147, Train Linf Norm: 9.3365, Test Linf Norm: 1.2413\n",
            "Epoch 151: Train Loss: 0.0159, Test Loss: 0.0151, Train L1 Norm: 0.0197, Test L1 Norm: 0.0124, Train Linf Norm: 8.3654, Test Linf Norm: 1.3824\n",
            "Epoch 152: Train Loss: 0.0145, Test Loss: 0.0148, Train L1 Norm: 0.0190, Test L1 Norm: 0.0124, Train Linf Norm: 8.1878, Test Linf Norm: 1.1700\n",
            "Epoch 153: Train Loss: 0.0141, Test Loss: 0.0142, Train L1 Norm: 0.0182, Test L1 Norm: 0.0119, Train Linf Norm: 7.5302, Test Linf Norm: 1.2364\n",
            "Epoch 154: Train Loss: 0.0138, Test Loss: 0.0143, Train L1 Norm: 0.0185, Test L1 Norm: 0.0120, Train Linf Norm: 7.9993, Test Linf Norm: 1.4057\n",
            "Epoch 155: Train Loss: 0.0137, Test Loss: 0.0139, Train L1 Norm: 0.0189, Test L1 Norm: 0.0118, Train Linf Norm: 8.4020, Test Linf Norm: 1.3584\n",
            "Epoch 156: Train Loss: 0.0136, Test Loss: 0.0138, Train L1 Norm: 0.0183, Test L1 Norm: 0.0118, Train Linf Norm: 7.8611, Test Linf Norm: 1.3510\n",
            "Epoch 157: Train Loss: 0.0135, Test Loss: 0.0139, Train L1 Norm: 0.0187, Test L1 Norm: 0.0118, Train Linf Norm: 8.3410, Test Linf Norm: 1.2569\n",
            "Epoch 158: Train Loss: 0.0134, Test Loss: 0.0138, Train L1 Norm: 0.0183, Test L1 Norm: 0.0118, Train Linf Norm: 7.8850, Test Linf Norm: 1.2875\n",
            "Epoch 159: Train Loss: 0.0134, Test Loss: 0.0137, Train L1 Norm: 0.0183, Test L1 Norm: 0.0118, Train Linf Norm: 8.0441, Test Linf Norm: 1.2821\n",
            "Epoch 160: Train Loss: 0.0134, Test Loss: 0.0137, Train L1 Norm: 0.0183, Test L1 Norm: 0.0117, Train Linf Norm: 7.8931, Test Linf Norm: 1.2791\n",
            "Epoch 161: Train Loss: 0.0134, Test Loss: 0.0137, Train L1 Norm: 0.0184, Test L1 Norm: 0.0117, Train Linf Norm: 8.0472, Test Linf Norm: 1.2699\n",
            "Epoch 162: Train Loss: 0.0134, Test Loss: 0.0137, Train L1 Norm: 0.0183, Test L1 Norm: 0.0117, Train Linf Norm: 7.8020, Test Linf Norm: 1.2719\n",
            "Epoch 163: Train Loss: 0.0134, Test Loss: 0.0137, Train L1 Norm: 0.0183, Test L1 Norm: 0.0117, Train Linf Norm: 7.9287, Test Linf Norm: 1.2700\n",
            "Epoch 164: Train Loss: 0.0134, Test Loss: 0.0137, Train L1 Norm: 0.0184, Test L1 Norm: 0.0117, Train Linf Norm: 8.0528, Test Linf Norm: 1.2680\n",
            "Epoch 165: Train Loss: 0.0133, Test Loss: 0.0137, Train L1 Norm: 0.0183, Test L1 Norm: 0.0117, Train Linf Norm: 7.9978, Test Linf Norm: 1.2795\n",
            "Epoch 166: Train Loss: 0.0133, Test Loss: 0.0137, Train L1 Norm: 0.0184, Test L1 Norm: 0.0117, Train Linf Norm: 8.1216, Test Linf Norm: 1.2585\n",
            "Epoch 167: Train Loss: 0.0133, Test Loss: 0.0136, Train L1 Norm: 0.0183, Test L1 Norm: 0.0117, Train Linf Norm: 7.9370, Test Linf Norm: 1.3325\n",
            "Epoch 168: Train Loss: 0.0133, Test Loss: 0.0135, Train L1 Norm: 0.0184, Test L1 Norm: 0.0117, Train Linf Norm: 8.1221, Test Linf Norm: 1.3272\n",
            "Epoch 169: Train Loss: 0.0132, Test Loss: 0.0135, Train L1 Norm: 0.0181, Test L1 Norm: 0.0117, Train Linf Norm: 7.9055, Test Linf Norm: 1.2691\n",
            "Epoch 170: Train Loss: 0.0132, Test Loss: 0.0136, Train L1 Norm: 0.0181, Test L1 Norm: 0.0118, Train Linf Norm: 7.9380, Test Linf Norm: 1.2047\n",
            "Epoch 171: Train Loss: 0.0135, Test Loss: 0.0140, Train L1 Norm: 0.0181, Test L1 Norm: 0.0119, Train Linf Norm: 7.7414, Test Linf Norm: 1.2206\n",
            "Epoch 172: Train Loss: 0.0152, Test Loss: 0.0144, Train L1 Norm: 0.0192, Test L1 Norm: 0.0119, Train Linf Norm: 8.1835, Test Linf Norm: 1.3872\n",
            "Epoch 173: Train Loss: 0.0190, Test Loss: 0.0197, Train L1 Norm: 0.0187, Test L1 Norm: 0.0143, Train Linf Norm: 6.2202, Test Linf Norm: 1.1134\n",
            "Epoch 174: Train Loss: 0.0224, Test Loss: 0.0237, Train L1 Norm: 0.0242, Test L1 Norm: 0.0147, Train Linf Norm: 10.3393, Test Linf Norm: 1.5987\n",
            "Epoch 175: Train Loss: 0.0258, Test Loss: 0.0245, Train L1 Norm: 0.0263, Test L1 Norm: 0.0155, Train Linf Norm: 10.6993, Test Linf Norm: 1.1044\n",
            "Epoch 176: Train Loss: 0.0290, Test Loss: 0.0291, Train L1 Norm: 0.0283, Test L1 Norm: 0.0170, Train Linf Norm: 11.2311, Test Linf Norm: 1.7915\n",
            "Epoch 177: Train Loss: 0.0317, Test Loss: 0.0258, Train L1 Norm: 0.0238, Test L1 Norm: 0.0175, Train Linf Norm: 5.0606, Test Linf Norm: 1.0856\n",
            "Epoch 178: Train Loss: 0.0339, Test Loss: 0.0337, Train L1 Norm: 0.0299, Test L1 Norm: 0.0206, Train Linf Norm: 9.7778, Test Linf Norm: 2.6855\n",
            "Epoch 179: Train Loss: 0.0357, Test Loss: 0.0399, Train L1 Norm: 0.0305, Test L1 Norm: 0.0215, Train Linf Norm: 10.1459, Test Linf Norm: 1.0995\n",
            "Epoch 180: Train Loss: 0.0374, Test Loss: 0.0373, Train L1 Norm: 0.0356, Test L1 Norm: 0.0219, Train Linf Norm: 14.2734, Test Linf Norm: 2.1302\n",
            "Epoch 181: Train Loss: 0.0387, Test Loss: 0.0352, Train L1 Norm: 0.0302, Test L1 Norm: 0.0220, Train Linf Norm: 7.7281, Test Linf Norm: 1.0426\n",
            "Epoch 182: Train Loss: 0.0395, Test Loss: 0.0403, Train L1 Norm: 0.0328, Test L1 Norm: 0.0256, Train Linf Norm: 10.0529, Test Linf Norm: 3.1763\n",
            "Epoch 183: Train Loss: 0.0400, Test Loss: 0.0437, Train L1 Norm: 0.0362, Test L1 Norm: 0.0211, Train Linf Norm: 8.7148, Test Linf Norm: 1.0767\n",
            "Epoch 184: Train Loss: 0.0402, Test Loss: 0.0331, Train L1 Norm: 0.0299, Test L1 Norm: 0.0232, Train Linf Norm: 6.9624, Test Linf Norm: 2.8148\n",
            "Epoch 185: Train Loss: 0.0397, Test Loss: 0.0412, Train L1 Norm: 0.0303, Test L1 Norm: 0.0229, Train Linf Norm: 7.6698, Test Linf Norm: 1.0000\n",
            "Epoch 186: Train Loss: 0.0393, Test Loss: 0.0375, Train L1 Norm: 0.0313, Test L1 Norm: 0.0234, Train Linf Norm: 8.8197, Test Linf Norm: 2.8092\n",
            "Epoch 187: Train Loss: 0.0382, Test Loss: 0.0346, Train L1 Norm: 0.0296, Test L1 Norm: 0.0210, Train Linf Norm: 7.6727, Test Linf Norm: 1.1050\n",
            "Epoch 188: Train Loss: 0.0369, Test Loss: 0.0288, Train L1 Norm: 0.0267, Test L1 Norm: 0.0199, Train Linf Norm: 5.2971, Test Linf Norm: 3.0870\n",
            "Epoch 189: Train Loss: 0.0354, Test Loss: 0.0443, Train L1 Norm: 0.0277, Test L1 Norm: 0.0230, Train Linf Norm: 7.2083, Test Linf Norm: 1.1490\n",
            "Epoch 190: Train Loss: 0.0334, Test Loss: 0.0254, Train L1 Norm: 0.0312, Test L1 Norm: 0.0168, Train Linf Norm: 12.1758, Test Linf Norm: 1.9108\n",
            "Epoch 191: Train Loss: 0.0311, Test Loss: 0.0306, Train L1 Norm: 0.0280, Test L1 Norm: 0.0189, Train Linf Norm: 10.1386, Test Linf Norm: 1.0881\n",
            "Epoch 192: Train Loss: 0.0282, Test Loss: 0.0255, Train L1 Norm: 0.0236, Test L1 Norm: 0.0153, Train Linf Norm: 6.7578, Test Linf Norm: 1.6508\n",
            "Epoch 193: Train Loss: 0.0258, Test Loss: 0.0266, Train L1 Norm: 0.0256, Test L1 Norm: 0.0187, Train Linf Norm: 8.7707, Test Linf Norm: 1.0628\n",
            "Epoch 194: Train Loss: 0.0225, Test Loss: 0.0188, Train L1 Norm: 0.0231, Test L1 Norm: 0.0135, Train Linf Norm: 9.4840, Test Linf Norm: 1.6671\n",
            "Epoch 195: Train Loss: 0.0196, Test Loss: 0.0196, Train L1 Norm: 0.0187, Test L1 Norm: 0.0142, Train Linf Norm: 6.1861, Test Linf Norm: 1.1431\n",
            "Epoch 196: Train Loss: 0.0164, Test Loss: 0.0183, Train L1 Norm: 0.0182, Test L1 Norm: 0.0131, Train Linf Norm: 7.0329, Test Linf Norm: 1.5544\n",
            "Epoch 197: Train Loss: 0.0141, Test Loss: 0.0140, Train L1 Norm: 0.0175, Test L1 Norm: 0.0118, Train Linf Norm: 7.0979, Test Linf Norm: 1.2678\n",
            "Epoch 198: Train Loss: 0.0131, Test Loss: 0.0146, Train L1 Norm: 0.0172, Test L1 Norm: 0.0120, Train Linf Norm: 7.2617, Test Linf Norm: 1.1995\n",
            "Epoch 199: Train Loss: 0.0129, Test Loss: 0.0136, Train L1 Norm: 0.0166, Test L1 Norm: 0.0113, Train Linf Norm: 6.8215, Test Linf Norm: 1.3771\n",
            "Epoch 200: Train Loss: 0.0127, Test Loss: 0.0135, Train L1 Norm: 0.0161, Test L1 Norm: 0.0114, Train Linf Norm: 6.1090, Test Linf Norm: 1.2800\n",
            "Epoch 201: Train Loss: 0.0125, Test Loss: 0.0128, Train L1 Norm: 0.0166, Test L1 Norm: 0.0112, Train Linf Norm: 6.9898, Test Linf Norm: 1.3117\n",
            "Epoch 202: Train Loss: 0.0124, Test Loss: 0.0127, Train L1 Norm: 0.0166, Test L1 Norm: 0.0111, Train Linf Norm: 6.1292, Test Linf Norm: 1.3153\n",
            "Epoch 203: Train Loss: 0.0124, Test Loss: 0.0127, Train L1 Norm: 0.0162, Test L1 Norm: 0.0111, Train Linf Norm: 6.6642, Test Linf Norm: 1.3144\n",
            "Epoch 204: Train Loss: 0.0123, Test Loss: 0.0127, Train L1 Norm: 0.0164, Test L1 Norm: 0.0111, Train Linf Norm: 6.8217, Test Linf Norm: 1.2955\n",
            "Epoch 205: Train Loss: 0.0123, Test Loss: 0.0126, Train L1 Norm: 0.0164, Test L1 Norm: 0.0111, Train Linf Norm: 6.9718, Test Linf Norm: 1.2884\n",
            "Epoch 206: Train Loss: 0.0123, Test Loss: 0.0127, Train L1 Norm: 0.0163, Test L1 Norm: 0.0111, Train Linf Norm: 6.8355, Test Linf Norm: 1.2934\n",
            "Epoch 207: Train Loss: 0.0123, Test Loss: 0.0126, Train L1 Norm: 0.0163, Test L1 Norm: 0.0111, Train Linf Norm: 6.7969, Test Linf Norm: 1.2989\n",
            "Epoch 208: Train Loss: 0.0123, Test Loss: 0.0126, Train L1 Norm: 0.0163, Test L1 Norm: 0.0111, Train Linf Norm: 6.7837, Test Linf Norm: 1.2981\n",
            "Epoch 209: Train Loss: 0.0123, Test Loss: 0.0126, Train L1 Norm: 0.0163, Test L1 Norm: 0.0111, Train Linf Norm: 6.8727, Test Linf Norm: 1.2986\n",
            "Epoch 210: Train Loss: 0.0123, Test Loss: 0.0126, Train L1 Norm: 0.0163, Test L1 Norm: 0.0110, Train Linf Norm: 6.8057, Test Linf Norm: 1.3104\n",
            "Epoch 211: Train Loss: 0.0123, Test Loss: 0.0126, Train L1 Norm: 0.0164, Test L1 Norm: 0.0110, Train Linf Norm: 6.0814, Test Linf Norm: 1.2938\n",
            "Epoch 212: Train Loss: 0.0123, Test Loss: 0.0127, Train L1 Norm: 0.0163, Test L1 Norm: 0.0110, Train Linf Norm: 6.8910, Test Linf Norm: 1.3333\n",
            "Epoch 213: Train Loss: 0.0123, Test Loss: 0.0126, Train L1 Norm: 0.0163, Test L1 Norm: 0.0109, Train Linf Norm: 6.8143, Test Linf Norm: 1.3030\n",
            "Epoch 214: Train Loss: 0.0122, Test Loss: 0.0127, Train L1 Norm: 0.0163, Test L1 Norm: 0.0110, Train Linf Norm: 6.5625, Test Linf Norm: 1.3184\n",
            "Epoch 215: Train Loss: 0.0122, Test Loss: 0.0128, Train L1 Norm: 0.0164, Test L1 Norm: 0.0110, Train Linf Norm: 6.9276, Test Linf Norm: 1.2085\n",
            "Epoch 216: Train Loss: 0.0122, Test Loss: 0.0124, Train L1 Norm: 0.0162, Test L1 Norm: 0.0110, Train Linf Norm: 6.7879, Test Linf Norm: 1.2863\n",
            "Epoch 217: Train Loss: 0.0122, Test Loss: 0.0129, Train L1 Norm: 0.0158, Test L1 Norm: 0.0109, Train Linf Norm: 5.8276, Test Linf Norm: 1.2938\n",
            "Epoch 218: Train Loss: 0.0133, Test Loss: 0.0163, Train L1 Norm: 0.0170, Test L1 Norm: 0.0118, Train Linf Norm: 7.2315, Test Linf Norm: 1.4267\n",
            "Epoch 219: Train Loss: 0.0163, Test Loss: 0.0149, Train L1 Norm: 0.0182, Test L1 Norm: 0.0125, Train Linf Norm: 7.2302, Test Linf Norm: 1.1541\n",
            "Epoch 220: Train Loss: 0.0197, Test Loss: 0.0227, Train L1 Norm: 0.0203, Test L1 Norm: 0.0138, Train Linf Norm: 7.5770, Test Linf Norm: 1.5373\n",
            "Epoch 221: Train Loss: 0.0227, Test Loss: 0.0197, Train L1 Norm: 0.0207, Test L1 Norm: 0.0139, Train Linf Norm: 6.7547, Test Linf Norm: 1.1719\n",
            "Epoch 222: Train Loss: 0.0254, Test Loss: 0.0249, Train L1 Norm: 0.0224, Test L1 Norm: 0.0154, Train Linf Norm: 6.8323, Test Linf Norm: 1.6778\n",
            "Epoch 223: Train Loss: 0.0282, Test Loss: 0.0301, Train L1 Norm: 0.0213, Test L1 Norm: 0.0196, Train Linf Norm: 4.5684, Test Linf Norm: 1.1396\n",
            "Epoch 224: Train Loss: 0.0303, Test Loss: 0.0325, Train L1 Norm: 0.0208, Test L1 Norm: 0.0199, Train Linf Norm: 2.7905, Test Linf Norm: 2.1855\n",
            "Epoch 225: Train Loss: 0.0320, Test Loss: 0.0272, Train L1 Norm: 0.0232, Test L1 Norm: 0.0173, Train Linf Norm: 4.3151, Test Linf Norm: 1.1105\n",
            "Epoch 226: Train Loss: 0.0333, Test Loss: 0.0291, Train L1 Norm: 0.0289, Test L1 Norm: 0.0187, Train Linf Norm: 9.8537, Test Linf Norm: 2.0733\n",
            "Epoch 227: Train Loss: 0.0344, Test Loss: 0.0324, Train L1 Norm: 0.0335, Test L1 Norm: 0.0201, Train Linf Norm: 13.9037, Test Linf Norm: 1.1171\n",
            "Epoch 228: Train Loss: 0.0354, Test Loss: 0.0295, Train L1 Norm: 0.0325, Test L1 Norm: 0.0206, Train Linf Norm: 12.1224, Test Linf Norm: 2.3477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:14:28,076]\u001b[0m Trial 22 finished with value: 0.022621359422802925 and parameters: {'n_layers': 3, 'n_units_0': 275, 'n_units_1': 1233, 'n_units_2': 815, 'hidden_activation': 'LeakyReLU', 'output_activation': 'ReLU', 'loss': 'MAE', 'optimizer': 'Adagrad', 'lr': 0.001582305314733282, 'batch_size': 1048, 'n_epochs': 229, 'scheduler': 'CosineAnnealingLR', 't_max_fraction': 0.10248989277084633, 'eta_min': 3.556466440417813e-06}. Best is trial 8 with value: 0.008597097944840789.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 229: Train Loss: 0.0359, Test Loss: 0.0416, Train L1 Norm: 0.0244, Test L1 Norm: 0.0226, Train Linf Norm: 3.8636, Test Linf Norm: 1.1134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:14:31,588]\u001b[0m Trial 23 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 3.4113, Test Loss: 3.4125, Train L1 Norm: 1.0114, Test L1 Norm: 1.0000, Train Linf Norm: 1.1714, Test Linf Norm: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:14:34,042]\u001b[0m Trial 24 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 3.7280, Test Loss: 3.4125, Train L1 Norm: 1.2524, Test L1 Norm: 1.0000, Train Linf Norm: 24.5472, Test Linf Norm: 1.0000\n",
            "Epoch 1: Train Loss: 0.4408, Test Loss: 0.2698, Train L1 Norm: 0.4328, Test L1 Norm: 0.1027, Train Linf Norm: 30.5559, Test Linf Norm: 1.0507\n",
            "Epoch 2: Train Loss: 0.1569, Test Loss: 0.0851, Train L1 Norm: 0.1908, Test L1 Norm: 0.0744, Train Linf Norm: 15.6812, Test Linf Norm: 3.2279\n",
            "Epoch 3: Train Loss: 0.1098, Test Loss: 0.1281, Train L1 Norm: 0.0961, Test L1 Norm: 0.0520, Train Linf Norm: 6.0214, Test Linf Norm: 0.8563\n",
            "Epoch 4: Train Loss: 0.0877, Test Loss: 0.0926, Train L1 Norm: 0.0907, Test L1 Norm: 0.0440, Train Linf Norm: 6.5628, Test Linf Norm: 0.6869\n",
            "Epoch 5: Train Loss: 0.0725, Test Loss: 0.0624, Train L1 Norm: 0.1403, Test L1 Norm: 0.0353, Train Linf Norm: 13.7245, Test Linf Norm: 1.3651\n",
            "Epoch 6: Train Loss: 0.0616, Test Loss: 0.0592, Train L1 Norm: 0.0543, Test L1 Norm: 0.0450, Train Linf Norm: 3.2966, Test Linf Norm: 2.0095\n",
            "Epoch 7: Train Loss: 0.0531, Test Loss: 0.0536, Train L1 Norm: 0.0521, Test L1 Norm: 0.0314, Train Linf Norm: 3.5522, Test Linf Norm: 1.2944\n",
            "Epoch 8: Train Loss: 0.0459, Test Loss: 0.0242, Train L1 Norm: 0.0437, Test L1 Norm: 0.0263, Train Linf Norm: 2.9112, Test Linf Norm: 1.4453\n",
            "Epoch 9: Train Loss: 0.0386, Test Loss: 0.0319, Train L1 Norm: 0.0545, Test L1 Norm: 0.0274, Train Linf Norm: 4.6438, Test Linf Norm: 1.3545\n",
            "Epoch 10: Train Loss: 0.0340, Test Loss: 0.0307, Train L1 Norm: 0.0386, Test L1 Norm: 0.0180, Train Linf Norm: 2.8449, Test Linf Norm: 0.6780\n",
            "Epoch 11: Train Loss: 0.0287, Test Loss: 0.0268, Train L1 Norm: 0.0356, Test L1 Norm: 0.0166, Train Linf Norm: 2.7464, Test Linf Norm: 0.6552\n",
            "Epoch 12: Train Loss: 0.0243, Test Loss: 0.0253, Train L1 Norm: 0.0289, Test L1 Norm: 0.0290, Train Linf Norm: 2.1041, Test Linf Norm: 1.5324\n",
            "Epoch 13: Train Loss: 0.0205, Test Loss: 0.0137, Train L1 Norm: 0.0273, Test L1 Norm: 0.0126, Train Linf Norm: 2.1545, Test Linf Norm: 0.6144\n",
            "Epoch 14: Train Loss: 0.0181, Test Loss: 0.0135, Train L1 Norm: 0.0244, Test L1 Norm: 0.0122, Train Linf Norm: 1.8968, Test Linf Norm: 0.5769\n",
            "Epoch 15: Train Loss: 0.0161, Test Loss: 0.0129, Train L1 Norm: 0.0202, Test L1 Norm: 0.0109, Train Linf Norm: 1.4544, Test Linf Norm: 0.4287\n",
            "Epoch 16: Train Loss: 0.0142, Test Loss: 0.0157, Train L1 Norm: 0.0194, Test L1 Norm: 0.0114, Train Linf Norm: 1.4508, Test Linf Norm: 0.4493\n",
            "Epoch 17: Train Loss: 0.0134, Test Loss: 0.0124, Train L1 Norm: 0.0185, Test L1 Norm: 0.0118, Train Linf Norm: 1.3756, Test Linf Norm: 0.5625\n",
            "Epoch 18: Train Loss: 0.0133, Test Loss: 0.0115, Train L1 Norm: 0.0176, Test L1 Norm: 0.0104, Train Linf Norm: 1.2599, Test Linf Norm: 0.3813\n",
            "Epoch 19: Train Loss: 0.0134, Test Loss: 0.0120, Train L1 Norm: 0.0189, Test L1 Norm: 0.0104, Train Linf Norm: 1.4389, Test Linf Norm: 0.4274\n",
            "Epoch 20: Train Loss: 0.0141, Test Loss: 0.0161, Train L1 Norm: 0.0208, Test L1 Norm: 0.0112, Train Linf Norm: 1.6560, Test Linf Norm: 0.4251\n",
            "Epoch 21: Train Loss: 0.0153, Test Loss: 0.0161, Train L1 Norm: 0.0185, Test L1 Norm: 0.0129, Train Linf Norm: 1.2998, Test Linf Norm: 0.4241\n",
            "Epoch 22: Train Loss: 0.0168, Test Loss: 0.0186, Train L1 Norm: 0.0169, Test L1 Norm: 0.0131, Train Linf Norm: 1.0366, Test Linf Norm: 0.4079\n",
            "Epoch 23: Train Loss: 0.0188, Test Loss: 0.0206, Train L1 Norm: 0.0195, Test L1 Norm: 0.0126, Train Linf Norm: 1.2695, Test Linf Norm: 0.4149\n",
            "Epoch 24: Train Loss: 0.0208, Test Loss: 0.0196, Train L1 Norm: 0.0203, Test L1 Norm: 0.0140, Train Linf Norm: 1.3006, Test Linf Norm: 0.4375\n",
            "Epoch 25: Train Loss: 0.0226, Test Loss: 0.0239, Train L1 Norm: 0.0359, Test L1 Norm: 0.0128, Train Linf Norm: 3.1830, Test Linf Norm: 0.4194\n",
            "Epoch 26: Train Loss: 0.0245, Test Loss: 0.0242, Train L1 Norm: 0.0231, Test L1 Norm: 0.0153, Train Linf Norm: 1.4253, Test Linf Norm: 0.4561\n",
            "Epoch 27: Train Loss: 0.0263, Test Loss: 0.0393, Train L1 Norm: 0.0220, Test L1 Norm: 0.0220, Train Linf Norm: 1.2172, Test Linf Norm: 0.5109\n",
            "Epoch 28: Train Loss: 0.0279, Test Loss: 0.0256, Train L1 Norm: 0.0248, Test L1 Norm: 0.0175, Train Linf Norm: 1.4851, Test Linf Norm: 0.6694\n",
            "Epoch 29: Train Loss: 0.0286, Test Loss: 0.0341, Train L1 Norm: 0.0285, Test L1 Norm: 0.0176, Train Linf Norm: 1.8969, Test Linf Norm: 0.4844\n",
            "Epoch 30: Train Loss: 0.0299, Test Loss: 0.0336, Train L1 Norm: 0.0276, Test L1 Norm: 0.0166, Train Linf Norm: 1.7134, Test Linf Norm: 0.6295\n",
            "Epoch 31: Train Loss: 0.0306, Test Loss: 0.0248, Train L1 Norm: 0.0293, Test L1 Norm: 0.0177, Train Linf Norm: 1.9153, Test Linf Norm: 0.8606\n",
            "Epoch 32: Train Loss: 0.0315, Test Loss: 0.0352, Train L1 Norm: 0.0313, Test L1 Norm: 0.0188, Train Linf Norm: 2.1486, Test Linf Norm: 0.4810\n",
            "Epoch 33: Train Loss: 0.0314, Test Loss: 0.0378, Train L1 Norm: 0.0412, Test L1 Norm: 0.0190, Train Linf Norm: 3.3774, Test Linf Norm: 0.4591\n",
            "Epoch 34: Train Loss: 0.0311, Test Loss: 0.0197, Train L1 Norm: 0.0250, Test L1 Norm: 0.0135, Train Linf Norm: 1.3520, Test Linf Norm: 0.5540\n",
            "Epoch 35: Train Loss: 0.0306, Test Loss: 0.0304, Train L1 Norm: 0.0352, Test L1 Norm: 0.0247, Train Linf Norm: 2.6928, Test Linf Norm: 1.2440\n",
            "Epoch 36: Train Loss: 0.0301, Test Loss: 0.0392, Train L1 Norm: 0.0259, Test L1 Norm: 0.0167, Train Linf Norm: 1.5328, Test Linf Norm: 0.4823\n",
            "Epoch 37: Train Loss: 0.0287, Test Loss: 0.0416, Train L1 Norm: 0.0227, Test L1 Norm: 0.0182, Train Linf Norm: 1.2307, Test Linf Norm: 0.4194\n",
            "Epoch 38: Train Loss: 0.0272, Test Loss: 0.0187, Train L1 Norm: 0.0268, Test L1 Norm: 0.0164, Train Linf Norm: 1.7572, Test Linf Norm: 0.7540\n",
            "Epoch 39: Train Loss: 0.0252, Test Loss: 0.0298, Train L1 Norm: 0.0233, Test L1 Norm: 0.0208, Train Linf Norm: 1.4454, Test Linf Norm: 0.8811\n",
            "Epoch 40: Train Loss: 0.0235, Test Loss: 0.0274, Train L1 Norm: 0.0232, Test L1 Norm: 0.0148, Train Linf Norm: 1.5321, Test Linf Norm: 0.4862\n",
            "Epoch 41: Train Loss: 0.0215, Test Loss: 0.0211, Train L1 Norm: 0.0182, Test L1 Norm: 0.0123, Train Linf Norm: 1.0201, Test Linf Norm: 0.3644\n",
            "Epoch 42: Train Loss: 0.0197, Test Loss: 0.0280, Train L1 Norm: 0.0168, Test L1 Norm: 0.0150, Train Linf Norm: 0.9488, Test Linf Norm: 0.5394\n",
            "Epoch 43: Train Loss: 0.0172, Test Loss: 0.0170, Train L1 Norm: 0.0152, Test L1 Norm: 0.0112, Train Linf Norm: 0.8715, Test Linf Norm: 0.3602\n",
            "Epoch 44: Train Loss: 0.0150, Test Loss: 0.0117, Train L1 Norm: 0.0143, Test L1 Norm: 0.0087, Train Linf Norm: 0.8715, Test Linf Norm: 0.3278\n",
            "Epoch 45: Train Loss: 0.0129, Test Loss: 0.0116, Train L1 Norm: 0.0147, Test L1 Norm: 0.0089, Train Linf Norm: 1.0183, Test Linf Norm: 0.3454\n",
            "Epoch 46: Train Loss: 0.0113, Test Loss: 0.0098, Train L1 Norm: 0.0119, Test L1 Norm: 0.0083, Train Linf Norm: 0.7321, Test Linf Norm: 0.3190\n",
            "Epoch 47: Train Loss: 0.0100, Test Loss: 0.0100, Train L1 Norm: 0.0127, Test L1 Norm: 0.0086, Train Linf Norm: 0.8841, Test Linf Norm: 0.3644\n",
            "Epoch 48: Train Loss: 0.0092, Test Loss: 0.0089, Train L1 Norm: 0.0118, Test L1 Norm: 0.0079, Train Linf Norm: 0.8014, Test Linf Norm: 0.3185\n",
            "Epoch 49: Train Loss: 0.0087, Test Loss: 0.0098, Train L1 Norm: 0.0104, Test L1 Norm: 0.0083, Train Linf Norm: 0.6502, Test Linf Norm: 0.3440\n",
            "Epoch 50: Train Loss: 0.0084, Test Loss: 0.0081, Train L1 Norm: 0.0107, Test L1 Norm: 0.0081, Train Linf Norm: 0.7109, Test Linf Norm: 0.3643\n",
            "Epoch 51: Train Loss: 0.0082, Test Loss: 0.0082, Train L1 Norm: 0.0097, Test L1 Norm: 0.0078, Train Linf Norm: 0.5911, Test Linf Norm: 0.3118\n",
            "Epoch 52: Train Loss: 0.0081, Test Loss: 0.0083, Train L1 Norm: 0.0114, Test L1 Norm: 0.0075, Train Linf Norm: 0.8230, Test Linf Norm: 0.2970\n",
            "Epoch 53: Train Loss: 0.0082, Test Loss: 0.0079, Train L1 Norm: 0.0092, Test L1 Norm: 0.0079, Train Linf Norm: 0.5414, Test Linf Norm: 0.3254\n",
            "Epoch 54: Train Loss: 0.0082, Test Loss: 0.0080, Train L1 Norm: 0.0094, Test L1 Norm: 0.0074, Train Linf Norm: 0.5557, Test Linf Norm: 0.2963\n",
            "Epoch 55: Train Loss: 0.0086, Test Loss: 0.0084, Train L1 Norm: 0.0093, Test L1 Norm: 0.0072, Train Linf Norm: 0.5174, Test Linf Norm: 0.2734\n",
            "Epoch 56: Train Loss: 0.0091, Test Loss: 0.0083, Train L1 Norm: 0.0101, Test L1 Norm: 0.0074, Train Linf Norm: 0.6127, Test Linf Norm: 0.3007\n",
            "Epoch 57: Train Loss: 0.0103, Test Loss: 0.0083, Train L1 Norm: 0.0128, Test L1 Norm: 0.0102, Train Linf Norm: 0.9016, Test Linf Norm: 0.5246\n",
            "Epoch 58: Train Loss: 0.0119, Test Loss: 0.0127, Train L1 Norm: 0.0117, Test L1 Norm: 0.0093, Train Linf Norm: 0.6988, Test Linf Norm: 0.3472\n",
            "Epoch 59: Train Loss: 0.0137, Test Loss: 0.0086, Train L1 Norm: 0.0115, Test L1 Norm: 0.0077, Train Linf Norm: 0.5909, Test Linf Norm: 0.3167\n",
            "Epoch 60: Train Loss: 0.0150, Test Loss: 0.0124, Train L1 Norm: 0.0128, Test L1 Norm: 0.0093, Train Linf Norm: 0.6847, Test Linf Norm: 0.3681\n",
            "Epoch 61: Train Loss: 0.0170, Test Loss: 0.0180, Train L1 Norm: 0.0141, Test L1 Norm: 0.0134, Train Linf Norm: 0.7404, Test Linf Norm: 0.6342\n",
            "Epoch 62: Train Loss: 0.0181, Test Loss: 0.0171, Train L1 Norm: 0.0226, Test L1 Norm: 0.0119, Train Linf Norm: 1.7619, Test Linf Norm: 0.3886\n",
            "Epoch 63: Train Loss: 0.0197, Test Loss: 0.0201, Train L1 Norm: 0.0177, Test L1 Norm: 0.0106, Train Linf Norm: 1.0702, Test Linf Norm: 0.3423\n",
            "Epoch 64: Train Loss: 0.0203, Test Loss: 0.0209, Train L1 Norm: 0.0180, Test L1 Norm: 0.0118, Train Linf Norm: 1.0856, Test Linf Norm: 0.3744\n",
            "Epoch 65: Train Loss: 0.0215, Test Loss: 0.0178, Train L1 Norm: 0.0162, Test L1 Norm: 0.0187, Train Linf Norm: 0.7838, Test Linf Norm: 0.9372\n",
            "Epoch 66: Train Loss: 0.0221, Test Loss: 0.0198, Train L1 Norm: 0.0161, Test L1 Norm: 0.0129, Train Linf Norm: 0.7345, Test Linf Norm: 0.4169\n",
            "Epoch 67: Train Loss: 0.0226, Test Loss: 0.0297, Train L1 Norm: 0.0183, Test L1 Norm: 0.0163, Train Linf Norm: 0.9741, Test Linf Norm: 0.5511\n",
            "Epoch 68: Train Loss: 0.0225, Test Loss: 0.0205, Train L1 Norm: 0.0170, Test L1 Norm: 0.0142, Train Linf Norm: 0.8098, Test Linf Norm: 0.5744\n",
            "Epoch 69: Train Loss: 0.0222, Test Loss: 0.0186, Train L1 Norm: 0.0171, Test L1 Norm: 0.0119, Train Linf Norm: 0.8448, Test Linf Norm: 0.3592\n",
            "Epoch 70: Train Loss: 0.0219, Test Loss: 0.0200, Train L1 Norm: 0.0296, Test L1 Norm: 0.0144, Train Linf Norm: 2.4720, Test Linf Norm: 0.5721\n",
            "Epoch 71: Train Loss: 0.0212, Test Loss: 0.0195, Train L1 Norm: 0.0197, Test L1 Norm: 0.0137, Train Linf Norm: 1.2425, Test Linf Norm: 0.4443\n",
            "Epoch 72: Train Loss: 0.0203, Test Loss: 0.0200, Train L1 Norm: 0.0165, Test L1 Norm: 0.0120, Train Linf Norm: 0.8707, Test Linf Norm: 0.3906\n",
            "Epoch 73: Train Loss: 0.0192, Test Loss: 0.0189, Train L1 Norm: 0.0155, Test L1 Norm: 0.0109, Train Linf Norm: 0.8271, Test Linf Norm: 0.3940\n",
            "Epoch 74: Train Loss: 0.0176, Test Loss: 0.0239, Train L1 Norm: 0.0184, Test L1 Norm: 0.0125, Train Linf Norm: 1.2751, Test Linf Norm: 0.3949\n",
            "Epoch 75: Train Loss: 0.0161, Test Loss: 0.0141, Train L1 Norm: 0.0150, Test L1 Norm: 0.0088, Train Linf Norm: 0.9271, Test Linf Norm: 0.2799\n",
            "Epoch 76: Train Loss: 0.0148, Test Loss: 0.0118, Train L1 Norm: 0.0131, Test L1 Norm: 0.0088, Train Linf Norm: 0.7524, Test Linf Norm: 0.3416\n",
            "Epoch 77: Train Loss: 0.0130, Test Loss: 0.0177, Train L1 Norm: 0.0148, Test L1 Norm: 0.0094, Train Linf Norm: 1.0645, Test Linf Norm: 0.2750\n",
            "Epoch 78: Train Loss: 0.0116, Test Loss: 0.0109, Train L1 Norm: 0.0115, Test L1 Norm: 0.0075, Train Linf Norm: 0.7089, Test Linf Norm: 0.2789\n",
            "Epoch 79: Train Loss: 0.0101, Test Loss: 0.0117, Train L1 Norm: 0.0108, Test L1 Norm: 0.0080, Train Linf Norm: 0.6650, Test Linf Norm: 0.3174\n",
            "Epoch 80: Train Loss: 0.0088, Test Loss: 0.0087, Train L1 Norm: 0.0098, Test L1 Norm: 0.0070, Train Linf Norm: 0.6148, Test Linf Norm: 0.2702\n",
            "Epoch 81: Train Loss: 0.0080, Test Loss: 0.0080, Train L1 Norm: 0.0090, Test L1 Norm: 0.0069, Train Linf Norm: 0.5480, Test Linf Norm: 0.2642\n",
            "Epoch 82: Train Loss: 0.0075, Test Loss: 0.0072, Train L1 Norm: 0.0079, Test L1 Norm: 0.0072, Train Linf Norm: 0.4335, Test Linf Norm: 0.3087\n",
            "Epoch 83: Train Loss: 0.0072, Test Loss: 0.0082, Train L1 Norm: 0.0085, Test L1 Norm: 0.0065, Train Linf Norm: 0.5224, Test Linf Norm: 0.2487\n",
            "Epoch 84: Train Loss: 0.0070, Test Loss: 0.0070, Train L1 Norm: 0.0077, Test L1 Norm: 0.0070, Train Linf Norm: 0.4356, Test Linf Norm: 0.3012\n",
            "Epoch 85: Train Loss: 0.0069, Test Loss: 0.0072, Train L1 Norm: 0.0079, Test L1 Norm: 0.0064, Train Linf Norm: 0.4591, Test Linf Norm: 0.2598\n",
            "Epoch 86: Train Loss: 0.0069, Test Loss: 0.0070, Train L1 Norm: 0.0086, Test L1 Norm: 0.0062, Train Linf Norm: 0.5577, Test Linf Norm: 0.2306\n",
            "Epoch 87: Train Loss: 0.0069, Test Loss: 0.0071, Train L1 Norm: 0.0077, Test L1 Norm: 0.0065, Train Linf Norm: 0.4482, Test Linf Norm: 0.2643\n",
            "Epoch 88: Train Loss: 0.0069, Test Loss: 0.0071, Train L1 Norm: 0.0073, Test L1 Norm: 0.0064, Train Linf Norm: 0.3836, Test Linf Norm: 0.2546\n",
            "Epoch 89: Train Loss: 0.0070, Test Loss: 0.0068, Train L1 Norm: 0.0083, Test L1 Norm: 0.0065, Train Linf Norm: 0.5181, Test Linf Norm: 0.2720\n",
            "Epoch 90: Train Loss: 0.0073, Test Loss: 0.0074, Train L1 Norm: 0.0074, Test L1 Norm: 0.0064, Train Linf Norm: 0.3793, Test Linf Norm: 0.2563\n",
            "Epoch 91: Train Loss: 0.0080, Test Loss: 0.0069, Train L1 Norm: 0.0081, Test L1 Norm: 0.0062, Train Linf Norm: 0.4355, Test Linf Norm: 0.2439\n",
            "Epoch 92: Train Loss: 0.0090, Test Loss: 0.0098, Train L1 Norm: 0.0083, Test L1 Norm: 0.0068, Train Linf Norm: 0.4248, Test Linf Norm: 0.2355\n",
            "Epoch 93: Train Loss: 0.0104, Test Loss: 0.0095, Train L1 Norm: 0.0095, Test L1 Norm: 0.0087, Train Linf Norm: 0.5197, Test Linf Norm: 0.3455\n",
            "Epoch 94: Train Loss: 0.0119, Test Loss: 0.0115, Train L1 Norm: 0.0109, Test L1 Norm: 0.0082, Train Linf Norm: 0.6116, Test Linf Norm: 0.3163\n",
            "Epoch 95: Train Loss: 0.0133, Test Loss: 0.0124, Train L1 Norm: 0.0121, Test L1 Norm: 0.0091, Train Linf Norm: 0.7132, Test Linf Norm: 0.3167\n",
            "Epoch 96: Train Loss: 0.0144, Test Loss: 0.0184, Train L1 Norm: 0.0145, Test L1 Norm: 0.0103, Train Linf Norm: 0.9467, Test Linf Norm: 0.3383\n",
            "Epoch 97: Train Loss: 0.0158, Test Loss: 0.0201, Train L1 Norm: 0.0137, Test L1 Norm: 0.0113, Train Linf Norm: 0.7788, Test Linf Norm: 0.3515\n",
            "Epoch 98: Train Loss: 0.0166, Test Loss: 0.0172, Train L1 Norm: 0.0141, Test L1 Norm: 0.0144, Train Linf Norm: 0.7673, Test Linf Norm: 0.4853\n",
            "Epoch 99: Train Loss: 0.0174, Test Loss: 0.0184, Train L1 Norm: 0.0279, Test L1 Norm: 0.0111, Train Linf Norm: 2.4845, Test Linf Norm: 0.4193\n",
            "Epoch 100: Train Loss: 0.0181, Test Loss: 0.0169, Train L1 Norm: 0.0150, Test L1 Norm: 0.0120, Train Linf Norm: 0.8115, Test Linf Norm: 0.4414\n",
            "Epoch 101: Train Loss: 0.0186, Test Loss: 0.0178, Train L1 Norm: 0.0188, Test L1 Norm: 0.0106, Train Linf Norm: 1.2551, Test Linf Norm: 0.3121\n",
            "Epoch 102: Train Loss: 0.0186, Test Loss: 0.0210, Train L1 Norm: 0.0219, Test L1 Norm: 0.0122, Train Linf Norm: 1.6730, Test Linf Norm: 0.4336\n",
            "Epoch 103: Train Loss: 0.0187, Test Loss: 0.0225, Train L1 Norm: 0.0151, Test L1 Norm: 0.0107, Train Linf Norm: 0.8035, Test Linf Norm: 0.2715\n",
            "Epoch 104: Train Loss: 0.0183, Test Loss: 0.0158, Train L1 Norm: 0.0186, Test L1 Norm: 0.0093, Train Linf Norm: 1.2616, Test Linf Norm: 0.3085\n",
            "Epoch 105: Train Loss: 0.0178, Test Loss: 0.0237, Train L1 Norm: 0.0143, Test L1 Norm: 0.0113, Train Linf Norm: 0.7623, Test Linf Norm: 0.3289\n",
            "Epoch 106: Train Loss: 0.0170, Test Loss: 0.0149, Train L1 Norm: 0.0128, Test L1 Norm: 0.0115, Train Linf Norm: 0.5922, Test Linf Norm: 0.4326\n",
            "Epoch 107: Train Loss: 0.0160, Test Loss: 0.0103, Train L1 Norm: 0.0152, Test L1 Norm: 0.0130, Train Linf Norm: 0.9501, Test Linf Norm: 0.6307\n",
            "Epoch 108: Train Loss: 0.0148, Test Loss: 0.0137, Train L1 Norm: 0.0120, Test L1 Norm: 0.0098, Train Linf Norm: 0.6099, Test Linf Norm: 0.3790\n",
            "Epoch 109: Train Loss: 0.0137, Test Loss: 0.0101, Train L1 Norm: 0.0106, Test L1 Norm: 0.0094, Train Linf Norm: 0.4915, Test Linf Norm: 0.4131\n",
            "Epoch 110: Train Loss: 0.0124, Test Loss: 0.0120, Train L1 Norm: 0.0101, Test L1 Norm: 0.0071, Train Linf Norm: 0.5017, Test Linf Norm: 0.2220\n",
            "Epoch 111: Train Loss: 0.0112, Test Loss: 0.0077, Train L1 Norm: 0.0100, Test L1 Norm: 0.0064, Train Linf Norm: 0.5584, Test Linf Norm: 0.2419\n",
            "Epoch 112: Train Loss: 0.0097, Test Loss: 0.0109, Train L1 Norm: 0.0086, Test L1 Norm: 0.0071, Train Linf Norm: 0.4352, Test Linf Norm: 0.2387\n",
            "Epoch 113: Train Loss: 0.0085, Test Loss: 0.0074, Train L1 Norm: 0.0107, Test L1 Norm: 0.0061, Train Linf Norm: 0.7728, Test Linf Norm: 0.2224\n",
            "Epoch 114: Train Loss: 0.0075, Test Loss: 0.0080, Train L1 Norm: 0.0078, Test L1 Norm: 0.0064, Train Linf Norm: 0.4469, Test Linf Norm: 0.2617\n",
            "Epoch 115: Train Loss: 0.0069, Test Loss: 0.0068, Train L1 Norm: 0.0079, Test L1 Norm: 0.0062, Train Linf Norm: 0.4885, Test Linf Norm: 0.2491\n",
            "Epoch 116: Train Loss: 0.0066, Test Loss: 0.0068, Train L1 Norm: 0.0076, Test L1 Norm: 0.0063, Train Linf Norm: 0.4668, Test Linf Norm: 0.2754\n",
            "Epoch 117: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0072, Test L1 Norm: 0.0061, Train Linf Norm: 0.4200, Test Linf Norm: 0.2569\n",
            "Epoch 118: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0076, Test L1 Norm: 0.0061, Train Linf Norm: 0.4866, Test Linf Norm: 0.2537\n",
            "Epoch 119: Train Loss: 0.0062, Test Loss: 0.0065, Train L1 Norm: 0.0069, Test L1 Norm: 0.0058, Train Linf Norm: 0.3911, Test Linf Norm: 0.2269\n",
            "Epoch 120: Train Loss: 0.0062, Test Loss: 0.0063, Train L1 Norm: 0.0067, Test L1 Norm: 0.0060, Train Linf Norm: 0.3700, Test Linf Norm: 0.2511\n",
            "Epoch 121: Train Loss: 0.0062, Test Loss: 0.0067, Train L1 Norm: 0.0064, Test L1 Norm: 0.0059, Train Linf Norm: 0.3306, Test Linf Norm: 0.2303\n",
            "Epoch 122: Train Loss: 0.0062, Test Loss: 0.0074, Train L1 Norm: 0.0065, Test L1 Norm: 0.0058, Train Linf Norm: 0.3581, Test Linf Norm: 0.2062\n",
            "Epoch 123: Train Loss: 0.0063, Test Loss: 0.0063, Train L1 Norm: 0.0074, Test L1 Norm: 0.0058, Train Linf Norm: 0.4652, Test Linf Norm: 0.2370\n",
            "Epoch 124: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0068, Test L1 Norm: 0.0057, Train Linf Norm: 0.3791, Test Linf Norm: 0.2025\n",
            "Epoch 125: Train Loss: 0.0068, Test Loss: 0.0064, Train L1 Norm: 0.0107, Test L1 Norm: 0.0057, Train Linf Norm: 0.8524, Test Linf Norm: 0.2137\n",
            "Epoch 126: Train Loss: 0.0075, Test Loss: 0.0072, Train L1 Norm: 0.0071, Test L1 Norm: 0.0060, Train Linf Norm: 0.3574, Test Linf Norm: 0.2222\n",
            "Epoch 127: Train Loss: 0.0087, Test Loss: 0.0092, Train L1 Norm: 0.0083, Test L1 Norm: 0.0064, Train Linf Norm: 0.4527, Test Linf Norm: 0.2274\n",
            "Epoch 128: Train Loss: 0.0100, Test Loss: 0.0072, Train L1 Norm: 0.0089, Test L1 Norm: 0.0059, Train Linf Norm: 0.4745, Test Linf Norm: 0.2128\n",
            "Epoch 129: Train Loss: 0.0113, Test Loss: 0.0086, Train L1 Norm: 0.0112, Test L1 Norm: 0.0076, Train Linf Norm: 0.7083, Test Linf Norm: 0.3170\n",
            "Epoch 130: Train Loss: 0.0124, Test Loss: 0.0135, Train L1 Norm: 0.0157, Test L1 Norm: 0.0112, Train Linf Norm: 1.2328, Test Linf Norm: 0.4725\n",
            "Epoch 131: Train Loss: 0.0135, Test Loss: 0.0173, Train L1 Norm: 0.0109, Test L1 Norm: 0.0091, Train Linf Norm: 0.5451, Test Linf Norm: 0.3016\n",
            "Epoch 132: Train Loss: 0.0144, Test Loss: 0.0166, Train L1 Norm: 0.0108, Test L1 Norm: 0.0089, Train Linf Norm: 0.4918, Test Linf Norm: 0.2258\n",
            "Epoch 133: Train Loss: 0.0148, Test Loss: 0.0137, Train L1 Norm: 0.0135, Test L1 Norm: 0.0093, Train Linf Norm: 0.8114, Test Linf Norm: 0.3374\n",
            "Epoch 134: Train Loss: 0.0157, Test Loss: 0.0161, Train L1 Norm: 0.0146, Test L1 Norm: 0.0125, Train Linf Norm: 0.8899, Test Linf Norm: 0.5816\n",
            "Epoch 135: Train Loss: 0.0160, Test Loss: 0.0140, Train L1 Norm: 0.0144, Test L1 Norm: 0.0092, Train Linf Norm: 0.8395, Test Linf Norm: 0.3315\n",
            "Epoch 136: Train Loss: 0.0162, Test Loss: 0.0120, Train L1 Norm: 0.0151, Test L1 Norm: 0.0100, Train Linf Norm: 0.9469, Test Linf Norm: 0.4355\n",
            "Epoch 137: Train Loss: 0.0159, Test Loss: 0.0170, Train L1 Norm: 0.0133, Test L1 Norm: 0.0100, Train Linf Norm: 0.7269, Test Linf Norm: 0.3557\n",
            "Epoch 138: Train Loss: 0.0159, Test Loss: 0.0144, Train L1 Norm: 0.0178, Test L1 Norm: 0.0090, Train Linf Norm: 1.2973, Test Linf Norm: 0.3216\n",
            "Epoch 139: Train Loss: 0.0155, Test Loss: 0.0176, Train L1 Norm: 0.0121, Test L1 Norm: 0.0102, Train Linf Norm: 0.6044, Test Linf Norm: 0.3703\n",
            "Epoch 140: Train Loss: 0.0151, Test Loss: 0.0111, Train L1 Norm: 0.0140, Test L1 Norm: 0.0082, Train Linf Norm: 0.8672, Test Linf Norm: 0.3142\n",
            "Epoch 141: Train Loss: 0.0141, Test Loss: 0.0108, Train L1 Norm: 0.0130, Test L1 Norm: 0.0081, Train Linf Norm: 0.7943, Test Linf Norm: 0.3130\n",
            "Epoch 142: Train Loss: 0.0134, Test Loss: 0.0109, Train L1 Norm: 0.0108, Test L1 Norm: 0.0067, Train Linf Norm: 0.5542, Test Linf Norm: 0.2122\n",
            "Epoch 143: Train Loss: 0.0123, Test Loss: 0.0131, Train L1 Norm: 0.0104, Test L1 Norm: 0.0096, Train Linf Norm: 0.5539, Test Linf Norm: 0.3159\n",
            "Epoch 144: Train Loss: 0.0109, Test Loss: 0.0116, Train L1 Norm: 0.0114, Test L1 Norm: 0.0069, Train Linf Norm: 0.7591, Test Linf Norm: 0.2040\n",
            "Epoch 145: Train Loss: 0.0096, Test Loss: 0.0103, Train L1 Norm: 0.0080, Test L1 Norm: 0.0080, Train Linf Norm: 0.3881, Test Linf Norm: 0.2968\n",
            "Epoch 146: Train Loss: 0.0085, Test Loss: 0.0092, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.8589, Test Linf Norm: 0.2222\n",
            "Epoch 147: Train Loss: 0.0073, Test Loss: 0.0094, Train L1 Norm: 0.0069, Test L1 Norm: 0.0071, Train Linf Norm: 0.3615, Test Linf Norm: 0.2586\n",
            "Epoch 148: Train Loss: 0.0066, Test Loss: 0.0074, Train L1 Norm: 0.0080, Test L1 Norm: 0.0059, Train Linf Norm: 0.5290, Test Linf Norm: 0.2190\n",
            "Epoch 149: Train Loss: 0.0063, Test Loss: 0.0067, Train L1 Norm: 0.0068, Test L1 Norm: 0.0058, Train Linf Norm: 0.3890, Test Linf Norm: 0.2303\n",
            "Epoch 150: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0073, Test L1 Norm: 0.0061, Train Linf Norm: 0.4578, Test Linf Norm: 0.2493\n",
            "Epoch 151: Train Loss: 0.0059, Test Loss: 0.0063, Train L1 Norm: 0.0064, Test L1 Norm: 0.0056, Train Linf Norm: 0.3632, Test Linf Norm: 0.2228\n",
            "Epoch 152: Train Loss: 0.0058, Test Loss: 0.0064, Train L1 Norm: 0.0062, Test L1 Norm: 0.0057, Train Linf Norm: 0.3411, Test Linf Norm: 0.2282\n",
            "Epoch 153: Train Loss: 0.0057, Test Loss: 0.0060, Train L1 Norm: 0.0062, Test L1 Norm: 0.0055, Train Linf Norm: 0.3503, Test Linf Norm: 0.2056\n",
            "Epoch 154: Train Loss: 0.0057, Test Loss: 0.0062, Train L1 Norm: 0.0061, Test L1 Norm: 0.0056, Train Linf Norm: 0.3300, Test Linf Norm: 0.2256\n",
            "Epoch 155: Train Loss: 0.0057, Test Loss: 0.0061, Train L1 Norm: 0.0066, Test L1 Norm: 0.0055, Train Linf Norm: 0.3914, Test Linf Norm: 0.2191\n",
            "Epoch 156: Train Loss: 0.0057, Test Loss: 0.0059, Train L1 Norm: 0.0062, Test L1 Norm: 0.0054, Train Linf Norm: 0.3430, Test Linf Norm: 0.2043\n",
            "Epoch 157: Train Loss: 0.0058, Test Loss: 0.0066, Train L1 Norm: 0.0063, Test L1 Norm: 0.0060, Train Linf Norm: 0.3495, Test Linf Norm: 0.2358\n",
            "Epoch 158: Train Loss: 0.0059, Test Loss: 0.0060, Train L1 Norm: 0.0062, Test L1 Norm: 0.0061, Train Linf Norm: 0.3380, Test Linf Norm: 0.2625\n",
            "Epoch 159: Train Loss: 0.0062, Test Loss: 0.0066, Train L1 Norm: 0.0069, Test L1 Norm: 0.0054, Train Linf Norm: 0.4064, Test Linf Norm: 0.1915\n",
            "Epoch 160: Train Loss: 0.0069, Test Loss: 0.0086, Train L1 Norm: 0.0090, Test L1 Norm: 0.0062, Train Linf Norm: 0.6432, Test Linf Norm: 0.2324\n",
            "Epoch 161: Train Loss: 0.0077, Test Loss: 0.0061, Train L1 Norm: 0.0095, Test L1 Norm: 0.0058, Train Linf Norm: 0.6753, Test Linf Norm: 0.2354\n",
            "Epoch 162: Train Loss: 0.0088, Test Loss: 0.0093, Train L1 Norm: 0.0099, Test L1 Norm: 0.0073, Train Linf Norm: 0.6741, Test Linf Norm: 0.2824\n",
            "Epoch 163: Train Loss: 0.0098, Test Loss: 0.0103, Train L1 Norm: 0.0136, Test L1 Norm: 0.0066, Train Linf Norm: 1.0974, Test Linf Norm: 0.2245\n",
            "Epoch 164: Train Loss: 0.0111, Test Loss: 0.0154, Train L1 Norm: 0.0092, Test L1 Norm: 0.0083, Train Linf Norm: 0.4681, Test Linf Norm: 0.2425\n",
            "Epoch 165: Train Loss: 0.0121, Test Loss: 0.0114, Train L1 Norm: 0.0101, Test L1 Norm: 0.0070, Train Linf Norm: 0.5293, Test Linf Norm: 0.2169\n",
            "Epoch 166: Train Loss: 0.0129, Test Loss: 0.0138, Train L1 Norm: 0.0105, Test L1 Norm: 0.0101, Train Linf Norm: 0.5346, Test Linf Norm: 0.3477\n",
            "Epoch 167: Train Loss: 0.0136, Test Loss: 0.0151, Train L1 Norm: 0.0125, Test L1 Norm: 0.0087, Train Linf Norm: 0.7569, Test Linf Norm: 0.2973\n",
            "Epoch 168: Train Loss: 0.0140, Test Loss: 0.0113, Train L1 Norm: 0.0126, Test L1 Norm: 0.0096, Train Linf Norm: 0.7441, Test Linf Norm: 0.4086\n",
            "Epoch 169: Train Loss: 0.0144, Test Loss: 0.0168, Train L1 Norm: 0.0122, Test L1 Norm: 0.0090, Train Linf Norm: 0.6727, Test Linf Norm: 0.2641\n",
            "Epoch 170: Train Loss: 0.0148, Test Loss: 0.0135, Train L1 Norm: 0.0109, Test L1 Norm: 0.0107, Train Linf Norm: 0.4912, Test Linf Norm: 0.4540\n",
            "Epoch 171: Train Loss: 0.0146, Test Loss: 0.0141, Train L1 Norm: 0.0129, Test L1 Norm: 0.0090, Train Linf Norm: 0.7440, Test Linf Norm: 0.3343\n",
            "Epoch 172: Train Loss: 0.0145, Test Loss: 0.0186, Train L1 Norm: 0.0114, Test L1 Norm: 0.0134, Train Linf Norm: 0.5334, Test Linf Norm: 0.6104\n",
            "Epoch 173: Train Loss: 0.0141, Test Loss: 0.0102, Train L1 Norm: 0.0137, Test L1 Norm: 0.0083, Train Linf Norm: 0.8822, Test Linf Norm: 0.2596\n",
            "Epoch 174: Train Loss: 0.0136, Test Loss: 0.0117, Train L1 Norm: 0.0123, Test L1 Norm: 0.0081, Train Linf Norm: 0.7315, Test Linf Norm: 0.2933\n",
            "Epoch 175: Train Loss: 0.0126, Test Loss: 0.0148, Train L1 Norm: 0.0101, Test L1 Norm: 0.0099, Train Linf Norm: 0.5031, Test Linf Norm: 0.3753\n",
            "Epoch 176: Train Loss: 0.0120, Test Loss: 0.0094, Train L1 Norm: 0.0118, Test L1 Norm: 0.0067, Train Linf Norm: 0.7570, Test Linf Norm: 0.2200\n",
            "Epoch 177: Train Loss: 0.0109, Test Loss: 0.0079, Train L1 Norm: 0.0104, Test L1 Norm: 0.0060, Train Linf Norm: 0.6380, Test Linf Norm: 0.2117\n",
            "Epoch 178: Train Loss: 0.0099, Test Loss: 0.0072, Train L1 Norm: 0.0081, Test L1 Norm: 0.0060, Train Linf Norm: 0.3948, Test Linf Norm: 0.2048\n",
            "Epoch 179: Train Loss: 0.0089, Test Loss: 0.0082, Train L1 Norm: 0.0096, Test L1 Norm: 0.0064, Train Linf Norm: 0.6315, Test Linf Norm: 0.2359\n",
            "Epoch 180: Train Loss: 0.0078, Test Loss: 0.0079, Train L1 Norm: 0.0074, Test L1 Norm: 0.0065, Train Linf Norm: 0.4107, Test Linf Norm: 0.2552\n",
            "Epoch 181: Train Loss: 0.0068, Test Loss: 0.0062, Train L1 Norm: 0.0067, Test L1 Norm: 0.0059, Train Linf Norm: 0.3612, Test Linf Norm: 0.2484\n",
            "Epoch 182: Train Loss: 0.0062, Test Loss: 0.0066, Train L1 Norm: 0.0072, Test L1 Norm: 0.0067, Train Linf Norm: 0.4528, Test Linf Norm: 0.2953\n",
            "Epoch 183: Train Loss: 0.0059, Test Loss: 0.0059, Train L1 Norm: 0.0061, Test L1 Norm: 0.0056, Train Linf Norm: 0.3325, Test Linf Norm: 0.2339\n",
            "Epoch 184: Train Loss: 0.0056, Test Loss: 0.0065, Train L1 Norm: 0.0076, Test L1 Norm: 0.0058, Train Linf Norm: 0.5337, Test Linf Norm: 0.2231\n",
            "Epoch 185: Train Loss: 0.0056, Test Loss: 0.0058, Train L1 Norm: 0.0062, Test L1 Norm: 0.0058, Train Linf Norm: 0.3614, Test Linf Norm: 0.2485\n",
            "Epoch 186: Train Loss: 0.0055, Test Loss: 0.0058, Train L1 Norm: 0.0059, Test L1 Norm: 0.0053, Train Linf Norm: 0.3200, Test Linf Norm: 0.2076\n",
            "Epoch 187: Train Loss: 0.0054, Test Loss: 0.0071, Train L1 Norm: 0.0059, Test L1 Norm: 0.0060, Train Linf Norm: 0.3321, Test Linf Norm: 0.2346\n",
            "Epoch 188: Train Loss: 0.0054, Test Loss: 0.0057, Train L1 Norm: 0.0062, Test L1 Norm: 0.0054, Train Linf Norm: 0.3779, Test Linf Norm: 0.2046\n",
            "Epoch 189: Train Loss: 0.0054, Test Loss: 0.0057, Train L1 Norm: 0.0062, Test L1 Norm: 0.0053, Train Linf Norm: 0.3710, Test Linf Norm: 0.2031\n",
            "Epoch 190: Train Loss: 0.0054, Test Loss: 0.0058, Train L1 Norm: 0.0061, Test L1 Norm: 0.0054, Train Linf Norm: 0.3643, Test Linf Norm: 0.2083\n",
            "Epoch 191: Train Loss: 0.0054, Test Loss: 0.0058, Train L1 Norm: 0.0063, Test L1 Norm: 0.0052, Train Linf Norm: 0.3771, Test Linf Norm: 0.1980\n",
            "Epoch 192: Train Loss: 0.0056, Test Loss: 0.0057, Train L1 Norm: 0.0063, Test L1 Norm: 0.0056, Train Linf Norm: 0.3757, Test Linf Norm: 0.2260\n",
            "Epoch 193: Train Loss: 0.0058, Test Loss: 0.0068, Train L1 Norm: 0.0070, Test L1 Norm: 0.0055, Train Linf Norm: 0.4520, Test Linf Norm: 0.2066\n",
            "Epoch 194: Train Loss: 0.0063, Test Loss: 0.0062, Train L1 Norm: 0.0063, Test L1 Norm: 0.0055, Train Linf Norm: 0.3399, Test Linf Norm: 0.2218\n",
            "Epoch 195: Train Loss: 0.0068, Test Loss: 0.0082, Train L1 Norm: 0.0078, Test L1 Norm: 0.0060, Train Linf Norm: 0.5231, Test Linf Norm: 0.2157\n",
            "Epoch 196: Train Loss: 0.0080, Test Loss: 0.0071, Train L1 Norm: 0.0071, Test L1 Norm: 0.0067, Train Linf Norm: 0.3692, Test Linf Norm: 0.2913\n",
            "Epoch 197: Train Loss: 0.0090, Test Loss: 0.0089, Train L1 Norm: 0.0076, Test L1 Norm: 0.0063, Train Linf Norm: 0.3849, Test Linf Norm: 0.2182\n",
            "Epoch 198: Train Loss: 0.0099, Test Loss: 0.0086, Train L1 Norm: 0.0081, Test L1 Norm: 0.0065, Train Linf Norm: 0.3977, Test Linf Norm: 0.2468\n",
            "Epoch 199: Train Loss: 0.0110, Test Loss: 0.0122, Train L1 Norm: 0.0088, Test L1 Norm: 0.0070, Train Linf Norm: 0.4312, Test Linf Norm: 0.2281\n",
            "Epoch 200: Train Loss: 0.0118, Test Loss: 0.0109, Train L1 Norm: 0.0096, Test L1 Norm: 0.0077, Train Linf Norm: 0.4792, Test Linf Norm: 0.2984\n",
            "Epoch 201: Train Loss: 0.0125, Test Loss: 0.0132, Train L1 Norm: 0.0121, Test L1 Norm: 0.0091, Train Linf Norm: 0.7610, Test Linf Norm: 0.3220\n",
            "Epoch 202: Train Loss: 0.0128, Test Loss: 0.0102, Train L1 Norm: 0.0165, Test L1 Norm: 0.0072, Train Linf Norm: 1.3142, Test Linf Norm: 0.2468\n",
            "Epoch 203: Train Loss: 0.0134, Test Loss: 0.0117, Train L1 Norm: 0.0205, Test L1 Norm: 0.0105, Train Linf Norm: 1.7946, Test Linf Norm: 0.3927\n",
            "Epoch 204: Train Loss: 0.0134, Test Loss: 0.0165, Train L1 Norm: 0.0109, Test L1 Norm: 0.0118, Train Linf Norm: 0.5534, Test Linf Norm: 0.4810\n",
            "Epoch 205: Train Loss: 0.0133, Test Loss: 0.0120, Train L1 Norm: 0.0130, Test L1 Norm: 0.0078, Train Linf Norm: 0.8385, Test Linf Norm: 0.2841\n",
            "Epoch 206: Train Loss: 0.0134, Test Loss: 0.0166, Train L1 Norm: 0.0103, Test L1 Norm: 0.0123, Train Linf Norm: 0.4847, Test Linf Norm: 0.5115\n",
            "Epoch 207: Train Loss: 0.0130, Test Loss: 0.0093, Train L1 Norm: 0.0102, Test L1 Norm: 0.0067, Train Linf Norm: 0.5144, Test Linf Norm: 0.2248\n",
            "Epoch 208: Train Loss: 0.0124, Test Loss: 0.0125, Train L1 Norm: 0.0122, Test L1 Norm: 0.0080, Train Linf Norm: 0.8006, Test Linf Norm: 0.2732\n",
            "Epoch 209: Train Loss: 0.0118, Test Loss: 0.0119, Train L1 Norm: 0.0105, Test L1 Norm: 0.0098, Train Linf Norm: 0.6018, Test Linf Norm: 0.4457\n",
            "Epoch 210: Train Loss: 0.0111, Test Loss: 0.0084, Train L1 Norm: 0.0140, Test L1 Norm: 0.0060, Train Linf Norm: 1.0874, Test Linf Norm: 0.2216\n",
            "Epoch 211: Train Loss: 0.0102, Test Loss: 0.0089, Train L1 Norm: 0.0084, Test L1 Norm: 0.0079, Train Linf Norm: 0.4176, Test Linf Norm: 0.3442\n",
            "Epoch 212: Train Loss: 0.0090, Test Loss: 0.0104, Train L1 Norm: 0.0080, Test L1 Norm: 0.0071, Train Linf Norm: 0.4437, Test Linf Norm: 0.2614\n",
            "Epoch 213: Train Loss: 0.0081, Test Loss: 0.0065, Train L1 Norm: 0.0080, Test L1 Norm: 0.0061, Train Linf Norm: 0.4879, Test Linf Norm: 0.2531\n",
            "Epoch 214: Train Loss: 0.0072, Test Loss: 0.0057, Train L1 Norm: 0.0072, Test L1 Norm: 0.0051, Train Linf Norm: 0.4211, Test Linf Norm: 0.1834\n",
            "Epoch 215: Train Loss: 0.0064, Test Loss: 0.0073, Train L1 Norm: 0.0060, Test L1 Norm: 0.0057, Train Linf Norm: 0.3020, Test Linf Norm: 0.2140\n",
            "Epoch 216: Train Loss: 0.0058, Test Loss: 0.0057, Train L1 Norm: 0.0060, Test L1 Norm: 0.0050, Train Linf Norm: 0.3370, Test Linf Norm: 0.1846\n",
            "Epoch 217: Train Loss: 0.0056, Test Loss: 0.0057, Train L1 Norm: 0.0054, Test L1 Norm: 0.0050, Train Linf Norm: 0.2729, Test Linf Norm: 0.1855\n",
            "Epoch 218: Train Loss: 0.0053, Test Loss: 0.0058, Train L1 Norm: 0.0056, Test L1 Norm: 0.0053, Train Linf Norm: 0.3185, Test Linf Norm: 0.2043\n",
            "Epoch 219: Train Loss: 0.0053, Test Loss: 0.0056, Train L1 Norm: 0.0057, Test L1 Norm: 0.0053, Train Linf Norm: 0.3236, Test Linf Norm: 0.2146\n",
            "Epoch 220: Train Loss: 0.0052, Test Loss: 0.0056, Train L1 Norm: 0.0054, Test L1 Norm: 0.0050, Train Linf Norm: 0.2957, Test Linf Norm: 0.1781\n",
            "Epoch 221: Train Loss: 0.0052, Test Loss: 0.0055, Train L1 Norm: 0.0054, Test L1 Norm: 0.0051, Train Linf Norm: 0.2844, Test Linf Norm: 0.1943\n",
            "Epoch 222: Train Loss: 0.0051, Test Loss: 0.0056, Train L1 Norm: 0.0056, Test L1 Norm: 0.0051, Train Linf Norm: 0.3084, Test Linf Norm: 0.1998\n",
            "Epoch 223: Train Loss: 0.0051, Test Loss: 0.0055, Train L1 Norm: 0.0054, Test L1 Norm: 0.0051, Train Linf Norm: 0.2876, Test Linf Norm: 0.1943\n",
            "Epoch 224: Train Loss: 0.0052, Test Loss: 0.0057, Train L1 Norm: 0.0053, Test L1 Norm: 0.0049, Train Linf Norm: 0.2789, Test Linf Norm: 0.1758\n",
            "Epoch 225: Train Loss: 0.0052, Test Loss: 0.0055, Train L1 Norm: 0.0056, Test L1 Norm: 0.0054, Train Linf Norm: 0.3155, Test Linf Norm: 0.2172\n",
            "Epoch 226: Train Loss: 0.0053, Test Loss: 0.0055, Train L1 Norm: 0.0056, Test L1 Norm: 0.0054, Train Linf Norm: 0.3049, Test Linf Norm: 0.2221\n",
            "Epoch 227: Train Loss: 0.0055, Test Loss: 0.0056, Train L1 Norm: 0.0059, Test L1 Norm: 0.0050, Train Linf Norm: 0.3325, Test Linf Norm: 0.1799\n",
            "Epoch 228: Train Loss: 0.0059, Test Loss: 0.0070, Train L1 Norm: 0.0059, Test L1 Norm: 0.0055, Train Linf Norm: 0.3139, Test Linf Norm: 0.1969\n",
            "Epoch 229: Train Loss: 0.0066, Test Loss: 0.0065, Train L1 Norm: 0.0073, Test L1 Norm: 0.0054, Train Linf Norm: 0.4725, Test Linf Norm: 0.1990\n",
            "Epoch 230: Train Loss: 0.0072, Test Loss: 0.0059, Train L1 Norm: 0.0073, Test L1 Norm: 0.0054, Train Linf Norm: 0.4296, Test Linf Norm: 0.2226\n",
            "Epoch 231: Train Loss: 0.0083, Test Loss: 0.0073, Train L1 Norm: 0.0070, Test L1 Norm: 0.0060, Train Linf Norm: 0.3318, Test Linf Norm: 0.2349\n",
            "Epoch 232: Train Loss: 0.0092, Test Loss: 0.0083, Train L1 Norm: 0.0076, Test L1 Norm: 0.0078, Train Linf Norm: 0.3765, Test Linf Norm: 0.3082\n",
            "Epoch 233: Train Loss: 0.0102, Test Loss: 0.0093, Train L1 Norm: 0.0082, Test L1 Norm: 0.0059, Train Linf Norm: 0.4080, Test Linf Norm: 0.1945\n",
            "Epoch 234: Train Loss: 0.0109, Test Loss: 0.0123, Train L1 Norm: 0.0106, Test L1 Norm: 0.0084, Train Linf Norm: 0.6702, Test Linf Norm: 0.2947\n",
            "Epoch 235: Train Loss: 0.0116, Test Loss: 0.0146, Train L1 Norm: 0.0095, Test L1 Norm: 0.0086, Train Linf Norm: 0.4926, Test Linf Norm: 0.2913\n",
            "Epoch 236: Train Loss: 0.0121, Test Loss: 0.0108, Train L1 Norm: 0.0095, Test L1 Norm: 0.0109, Train Linf Norm: 0.4596, Test Linf Norm: 0.5448\n",
            "Epoch 237: Train Loss: 0.0125, Test Loss: 0.0088, Train L1 Norm: 0.0094, Test L1 Norm: 0.0089, Train Linf Norm: 0.4492, Test Linf Norm: 0.4534\n",
            "Epoch 238: Train Loss: 0.0126, Test Loss: 0.0119, Train L1 Norm: 0.0116, Test L1 Norm: 0.0105, Train Linf Norm: 0.7038, Test Linf Norm: 0.3876\n",
            "Epoch 239: Train Loss: 0.0126, Test Loss: 0.0116, Train L1 Norm: 0.0116, Test L1 Norm: 0.0067, Train Linf Norm: 0.6901, Test Linf Norm: 0.2258\n",
            "Epoch 240: Train Loss: 0.0123, Test Loss: 0.0151, Train L1 Norm: 0.0114, Test L1 Norm: 0.0094, Train Linf Norm: 0.6911, Test Linf Norm: 0.3458\n",
            "Epoch 241: Train Loss: 0.0122, Test Loss: 0.0094, Train L1 Norm: 0.0111, Test L1 Norm: 0.0072, Train Linf Norm: 0.6505, Test Linf Norm: 0.2804\n",
            "Epoch 242: Train Loss: 0.0116, Test Loss: 0.0126, Train L1 Norm: 0.0101, Test L1 Norm: 0.0097, Train Linf Norm: 0.5671, Test Linf Norm: 0.4113\n",
            "Epoch 243: Train Loss: 0.0111, Test Loss: 0.0123, Train L1 Norm: 0.0085, Test L1 Norm: 0.0097, Train Linf Norm: 0.3954, Test Linf Norm: 0.3685\n",
            "Epoch 244: Train Loss: 0.0102, Test Loss: 0.0084, Train L1 Norm: 0.0119, Test L1 Norm: 0.0071, Train Linf Norm: 0.8751, Test Linf Norm: 0.2725\n",
            "Epoch 245: Train Loss: 0.0094, Test Loss: 0.0083, Train L1 Norm: 0.0089, Test L1 Norm: 0.0055, Train Linf Norm: 0.5329, Test Linf Norm: 0.1733\n",
            "Epoch 246: Train Loss: 0.0087, Test Loss: 0.0105, Train L1 Norm: 0.0074, Test L1 Norm: 0.0073, Train Linf Norm: 0.3773, Test Linf Norm: 0.2731\n",
            "Epoch 247: Train Loss: 0.0075, Test Loss: 0.0063, Train L1 Norm: 0.0068, Test L1 Norm: 0.0059, Train Linf Norm: 0.3644, Test Linf Norm: 0.2431\n",
            "Epoch 248: Train Loss: 0.0066, Test Loss: 0.0090, Train L1 Norm: 0.0065, Test L1 Norm: 0.0066, Train Linf Norm: 0.3743, Test Linf Norm: 0.2458\n",
            "Epoch 249: Train Loss: 0.0060, Test Loss: 0.0071, Train L1 Norm: 0.0064, Test L1 Norm: 0.0053, Train Linf Norm: 0.3905, Test Linf Norm: 0.1878\n",
            "Epoch 250: Train Loss: 0.0056, Test Loss: 0.0054, Train L1 Norm: 0.0059, Test L1 Norm: 0.0057, Train Linf Norm: 0.3370, Test Linf Norm: 0.2475\n",
            "Epoch 251: Train Loss: 0.0053, Test Loss: 0.0056, Train L1 Norm: 0.0062, Test L1 Norm: 0.0052, Train Linf Norm: 0.3897, Test Linf Norm: 0.2077\n",
            "Epoch 252: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0060, Test L1 Norm: 0.0051, Train Linf Norm: 0.3746, Test Linf Norm: 0.2045\n",
            "Epoch 253: Train Loss: 0.0050, Test Loss: 0.0054, Train L1 Norm: 0.0059, Test L1 Norm: 0.0049, Train Linf Norm: 0.3703, Test Linf Norm: 0.1809\n",
            "Epoch 254: Train Loss: 0.0049, Test Loss: 0.0054, Train L1 Norm: 0.0059, Test L1 Norm: 0.0049, Train Linf Norm: 0.3726, Test Linf Norm: 0.1842\n",
            "Epoch 255: Train Loss: 0.0049, Test Loss: 0.0054, Train L1 Norm: 0.0055, Test L1 Norm: 0.0051, Train Linf Norm: 0.3208, Test Linf Norm: 0.1958\n",
            "Epoch 256: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0058, Test L1 Norm: 0.0050, Train Linf Norm: 0.3605, Test Linf Norm: 0.1939\n",
            "Epoch 257: Train Loss: 0.0049, Test Loss: 0.0059, Train L1 Norm: 0.0057, Test L1 Norm: 0.0049, Train Linf Norm: 0.3536, Test Linf Norm: 0.1747\n",
            "Epoch 258: Train Loss: 0.0049, Test Loss: 0.0060, Train L1 Norm: 0.0056, Test L1 Norm: 0.0051, Train Linf Norm: 0.3450, Test Linf Norm: 0.1954\n",
            "Epoch 259: Train Loss: 0.0049, Test Loss: 0.0054, Train L1 Norm: 0.0067, Test L1 Norm: 0.0052, Train Linf Norm: 0.4717, Test Linf Norm: 0.2113\n",
            "Epoch 260: Train Loss: 0.0051, Test Loss: 0.0054, Train L1 Norm: 0.0062, Test L1 Norm: 0.0052, Train Linf Norm: 0.4019, Test Linf Norm: 0.2111\n",
            "Epoch 261: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0054, Test L1 Norm: 0.0053, Train Linf Norm: 0.3048, Test Linf Norm: 0.2200\n",
            "Epoch 262: Train Loss: 0.0055, Test Loss: 0.0063, Train L1 Norm: 0.0077, Test L1 Norm: 0.0055, Train Linf Norm: 0.5701, Test Linf Norm: 0.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:26:22,856]\u001b[0m Trial 25 finished with value: 0.005237087005376816 and parameters: {'n_layers': 5, 'n_units_0': 1592, 'n_units_1': 618, 'n_units_2': 324, 'n_units_3': 909, 'n_units_4': 852, 'hidden_activation': 'ReLU', 'output_activation': 'ReLU', 'loss': 'MAE', 'optimizer': 'Adagrad', 'lr': 0.0018170214036280867, 'batch_size': 128, 'n_epochs': 263, 'scheduler': 'CosineAnnealingLR', 't_max_fraction': 0.06741046581763749, 'eta_min': 0.0006165140566273801}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 263: Train Loss: 0.0060, Test Loss: 0.0065, Train L1 Norm: 0.0059, Test L1 Norm: 0.0052, Train Linf Norm: 0.3182, Test Linf Norm: 0.1960\n",
            "Epoch 1: Train Loss: 0.3046, Test Loss: 0.0520, Train L1 Norm: 1.0474, Test L1 Norm: 0.0645, Train Linf Norm: 110.9328, Test Linf Norm: 3.7362\n",
            "Epoch 2: Train Loss: 0.0304, Test Loss: 0.0277, Train L1 Norm: 0.1510, Test L1 Norm: 0.0329, Train Linf Norm: 15.7486, Test Linf Norm: 1.6187\n",
            "Epoch 3: Train Loss: 0.0228, Test Loss: 0.0229, Train L1 Norm: 0.1573, Test L1 Norm: 0.0348, Train Linf Norm: 17.7864, Test Linf Norm: 2.3471\n",
            "Epoch 4: Train Loss: 0.0173, Test Loss: 0.0130, Train L1 Norm: 0.1017, Test L1 Norm: 0.0276, Train Linf Norm: 10.9457, Test Linf Norm: 1.9298\n",
            "Epoch 5: Train Loss: 0.0192, Test Loss: 0.0227, Train L1 Norm: 0.1611, Test L1 Norm: 0.0369, Train Linf Norm: 18.3911, Test Linf Norm: 2.6484\n",
            "Epoch 6: Train Loss: 0.0283, Test Loss: 0.0208, Train L1 Norm: 0.0645, Test L1 Norm: 0.0204, Train Linf Norm: 5.9678, Test Linf Norm: 0.6809\n",
            "Epoch 7: Train Loss: 0.0174, Test Loss: 0.0249, Train L1 Norm: 0.1972, Test L1 Norm: 0.0205, Train Linf Norm: 23.3408, Test Linf Norm: 0.6656\n",
            "Epoch 8: Train Loss: 0.0247, Test Loss: 0.0219, Train L1 Norm: 0.0903, Test L1 Norm: 0.0255, Train Linf Norm: 9.4984, Test Linf Norm: 1.1739\n",
            "Epoch 9: Train Loss: 0.0380, Test Loss: 0.0594, Train L1 Norm: 0.0998, Test L1 Norm: 0.0381, Train Linf Norm: 10.0390, Test Linf Norm: 1.5736\n",
            "Epoch 10: Train Loss: 0.0295, Test Loss: 0.0174, Train L1 Norm: 0.1337, Test L1 Norm: 0.0318, Train Linf Norm: 14.5327, Test Linf Norm: 2.1168\n",
            "Epoch 11: Train Loss: 0.0157, Test Loss: 0.0110, Train L1 Norm: 0.0973, Test L1 Norm: 0.0159, Train Linf Norm: 10.7713, Test Linf Norm: 0.9134\n",
            "Epoch 12: Train Loss: 0.0124, Test Loss: 0.0118, Train L1 Norm: 0.0985, Test L1 Norm: 0.0185, Train Linf Norm: 11.1899, Test Linf Norm: 1.2026\n",
            "Epoch 13: Train Loss: 0.0137, Test Loss: 0.0090, Train L1 Norm: 0.0648, Test L1 Norm: 0.0204, Train Linf Norm: 6.7717, Test Linf Norm: 1.4902\n",
            "Epoch 14: Train Loss: 0.0124, Test Loss: 0.0095, Train L1 Norm: 0.0865, Test L1 Norm: 0.0132, Train Linf Norm: 9.6766, Test Linf Norm: 0.7554\n",
            "Epoch 15: Train Loss: 0.0157, Test Loss: 0.0181, Train L1 Norm: 0.0894, Test L1 Norm: 0.0473, Train Linf Norm: 9.9755, Test Linf Norm: 3.8079\n",
            "Epoch 16: Train Loss: 0.0094, Test Loss: 0.0085, Train L1 Norm: 0.0899, Test L1 Norm: 0.0126, Train Linf Norm: 10.3884, Test Linf Norm: 0.6905\n",
            "Epoch 17: Train Loss: 0.0108, Test Loss: 0.0106, Train L1 Norm: 0.0542, Test L1 Norm: 0.0114, Train Linf Norm: 5.8316, Test Linf Norm: 0.4722\n",
            "Epoch 18: Train Loss: 0.0074, Test Loss: 0.0075, Train L1 Norm: 0.0611, Test L1 Norm: 0.0114, Train Linf Norm: 6.9895, Test Linf Norm: 0.4452\n",
            "Epoch 19: Train Loss: 0.0073, Test Loss: 0.0089, Train L1 Norm: 0.0658, Test L1 Norm: 0.0134, Train Linf Norm: 7.4911, Test Linf Norm: 0.9020\n",
            "Epoch 20: Train Loss: 0.0074, Test Loss: 0.0061, Train L1 Norm: 0.0521, Test L1 Norm: 0.0136, Train Linf Norm: 5.8013, Test Linf Norm: 0.9532\n",
            "Epoch 21: Train Loss: 0.0071, Test Loss: 0.0066, Train L1 Norm: 0.0417, Test L1 Norm: 0.0097, Train Linf Norm: 4.4995, Test Linf Norm: 0.5354\n",
            "Epoch 22: Train Loss: 0.0084, Test Loss: 0.0094, Train L1 Norm: 0.0461, Test L1 Norm: 0.0168, Train Linf Norm: 4.9406, Test Linf Norm: 0.9710\n",
            "Epoch 23: Train Loss: 0.0099, Test Loss: 0.0076, Train L1 Norm: 0.0540, Test L1 Norm: 0.0126, Train Linf Norm: 5.8995, Test Linf Norm: 0.6850\n",
            "Epoch 24: Train Loss: 0.0079, Test Loss: 0.0061, Train L1 Norm: 0.0391, Test L1 Norm: 0.0117, Train Linf Norm: 4.1221, Test Linf Norm: 0.6620\n",
            "Epoch 25: Train Loss: 0.0059, Test Loss: 0.0103, Train L1 Norm: 0.0526, Test L1 Norm: 0.0144, Train Linf Norm: 5.9232, Test Linf Norm: 0.9831\n",
            "Epoch 26: Train Loss: 0.0094, Test Loss: 0.0069, Train L1 Norm: 0.0508, Test L1 Norm: 0.0121, Train Linf Norm: 5.5438, Test Linf Norm: 0.8555\n",
            "Epoch 27: Train Loss: 0.0067, Test Loss: 0.0072, Train L1 Norm: 0.0446, Test L1 Norm: 0.0090, Train Linf Norm: 4.8580, Test Linf Norm: 0.4279\n",
            "Epoch 28: Train Loss: 0.0070, Test Loss: 0.0065, Train L1 Norm: 0.0400, Test L1 Norm: 0.0094, Train Linf Norm: 4.3106, Test Linf Norm: 0.5647\n",
            "Epoch 29: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0547, Test L1 Norm: 0.0112, Train Linf Norm: 6.1510, Test Linf Norm: 0.6130\n",
            "Epoch 30: Train Loss: 0.0059, Test Loss: 0.0052, Train L1 Norm: 0.0575, Test L1 Norm: 0.0127, Train Linf Norm: 6.6063, Test Linf Norm: 0.9615\n",
            "Epoch 31: Train Loss: 0.0052, Test Loss: 0.0070, Train L1 Norm: 0.0278, Test L1 Norm: 0.0081, Train Linf Norm: 2.9415, Test Linf Norm: 0.3658\n",
            "Epoch 32: Train Loss: 0.0067, Test Loss: 0.0077, Train L1 Norm: 0.0411, Test L1 Norm: 0.0079, Train Linf Norm: 4.5629, Test Linf Norm: 0.3944\n",
            "Epoch 33: Train Loss: 0.0063, Test Loss: 0.0049, Train L1 Norm: 0.0325, Test L1 Norm: 0.0084, Train Linf Norm: 3.4455, Test Linf Norm: 0.5264\n",
            "Epoch 34: Train Loss: 0.0045, Test Loss: 0.0049, Train L1 Norm: 0.0325, Test L1 Norm: 0.0079, Train Linf Norm: 3.5620, Test Linf Norm: 0.4605\n",
            "Epoch 35: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0278, Test L1 Norm: 0.0070, Train Linf Norm: 2.9824, Test Linf Norm: 0.3484\n",
            "Epoch 36: Train Loss: 0.0047, Test Loss: 0.0052, Train L1 Norm: 0.0362, Test L1 Norm: 0.0105, Train Linf Norm: 4.0409, Test Linf Norm: 0.7233\n",
            "Epoch 37: Train Loss: 0.0054, Test Loss: 0.0065, Train L1 Norm: 0.0351, Test L1 Norm: 0.0071, Train Linf Norm: 3.8582, Test Linf Norm: 0.3197\n",
            "Epoch 38: Train Loss: 0.0053, Test Loss: 0.0045, Train L1 Norm: 0.0438, Test L1 Norm: 0.0076, Train Linf Norm: 4.9807, Test Linf Norm: 0.4635\n",
            "Epoch 39: Train Loss: 0.0045, Test Loss: 0.0051, Train L1 Norm: 0.0302, Test L1 Norm: 0.0068, Train Linf Norm: 3.2814, Test Linf Norm: 0.3016\n",
            "Epoch 40: Train Loss: 0.0066, Test Loss: 0.0078, Train L1 Norm: 0.0449, Test L1 Norm: 0.0077, Train Linf Norm: 5.1003, Test Linf Norm: 0.3769\n",
            "Epoch 41: Train Loss: 0.0056, Test Loss: 0.0051, Train L1 Norm: 0.0324, Test L1 Norm: 0.0070, Train Linf Norm: 3.5211, Test Linf Norm: 0.3566\n",
            "Epoch 42: Train Loss: 0.0048, Test Loss: 0.0049, Train L1 Norm: 0.0425, Test L1 Norm: 0.0076, Train Linf Norm: 4.8636, Test Linf Norm: 0.4504\n",
            "Epoch 43: Train Loss: 0.0043, Test Loss: 0.0045, Train L1 Norm: 0.0316, Test L1 Norm: 0.0072, Train Linf Norm: 3.5020, Test Linf Norm: 0.3499\n",
            "Epoch 44: Train Loss: 0.0045, Test Loss: 0.0066, Train L1 Norm: 0.0279, Test L1 Norm: 0.0091, Train Linf Norm: 3.0346, Test Linf Norm: 0.5621\n",
            "Epoch 45: Train Loss: 0.0067, Test Loss: 0.0060, Train L1 Norm: 0.0298, Test L1 Norm: 0.0101, Train Linf Norm: 3.1421, Test Linf Norm: 0.5410\n",
            "Epoch 46: Train Loss: 0.0046, Test Loss: 0.0043, Train L1 Norm: 0.0329, Test L1 Norm: 0.0066, Train Linf Norm: 3.6611, Test Linf Norm: 0.3370\n",
            "Epoch 47: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0311, Test L1 Norm: 0.0063, Train Linf Norm: 3.4627, Test Linf Norm: 0.3315\n",
            "Epoch 48: Train Loss: 0.0041, Test Loss: 0.0042, Train L1 Norm: 0.0287, Test L1 Norm: 0.0063, Train Linf Norm: 3.1689, Test Linf Norm: 0.3307\n",
            "Epoch 49: Train Loss: 0.0040, Test Loss: 0.0043, Train L1 Norm: 0.0303, Test L1 Norm: 0.0060, Train Linf Norm: 3.3753, Test Linf Norm: 0.2666\n",
            "Epoch 50: Train Loss: 0.0039, Test Loss: 0.0044, Train L1 Norm: 0.0231, Test L1 Norm: 0.0066, Train Linf Norm: 2.4568, Test Linf Norm: 0.3507\n",
            "Epoch 51: Train Loss: 0.0040, Test Loss: 0.0047, Train L1 Norm: 0.0221, Test L1 Norm: 0.0062, Train Linf Norm: 2.3289, Test Linf Norm: 0.2930\n",
            "Epoch 52: Train Loss: 0.0040, Test Loss: 0.0044, Train L1 Norm: 0.0249, Test L1 Norm: 0.0060, Train Linf Norm: 2.6811, Test Linf Norm: 0.2791\n",
            "Epoch 53: Train Loss: 0.0044, Test Loss: 0.0041, Train L1 Norm: 0.0245, Test L1 Norm: 0.0060, Train Linf Norm: 2.6306, Test Linf Norm: 0.2778\n",
            "Epoch 54: Train Loss: 0.0041, Test Loss: 0.0050, Train L1 Norm: 0.0280, Test L1 Norm: 0.0066, Train Linf Norm: 3.0602, Test Linf Norm: 0.3309\n",
            "Epoch 55: Train Loss: 0.0040, Test Loss: 0.0047, Train L1 Norm: 0.0226, Test L1 Norm: 0.0059, Train Linf Norm: 2.3757, Test Linf Norm: 0.2576\n",
            "Epoch 56: Train Loss: 0.0042, Test Loss: 0.0041, Train L1 Norm: 0.0232, Test L1 Norm: 0.0061, Train Linf Norm: 2.4774, Test Linf Norm: 0.2917\n",
            "Epoch 57: Train Loss: 0.0042, Test Loss: 0.0051, Train L1 Norm: 0.0217, Test L1 Norm: 0.0064, Train Linf Norm: 2.2949, Test Linf Norm: 0.3217\n",
            "Epoch 58: Train Loss: 0.0042, Test Loss: 0.0041, Train L1 Norm: 0.0226, Test L1 Norm: 0.0058, Train Linf Norm: 2.3956, Test Linf Norm: 0.2842\n",
            "Epoch 59: Train Loss: 0.0038, Test Loss: 0.0041, Train L1 Norm: 0.0239, Test L1 Norm: 0.0057, Train Linf Norm: 2.5655, Test Linf Norm: 0.2563\n",
            "Epoch 60: Train Loss: 0.0039, Test Loss: 0.0041, Train L1 Norm: 0.0253, Test L1 Norm: 0.0059, Train Linf Norm: 2.7269, Test Linf Norm: 0.2736\n",
            "Epoch 61: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0211, Test L1 Norm: 0.0059, Train Linf Norm: 2.2381, Test Linf Norm: 0.2920\n",
            "Epoch 62: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0234, Test L1 Norm: 0.0059, Train Linf Norm: 2.5349, Test Linf Norm: 0.2970\n",
            "Epoch 63: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0215, Test L1 Norm: 0.0057, Train Linf Norm: 2.2816, Test Linf Norm: 0.2689\n",
            "Epoch 64: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0224, Test L1 Norm: 0.0056, Train Linf Norm: 2.3887, Test Linf Norm: 0.2523\n",
            "Epoch 65: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0238, Test L1 Norm: 0.0058, Train Linf Norm: 2.5808, Test Linf Norm: 0.2758\n",
            "Epoch 66: Train Loss: 0.0038, Test Loss: 0.0040, Train L1 Norm: 0.0243, Test L1 Norm: 0.0056, Train Linf Norm: 2.6290, Test Linf Norm: 0.2527\n",
            "Epoch 67: Train Loss: 0.0038, Test Loss: 0.0040, Train L1 Norm: 0.0221, Test L1 Norm: 0.0056, Train Linf Norm: 2.3615, Test Linf Norm: 0.2482\n",
            "Epoch 68: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0232, Test L1 Norm: 0.0064, Train Linf Norm: 2.4985, Test Linf Norm: 0.3594\n",
            "Epoch 69: Train Loss: 0.0038, Test Loss: 0.0041, Train L1 Norm: 0.0213, Test L1 Norm: 0.0056, Train Linf Norm: 2.2451, Test Linf Norm: 0.2422\n",
            "Epoch 70: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0221, Test L1 Norm: 0.0056, Train Linf Norm: 2.3548, Test Linf Norm: 0.2450\n",
            "Epoch 71: Train Loss: 0.0037, Test Loss: 0.0041, Train L1 Norm: 0.0227, Test L1 Norm: 0.0058, Train Linf Norm: 2.4274, Test Linf Norm: 0.2700\n",
            "Epoch 72: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0226, Test L1 Norm: 0.0059, Train Linf Norm: 2.4260, Test Linf Norm: 0.3031\n",
            "Epoch 73: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0229, Test L1 Norm: 0.0057, Train Linf Norm: 2.4669, Test Linf Norm: 0.2743\n",
            "Epoch 74: Train Loss: 0.0037, Test Loss: 0.0040, Train L1 Norm: 0.0207, Test L1 Norm: 0.0057, Train Linf Norm: 2.1966, Test Linf Norm: 0.2587\n",
            "Epoch 75: Train Loss: 0.0037, Test Loss: 0.0041, Train L1 Norm: 0.0215, Test L1 Norm: 0.0058, Train Linf Norm: 2.2834, Test Linf Norm: 0.2687\n",
            "Epoch 76: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0212, Test L1 Norm: 0.0057, Train Linf Norm: 2.2657, Test Linf Norm: 0.2735\n",
            "Epoch 77: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0199, Test L1 Norm: 0.0056, Train Linf Norm: 2.0897, Test Linf Norm: 0.2565\n",
            "Epoch 78: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0202, Test L1 Norm: 0.0057, Train Linf Norm: 2.1320, Test Linf Norm: 0.2696\n",
            "Epoch 79: Train Loss: 0.0036, Test Loss: 0.0041, Train L1 Norm: 0.0204, Test L1 Norm: 0.0056, Train Linf Norm: 2.1597, Test Linf Norm: 0.2451\n",
            "Epoch 80: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0218, Test L1 Norm: 0.0057, Train Linf Norm: 2.3336, Test Linf Norm: 0.2618\n",
            "Epoch 81: Train Loss: 0.0036, Test Loss: 0.0040, Train L1 Norm: 0.0203, Test L1 Norm: 0.0057, Train Linf Norm: 2.1370, Test Linf Norm: 0.2676\n",
            "Epoch 82: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0199, Test L1 Norm: 0.0056, Train Linf Norm: 2.0839, Test Linf Norm: 0.2485\n",
            "Epoch 83: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0201, Test L1 Norm: 0.0057, Train Linf Norm: 2.1209, Test Linf Norm: 0.2625\n",
            "Epoch 84: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0202, Test L1 Norm: 0.0056, Train Linf Norm: 2.1352, Test Linf Norm: 0.2548\n",
            "Epoch 85: Train Loss: 0.0036, Test Loss: 0.0040, Train L1 Norm: 0.0203, Test L1 Norm: 0.0058, Train Linf Norm: 2.1473, Test Linf Norm: 0.2743\n",
            "Epoch 86: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0196, Test L1 Norm: 0.0056, Train Linf Norm: 2.0561, Test Linf Norm: 0.2589\n",
            "Epoch 87: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0203, Test L1 Norm: 0.0056, Train Linf Norm: 2.1401, Test Linf Norm: 0.2483\n",
            "Epoch 88: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0711, Test Linf Norm: 0.2559\n",
            "Epoch 89: Train Loss: 0.0036, Test Loss: 0.0040, Train L1 Norm: 0.0208, Test L1 Norm: 0.0056, Train Linf Norm: 2.2154, Test Linf Norm: 0.2455\n",
            "Epoch 90: Train Loss: 0.0036, Test Loss: 0.0040, Train L1 Norm: 0.0199, Test L1 Norm: 0.0056, Train Linf Norm: 2.1090, Test Linf Norm: 0.2481\n",
            "Epoch 91: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0887, Test Linf Norm: 0.2548\n",
            "Epoch 92: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0202, Test L1 Norm: 0.0056, Train Linf Norm: 2.1194, Test Linf Norm: 0.2578\n",
            "Epoch 93: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0056, Train Linf Norm: 2.0657, Test Linf Norm: 0.2556\n",
            "Epoch 94: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0199, Test L1 Norm: 0.0057, Train Linf Norm: 2.1006, Test Linf Norm: 0.2627\n",
            "Epoch 95: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0205, Test L1 Norm: 0.0056, Train Linf Norm: 2.1730, Test Linf Norm: 0.2550\n",
            "Epoch 96: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0196, Test L1 Norm: 0.0056, Train Linf Norm: 2.0501, Test Linf Norm: 0.2537\n",
            "Epoch 97: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0199, Test L1 Norm: 0.0056, Train Linf Norm: 2.1120, Test Linf Norm: 0.2569\n",
            "Epoch 98: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0195, Test L1 Norm: 0.0056, Train Linf Norm: 2.0434, Test Linf Norm: 0.2571\n",
            "Epoch 99: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0202, Test L1 Norm: 0.0057, Train Linf Norm: 2.1356, Test Linf Norm: 0.2633\n",
            "Epoch 100: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0195, Test L1 Norm: 0.0056, Train Linf Norm: 2.0500, Test Linf Norm: 0.2545\n",
            "Epoch 101: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0057, Train Linf Norm: 2.0693, Test Linf Norm: 0.2633\n",
            "Epoch 102: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0794, Test Linf Norm: 0.2589\n",
            "Epoch 103: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0056, Train Linf Norm: 2.0740, Test Linf Norm: 0.2602\n",
            "Epoch 104: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0056, Train Linf Norm: 2.0585, Test Linf Norm: 0.2557\n",
            "Epoch 105: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0203, Test L1 Norm: 0.0056, Train Linf Norm: 2.1532, Test Linf Norm: 0.2599\n",
            "Epoch 106: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0199, Test L1 Norm: 0.0056, Train Linf Norm: 2.0891, Test Linf Norm: 0.2556\n",
            "Epoch 107: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0056, Train Linf Norm: 2.0732, Test Linf Norm: 0.2569\n",
            "Epoch 108: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0196, Test L1 Norm: 0.0056, Train Linf Norm: 2.0672, Test Linf Norm: 0.2572\n",
            "Epoch 109: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0899, Test Linf Norm: 0.2570\n",
            "Epoch 110: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0816, Test Linf Norm: 0.2566\n",
            "Epoch 111: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0056, Train Linf Norm: 2.0778, Test Linf Norm: 0.2564\n",
            "Epoch 112: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0056, Train Linf Norm: 2.0721, Test Linf Norm: 0.2589\n",
            "Epoch 113: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0783, Test Linf Norm: 0.2575\n",
            "Epoch 114: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0056, Train Linf Norm: 2.0610, Test Linf Norm: 0.2557\n",
            "Epoch 115: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0200, Test L1 Norm: 0.0056, Train Linf Norm: 2.0961, Test Linf Norm: 0.2600\n",
            "Epoch 116: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0932, Test Linf Norm: 0.2577\n",
            "Epoch 117: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0860, Test Linf Norm: 0.2557\n",
            "Epoch 118: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0842, Test Linf Norm: 0.2574\n",
            "Epoch 119: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0056, Train Linf Norm: 2.0620, Test Linf Norm: 0.2576\n",
            "Epoch 120: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0833, Test Linf Norm: 0.2580\n",
            "Epoch 121: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0813, Test Linf Norm: 0.2567\n",
            "Epoch 122: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0717, Test Linf Norm: 0.2574\n",
            "Epoch 123: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0859, Test Linf Norm: 0.2579\n",
            "Epoch 124: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0692, Test Linf Norm: 0.2573\n",
            "Epoch 125: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0056, Train Linf Norm: 2.0755, Test Linf Norm: 0.2573\n",
            "Epoch 126: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0877, Test Linf Norm: 0.2576\n",
            "Epoch 127: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0817, Test Linf Norm: 0.2574\n",
            "Epoch 128: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0849, Test Linf Norm: 0.2573\n",
            "Epoch 129: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0696, Test Linf Norm: 0.2574\n",
            "Epoch 130: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0846, Test Linf Norm: 0.2576\n",
            "Epoch 131: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0748, Test Linf Norm: 0.2573\n",
            "Epoch 132: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0197, Test L1 Norm: 0.0056, Train Linf Norm: 2.0734, Test Linf Norm: 0.2570\n",
            "Epoch 133: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0810, Test Linf Norm: 0.2571\n",
            "Epoch 134: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0866, Test Linf Norm: 0.2576\n",
            "Epoch 135: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0808, Test Linf Norm: 0.2573\n",
            "Epoch 136: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0770, Test Linf Norm: 0.2575\n",
            "Epoch 137: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0848, Test Linf Norm: 0.2575\n",
            "Epoch 138: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0852, Test Linf Norm: 0.2575\n",
            "Epoch 139: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0746, Test Linf Norm: 0.2574\n",
            "Epoch 140: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0803, Test Linf Norm: 0.2574\n",
            "Epoch 141: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0792, Test Linf Norm: 0.2575\n",
            "Epoch 142: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0832, Test Linf Norm: 0.2575\n",
            "Epoch 143: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0870, Test Linf Norm: 0.2575\n",
            "Epoch 144: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0769, Test Linf Norm: 0.2574\n",
            "Epoch 145: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0778, Test Linf Norm: 0.2575\n",
            "Epoch 146: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0737, Test Linf Norm: 0.2574\n",
            "Epoch 147: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0849, Test Linf Norm: 0.2575\n",
            "Epoch 148: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0919, Test Linf Norm: 0.2575\n",
            "Epoch 149: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0830, Test Linf Norm: 0.2575\n",
            "Epoch 150: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0778, Test Linf Norm: 0.2575\n",
            "Epoch 151: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0746, Test Linf Norm: 0.2575\n",
            "Epoch 152: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0839, Test Linf Norm: 0.2575\n",
            "Epoch 153: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0839, Test Linf Norm: 0.2575\n",
            "Epoch 154: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0715, Test Linf Norm: 0.2575\n",
            "Epoch 155: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0661, Test Linf Norm: 0.2575\n",
            "Epoch 156: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0768, Test Linf Norm: 0.2575\n",
            "Epoch 157: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0797, Test Linf Norm: 0.2575\n",
            "Epoch 158: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0792, Test Linf Norm: 0.2575\n",
            "Epoch 159: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0756, Test Linf Norm: 0.2575\n",
            "Epoch 160: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0739, Test Linf Norm: 0.2575\n",
            "Epoch 161: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0834, Test Linf Norm: 0.2575\n",
            "Epoch 162: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0929, Test Linf Norm: 0.2575\n",
            "Epoch 163: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0812, Test Linf Norm: 0.2575\n",
            "Epoch 164: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0697, Test Linf Norm: 0.2575\n",
            "Epoch 165: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0752, Test Linf Norm: 0.2575\n",
            "Epoch 166: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0824, Test Linf Norm: 0.2575\n",
            "Epoch 167: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0777, Test Linf Norm: 0.2575\n",
            "Epoch 168: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0840, Test Linf Norm: 0.2575\n",
            "Epoch 169: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0748, Test Linf Norm: 0.2575\n",
            "Epoch 170: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0849, Test Linf Norm: 0.2575\n",
            "Epoch 171: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0791, Test Linf Norm: 0.2575\n",
            "Epoch 172: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0770, Test Linf Norm: 0.2575\n",
            "Epoch 173: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0626, Test Linf Norm: 0.2575\n",
            "Epoch 174: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0812, Test Linf Norm: 0.2575\n",
            "Epoch 175: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0829, Test Linf Norm: 0.2575\n",
            "Epoch 176: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0748, Test Linf Norm: 0.2575\n",
            "Epoch 177: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0791, Test Linf Norm: 0.2575\n",
            "Epoch 178: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0774, Test Linf Norm: 0.2575\n",
            "Epoch 179: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0727, Test Linf Norm: 0.2575\n",
            "Epoch 180: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0754, Test Linf Norm: 0.2575\n",
            "Epoch 181: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0818, Test Linf Norm: 0.2575\n",
            "Epoch 182: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0847, Test Linf Norm: 0.2575\n",
            "Epoch 183: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0896, Test Linf Norm: 0.2575\n",
            "Epoch 184: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0850, Test Linf Norm: 0.2575\n",
            "Epoch 185: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0797, Test Linf Norm: 0.2575\n",
            "Epoch 186: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0712, Test Linf Norm: 0.2575\n",
            "Epoch 187: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0854, Test Linf Norm: 0.2575\n",
            "Epoch 188: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0492, Test Linf Norm: 0.2575\n",
            "Epoch 189: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0842, Test Linf Norm: 0.2575\n",
            "Epoch 190: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0796, Test Linf Norm: 0.2575\n",
            "Epoch 191: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0713, Test Linf Norm: 0.2575\n",
            "Epoch 192: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0773, Test Linf Norm: 0.2575\n",
            "Epoch 193: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0725, Test Linf Norm: 0.2575\n",
            "Epoch 194: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0897, Test Linf Norm: 0.2575\n",
            "Epoch 195: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0820, Test Linf Norm: 0.2575\n",
            "Epoch 196: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0747, Test Linf Norm: 0.2575\n",
            "Epoch 197: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0665, Test Linf Norm: 0.2575\n",
            "Epoch 198: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0851, Test Linf Norm: 0.2575\n",
            "Epoch 199: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0670, Test Linf Norm: 0.2575\n",
            "Epoch 200: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0697, Test Linf Norm: 0.2575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:35:16,871]\u001b[0m Trial 26 finished with value: 0.00562210945636034 and parameters: {'n_layers': 5, 'n_units_0': 1717, 'n_units_1': 589, 'n_units_2': 359, 'n_units_3': 833, 'n_units_4': 725, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0007442950022051175, 'batch_size': 128, 'n_epochs': 201, 'scheduler': 'StepLR', 'weight_decay': 3.1630887907100614e-05, 'beta1': 0.9972887402560922, 'beta2': 0.9995310052187939, 'step_size': 15, 'gamma': 0.26445612198891955}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 201: Train Loss: 0.0036, Test Loss: 0.0039, Train L1 Norm: 0.0198, Test L1 Norm: 0.0056, Train Linf Norm: 2.0794, Test Linf Norm: 0.2575\n",
            "Epoch 1: Train Loss: 0.3903, Test Loss: 0.0849, Train L1 Norm: 0.7689, Test L1 Norm: 0.0974, Train Linf Norm: 71.9885, Test Linf Norm: 5.7724\n",
            "Epoch 2: Train Loss: 0.0416, Test Loss: 0.0216, Train L1 Norm: 0.1452, Test L1 Norm: 0.0274, Train Linf Norm: 14.0545, Test Linf Norm: 1.3437\n",
            "Epoch 3: Train Loss: 0.0247, Test Loss: 0.0145, Train L1 Norm: 0.2062, Test L1 Norm: 0.0218, Train Linf Norm: 23.8750, Test Linf Norm: 0.9600\n",
            "Epoch 4: Train Loss: 0.0150, Test Loss: 0.0145, Train L1 Norm: 0.0936, Test L1 Norm: 0.0435, Train Linf Norm: 10.1313, Test Linf Norm: 3.3805\n",
            "Epoch 5: Train Loss: 0.0172, Test Loss: 0.0145, Train L1 Norm: 0.1579, Test L1 Norm: 0.0334, Train Linf Norm: 18.3032, Test Linf Norm: 2.5080\n",
            "Epoch 6: Train Loss: 0.0142, Test Loss: 0.0140, Train L1 Norm: 0.0780, Test L1 Norm: 0.0392, Train Linf Norm: 8.3957, Test Linf Norm: 3.1847\n",
            "Epoch 7: Train Loss: 0.0160, Test Loss: 0.0166, Train L1 Norm: 0.1274, Test L1 Norm: 0.0270, Train Linf Norm: 14.8339, Test Linf Norm: 2.0530\n",
            "Epoch 8: Train Loss: 0.0175, Test Loss: 0.0170, Train L1 Norm: 0.0719, Test L1 Norm: 0.0241, Train Linf Norm: 7.7104, Test Linf Norm: 1.5537\n",
            "Epoch 9: Train Loss: 0.0200, Test Loss: 0.0186, Train L1 Norm: 0.1028, Test L1 Norm: 0.0189, Train Linf Norm: 11.5002, Test Linf Norm: 1.0962\n",
            "Epoch 10: Train Loss: 0.0132, Test Loss: 0.0144, Train L1 Norm: 0.0982, Test L1 Norm: 0.0174, Train Linf Norm: 11.2146, Test Linf Norm: 1.1509\n",
            "Epoch 11: Train Loss: 0.0184, Test Loss: 0.0092, Train L1 Norm: 0.0489, Test L1 Norm: 0.0148, Train Linf Norm: 4.8633, Test Linf Norm: 0.8027\n",
            "Epoch 12: Train Loss: 0.0194, Test Loss: 0.0324, Train L1 Norm: 0.1206, Test L1 Norm: 0.0271, Train Linf Norm: 13.8279, Test Linf Norm: 1.6073\n",
            "Epoch 13: Train Loss: 0.0221, Test Loss: 0.0202, Train L1 Norm: 0.0896, Test L1 Norm: 0.0205, Train Linf Norm: 9.8331, Test Linf Norm: 1.2393\n",
            "Epoch 14: Train Loss: 0.0124, Test Loss: 0.0094, Train L1 Norm: 0.0674, Test L1 Norm: 0.0249, Train Linf Norm: 7.3935, Test Linf Norm: 2.0054\n",
            "Epoch 15: Train Loss: 0.0100, Test Loss: 0.0100, Train L1 Norm: 0.0955, Test L1 Norm: 0.0176, Train Linf Norm: 11.1874, Test Linf Norm: 1.2970\n",
            "Epoch 16: Train Loss: 0.0088, Test Loss: 0.0077, Train L1 Norm: 0.0677, Test L1 Norm: 0.0137, Train Linf Norm: 7.8187, Test Linf Norm: 1.0534\n",
            "Epoch 17: Train Loss: 0.0083, Test Loss: 0.0081, Train L1 Norm: 0.0691, Test L1 Norm: 0.0164, Train Linf Norm: 8.0076, Test Linf Norm: 1.2231\n",
            "Epoch 18: Train Loss: 0.0080, Test Loss: 0.0073, Train L1 Norm: 0.0686, Test L1 Norm: 0.0120, Train Linf Norm: 7.9349, Test Linf Norm: 0.8961\n",
            "Epoch 19: Train Loss: 0.0081, Test Loss: 0.0085, Train L1 Norm: 0.0860, Test L1 Norm: 0.0101, Train Linf Norm: 10.1757, Test Linf Norm: 0.6348\n",
            "Epoch 20: Train Loss: 0.0107, Test Loss: 0.0086, Train L1 Norm: 0.0396, Test L1 Norm: 0.0157, Train Linf Norm: 4.1079, Test Linf Norm: 1.1709\n",
            "Epoch 21: Train Loss: 0.0088, Test Loss: 0.0143, Train L1 Norm: 0.0544, Test L1 Norm: 0.0139, Train Linf Norm: 6.1790, Test Linf Norm: 0.7910\n",
            "Epoch 22: Train Loss: 0.0101, Test Loss: 0.0193, Train L1 Norm: 0.0504, Test L1 Norm: 0.0161, Train Linf Norm: 5.6142, Test Linf Norm: 0.9169\n",
            "Epoch 23: Train Loss: 0.0085, Test Loss: 0.0066, Train L1 Norm: 0.0604, Test L1 Norm: 0.0090, Train Linf Norm: 6.8917, Test Linf Norm: 0.4902\n",
            "Epoch 24: Train Loss: 0.0078, Test Loss: 0.0151, Train L1 Norm: 0.0490, Test L1 Norm: 0.0145, Train Linf Norm: 5.4961, Test Linf Norm: 0.6890\n",
            "Epoch 25: Train Loss: 0.0107, Test Loss: 0.0150, Train L1 Norm: 0.0538, Test L1 Norm: 0.0125, Train Linf Norm: 6.0081, Test Linf Norm: 0.7078\n",
            "Epoch 26: Train Loss: 0.0120, Test Loss: 0.0099, Train L1 Norm: 0.0609, Test L1 Norm: 0.0131, Train Linf Norm: 6.8861, Test Linf Norm: 0.8864\n",
            "Epoch 27: Train Loss: 0.0087, Test Loss: 0.0067, Train L1 Norm: 0.0554, Test L1 Norm: 0.0103, Train Linf Norm: 6.3638, Test Linf Norm: 0.7031\n",
            "Epoch 28: Train Loss: 0.0066, Test Loss: 0.0075, Train L1 Norm: 0.0605, Test L1 Norm: 0.0105, Train Linf Norm: 7.0812, Test Linf Norm: 0.7228\n",
            "Epoch 29: Train Loss: 0.0076, Test Loss: 0.0063, Train L1 Norm: 0.0366, Test L1 Norm: 0.0084, Train Linf Norm: 3.9575, Test Linf Norm: 0.5110\n",
            "Epoch 30: Train Loss: 0.0091, Test Loss: 0.0082, Train L1 Norm: 0.0418, Test L1 Norm: 0.0096, Train Linf Norm: 4.6297, Test Linf Norm: 0.6241\n",
            "Epoch 31: Train Loss: 0.0059, Test Loss: 0.0053, Train L1 Norm: 0.0444, Test L1 Norm: 0.0085, Train Linf Norm: 5.0764, Test Linf Norm: 0.5672\n",
            "Epoch 32: Train Loss: 0.0055, Test Loss: 0.0062, Train L1 Norm: 0.0364, Test L1 Norm: 0.0083, Train Linf Norm: 4.0965, Test Linf Norm: 0.5115\n",
            "Epoch 33: Train Loss: 0.0065, Test Loss: 0.0059, Train L1 Norm: 0.0359, Test L1 Norm: 0.0112, Train Linf Norm: 3.9253, Test Linf Norm: 0.8282\n",
            "Epoch 34: Train Loss: 0.0085, Test Loss: 0.0083, Train L1 Norm: 0.0398, Test L1 Norm: 0.0089, Train Linf Norm: 4.4025, Test Linf Norm: 0.5644\n",
            "Epoch 35: Train Loss: 0.0059, Test Loss: 0.0060, Train L1 Norm: 0.0432, Test L1 Norm: 0.0086, Train Linf Norm: 4.9348, Test Linf Norm: 0.5219\n",
            "Epoch 36: Train Loss: 0.0064, Test Loss: 0.0096, Train L1 Norm: 0.0405, Test L1 Norm: 0.0098, Train Linf Norm: 4.5765, Test Linf Norm: 0.5385\n",
            "Epoch 37: Train Loss: 0.0075, Test Loss: 0.0053, Train L1 Norm: 0.0496, Test L1 Norm: 0.0084, Train Linf Norm: 5.6987, Test Linf Norm: 0.5821\n",
            "Epoch 38: Train Loss: 0.0055, Test Loss: 0.0058, Train L1 Norm: 0.0435, Test L1 Norm: 0.0086, Train Linf Norm: 5.0558, Test Linf Norm: 0.6089\n",
            "Epoch 39: Train Loss: 0.0056, Test Loss: 0.0051, Train L1 Norm: 0.0463, Test L1 Norm: 0.0074, Train Linf Norm: 5.3833, Test Linf Norm: 0.4377\n",
            "Epoch 40: Train Loss: 0.0055, Test Loss: 0.0047, Train L1 Norm: 0.0499, Test L1 Norm: 0.0088, Train Linf Norm: 5.7971, Test Linf Norm: 0.6461\n",
            "Epoch 41: Train Loss: 0.0050, Test Loss: 0.0048, Train L1 Norm: 0.0460, Test L1 Norm: 0.0095, Train Linf Norm: 5.3543, Test Linf Norm: 0.7009\n",
            "Epoch 42: Train Loss: 0.0051, Test Loss: 0.0050, Train L1 Norm: 0.0418, Test L1 Norm: 0.0093, Train Linf Norm: 4.8174, Test Linf Norm: 0.6881\n",
            "Epoch 43: Train Loss: 0.0050, Test Loss: 0.0064, Train L1 Norm: 0.0503, Test L1 Norm: 0.0087, Train Linf Norm: 5.9232, Test Linf Norm: 0.6005\n",
            "Epoch 44: Train Loss: 0.0059, Test Loss: 0.0052, Train L1 Norm: 0.0495, Test L1 Norm: 0.0077, Train Linf Norm: 5.7764, Test Linf Norm: 0.5054\n",
            "Epoch 45: Train Loss: 0.0056, Test Loss: 0.0057, Train L1 Norm: 0.0520, Test L1 Norm: 0.0095, Train Linf Norm: 6.0783, Test Linf Norm: 0.7055\n",
            "Epoch 46: Train Loss: 0.0052, Test Loss: 0.0046, Train L1 Norm: 0.0450, Test L1 Norm: 0.0083, Train Linf Norm: 5.2104, Test Linf Norm: 0.6072\n",
            "Epoch 47: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0448, Test L1 Norm: 0.0090, Train Linf Norm: 5.2546, Test Linf Norm: 0.6751\n",
            "Epoch 48: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0425, Test L1 Norm: 0.0079, Train Linf Norm: 4.9403, Test Linf Norm: 0.5344\n",
            "Epoch 49: Train Loss: 0.0045, Test Loss: 0.0045, Train L1 Norm: 0.0469, Test L1 Norm: 0.0082, Train Linf Norm: 5.5145, Test Linf Norm: 0.5991\n",
            "Epoch 50: Train Loss: 0.0045, Test Loss: 0.0048, Train L1 Norm: 0.0411, Test L1 Norm: 0.0082, Train Linf Norm: 4.7800, Test Linf Norm: 0.5818\n",
            "Epoch 51: Train Loss: 0.0045, Test Loss: 0.0044, Train L1 Norm: 0.0418, Test L1 Norm: 0.0073, Train Linf Norm: 4.8859, Test Linf Norm: 0.4752\n",
            "Epoch 52: Train Loss: 0.0044, Test Loss: 0.0047, Train L1 Norm: 0.0424, Test L1 Norm: 0.0082, Train Linf Norm: 4.9437, Test Linf Norm: 0.5941\n",
            "Epoch 53: Train Loss: 0.0044, Test Loss: 0.0050, Train L1 Norm: 0.0401, Test L1 Norm: 0.0077, Train Linf Norm: 4.6486, Test Linf Norm: 0.5210\n",
            "Epoch 54: Train Loss: 0.0047, Test Loss: 0.0052, Train L1 Norm: 0.0406, Test L1 Norm: 0.0073, Train Linf Norm: 4.7423, Test Linf Norm: 0.4739\n",
            "Epoch 55: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0423, Test L1 Norm: 0.0080, Train Linf Norm: 4.9336, Test Linf Norm: 0.5581\n",
            "Epoch 56: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0403, Test L1 Norm: 0.0077, Train Linf Norm: 4.6911, Test Linf Norm: 0.5238\n",
            "Epoch 57: Train Loss: 0.0048, Test Loss: 0.0055, Train L1 Norm: 0.0419, Test L1 Norm: 0.0083, Train Linf Norm: 4.8807, Test Linf Norm: 0.5753\n",
            "Epoch 58: Train Loss: 0.0050, Test Loss: 0.0045, Train L1 Norm: 0.0405, Test L1 Norm: 0.0073, Train Linf Norm: 4.6941, Test Linf Norm: 0.4835\n",
            "Epoch 59: Train Loss: 0.0047, Test Loss: 0.0052, Train L1 Norm: 0.0415, Test L1 Norm: 0.0076, Train Linf Norm: 4.8361, Test Linf Norm: 0.5185\n",
            "Epoch 60: Train Loss: 0.0047, Test Loss: 0.0046, Train L1 Norm: 0.0372, Test L1 Norm: 0.0075, Train Linf Norm: 4.2984, Test Linf Norm: 0.5182\n",
            "Epoch 61: Train Loss: 0.0043, Test Loss: 0.0045, Train L1 Norm: 0.0399, Test L1 Norm: 0.0082, Train Linf Norm: 4.6418, Test Linf Norm: 0.5993\n",
            "Epoch 62: Train Loss: 0.0042, Test Loss: 0.0043, Train L1 Norm: 0.0391, Test L1 Norm: 0.0075, Train Linf Norm: 4.5405, Test Linf Norm: 0.5229\n",
            "Epoch 63: Train Loss: 0.0041, Test Loss: 0.0043, Train L1 Norm: 0.0385, Test L1 Norm: 0.0081, Train Linf Norm: 4.4889, Test Linf Norm: 0.5904\n",
            "Epoch 64: Train Loss: 0.0042, Test Loss: 0.0043, Train L1 Norm: 0.0385, Test L1 Norm: 0.0077, Train Linf Norm: 4.4967, Test Linf Norm: 0.5494\n",
            "Epoch 65: Train Loss: 0.0042, Test Loss: 0.0045, Train L1 Norm: 0.0398, Test L1 Norm: 0.0077, Train Linf Norm: 4.6528, Test Linf Norm: 0.5475\n",
            "Epoch 66: Train Loss: 0.0044, Test Loss: 0.0049, Train L1 Norm: 0.0389, Test L1 Norm: 0.0077, Train Linf Norm: 4.5593, Test Linf Norm: 0.5399\n",
            "Epoch 67: Train Loss: 0.0043, Test Loss: 0.0042, Train L1 Norm: 0.0389, Test L1 Norm: 0.0074, Train Linf Norm: 4.3780, Test Linf Norm: 0.5300\n",
            "Epoch 68: Train Loss: 0.0043, Test Loss: 0.0043, Train L1 Norm: 0.0393, Test L1 Norm: 0.0076, Train Linf Norm: 4.5890, Test Linf Norm: 0.5424\n",
            "Epoch 69: Train Loss: 0.0043, Test Loss: 0.0045, Train L1 Norm: 0.0397, Test L1 Norm: 0.0075, Train Linf Norm: 4.6486, Test Linf Norm: 0.5179\n",
            "Epoch 70: Train Loss: 0.0043, Test Loss: 0.0044, Train L1 Norm: 0.0379, Test L1 Norm: 0.0073, Train Linf Norm: 4.3990, Test Linf Norm: 0.5115\n",
            "Epoch 71: Train Loss: 0.0043, Test Loss: 0.0044, Train L1 Norm: 0.0383, Test L1 Norm: 0.0075, Train Linf Norm: 4.4663, Test Linf Norm: 0.5288\n",
            "Epoch 72: Train Loss: 0.0042, Test Loss: 0.0043, Train L1 Norm: 0.0393, Test L1 Norm: 0.0075, Train Linf Norm: 4.5818, Test Linf Norm: 0.5339\n",
            "Epoch 73: Train Loss: 0.0041, Test Loss: 0.0043, Train L1 Norm: 0.0366, Test L1 Norm: 0.0071, Train Linf Norm: 4.2181, Test Linf Norm: 0.4844\n",
            "Epoch 74: Train Loss: 0.0041, Test Loss: 0.0043, Train L1 Norm: 0.0377, Test L1 Norm: 0.0073, Train Linf Norm: 4.3550, Test Linf Norm: 0.5096\n",
            "Epoch 75: Train Loss: 0.0041, Test Loss: 0.0044, Train L1 Norm: 0.0383, Test L1 Norm: 0.0079, Train Linf Norm: 4.4685, Test Linf Norm: 0.5727\n",
            "Epoch 76: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0400, Test L1 Norm: 0.0073, Train Linf Norm: 4.6861, Test Linf Norm: 0.5132\n",
            "Epoch 77: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0377, Test L1 Norm: 0.0073, Train Linf Norm: 4.3799, Test Linf Norm: 0.5125\n",
            "Epoch 78: Train Loss: 0.0041, Test Loss: 0.0045, Train L1 Norm: 0.0385, Test L1 Norm: 0.0076, Train Linf Norm: 4.4753, Test Linf Norm: 0.5364\n",
            "Epoch 79: Train Loss: 0.0042, Test Loss: 0.0045, Train L1 Norm: 0.0378, Test L1 Norm: 0.0074, Train Linf Norm: 4.3417, Test Linf Norm: 0.5194\n",
            "Epoch 80: Train Loss: 0.0041, Test Loss: 0.0045, Train L1 Norm: 0.0379, Test L1 Norm: 0.0074, Train Linf Norm: 4.3930, Test Linf Norm: 0.5192\n",
            "Epoch 81: Train Loss: 0.0041, Test Loss: 0.0042, Train L1 Norm: 0.0376, Test L1 Norm: 0.0073, Train Linf Norm: 4.3989, Test Linf Norm: 0.5128\n",
            "Epoch 82: Train Loss: 0.0041, Test Loss: 0.0043, Train L1 Norm: 0.0380, Test L1 Norm: 0.0074, Train Linf Norm: 4.4350, Test Linf Norm: 0.5178\n",
            "Epoch 83: Train Loss: 0.0041, Test Loss: 0.0043, Train L1 Norm: 0.0380, Test L1 Norm: 0.0073, Train Linf Norm: 4.3876, Test Linf Norm: 0.5164\n",
            "Epoch 84: Train Loss: 0.0041, Test Loss: 0.0043, Train L1 Norm: 0.0381, Test L1 Norm: 0.0074, Train Linf Norm: 4.4671, Test Linf Norm: 0.5258\n",
            "Epoch 85: Train Loss: 0.0040, Test Loss: 0.0043, Train L1 Norm: 0.0382, Test L1 Norm: 0.0073, Train Linf Norm: 4.4269, Test Linf Norm: 0.5106\n",
            "Epoch 86: Train Loss: 0.0041, Test Loss: 0.0043, Train L1 Norm: 0.0384, Test L1 Norm: 0.0074, Train Linf Norm: 4.4745, Test Linf Norm: 0.5207\n",
            "Epoch 87: Train Loss: 0.0041, Test Loss: 0.0043, Train L1 Norm: 0.0379, Test L1 Norm: 0.0073, Train Linf Norm: 4.3901, Test Linf Norm: 0.5158\n",
            "Epoch 88: Train Loss: 0.0040, Test Loss: 0.0043, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3055, Test Linf Norm: 0.5182\n",
            "Epoch 89: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0380, Test L1 Norm: 0.0073, Train Linf Norm: 4.4090, Test Linf Norm: 0.5162\n",
            "Epoch 90: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0371, Test L1 Norm: 0.0073, Train Linf Norm: 4.3215, Test Linf Norm: 0.5183\n",
            "Epoch 91: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3452, Test Linf Norm: 0.5165\n",
            "Epoch 92: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0377, Test L1 Norm: 0.0073, Train Linf Norm: 4.3846, Test Linf Norm: 0.5119\n",
            "Epoch 93: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3243, Test Linf Norm: 0.5169\n",
            "Epoch 94: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0376, Test L1 Norm: 0.0073, Train Linf Norm: 4.3709, Test Linf Norm: 0.5185\n",
            "Epoch 95: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0377, Test L1 Norm: 0.0073, Train Linf Norm: 4.4097, Test Linf Norm: 0.5171\n",
            "Epoch 96: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0376, Test L1 Norm: 0.0073, Train Linf Norm: 4.3769, Test Linf Norm: 0.5134\n",
            "Epoch 97: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3608, Test Linf Norm: 0.5122\n",
            "Epoch 98: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0378, Test L1 Norm: 0.0073, Train Linf Norm: 4.4165, Test Linf Norm: 0.5194\n",
            "Epoch 99: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0378, Test L1 Norm: 0.0073, Train Linf Norm: 4.4320, Test Linf Norm: 0.5162\n",
            "Epoch 100: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0373, Test L1 Norm: 0.0073, Train Linf Norm: 4.3359, Test Linf Norm: 0.5129\n",
            "Epoch 101: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0376, Test L1 Norm: 0.0073, Train Linf Norm: 4.3646, Test Linf Norm: 0.5196\n",
            "Epoch 102: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0376, Test L1 Norm: 0.0073, Train Linf Norm: 4.3760, Test Linf Norm: 0.5180\n",
            "Epoch 103: Train Loss: 0.0040, Test Loss: 0.0043, Train L1 Norm: 0.0372, Test L1 Norm: 0.0073, Train Linf Norm: 4.3454, Test Linf Norm: 0.5100\n",
            "Epoch 104: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3696, Test Linf Norm: 0.5185\n",
            "Epoch 105: Train Loss: 0.0040, Test Loss: 0.0043, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3559, Test Linf Norm: 0.5165\n",
            "Epoch 106: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0072, Train Linf Norm: 4.3657, Test Linf Norm: 0.5112\n",
            "Epoch 107: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3660, Test Linf Norm: 0.5169\n",
            "Epoch 108: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3760, Test Linf Norm: 0.5160\n",
            "Epoch 109: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3737, Test Linf Norm: 0.5148\n",
            "Epoch 110: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3525, Test Linf Norm: 0.5155\n",
            "Epoch 111: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3516, Test Linf Norm: 0.5151\n",
            "Epoch 112: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3477, Test Linf Norm: 0.5167\n",
            "Epoch 113: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.2989, Test Linf Norm: 0.5142\n",
            "Epoch 114: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0373, Test L1 Norm: 0.0073, Train Linf Norm: 4.3545, Test Linf Norm: 0.5127\n",
            "Epoch 115: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3727, Test Linf Norm: 0.5182\n",
            "Epoch 116: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3519, Test Linf Norm: 0.5150\n",
            "Epoch 117: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3690, Test Linf Norm: 0.5154\n",
            "Epoch 118: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0376, Test L1 Norm: 0.0073, Train Linf Norm: 4.3712, Test Linf Norm: 0.5170\n",
            "Epoch 119: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3576, Test Linf Norm: 0.5138\n",
            "Epoch 120: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3484, Test Linf Norm: 0.5174\n",
            "Epoch 121: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3776, Test Linf Norm: 0.5168\n",
            "Epoch 122: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3641, Test Linf Norm: 0.5153\n",
            "Epoch 123: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3553, Test Linf Norm: 0.5156\n",
            "Epoch 124: Train Loss: 0.0040, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3701, Test Linf Norm: 0.5155\n",
            "Epoch 125: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3511, Test Linf Norm: 0.5155\n",
            "Epoch 126: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3718, Test Linf Norm: 0.5157\n",
            "Epoch 127: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3859, Test Linf Norm: 0.5156\n",
            "Epoch 128: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3448, Test Linf Norm: 0.5157\n",
            "Epoch 129: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3738, Test Linf Norm: 0.5157\n",
            "Epoch 130: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3514, Test Linf Norm: 0.5154\n",
            "Epoch 131: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3676, Test Linf Norm: 0.5156\n",
            "Epoch 132: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3818, Test Linf Norm: 0.5157\n",
            "Epoch 133: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3695, Test Linf Norm: 0.5154\n",
            "Epoch 134: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3628, Test Linf Norm: 0.5151\n",
            "Epoch 135: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3628, Test Linf Norm: 0.5153\n",
            "Epoch 136: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3629, Test Linf Norm: 0.5156\n",
            "Epoch 137: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0375, Test L1 Norm: 0.0073, Train Linf Norm: 4.3669, Test Linf Norm: 0.5157\n",
            "Epoch 138: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3552, Test Linf Norm: 0.5155\n",
            "Epoch 139: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3465, Test Linf Norm: 0.5155\n",
            "Epoch 140: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3651, Test Linf Norm: 0.5155\n",
            "Epoch 141: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3610, Test Linf Norm: 0.5155\n",
            "Epoch 142: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3456, Test Linf Norm: 0.5154\n",
            "Epoch 143: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3516, Test Linf Norm: 0.5154\n",
            "Epoch 144: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3505, Test Linf Norm: 0.5154\n",
            "Epoch 145: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3441, Test Linf Norm: 0.5154\n",
            "Epoch 146: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3574, Test Linf Norm: 0.5154\n",
            "Epoch 147: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3675, Test Linf Norm: 0.5155\n",
            "Epoch 148: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3310, Test Linf Norm: 0.5155\n",
            "Epoch 149: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3779, Test Linf Norm: 0.5155\n",
            "Epoch 150: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3735, Test Linf Norm: 0.5154\n",
            "Epoch 151: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3678, Test Linf Norm: 0.5154\n",
            "Epoch 152: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3562, Test Linf Norm: 0.5154\n",
            "Epoch 153: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3477, Test Linf Norm: 0.5154\n",
            "Epoch 154: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3600, Test Linf Norm: 0.5154\n",
            "Epoch 155: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3659, Test Linf Norm: 0.5154\n",
            "Epoch 156: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3543, Test Linf Norm: 0.5154\n",
            "Epoch 157: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3280, Test Linf Norm: 0.5154\n",
            "Epoch 158: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3672, Test Linf Norm: 0.5154\n",
            "Epoch 159: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3640, Test Linf Norm: 0.5154\n",
            "Epoch 160: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 3.6957, Test Linf Norm: 0.5154\n",
            "Epoch 161: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3442, Test Linf Norm: 0.5154\n",
            "Epoch 162: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3478, Test Linf Norm: 0.5154\n",
            "Epoch 163: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3627, Test Linf Norm: 0.5154\n",
            "Epoch 164: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3607, Test Linf Norm: 0.5154\n",
            "Epoch 165: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3786, Test Linf Norm: 0.5154\n",
            "Epoch 166: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3719, Test Linf Norm: 0.5154\n",
            "Epoch 167: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3697, Test Linf Norm: 0.5154\n",
            "Epoch 168: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3755, Test Linf Norm: 0.5154\n",
            "Epoch 169: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3564, Test Linf Norm: 0.5154\n",
            "Epoch 170: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3325, Test Linf Norm: 0.5154\n",
            "Epoch 171: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3881, Test Linf Norm: 0.5154\n",
            "Epoch 172: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3115, Test Linf Norm: 0.5154\n",
            "Epoch 173: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3510, Test Linf Norm: 0.5154\n",
            "Epoch 174: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3783, Test Linf Norm: 0.5154\n",
            "Epoch 175: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3531, Test Linf Norm: 0.5154\n",
            "Epoch 176: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3629, Test Linf Norm: 0.5154\n",
            "Epoch 177: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3529, Test Linf Norm: 0.5154\n",
            "Epoch 178: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3621, Test Linf Norm: 0.5154\n",
            "Epoch 179: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3525, Test Linf Norm: 0.5154\n",
            "Epoch 180: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3337, Test Linf Norm: 0.5154\n",
            "Epoch 181: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3544, Test Linf Norm: 0.5154\n",
            "Epoch 182: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3519, Test Linf Norm: 0.5154\n",
            "Epoch 183: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3693, Test Linf Norm: 0.5154\n",
            "Epoch 184: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3718, Test Linf Norm: 0.5154\n",
            "Epoch 185: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3492, Test Linf Norm: 0.5154\n",
            "Epoch 186: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3605, Test Linf Norm: 0.5154\n",
            "Epoch 187: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3493, Test Linf Norm: 0.5154\n",
            "Epoch 188: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3485, Test Linf Norm: 0.5154\n",
            "Epoch 189: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3553, Test Linf Norm: 0.5154\n",
            "Epoch 190: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3682, Test Linf Norm: 0.5154\n",
            "Epoch 191: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3569, Test Linf Norm: 0.5154\n",
            "Epoch 192: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3617, Test Linf Norm: 0.5154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:44:27,302]\u001b[0m Trial 27 finished with value: 0.007278379293158651 and parameters: {'n_layers': 5, 'n_units_0': 1862, 'n_units_1': 657, 'n_units_2': 334, 'n_units_3': 916, 'n_units_4': 1192, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0007625606649989964, 'batch_size': 128, 'n_epochs': 193, 'scheduler': 'StepLR', 'weight_decay': 0.0008263766700659897, 'beta1': 0.9986981254335395, 'beta2': 0.9995327773635835, 'step_size': 15, 'gamma': 0.269364315663476}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 193: Train Loss: 0.0039, Test Loss: 0.0042, Train L1 Norm: 0.0374, Test L1 Norm: 0.0073, Train Linf Norm: 4.3793, Test Linf Norm: 0.5154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:44:30,076]\u001b[0m Trial 28 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1565, Test Loss: 0.0070, Train L1 Norm: 1.8513, Test L1 Norm: 0.3463, Train Linf Norm: 201.9131, Test Linf Norm: 25.6661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:44:32,592]\u001b[0m Trial 29 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 2.4250, Test Loss: 0.0793, Train L1 Norm: 2.8720, Test L1 Norm: 0.6180, Train Linf Norm: 292.7251, Test Linf Norm: 45.9126\n",
            "Epoch 1: Train Loss: 0.0970, Test Loss: 0.0065, Train L1 Norm: 0.5907, Test L1 Norm: 0.1205, Train Linf Norm: 96.6596, Test Linf Norm: 13.7742\n",
            "Epoch 2: Train Loss: 0.0091, Test Loss: 0.0038, Train L1 Norm: 0.4875, Test L1 Norm: 0.0973, Train Linf Norm: 103.4617, Test Linf Norm: 10.6875\n",
            "Epoch 3: Train Loss: 0.0096, Test Loss: 0.0167, Train L1 Norm: 0.3971, Test L1 Norm: 0.0980, Train Linf Norm: 83.8779, Test Linf Norm: 8.0109\n",
            "Epoch 4: Train Loss: 0.0091, Test Loss: 0.0051, Train L1 Norm: 0.3171, Test L1 Norm: 0.0846, Train Linf Norm: 65.8888, Test Linf Norm: 9.2906\n",
            "Epoch 5: Train Loss: 0.0079, Test Loss: 0.0014, Train L1 Norm: 0.2929, Test L1 Norm: 0.0574, Train Linf Norm: 61.6691, Test Linf Norm: 6.3267\n",
            "Epoch 6: Train Loss: 0.0048, Test Loss: 0.0365, Train L1 Norm: 0.2233, Test L1 Norm: 0.1052, Train Linf Norm: 46.5523, Test Linf Norm: 7.7457\n",
            "Epoch 7: Train Loss: 0.0091, Test Loss: 0.0216, Train L1 Norm: 0.2788, Test L1 Norm: 0.0873, Train Linf Norm: 58.8236, Test Linf Norm: 8.0358\n",
            "Epoch 8: Train Loss: 0.0074, Test Loss: 0.0030, Train L1 Norm: 0.2638, Test L1 Norm: 0.0536, Train Linf Norm: 54.9264, Test Linf Norm: 6.3921\n",
            "Epoch 9: Train Loss: 0.0045, Test Loss: 0.0051, Train L1 Norm: 0.2039, Test L1 Norm: 0.0676, Train Linf Norm: 41.8138, Test Linf Norm: 6.8120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:44:52,387]\u001b[0m Trial 30 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss: 0.0062, Test Loss: 0.0016, Train L1 Norm: 0.2072, Test L1 Norm: 0.0529, Train Linf Norm: 42.3345, Test Linf Norm: 6.3517\n",
            "Epoch 1: Train Loss: 0.1932, Test Loss: 0.0895, Train L1 Norm: 0.6147, Test L1 Norm: 0.0894, Train Linf Norm: 62.3015, Test Linf Norm: 5.3120\n",
            "Epoch 2: Train Loss: 0.0556, Test Loss: 0.0344, Train L1 Norm: 0.2200, Test L1 Norm: 0.0439, Train Linf Norm: 23.7218, Test Linf Norm: 2.9322\n",
            "Epoch 3: Train Loss: 0.0553, Test Loss: 0.0754, Train L1 Norm: 0.1720, Test L1 Norm: 0.0519, Train Linf Norm: 18.2513, Test Linf Norm: 2.1370\n",
            "Epoch 4: Train Loss: 0.0504, Test Loss: 0.0371, Train L1 Norm: 0.1400, Test L1 Norm: 0.0344, Train Linf Norm: 14.4713, Test Linf Norm: 2.2912\n",
            "Epoch 5: Train Loss: 0.0464, Test Loss: 0.0530, Train L1 Norm: 0.1181, Test L1 Norm: 0.0294, Train Linf Norm: 12.1170, Test Linf Norm: 1.1333\n",
            "Epoch 6: Train Loss: 0.0393, Test Loss: 0.0303, Train L1 Norm: 0.0936, Test L1 Norm: 0.0266, Train Linf Norm: 9.3729, Test Linf Norm: 1.6095\n",
            "Epoch 7: Train Loss: 0.0555, Test Loss: 0.0452, Train L1 Norm: 0.1004, Test L1 Norm: 0.0337, Train Linf Norm: 9.5476, Test Linf Norm: 1.8687\n",
            "Epoch 8: Train Loss: 0.0373, Test Loss: 0.0703, Train L1 Norm: 0.0989, Test L1 Norm: 0.0444, Train Linf Norm: 10.2222, Test Linf Norm: 2.4749\n",
            "Epoch 9: Train Loss: 0.0319, Test Loss: 0.0285, Train L1 Norm: 0.0944, Test L1 Norm: 0.0206, Train Linf Norm: 9.9174, Test Linf Norm: 1.0148\n",
            "Epoch 10: Train Loss: 0.0365, Test Loss: 0.0898, Train L1 Norm: 0.0696, Test L1 Norm: 0.0390, Train Linf Norm: 6.5890, Test Linf Norm: 0.9891\n",
            "Epoch 11: Train Loss: 0.0334, Test Loss: 0.0419, Train L1 Norm: 0.0906, Test L1 Norm: 0.0268, Train Linf Norm: 9.4596, Test Linf Norm: 1.1234\n",
            "Epoch 12: Train Loss: 0.0308, Test Loss: 0.0278, Train L1 Norm: 0.0689, Test L1 Norm: 0.0276, Train Linf Norm: 6.8031, Test Linf Norm: 1.3919\n",
            "Epoch 13: Train Loss: 0.0385, Test Loss: 0.0554, Train L1 Norm: 0.0756, Test L1 Norm: 0.0302, Train Linf Norm: 7.3288, Test Linf Norm: 1.2096\n",
            "Epoch 14: Train Loss: 0.0360, Test Loss: 0.0287, Train L1 Norm: 0.0784, Test L1 Norm: 0.0266, Train Linf Norm: 7.7797, Test Linf Norm: 1.4470\n",
            "Epoch 15: Train Loss: 0.0324, Test Loss: 0.0221, Train L1 Norm: 0.0827, Test L1 Norm: 0.0188, Train Linf Norm: 8.5127, Test Linf Norm: 1.0758\n",
            "Epoch 16: Train Loss: 0.0181, Test Loss: 0.0132, Train L1 Norm: 0.0632, Test L1 Norm: 0.0165, Train Linf Norm: 6.8850, Test Linf Norm: 1.1106\n",
            "Epoch 17: Train Loss: 0.0165, Test Loss: 0.0118, Train L1 Norm: 0.0544, Test L1 Norm: 0.0117, Train Linf Norm: 5.8303, Test Linf Norm: 0.6938\n",
            "Epoch 18: Train Loss: 0.0146, Test Loss: 0.0146, Train L1 Norm: 0.0474, Test L1 Norm: 0.0119, Train Linf Norm: 5.0564, Test Linf Norm: 0.6431\n",
            "Epoch 19: Train Loss: 0.0131, Test Loss: 0.0101, Train L1 Norm: 0.0423, Test L1 Norm: 0.0111, Train Linf Norm: 4.4586, Test Linf Norm: 0.6910\n",
            "Epoch 20: Train Loss: 0.0136, Test Loss: 0.0124, Train L1 Norm: 0.0418, Test L1 Norm: 0.0111, Train Linf Norm: 4.3770, Test Linf Norm: 0.5373\n",
            "Epoch 21: Train Loss: 0.0125, Test Loss: 0.0098, Train L1 Norm: 0.0374, Test L1 Norm: 0.0099, Train Linf Norm: 3.8678, Test Linf Norm: 0.5003\n",
            "Epoch 22: Train Loss: 0.0148, Test Loss: 0.0137, Train L1 Norm: 0.0292, Test L1 Norm: 0.0124, Train Linf Norm: 2.7039, Test Linf Norm: 0.7647\n",
            "Epoch 23: Train Loss: 0.0139, Test Loss: 0.0180, Train L1 Norm: 0.0351, Test L1 Norm: 0.0123, Train Linf Norm: 3.5078, Test Linf Norm: 0.4727\n",
            "Epoch 24: Train Loss: 0.0136, Test Loss: 0.0110, Train L1 Norm: 0.0322, Test L1 Norm: 0.0101, Train Linf Norm: 3.1876, Test Linf Norm: 0.5036\n",
            "Epoch 25: Train Loss: 0.0136, Test Loss: 0.0105, Train L1 Norm: 0.0312, Test L1 Norm: 0.0141, Train Linf Norm: 3.0744, Test Linf Norm: 0.8724\n",
            "Epoch 26: Train Loss: 0.0146, Test Loss: 0.0103, Train L1 Norm: 0.0336, Test L1 Norm: 0.0094, Train Linf Norm: 3.3544, Test Linf Norm: 0.4821\n",
            "Epoch 27: Train Loss: 0.0133, Test Loss: 0.0093, Train L1 Norm: 0.0278, Test L1 Norm: 0.0085, Train Linf Norm: 2.6704, Test Linf Norm: 0.4334\n",
            "Epoch 28: Train Loss: 0.0127, Test Loss: 0.0135, Train L1 Norm: 0.0321, Test L1 Norm: 0.0099, Train Linf Norm: 3.2513, Test Linf Norm: 0.4737\n",
            "Epoch 29: Train Loss: 0.0147, Test Loss: 0.0177, Train L1 Norm: 0.0292, Test L1 Norm: 0.0149, Train Linf Norm: 2.7651, Test Linf Norm: 0.8614\n",
            "Epoch 30: Train Loss: 0.0143, Test Loss: 0.0200, Train L1 Norm: 0.0269, Test L1 Norm: 0.0151, Train Linf Norm: 2.5126, Test Linf Norm: 0.7129\n",
            "Epoch 31: Train Loss: 0.0093, Test Loss: 0.0084, Train L1 Norm: 0.0249, Test L1 Norm: 0.0085, Train Linf Norm: 2.5143, Test Linf Norm: 0.4885\n",
            "Epoch 32: Train Loss: 0.0088, Test Loss: 0.0087, Train L1 Norm: 0.0246, Test L1 Norm: 0.0086, Train Linf Norm: 2.5044, Test Linf Norm: 0.4810\n",
            "Epoch 33: Train Loss: 0.0095, Test Loss: 0.0077, Train L1 Norm: 0.0201, Test L1 Norm: 0.0081, Train Linf Norm: 1.9008, Test Linf Norm: 0.4751\n",
            "Epoch 34: Train Loss: 0.0086, Test Loss: 0.0081, Train L1 Norm: 0.0210, Test L1 Norm: 0.0080, Train Linf Norm: 2.0634, Test Linf Norm: 0.4457\n",
            "Epoch 35: Train Loss: 0.0088, Test Loss: 0.0121, Train L1 Norm: 0.0185, Test L1 Norm: 0.0086, Train Linf Norm: 1.7388, Test Linf Norm: 0.4302\n",
            "Epoch 36: Train Loss: 0.0087, Test Loss: 0.0079, Train L1 Norm: 0.0210, Test L1 Norm: 0.0079, Train Linf Norm: 2.0423, Test Linf Norm: 0.4136\n",
            "Epoch 37: Train Loss: 0.0084, Test Loss: 0.0081, Train L1 Norm: 0.0179, Test L1 Norm: 0.0076, Train Linf Norm: 1.6674, Test Linf Norm: 0.4118\n",
            "Epoch 38: Train Loss: 0.0092, Test Loss: 0.0076, Train L1 Norm: 0.0187, Test L1 Norm: 0.0075, Train Linf Norm: 1.7532, Test Linf Norm: 0.4336\n",
            "Epoch 39: Train Loss: 0.0085, Test Loss: 0.0085, Train L1 Norm: 0.0204, Test L1 Norm: 0.0082, Train Linf Norm: 1.9822, Test Linf Norm: 0.4651\n",
            "Epoch 40: Train Loss: 0.0086, Test Loss: 0.0094, Train L1 Norm: 0.0165, Test L1 Norm: 0.0082, Train Linf Norm: 1.4642, Test Linf Norm: 0.4058\n",
            "Epoch 41: Train Loss: 0.0086, Test Loss: 0.0091, Train L1 Norm: 0.0189, Test L1 Norm: 0.0076, Train Linf Norm: 1.7844, Test Linf Norm: 0.3866\n",
            "Epoch 42: Train Loss: 0.0087, Test Loss: 0.0089, Train L1 Norm: 0.0177, Test L1 Norm: 0.0079, Train Linf Norm: 1.6470, Test Linf Norm: 0.4437\n",
            "Epoch 43: Train Loss: 0.0083, Test Loss: 0.0081, Train L1 Norm: 0.0173, Test L1 Norm: 0.0075, Train Linf Norm: 1.6192, Test Linf Norm: 0.4252\n",
            "Epoch 44: Train Loss: 0.0090, Test Loss: 0.0076, Train L1 Norm: 0.0173, Test L1 Norm: 0.0076, Train Linf Norm: 1.5754, Test Linf Norm: 0.4515\n",
            "Epoch 45: Train Loss: 0.0086, Test Loss: 0.0080, Train L1 Norm: 0.0204, Test L1 Norm: 0.0076, Train Linf Norm: 1.9997, Test Linf Norm: 0.4207\n",
            "Epoch 46: Train Loss: 0.0073, Test Loss: 0.0072, Train L1 Norm: 0.0156, Test L1 Norm: 0.0075, Train Linf Norm: 1.4631, Test Linf Norm: 0.4478\n",
            "Epoch 47: Train Loss: 0.0072, Test Loss: 0.0074, Train L1 Norm: 0.0151, Test L1 Norm: 0.0071, Train Linf Norm: 1.4034, Test Linf Norm: 0.4065\n",
            "Epoch 48: Train Loss: 0.0074, Test Loss: 0.0074, Train L1 Norm: 0.0147, Test L1 Norm: 0.0070, Train Linf Norm: 1.3358, Test Linf Norm: 0.4004\n",
            "Epoch 49: Train Loss: 0.0075, Test Loss: 0.0099, Train L1 Norm: 0.0153, Test L1 Norm: 0.0079, Train Linf Norm: 1.4164, Test Linf Norm: 0.3957\n",
            "Epoch 50: Train Loss: 0.0075, Test Loss: 0.0070, Train L1 Norm: 0.0145, Test L1 Norm: 0.0071, Train Linf Norm: 1.3117, Test Linf Norm: 0.4141\n",
            "Epoch 51: Train Loss: 0.0073, Test Loss: 0.0071, Train L1 Norm: 0.0139, Test L1 Norm: 0.0070, Train Linf Norm: 1.2259, Test Linf Norm: 0.4046\n",
            "Epoch 52: Train Loss: 0.0073, Test Loss: 0.0070, Train L1 Norm: 0.0151, Test L1 Norm: 0.0072, Train Linf Norm: 1.3914, Test Linf Norm: 0.4277\n",
            "Epoch 53: Train Loss: 0.0071, Test Loss: 0.0071, Train L1 Norm: 0.0146, Test L1 Norm: 0.0071, Train Linf Norm: 1.3428, Test Linf Norm: 0.4165\n",
            "Epoch 54: Train Loss: 0.0073, Test Loss: 0.0073, Train L1 Norm: 0.0139, Test L1 Norm: 0.0071, Train Linf Norm: 1.2353, Test Linf Norm: 0.4045\n",
            "Epoch 55: Train Loss: 0.0074, Test Loss: 0.0070, Train L1 Norm: 0.0144, Test L1 Norm: 0.0069, Train Linf Norm: 1.2913, Test Linf Norm: 0.3971\n",
            "Epoch 56: Train Loss: 0.0072, Test Loss: 0.0071, Train L1 Norm: 0.0134, Test L1 Norm: 0.0069, Train Linf Norm: 1.1922, Test Linf Norm: 0.3924\n",
            "Epoch 57: Train Loss: 0.0072, Test Loss: 0.0070, Train L1 Norm: 0.0138, Test L1 Norm: 0.0069, Train Linf Norm: 1.2403, Test Linf Norm: 0.3971\n",
            "Epoch 58: Train Loss: 0.0074, Test Loss: 0.0071, Train L1 Norm: 0.0139, Test L1 Norm: 0.0069, Train Linf Norm: 1.2491, Test Linf Norm: 0.4028\n",
            "Epoch 59: Train Loss: 0.0072, Test Loss: 0.0074, Train L1 Norm: 0.0141, Test L1 Norm: 0.0071, Train Linf Norm: 1.2609, Test Linf Norm: 0.3863\n",
            "Epoch 60: Train Loss: 0.0071, Test Loss: 0.0070, Train L1 Norm: 0.0149, Test L1 Norm: 0.0071, Train Linf Norm: 1.3838, Test Linf Norm: 0.4144\n",
            "Epoch 61: Train Loss: 0.0068, Test Loss: 0.0068, Train L1 Norm: 0.0129, Test L1 Norm: 0.0068, Train Linf Norm: 1.1371, Test Linf Norm: 0.3945\n",
            "Epoch 62: Train Loss: 0.0067, Test Loss: 0.0068, Train L1 Norm: 0.0128, Test L1 Norm: 0.0069, Train Linf Norm: 1.1376, Test Linf Norm: 0.4048\n",
            "Epoch 63: Train Loss: 0.0068, Test Loss: 0.0068, Train L1 Norm: 0.0131, Test L1 Norm: 0.0068, Train Linf Norm: 1.1713, Test Linf Norm: 0.4004\n",
            "Epoch 64: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0134, Test L1 Norm: 0.0068, Train Linf Norm: 1.2044, Test Linf Norm: 0.3980\n",
            "Epoch 65: Train Loss: 0.0067, Test Loss: 0.0068, Train L1 Norm: 0.0134, Test L1 Norm: 0.0068, Train Linf Norm: 1.2068, Test Linf Norm: 0.3957\n",
            "Epoch 66: Train Loss: 0.0068, Test Loss: 0.0070, Train L1 Norm: 0.0129, Test L1 Norm: 0.0068, Train Linf Norm: 1.1423, Test Linf Norm: 0.3954\n",
            "Epoch 67: Train Loss: 0.0067, Test Loss: 0.0070, Train L1 Norm: 0.0132, Test L1 Norm: 0.0070, Train Linf Norm: 1.1887, Test Linf Norm: 0.4137\n",
            "Epoch 68: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0123, Test L1 Norm: 0.0068, Train Linf Norm: 1.0724, Test Linf Norm: 0.3939\n",
            "Epoch 69: Train Loss: 0.0067, Test Loss: 0.0069, Train L1 Norm: 0.0135, Test L1 Norm: 0.0068, Train Linf Norm: 1.2208, Test Linf Norm: 0.3950\n",
            "Epoch 70: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0127, Test L1 Norm: 0.0069, Train Linf Norm: 1.1174, Test Linf Norm: 0.4038\n",
            "Epoch 71: Train Loss: 0.0067, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0068, Train Linf Norm: 1.0834, Test Linf Norm: 0.4031\n",
            "Epoch 72: Train Loss: 0.0067, Test Loss: 0.0068, Train L1 Norm: 0.0132, Test L1 Norm: 0.0069, Train Linf Norm: 1.1810, Test Linf Norm: 0.4097\n",
            "Epoch 73: Train Loss: 0.0067, Test Loss: 0.0068, Train L1 Norm: 0.0127, Test L1 Norm: 0.0068, Train Linf Norm: 1.1155, Test Linf Norm: 0.3989\n",
            "Epoch 74: Train Loss: 0.0067, Test Loss: 0.0068, Train L1 Norm: 0.0126, Test L1 Norm: 0.0068, Train Linf Norm: 1.1078, Test Linf Norm: 0.4028\n",
            "Epoch 75: Train Loss: 0.0067, Test Loss: 0.0072, Train L1 Norm: 0.0130, Test L1 Norm: 0.0070, Train Linf Norm: 1.1642, Test Linf Norm: 0.4049\n",
            "Epoch 76: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0128, Test L1 Norm: 0.0067, Train Linf Norm: 1.1329, Test Linf Norm: 0.3961\n",
            "Epoch 77: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0068, Train Linf Norm: 1.0945, Test Linf Norm: 0.4004\n",
            "Epoch 78: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0131, Test L1 Norm: 0.0068, Train Linf Norm: 1.1791, Test Linf Norm: 0.3971\n",
            "Epoch 79: Train Loss: 0.0066, Test Loss: 0.0068, Train L1 Norm: 0.0128, Test L1 Norm: 0.0068, Train Linf Norm: 1.1347, Test Linf Norm: 0.3963\n",
            "Epoch 80: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1138, Test Linf Norm: 0.3956\n",
            "Epoch 81: Train Loss: 0.0066, Test Loss: 0.0068, Train L1 Norm: 0.0127, Test L1 Norm: 0.0068, Train Linf Norm: 1.1170, Test Linf Norm: 0.3952\n",
            "Epoch 82: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0068, Train Linf Norm: 1.1108, Test Linf Norm: 0.3988\n",
            "Epoch 83: Train Loss: 0.0066, Test Loss: 0.0068, Train L1 Norm: 0.0133, Test L1 Norm: 0.0068, Train Linf Norm: 1.2099, Test Linf Norm: 0.3948\n",
            "Epoch 84: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0131, Test L1 Norm: 0.0068, Train Linf Norm: 1.1838, Test Linf Norm: 0.3969\n",
            "Epoch 85: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0128, Test L1 Norm: 0.0067, Train Linf Norm: 1.1496, Test Linf Norm: 0.3959\n",
            "Epoch 86: Train Loss: 0.0066, Test Loss: 0.0068, Train L1 Norm: 0.0132, Test L1 Norm: 0.0068, Train Linf Norm: 1.1815, Test Linf Norm: 0.3942\n",
            "Epoch 87: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0128, Test L1 Norm: 0.0068, Train Linf Norm: 1.1366, Test Linf Norm: 0.3987\n",
            "Epoch 88: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0131, Test L1 Norm: 0.0067, Train Linf Norm: 1.1562, Test Linf Norm: 0.3923\n",
            "Epoch 89: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0068, Train Linf Norm: 1.1144, Test Linf Norm: 0.3973\n",
            "Epoch 90: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0129, Test L1 Norm: 0.0068, Train Linf Norm: 1.1672, Test Linf Norm: 0.4002\n",
            "Epoch 91: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1122, Test Linf Norm: 0.3946\n",
            "Epoch 92: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1118, Test Linf Norm: 0.3962\n",
            "Epoch 93: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0129, Test L1 Norm: 0.0067, Train Linf Norm: 1.1607, Test Linf Norm: 0.3968\n",
            "Epoch 94: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1269, Test Linf Norm: 0.3963\n",
            "Epoch 95: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1247, Test Linf Norm: 0.3922\n",
            "Epoch 96: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0128, Test L1 Norm: 0.0067, Train Linf Norm: 1.1385, Test Linf Norm: 0.3951\n",
            "Epoch 97: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1310, Test Linf Norm: 0.3953\n",
            "Epoch 98: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0068, Train Linf Norm: 1.1312, Test Linf Norm: 0.3973\n",
            "Epoch 99: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0125, Test L1 Norm: 0.0067, Train Linf Norm: 1.0962, Test Linf Norm: 0.3920\n",
            "Epoch 100: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0128, Test L1 Norm: 0.0067, Train Linf Norm: 1.1376, Test Linf Norm: 0.3952\n",
            "Epoch 101: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0129, Test L1 Norm: 0.0068, Train Linf Norm: 1.1542, Test Linf Norm: 0.3976\n",
            "Epoch 102: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1097, Test Linf Norm: 0.3957\n",
            "Epoch 103: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0128, Test L1 Norm: 0.0068, Train Linf Norm: 1.1481, Test Linf Norm: 0.3970\n",
            "Epoch 104: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0125, Test L1 Norm: 0.0067, Train Linf Norm: 1.1178, Test Linf Norm: 0.3915\n",
            "Epoch 105: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0068, Train Linf Norm: 1.1285, Test Linf Norm: 0.3974\n",
            "Epoch 106: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1269, Test Linf Norm: 0.3945\n",
            "Epoch 107: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1209, Test Linf Norm: 0.3946\n",
            "Epoch 108: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1143, Test Linf Norm: 0.3953\n",
            "Epoch 109: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1124, Test Linf Norm: 0.3941\n",
            "Epoch 110: Train Loss: 0.0066, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1157, Test Linf Norm: 0.3947\n",
            "Epoch 111: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1218, Test Linf Norm: 0.3938\n",
            "Epoch 112: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1268, Test Linf Norm: 0.3955\n",
            "Epoch 113: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1145, Test Linf Norm: 0.3944\n",
            "Epoch 114: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1158, Test Linf Norm: 0.3945\n",
            "Epoch 115: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1254, Test Linf Norm: 0.3955\n",
            "Epoch 116: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1166, Test Linf Norm: 0.3942\n",
            "Epoch 117: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1289, Test Linf Norm: 0.3945\n",
            "Epoch 118: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.0976, Test Linf Norm: 0.3940\n",
            "Epoch 119: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1264, Test Linf Norm: 0.3940\n",
            "Epoch 120: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1290, Test Linf Norm: 0.3948\n",
            "Epoch 121: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1428, Test Linf Norm: 0.3945\n",
            "Epoch 122: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1293, Test Linf Norm: 0.3946\n",
            "Epoch 123: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1286, Test Linf Norm: 0.3949\n",
            "Epoch 124: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1202, Test Linf Norm: 0.3945\n",
            "Epoch 125: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1316, Test Linf Norm: 0.3949\n",
            "Epoch 126: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1116, Test Linf Norm: 0.3950\n",
            "Epoch 127: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1345, Test Linf Norm: 0.3947\n",
            "Epoch 128: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1090, Test Linf Norm: 0.3952\n",
            "Epoch 129: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1207, Test Linf Norm: 0.3949\n",
            "Epoch 130: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1327, Test Linf Norm: 0.3946\n",
            "Epoch 131: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1337, Test Linf Norm: 0.3952\n",
            "Epoch 132: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1251, Test Linf Norm: 0.3944\n",
            "Epoch 133: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1209, Test Linf Norm: 0.3948\n",
            "Epoch 134: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1184, Test Linf Norm: 0.3947\n",
            "Epoch 135: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 1.1259, Test Linf Norm: 0.3948\n",
            "Epoch 136: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1051, Test Linf Norm: 0.3947\n",
            "Epoch 137: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1176, Test Linf Norm: 0.3946\n",
            "Epoch 138: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1301, Test Linf Norm: 0.3946\n",
            "Epoch 139: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1161, Test Linf Norm: 0.3946\n",
            "Epoch 140: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1182, Test Linf Norm: 0.3947\n",
            "Epoch 141: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1177, Test Linf Norm: 0.3946\n",
            "Epoch 142: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1218, Test Linf Norm: 0.3947\n",
            "Epoch 143: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1302, Test Linf Norm: 0.3946\n",
            "Epoch 144: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1248, Test Linf Norm: 0.3946\n",
            "Epoch 145: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1183, Test Linf Norm: 0.3946\n",
            "Epoch 146: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1334, Test Linf Norm: 0.3947\n",
            "Epoch 147: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1292, Test Linf Norm: 0.3947\n",
            "Epoch 148: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1146, Test Linf Norm: 0.3947\n",
            "Epoch 149: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1154, Test Linf Norm: 0.3947\n",
            "Epoch 150: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1346, Test Linf Norm: 0.3947\n",
            "Epoch 151: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1255, Test Linf Norm: 0.3947\n",
            "Epoch 152: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1223, Test Linf Norm: 0.3947\n",
            "Epoch 153: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1240, Test Linf Norm: 0.3947\n",
            "Epoch 154: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1219, Test Linf Norm: 0.3947\n",
            "Epoch 155: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1278, Test Linf Norm: 0.3947\n",
            "Epoch 156: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1188, Test Linf Norm: 0.3947\n",
            "Epoch 157: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1209, Test Linf Norm: 0.3947\n",
            "Epoch 158: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1249, Test Linf Norm: 0.3947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:51:08,227]\u001b[0m Trial 31 finished with value: 0.006728735327720642 and parameters: {'n_layers': 4, 'n_units_0': 1633, 'n_units_1': 614, 'n_units_2': 467, 'n_units_3': 408, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0007260950191510552, 'batch_size': 128, 'n_epochs': 159, 'scheduler': 'StepLR', 'weight_decay': 0.004558362364970325, 'beta1': 0.9780452491380748, 'beta2': 0.9995804045220867, 'step_size': 15, 'gamma': 0.24796806994629467}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 159: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 1.1289, Test Linf Norm: 0.3947\n",
            "Epoch 1: Train Loss: 0.1927, Test Loss: 0.0534, Train L1 Norm: 0.4116, Test L1 Norm: 0.0445, Train Linf Norm: 35.8202, Test Linf Norm: 2.0714\n",
            "Epoch 2: Train Loss: 0.0698, Test Loss: 0.0401, Train L1 Norm: 0.1549, Test L1 Norm: 0.0509, Train Linf Norm: 14.8701, Test Linf Norm: 3.0366\n",
            "Epoch 3: Train Loss: 0.0464, Test Loss: 0.0229, Train L1 Norm: 0.1719, Test L1 Norm: 0.0338, Train Linf Norm: 18.3301, Test Linf Norm: 2.0800\n",
            "Epoch 4: Train Loss: 0.0422, Test Loss: 0.0534, Train L1 Norm: 0.1960, Test L1 Norm: 0.0593, Train Linf Norm: 21.8966, Test Linf Norm: 3.3991\n",
            "Epoch 5: Train Loss: 0.0376, Test Loss: 0.0225, Train L1 Norm: 0.1379, Test L1 Norm: 0.0315, Train Linf Norm: 14.9059, Test Linf Norm: 2.0835\n",
            "Epoch 6: Train Loss: 0.0401, Test Loss: 0.0337, Train L1 Norm: 0.1291, Test L1 Norm: 0.0303, Train Linf Norm: 13.6598, Test Linf Norm: 1.8463\n",
            "Epoch 7: Train Loss: 0.0276, Test Loss: 0.0280, Train L1 Norm: 0.0871, Test L1 Norm: 0.0256, Train Linf Norm: 9.1032, Test Linf Norm: 1.4769\n",
            "Epoch 8: Train Loss: 0.0279, Test Loss: 0.0371, Train L1 Norm: 0.0687, Test L1 Norm: 0.0331, Train Linf Norm: 6.6400, Test Linf Norm: 1.5120\n",
            "Epoch 9: Train Loss: 0.0364, Test Loss: 0.0373, Train L1 Norm: 0.0592, Test L1 Norm: 0.0279, Train Linf Norm: 5.2089, Test Linf Norm: 1.4470\n",
            "Epoch 10: Train Loss: 0.0322, Test Loss: 0.0458, Train L1 Norm: 0.0886, Test L1 Norm: 0.0240, Train Linf Norm: 9.1080, Test Linf Norm: 0.8004\n",
            "Epoch 11: Train Loss: 0.0259, Test Loss: 0.0347, Train L1 Norm: 0.0762, Test L1 Norm: 0.0282, Train Linf Norm: 7.7918, Test Linf Norm: 1.4327\n",
            "Epoch 12: Train Loss: 0.0281, Test Loss: 0.0596, Train L1 Norm: 0.0753, Test L1 Norm: 0.0325, Train Linf Norm: 7.6651, Test Linf Norm: 1.4848\n",
            "Epoch 13: Train Loss: 0.0287, Test Loss: 0.0362, Train L1 Norm: 0.0771, Test L1 Norm: 0.0324, Train Linf Norm: 7.9674, Test Linf Norm: 1.9463\n",
            "Epoch 14: Train Loss: 0.0280, Test Loss: 0.0152, Train L1 Norm: 0.0504, Test L1 Norm: 0.0155, Train Linf Norm: 4.6391, Test Linf Norm: 0.9071\n",
            "Epoch 15: Train Loss: 0.0272, Test Loss: 0.0230, Train L1 Norm: 0.0922, Test L1 Norm: 0.0164, Train Linf Norm: 10.0072, Test Linf Norm: 0.7006\n",
            "Epoch 16: Train Loss: 0.0115, Test Loss: 0.0087, Train L1 Norm: 0.0452, Test L1 Norm: 0.0131, Train Linf Norm: 4.8670, Test Linf Norm: 0.9127\n",
            "Epoch 17: Train Loss: 0.0121, Test Loss: 0.0113, Train L1 Norm: 0.0466, Test L1 Norm: 0.0117, Train Linf Norm: 5.0278, Test Linf Norm: 0.7392\n",
            "Epoch 18: Train Loss: 0.0126, Test Loss: 0.0113, Train L1 Norm: 0.0452, Test L1 Norm: 0.0104, Train Linf Norm: 4.8761, Test Linf Norm: 0.6223\n",
            "Epoch 19: Train Loss: 0.0114, Test Loss: 0.0116, Train L1 Norm: 0.0334, Test L1 Norm: 0.0110, Train Linf Norm: 3.3371, Test Linf Norm: 0.6556\n",
            "Epoch 20: Train Loss: 0.0166, Test Loss: 0.0138, Train L1 Norm: 0.0430, Test L1 Norm: 0.0110, Train Linf Norm: 4.3983, Test Linf Norm: 0.6049\n",
            "Epoch 21: Train Loss: 0.0116, Test Loss: 0.0134, Train L1 Norm: 0.0385, Test L1 Norm: 0.0120, Train Linf Norm: 3.8771, Test Linf Norm: 0.6614\n",
            "Epoch 22: Train Loss: 0.0125, Test Loss: 0.0103, Train L1 Norm: 0.0332, Test L1 Norm: 0.0090, Train Linf Norm: 3.3419, Test Linf Norm: 0.4200\n",
            "Epoch 23: Train Loss: 0.0117, Test Loss: 0.0152, Train L1 Norm: 0.0250, Test L1 Norm: 0.0135, Train Linf Norm: 2.3250, Test Linf Norm: 0.8223\n",
            "Epoch 24: Train Loss: 0.0113, Test Loss: 0.0093, Train L1 Norm: 0.0309, Test L1 Norm: 0.0083, Train Linf Norm: 3.1139, Test Linf Norm: 0.4193\n",
            "Epoch 25: Train Loss: 0.0103, Test Loss: 0.0102, Train L1 Norm: 0.0324, Test L1 Norm: 0.0086, Train Linf Norm: 3.3471, Test Linf Norm: 0.4522\n",
            "Epoch 26: Train Loss: 0.0118, Test Loss: 0.0107, Train L1 Norm: 0.0296, Test L1 Norm: 0.0100, Train Linf Norm: 2.9134, Test Linf Norm: 0.6043\n",
            "Epoch 27: Train Loss: 0.0099, Test Loss: 0.0105, Train L1 Norm: 0.0271, Test L1 Norm: 0.0124, Train Linf Norm: 2.6514, Test Linf Norm: 0.7886\n",
            "Epoch 28: Train Loss: 0.0100, Test Loss: 0.0166, Train L1 Norm: 0.0252, Test L1 Norm: 0.0139, Train Linf Norm: 2.4452, Test Linf Norm: 0.7171\n",
            "Epoch 29: Train Loss: 0.0126, Test Loss: 0.0140, Train L1 Norm: 0.0327, Test L1 Norm: 0.0097, Train Linf Norm: 3.3124, Test Linf Norm: 0.3719\n",
            "Epoch 30: Train Loss: 0.0113, Test Loss: 0.0094, Train L1 Norm: 0.0328, Test L1 Norm: 0.0087, Train Linf Norm: 3.3829, Test Linf Norm: 0.4933\n",
            "Epoch 31: Train Loss: 0.0073, Test Loss: 0.0076, Train L1 Norm: 0.0222, Test L1 Norm: 0.0077, Train Linf Norm: 2.2659, Test Linf Norm: 0.4533\n",
            "Epoch 32: Train Loss: 0.0081, Test Loss: 0.0070, Train L1 Norm: 0.0246, Test L1 Norm: 0.0072, Train Linf Norm: 2.5224, Test Linf Norm: 0.4118\n",
            "Epoch 33: Train Loss: 0.0070, Test Loss: 0.0062, Train L1 Norm: 0.0244, Test L1 Norm: 0.0075, Train Linf Norm: 2.5673, Test Linf Norm: 0.4879\n",
            "Epoch 34: Train Loss: 0.0073, Test Loss: 0.0064, Train L1 Norm: 0.0221, Test L1 Norm: 0.0069, Train Linf Norm: 2.2457, Test Linf Norm: 0.4001\n",
            "Epoch 35: Train Loss: 0.0076, Test Loss: 0.0079, Train L1 Norm: 0.0233, Test L1 Norm: 0.0096, Train Linf Norm: 2.3903, Test Linf Norm: 0.6301\n",
            "Epoch 36: Train Loss: 0.0070, Test Loss: 0.0062, Train L1 Norm: 0.0193, Test L1 Norm: 0.0077, Train Linf Norm: 1.9100, Test Linf Norm: 0.5082\n",
            "Epoch 37: Train Loss: 0.0073, Test Loss: 0.0072, Train L1 Norm: 0.0208, Test L1 Norm: 0.0071, Train Linf Norm: 2.0887, Test Linf Norm: 0.4114\n",
            "Epoch 38: Train Loss: 0.0069, Test Loss: 0.0066, Train L1 Norm: 0.0196, Test L1 Norm: 0.0068, Train Linf Norm: 1.9481, Test Linf Norm: 0.3653\n",
            "Epoch 39: Train Loss: 0.0075, Test Loss: 0.0074, Train L1 Norm: 0.0190, Test L1 Norm: 0.0074, Train Linf Norm: 1.8494, Test Linf Norm: 0.4409\n",
            "Epoch 40: Train Loss: 0.0070, Test Loss: 0.0074, Train L1 Norm: 0.0193, Test L1 Norm: 0.0078, Train Linf Norm: 1.9002, Test Linf Norm: 0.4827\n",
            "Epoch 41: Train Loss: 0.0065, Test Loss: 0.0061, Train L1 Norm: 0.0181, Test L1 Norm: 0.0068, Train Linf Norm: 1.7594, Test Linf Norm: 0.3889\n",
            "Epoch 42: Train Loss: 0.0071, Test Loss: 0.0088, Train L1 Norm: 0.0196, Test L1 Norm: 0.0067, Train Linf Norm: 1.9296, Test Linf Norm: 0.2988\n",
            "Epoch 43: Train Loss: 0.0065, Test Loss: 0.0058, Train L1 Norm: 0.0208, Test L1 Norm: 0.0062, Train Linf Norm: 2.1455, Test Linf Norm: 0.3346\n",
            "Epoch 44: Train Loss: 0.0068, Test Loss: 0.0062, Train L1 Norm: 0.0187, Test L1 Norm: 0.0067, Train Linf Norm: 1.8344, Test Linf Norm: 0.3980\n",
            "Epoch 45: Train Loss: 0.0074, Test Loss: 0.0076, Train L1 Norm: 0.0183, Test L1 Norm: 0.0082, Train Linf Norm: 1.7931, Test Linf Norm: 0.4838\n",
            "Epoch 46: Train Loss: 0.0057, Test Loss: 0.0055, Train L1 Norm: 0.0177, Test L1 Norm: 0.0063, Train Linf Norm: 1.7902, Test Linf Norm: 0.3779\n",
            "Epoch 47: Train Loss: 0.0057, Test Loss: 0.0071, Train L1 Norm: 0.0175, Test L1 Norm: 0.0063, Train Linf Norm: 1.7651, Test Linf Norm: 0.3273\n",
            "Epoch 48: Train Loss: 0.0057, Test Loss: 0.0057, Train L1 Norm: 0.0166, Test L1 Norm: 0.0066, Train Linf Norm: 1.6554, Test Linf Norm: 0.4147\n",
            "Epoch 49: Train Loss: 0.0056, Test Loss: 0.0056, Train L1 Norm: 0.0178, Test L1 Norm: 0.0064, Train Linf Norm: 1.8104, Test Linf Norm: 0.3874\n",
            "Epoch 50: Train Loss: 0.0055, Test Loss: 0.0059, Train L1 Norm: 0.0174, Test L1 Norm: 0.0066, Train Linf Norm: 1.7603, Test Linf Norm: 0.4099\n",
            "Epoch 51: Train Loss: 0.0059, Test Loss: 0.0058, Train L1 Norm: 0.0162, Test L1 Norm: 0.0061, Train Linf Norm: 1.5910, Test Linf Norm: 0.3448\n",
            "Epoch 52: Train Loss: 0.0056, Test Loss: 0.0068, Train L1 Norm: 0.0158, Test L1 Norm: 0.0064, Train Linf Norm: 1.5420, Test Linf Norm: 0.3553\n",
            "Epoch 53: Train Loss: 0.0061, Test Loss: 0.0058, Train L1 Norm: 0.0162, Test L1 Norm: 0.0066, Train Linf Norm: 1.5870, Test Linf Norm: 0.4110\n",
            "Epoch 54: Train Loss: 0.0057, Test Loss: 0.0100, Train L1 Norm: 0.0165, Test L1 Norm: 0.0073, Train Linf Norm: 1.6403, Test Linf Norm: 0.2946\n",
            "Epoch 55: Train Loss: 0.0057, Test Loss: 0.0054, Train L1 Norm: 0.0158, Test L1 Norm: 0.0061, Train Linf Norm: 1.5500, Test Linf Norm: 0.3580\n",
            "Epoch 56: Train Loss: 0.0055, Test Loss: 0.0059, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 1.4391, Test Linf Norm: 0.3556\n",
            "Epoch 57: Train Loss: 0.0056, Test Loss: 0.0060, Train L1 Norm: 0.0156, Test L1 Norm: 0.0062, Train Linf Norm: 1.5353, Test Linf Norm: 0.3501\n",
            "Epoch 58: Train Loss: 0.0056, Test Loss: 0.0057, Train L1 Norm: 0.0158, Test L1 Norm: 0.0060, Train Linf Norm: 1.5516, Test Linf Norm: 0.3332\n",
            "Epoch 59: Train Loss: 0.0055, Test Loss: 0.0055, Train L1 Norm: 0.0152, Test L1 Norm: 0.0061, Train Linf Norm: 1.4846, Test Linf Norm: 0.3648\n",
            "Epoch 60: Train Loss: 0.0056, Test Loss: 0.0056, Train L1 Norm: 0.0143, Test L1 Norm: 0.0059, Train Linf Norm: 1.3633, Test Linf Norm: 0.3230\n",
            "Epoch 61: Train Loss: 0.0052, Test Loss: 0.0056, Train L1 Norm: 0.0139, Test L1 Norm: 0.0060, Train Linf Norm: 1.3365, Test Linf Norm: 0.3534\n",
            "Epoch 62: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0146, Test L1 Norm: 0.0059, Train Linf Norm: 1.4341, Test Linf Norm: 0.3425\n",
            "Epoch 63: Train Loss: 0.0051, Test Loss: 0.0056, Train L1 Norm: 0.0150, Test L1 Norm: 0.0060, Train Linf Norm: 1.4666, Test Linf Norm: 0.3458\n",
            "Epoch 64: Train Loss: 0.0051, Test Loss: 0.0054, Train L1 Norm: 0.0145, Test L1 Norm: 0.0060, Train Linf Norm: 1.4118, Test Linf Norm: 0.3490\n",
            "Epoch 65: Train Loss: 0.0051, Test Loss: 0.0054, Train L1 Norm: 0.0147, Test L1 Norm: 0.0059, Train Linf Norm: 1.4478, Test Linf Norm: 0.3436\n",
            "Epoch 66: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0146, Test L1 Norm: 0.0058, Train Linf Norm: 1.4163, Test Linf Norm: 0.3211\n",
            "Epoch 67: Train Loss: 0.0051, Test Loss: 0.0055, Train L1 Norm: 0.0145, Test L1 Norm: 0.0060, Train Linf Norm: 1.4101, Test Linf Norm: 0.3487\n",
            "Epoch 68: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0143, Test L1 Norm: 0.0060, Train Linf Norm: 1.3751, Test Linf Norm: 0.3580\n",
            "Epoch 69: Train Loss: 0.0053, Test Loss: 0.0055, Train L1 Norm: 0.0143, Test L1 Norm: 0.0060, Train Linf Norm: 1.3613, Test Linf Norm: 0.3498\n",
            "Epoch 70: Train Loss: 0.0051, Test Loss: 0.0055, Train L1 Norm: 0.0139, Test L1 Norm: 0.0059, Train Linf Norm: 1.3229, Test Linf Norm: 0.3402\n",
            "Epoch 71: Train Loss: 0.0051, Test Loss: 0.0054, Train L1 Norm: 0.0140, Test L1 Norm: 0.0059, Train Linf Norm: 1.3491, Test Linf Norm: 0.3443\n",
            "Epoch 72: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0140, Test L1 Norm: 0.0058, Train Linf Norm: 1.3349, Test Linf Norm: 0.3265\n",
            "Epoch 73: Train Loss: 0.0052, Test Loss: 0.0056, Train L1 Norm: 0.0140, Test L1 Norm: 0.0062, Train Linf Norm: 1.3565, Test Linf Norm: 0.3759\n",
            "Epoch 74: Train Loss: 0.0052, Test Loss: 0.0055, Train L1 Norm: 0.0139, Test L1 Norm: 0.0059, Train Linf Norm: 1.3386, Test Linf Norm: 0.3316\n",
            "Epoch 75: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0142, Test L1 Norm: 0.0059, Train Linf Norm: 1.3737, Test Linf Norm: 0.3424\n",
            "Epoch 76: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0135, Test L1 Norm: 0.0059, Train Linf Norm: 1.2921, Test Linf Norm: 0.3441\n",
            "Epoch 77: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0059, Train Linf Norm: 1.3108, Test Linf Norm: 0.3430\n",
            "Epoch 78: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0138, Test L1 Norm: 0.0058, Train Linf Norm: 1.3377, Test Linf Norm: 0.3308\n",
            "Epoch 79: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0141, Test L1 Norm: 0.0058, Train Linf Norm: 1.3779, Test Linf Norm: 0.3400\n",
            "Epoch 80: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0059, Train Linf Norm: 1.3262, Test Linf Norm: 0.3416\n",
            "Epoch 81: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0138, Test L1 Norm: 0.0059, Train Linf Norm: 1.0903, Test Linf Norm: 0.3431\n",
            "Epoch 82: Train Loss: 0.0050, Test Loss: 0.0054, Train L1 Norm: 0.0140, Test L1 Norm: 0.0059, Train Linf Norm: 1.3518, Test Linf Norm: 0.3432\n",
            "Epoch 83: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0138, Test L1 Norm: 0.0059, Train Linf Norm: 1.3322, Test Linf Norm: 0.3453\n",
            "Epoch 84: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0138, Test L1 Norm: 0.0059, Train Linf Norm: 1.3366, Test Linf Norm: 0.3432\n",
            "Epoch 85: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0139, Test L1 Norm: 0.0060, Train Linf Norm: 1.3463, Test Linf Norm: 0.3544\n",
            "Epoch 86: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3300, Test Linf Norm: 0.3349\n",
            "Epoch 87: Train Loss: 0.0050, Test Loss: 0.0054, Train L1 Norm: 0.0141, Test L1 Norm: 0.0058, Train Linf Norm: 1.3759, Test Linf Norm: 0.3289\n",
            "Epoch 88: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0134, Test L1 Norm: 0.0059, Train Linf Norm: 1.2834, Test Linf Norm: 0.3438\n",
            "Epoch 89: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0134, Test L1 Norm: 0.0058, Train Linf Norm: 1.2925, Test Linf Norm: 0.3304\n",
            "Epoch 90: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0140, Test L1 Norm: 0.0058, Train Linf Norm: 1.3611, Test Linf Norm: 0.3399\n",
            "Epoch 91: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0139, Test L1 Norm: 0.0058, Train Linf Norm: 1.3473, Test Linf Norm: 0.3411\n",
            "Epoch 92: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3056, Test Linf Norm: 0.3346\n",
            "Epoch 93: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3211, Test Linf Norm: 0.3399\n",
            "Epoch 94: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0138, Test L1 Norm: 0.0058, Train Linf Norm: 1.3345, Test Linf Norm: 0.3358\n",
            "Epoch 95: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3140, Test Linf Norm: 0.3407\n",
            "Epoch 96: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0138, Test L1 Norm: 0.0058, Train Linf Norm: 1.3380, Test Linf Norm: 0.3408\n",
            "Epoch 97: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3334, Test Linf Norm: 0.3359\n",
            "Epoch 98: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3247, Test Linf Norm: 0.3405\n",
            "Epoch 99: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3055, Test Linf Norm: 0.3368\n",
            "Epoch 100: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3385, Test Linf Norm: 0.3368\n",
            "Epoch 101: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3143, Test Linf Norm: 0.3398\n",
            "Epoch 102: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3319, Test Linf Norm: 0.3371\n",
            "Epoch 103: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3199, Test Linf Norm: 0.3360\n",
            "Epoch 104: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0138, Test L1 Norm: 0.0058, Train Linf Norm: 1.3234, Test Linf Norm: 0.3356\n",
            "Epoch 105: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0138, Test L1 Norm: 0.0059, Train Linf Norm: 1.3358, Test Linf Norm: 0.3420\n",
            "Epoch 106: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3036, Test Linf Norm: 0.3369\n",
            "Epoch 107: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3088, Test Linf Norm: 0.3407\n",
            "Epoch 108: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3284, Test Linf Norm: 0.3380\n",
            "Epoch 109: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3194, Test Linf Norm: 0.3361\n",
            "Epoch 110: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3212, Test Linf Norm: 0.3377\n",
            "Epoch 111: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3141, Test Linf Norm: 0.3391\n",
            "Epoch 112: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3244, Test Linf Norm: 0.3391\n",
            "Epoch 113: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.2604, Test Linf Norm: 0.3385\n",
            "Epoch 114: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3239, Test Linf Norm: 0.3377\n",
            "Epoch 115: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3142, Test Linf Norm: 0.3386\n",
            "Epoch 116: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3129, Test Linf Norm: 0.3388\n",
            "Epoch 117: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3118, Test Linf Norm: 0.3373\n",
            "Epoch 118: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3156, Test Linf Norm: 0.3394\n",
            "Epoch 119: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3286, Test Linf Norm: 0.3370\n",
            "Epoch 120: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3284, Test Linf Norm: 0.3397\n",
            "Epoch 121: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3282, Test Linf Norm: 0.3384\n",
            "Epoch 122: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3214, Test Linf Norm: 0.3384\n",
            "Epoch 123: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3107, Test Linf Norm: 0.3387\n",
            "Epoch 124: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3107, Test Linf Norm: 0.3380\n",
            "Epoch 125: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3210, Test Linf Norm: 0.3381\n",
            "Epoch 126: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3257, Test Linf Norm: 0.3386\n",
            "Epoch 127: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3277, Test Linf Norm: 0.3378\n",
            "Epoch 128: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3276, Test Linf Norm: 0.3384\n",
            "Epoch 129: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3131, Test Linf Norm: 0.3382\n",
            "Epoch 130: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.0683, Test Linf Norm: 0.3382\n",
            "Epoch 131: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3117, Test Linf Norm: 0.3374\n",
            "Epoch 132: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3086, Test Linf Norm: 0.3386\n",
            "Epoch 133: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.2998, Test Linf Norm: 0.3383\n",
            "Epoch 134: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0136, Test L1 Norm: 0.0058, Train Linf Norm: 1.3169, Test Linf Norm: 0.3383\n",
            "Epoch 135: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3265, Test Linf Norm: 0.3384\n",
            "Epoch 136: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3125, Test Linf Norm: 0.3385\n",
            "Epoch 137: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3266, Test Linf Norm: 0.3382\n",
            "Epoch 138: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3150, Test Linf Norm: 0.3382\n",
            "Epoch 139: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3252, Test Linf Norm: 0.3383\n",
            "Epoch 140: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3220, Test Linf Norm: 0.3381\n",
            "Epoch 141: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.2970, Test Linf Norm: 0.3383\n",
            "Epoch 142: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3217, Test Linf Norm: 0.3383\n",
            "Epoch 143: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3111, Test Linf Norm: 0.3383\n",
            "Epoch 144: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3146, Test Linf Norm: 0.3382\n",
            "Epoch 145: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3226, Test Linf Norm: 0.3383\n",
            "Epoch 146: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3134, Test Linf Norm: 0.3384\n",
            "Epoch 147: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3215, Test Linf Norm: 0.3384\n",
            "Epoch 148: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.2958, Test Linf Norm: 0.3382\n",
            "Epoch 149: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3265, Test Linf Norm: 0.3384\n",
            "Epoch 150: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3218, Test Linf Norm: 0.3382\n",
            "Epoch 151: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3207, Test Linf Norm: 0.3382\n",
            "Epoch 152: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3175, Test Linf Norm: 0.3382\n",
            "Epoch 153: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3226, Test Linf Norm: 0.3382\n",
            "Epoch 154: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3142, Test Linf Norm: 0.3382\n",
            "Epoch 155: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3322, Test Linf Norm: 0.3382\n",
            "Epoch 156: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3110, Test Linf Norm: 0.3382\n",
            "Epoch 157: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3241, Test Linf Norm: 0.3382\n",
            "Epoch 158: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3380, Test Linf Norm: 0.3382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 12:57:11,369]\u001b[0m Trial 32 finished with value: 0.005812677476555109 and parameters: {'n_layers': 4, 'n_units_0': 1590, 'n_units_1': 578, 'n_units_2': 420, 'n_units_3': 358, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0007866223202042066, 'batch_size': 128, 'n_epochs': 159, 'scheduler': 'StepLR', 'weight_decay': 0.0010729718073103289, 'beta1': 0.9827306743707601, 'beta2': 0.999601053816912, 'step_size': 15, 'gamma': 0.25736384236095805}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 159: Train Loss: 0.0049, Test Loss: 0.0053, Train L1 Norm: 0.0137, Test L1 Norm: 0.0058, Train Linf Norm: 1.3332, Test Linf Norm: 0.3382\n",
            "Epoch 1: Train Loss: 0.2054, Test Loss: 0.0253, Train L1 Norm: 0.5104, Test L1 Norm: 0.0370, Train Linf Norm: 48.6871, Test Linf Norm: 1.9883\n",
            "Epoch 2: Train Loss: 0.0470, Test Loss: 0.0212, Train L1 Norm: 0.2235, Test L1 Norm: 0.0456, Train Linf Norm: 24.5241, Test Linf Norm: 3.2420\n",
            "Epoch 3: Train Loss: 0.0424, Test Loss: 0.0362, Train L1 Norm: 0.1937, Test L1 Norm: 0.0413, Train Linf Norm: 21.2072, Test Linf Norm: 2.5269\n",
            "Epoch 4: Train Loss: 0.0267, Test Loss: 0.0204, Train L1 Norm: 0.1936, Test L1 Norm: 0.0459, Train Linf Norm: 22.1609, Test Linf Norm: 3.4308\n",
            "Epoch 5: Train Loss: 0.0399, Test Loss: 0.0306, Train L1 Norm: 0.1887, Test L1 Norm: 0.0328, Train Linf Norm: 21.1305, Test Linf Norm: 2.0327\n",
            "Epoch 6: Train Loss: 0.0336, Test Loss: 0.0553, Train L1 Norm: 0.1750, Test L1 Norm: 0.0471, Train Linf Norm: 19.6673, Test Linf Norm: 2.4887\n",
            "Epoch 7: Train Loss: 0.0329, Test Loss: 0.0170, Train L1 Norm: 0.1311, Test L1 Norm: 0.0270, Train Linf Norm: 14.3171, Test Linf Norm: 1.9393\n",
            "Epoch 8: Train Loss: 0.0248, Test Loss: 0.0239, Train L1 Norm: 0.1201, Test L1 Norm: 0.0250, Train Linf Norm: 13.3470, Test Linf Norm: 1.6018\n",
            "Epoch 9: Train Loss: 0.0305, Test Loss: 0.0122, Train L1 Norm: 0.1305, Test L1 Norm: 0.0242, Train Linf Norm: 14.5010, Test Linf Norm: 1.8671\n",
            "Epoch 10: Train Loss: 0.0260, Test Loss: 0.0216, Train L1 Norm: 0.1243, Test L1 Norm: 0.0200, Train Linf Norm: 13.9473, Test Linf Norm: 1.1740\n",
            "Epoch 11: Train Loss: 0.0263, Test Loss: 0.0283, Train L1 Norm: 0.1074, Test L1 Norm: 0.0279, Train Linf Norm: 11.8418, Test Linf Norm: 1.8175\n",
            "Epoch 12: Train Loss: 0.0430, Test Loss: 0.0525, Train L1 Norm: 0.1160, Test L1 Norm: 0.0320, Train Linf Norm: 11.8578, Test Linf Norm: 1.4820\n",
            "Epoch 13: Train Loss: 0.0264, Test Loss: 0.0448, Train L1 Norm: 0.0847, Test L1 Norm: 0.0318, Train Linf Norm: 8.9548, Test Linf Norm: 1.4478\n",
            "Epoch 14: Train Loss: 0.0200, Test Loss: 0.0176, Train L1 Norm: 0.0842, Test L1 Norm: 0.0197, Train Linf Norm: 9.2477, Test Linf Norm: 1.1961\n",
            "Epoch 15: Train Loss: 0.0325, Test Loss: 0.0237, Train L1 Norm: 0.0834, Test L1 Norm: 0.0232, Train Linf Norm: 8.4006, Test Linf Norm: 1.2779\n",
            "Epoch 16: Train Loss: 0.0108, Test Loss: 0.0085, Train L1 Norm: 0.0774, Test L1 Norm: 0.0143, Train Linf Norm: 8.8645, Test Linf Norm: 1.0433\n",
            "Epoch 17: Train Loss: 0.0092, Test Loss: 0.0093, Train L1 Norm: 0.0709, Test L1 Norm: 0.0134, Train Linf Norm: 8.2014, Test Linf Norm: 0.9203\n",
            "Epoch 18: Train Loss: 0.0099, Test Loss: 0.0109, Train L1 Norm: 0.0671, Test L1 Norm: 0.0123, Train Linf Norm: 7.7406, Test Linf Norm: 0.8048\n",
            "Epoch 19: Train Loss: 0.0093, Test Loss: 0.0076, Train L1 Norm: 0.0625, Test L1 Norm: 0.0111, Train Linf Norm: 7.1999, Test Linf Norm: 0.7494\n",
            "Epoch 20: Train Loss: 0.0098, Test Loss: 0.0078, Train L1 Norm: 0.0607, Test L1 Norm: 0.0114, Train Linf Norm: 6.9633, Test Linf Norm: 0.7595\n",
            "Epoch 21: Train Loss: 0.0092, Test Loss: 0.0084, Train L1 Norm: 0.0511, Test L1 Norm: 0.0114, Train Linf Norm: 5.7626, Test Linf Norm: 0.7539\n",
            "Epoch 22: Train Loss: 0.0116, Test Loss: 0.0111, Train L1 Norm: 0.0517, Test L1 Norm: 0.0112, Train Linf Norm: 5.7657, Test Linf Norm: 0.6566\n",
            "Epoch 23: Train Loss: 0.0095, Test Loss: 0.0065, Train L1 Norm: 0.0451, Test L1 Norm: 0.0087, Train Linf Norm: 4.9848, Test Linf Norm: 0.5152\n",
            "Epoch 24: Train Loss: 0.0080, Test Loss: 0.0103, Train L1 Norm: 0.0476, Test L1 Norm: 0.0090, Train Linf Norm: 5.3799, Test Linf Norm: 0.4832\n",
            "Epoch 25: Train Loss: 0.0093, Test Loss: 0.0091, Train L1 Norm: 0.0448, Test L1 Norm: 0.0092, Train Linf Norm: 4.9691, Test Linf Norm: 0.4683\n",
            "Epoch 26: Train Loss: 0.0100, Test Loss: 0.0150, Train L1 Norm: 0.0424, Test L1 Norm: 0.0111, Train Linf Norm: 4.6747, Test Linf Norm: 0.5297\n",
            "Epoch 27: Train Loss: 0.0090, Test Loss: 0.0081, Train L1 Norm: 0.0441, Test L1 Norm: 0.0104, Train Linf Norm: 4.9057, Test Linf Norm: 0.6417\n",
            "Epoch 28: Train Loss: 0.0094, Test Loss: 0.0068, Train L1 Norm: 0.0358, Test L1 Norm: 0.0085, Train Linf Norm: 3.8733, Test Linf Norm: 0.5026\n",
            "Epoch 29: Train Loss: 0.0084, Test Loss: 0.0094, Train L1 Norm: 0.0393, Test L1 Norm: 0.0084, Train Linf Norm: 4.3320, Test Linf Norm: 0.4111\n",
            "Epoch 30: Train Loss: 0.0081, Test Loss: 0.0066, Train L1 Norm: 0.0377, Test L1 Norm: 0.0075, Train Linf Norm: 4.1657, Test Linf Norm: 0.3702\n",
            "Epoch 31: Train Loss: 0.0059, Test Loss: 0.0059, Train L1 Norm: 0.0340, Test L1 Norm: 0.0072, Train Linf Norm: 3.7750, Test Linf Norm: 0.3974\n",
            "Epoch 32: Train Loss: 0.0058, Test Loss: 0.0059, Train L1 Norm: 0.0323, Test L1 Norm: 0.0069, Train Linf Norm: 3.5949, Test Linf Norm: 0.3722\n",
            "Epoch 33: Train Loss: 0.0056, Test Loss: 0.0072, Train L1 Norm: 0.0297, Test L1 Norm: 0.0071, Train Linf Norm: 3.2543, Test Linf Norm: 0.3578\n",
            "Epoch 34: Train Loss: 0.0058, Test Loss: 0.0057, Train L1 Norm: 0.0313, Test L1 Norm: 0.0071, Train Linf Norm: 3.4779, Test Linf Norm: 0.3991\n",
            "Epoch 35: Train Loss: 0.0058, Test Loss: 0.0055, Train L1 Norm: 0.0293, Test L1 Norm: 0.0071, Train Linf Norm: 3.2096, Test Linf Norm: 0.4044\n",
            "Epoch 36: Train Loss: 0.0058, Test Loss: 0.0056, Train L1 Norm: 0.0297, Test L1 Norm: 0.0068, Train Linf Norm: 3.2666, Test Linf Norm: 0.3658\n",
            "Epoch 37: Train Loss: 0.0061, Test Loss: 0.0055, Train L1 Norm: 0.0281, Test L1 Norm: 0.0066, Train Linf Norm: 3.0672, Test Linf Norm: 0.3504\n",
            "Epoch 38: Train Loss: 0.0058, Test Loss: 0.0063, Train L1 Norm: 0.0302, Test L1 Norm: 0.0066, Train Linf Norm: 3.3139, Test Linf Norm: 0.3262\n",
            "Epoch 39: Train Loss: 0.0055, Test Loss: 0.0058, Train L1 Norm: 0.0271, Test L1 Norm: 0.0073, Train Linf Norm: 2.9473, Test Linf Norm: 0.4116\n",
            "Epoch 40: Train Loss: 0.0058, Test Loss: 0.0059, Train L1 Norm: 0.0278, Test L1 Norm: 0.0062, Train Linf Norm: 3.0266, Test Linf Norm: 0.2870\n",
            "Epoch 41: Train Loss: 0.0055, Test Loss: 0.0065, Train L1 Norm: 0.0282, Test L1 Norm: 0.0071, Train Linf Norm: 3.1121, Test Linf Norm: 0.3812\n",
            "Epoch 42: Train Loss: 0.0058, Test Loss: 0.0055, Train L1 Norm: 0.0276, Test L1 Norm: 0.0060, Train Linf Norm: 2.9951, Test Linf Norm: 0.2708\n",
            "Epoch 43: Train Loss: 0.0058, Test Loss: 0.0056, Train L1 Norm: 0.0277, Test L1 Norm: 0.0065, Train Linf Norm: 3.0254, Test Linf Norm: 0.3345\n",
            "Epoch 44: Train Loss: 0.0055, Test Loss: 0.0066, Train L1 Norm: 0.0269, Test L1 Norm: 0.0068, Train Linf Norm: 2.9355, Test Linf Norm: 0.3395\n",
            "Epoch 45: Train Loss: 0.0055, Test Loss: 0.0054, Train L1 Norm: 0.0255, Test L1 Norm: 0.0060, Train Linf Norm: 2.7708, Test Linf Norm: 0.2957\n",
            "Epoch 46: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0254, Test L1 Norm: 0.0061, Train Linf Norm: 2.7559, Test Linf Norm: 0.3036\n",
            "Epoch 47: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0257, Test L1 Norm: 0.0061, Train Linf Norm: 2.8090, Test Linf Norm: 0.3037\n",
            "Epoch 48: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0252, Test L1 Norm: 0.0061, Train Linf Norm: 2.7510, Test Linf Norm: 0.3128\n",
            "Epoch 49: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0256, Test L1 Norm: 0.0062, Train Linf Norm: 2.7841, Test Linf Norm: 0.3219\n",
            "Epoch 50: Train Loss: 0.0051, Test Loss: 0.0055, Train L1 Norm: 0.0251, Test L1 Norm: 0.0062, Train Linf Norm: 2.6966, Test Linf Norm: 0.3166\n",
            "Epoch 51: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0256, Test L1 Norm: 0.0062, Train Linf Norm: 2.7972, Test Linf Norm: 0.3141\n",
            "Epoch 52: Train Loss: 0.0051, Test Loss: 0.0056, Train L1 Norm: 0.0251, Test L1 Norm: 0.0061, Train Linf Norm: 2.7325, Test Linf Norm: 0.3025\n",
            "Epoch 53: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0251, Test L1 Norm: 0.0061, Train Linf Norm: 2.7375, Test Linf Norm: 0.3097\n",
            "Epoch 54: Train Loss: 0.0050, Test Loss: 0.0056, Train L1 Norm: 0.0250, Test L1 Norm: 0.0060, Train Linf Norm: 2.7245, Test Linf Norm: 0.2941\n",
            "Epoch 55: Train Loss: 0.0050, Test Loss: 0.0054, Train L1 Norm: 0.0249, Test L1 Norm: 0.0062, Train Linf Norm: 2.6993, Test Linf Norm: 0.3167\n",
            "Epoch 56: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0252, Test L1 Norm: 0.0060, Train Linf Norm: 2.7519, Test Linf Norm: 0.3032\n",
            "Epoch 57: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0243, Test L1 Norm: 0.0060, Train Linf Norm: 2.6343, Test Linf Norm: 0.2983\n",
            "Epoch 58: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0244, Test L1 Norm: 0.0059, Train Linf Norm: 2.6567, Test Linf Norm: 0.2908\n",
            "Epoch 59: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0253, Test L1 Norm: 0.0059, Train Linf Norm: 2.7688, Test Linf Norm: 0.2868\n",
            "Epoch 60: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0248, Test L1 Norm: 0.0061, Train Linf Norm: 2.6655, Test Linf Norm: 0.3137\n",
            "Epoch 61: Train Loss: 0.0049, Test Loss: 0.0051, Train L1 Norm: 0.0244, Test L1 Norm: 0.0060, Train Linf Norm: 2.6587, Test Linf Norm: 0.3063\n",
            "Epoch 62: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0246, Test L1 Norm: 0.0060, Train Linf Norm: 2.6484, Test Linf Norm: 0.3007\n",
            "Epoch 63: Train Loss: 0.0049, Test Loss: 0.0052, Train L1 Norm: 0.0247, Test L1 Norm: 0.0060, Train Linf Norm: 2.6808, Test Linf Norm: 0.2960\n",
            "Epoch 64: Train Loss: 0.0048, Test Loss: 0.0052, Train L1 Norm: 0.0245, Test L1 Norm: 0.0059, Train Linf Norm: 2.6640, Test Linf Norm: 0.2943\n",
            "Epoch 65: Train Loss: 0.0048, Test Loss: 0.0053, Train L1 Norm: 0.0244, Test L1 Norm: 0.0060, Train Linf Norm: 2.6489, Test Linf Norm: 0.2960\n",
            "Epoch 66: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0244, Test L1 Norm: 0.0059, Train Linf Norm: 2.6579, Test Linf Norm: 0.2917\n",
            "Epoch 67: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0244, Test L1 Norm: 0.0059, Train Linf Norm: 2.6584, Test Linf Norm: 0.2890\n",
            "Epoch 68: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0244, Test L1 Norm: 0.0060, Train Linf Norm: 2.6604, Test Linf Norm: 0.2997\n",
            "Epoch 69: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0060, Train Linf Norm: 2.6263, Test Linf Norm: 0.3006\n",
            "Epoch 70: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0244, Test L1 Norm: 0.0059, Train Linf Norm: 2.6538, Test Linf Norm: 0.2976\n",
            "Epoch 71: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0060, Train Linf Norm: 2.6331, Test Linf Norm: 0.2995\n",
            "Epoch 72: Train Loss: 0.0048, Test Loss: 0.0052, Train L1 Norm: 0.0244, Test L1 Norm: 0.0059, Train Linf Norm: 2.6638, Test Linf Norm: 0.2948\n",
            "Epoch 73: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0243, Test L1 Norm: 0.0060, Train Linf Norm: 2.6320, Test Linf Norm: 0.3017\n",
            "Epoch 74: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6435, Test Linf Norm: 0.2938\n",
            "Epoch 75: Train Loss: 0.0049, Test Loss: 0.0052, Train L1 Norm: 0.0243, Test L1 Norm: 0.0059, Train Linf Norm: 2.6376, Test Linf Norm: 0.2889\n",
            "Epoch 76: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0240, Test L1 Norm: 0.0059, Train Linf Norm: 2.6150, Test Linf Norm: 0.2930\n",
            "Epoch 77: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0240, Test L1 Norm: 0.0059, Train Linf Norm: 2.6146, Test Linf Norm: 0.2971\n",
            "Epoch 78: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6305, Test Linf Norm: 0.2946\n",
            "Epoch 79: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6382, Test Linf Norm: 0.2958\n",
            "Epoch 80: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6295, Test Linf Norm: 0.2953\n",
            "Epoch 81: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6096, Test Linf Norm: 0.2988\n",
            "Epoch 82: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0241, Test L1 Norm: 0.0059, Train Linf Norm: 2.6254, Test Linf Norm: 0.2952\n",
            "Epoch 83: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0241, Test L1 Norm: 0.0059, Train Linf Norm: 2.6237, Test Linf Norm: 0.2956\n",
            "Epoch 84: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6397, Test Linf Norm: 0.2958\n",
            "Epoch 85: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6367, Test Linf Norm: 0.2973\n",
            "Epoch 86: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0243, Test L1 Norm: 0.0059, Train Linf Norm: 2.6195, Test Linf Norm: 0.2961\n",
            "Epoch 87: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0243, Test L1 Norm: 0.0059, Train Linf Norm: 2.6257, Test Linf Norm: 0.2960\n",
            "Epoch 88: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0241, Test L1 Norm: 0.0059, Train Linf Norm: 2.6269, Test Linf Norm: 0.2960\n",
            "Epoch 89: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0241, Test L1 Norm: 0.0059, Train Linf Norm: 2.6129, Test Linf Norm: 0.2968\n",
            "Epoch 90: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6339, Test Linf Norm: 0.2983\n",
            "Epoch 91: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6356, Test Linf Norm: 0.2978\n",
            "Epoch 92: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6206, Test Linf Norm: 0.2977\n",
            "Epoch 93: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6315, Test Linf Norm: 0.2977\n",
            "Epoch 94: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6381, Test Linf Norm: 0.2972\n",
            "Epoch 95: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6287, Test Linf Norm: 0.2976\n",
            "Epoch 96: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6375, Test Linf Norm: 0.2974\n",
            "Epoch 97: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6385, Test Linf Norm: 0.2982\n",
            "Epoch 98: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6414, Test Linf Norm: 0.2970\n",
            "Epoch 99: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6277, Test Linf Norm: 0.2972\n",
            "Epoch 100: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6369, Test Linf Norm: 0.2967\n",
            "Epoch 101: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6395, Test Linf Norm: 0.2973\n",
            "Epoch 102: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6139, Test Linf Norm: 0.2971\n",
            "Epoch 103: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6296, Test Linf Norm: 0.2975\n",
            "Epoch 104: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6375, Test Linf Norm: 0.2975\n",
            "Epoch 105: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6275, Test Linf Norm: 0.2971\n",
            "Epoch 106: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6187, Test Linf Norm: 0.2970\n",
            "Epoch 107: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6401, Test Linf Norm: 0.2970\n",
            "Epoch 108: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6270, Test Linf Norm: 0.2970\n",
            "Epoch 109: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6323, Test Linf Norm: 0.2970\n",
            "Epoch 110: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6353, Test Linf Norm: 0.2971\n",
            "Epoch 111: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6163, Test Linf Norm: 0.2970\n",
            "Epoch 112: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6121, Test Linf Norm: 0.2971\n",
            "Epoch 113: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6326, Test Linf Norm: 0.2970\n",
            "Epoch 114: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6265, Test Linf Norm: 0.2969\n",
            "Epoch 115: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6320, Test Linf Norm: 0.2971\n",
            "Epoch 116: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6243, Test Linf Norm: 0.2970\n",
            "Epoch 117: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6331, Test Linf Norm: 0.2972\n",
            "Epoch 118: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6321, Test Linf Norm: 0.2971\n",
            "Epoch 119: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6349, Test Linf Norm: 0.2970\n",
            "Epoch 120: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6267, Test Linf Norm: 0.2970\n",
            "Epoch 121: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6141, Test Linf Norm: 0.2970\n",
            "Epoch 122: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6306, Test Linf Norm: 0.2970\n",
            "Epoch 123: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6333, Test Linf Norm: 0.2970\n",
            "Epoch 124: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6409, Test Linf Norm: 0.2970\n",
            "Epoch 125: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6318, Test Linf Norm: 0.2970\n",
            "Epoch 126: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6454, Test Linf Norm: 0.2971\n",
            "Epoch 127: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6292, Test Linf Norm: 0.2971\n",
            "Epoch 128: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6369, Test Linf Norm: 0.2971\n",
            "Epoch 129: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6413, Test Linf Norm: 0.2971\n",
            "Epoch 130: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6266, Test Linf Norm: 0.2971\n",
            "Epoch 131: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6382, Test Linf Norm: 0.2971\n",
            "Epoch 132: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6468, Test Linf Norm: 0.2971\n",
            "Epoch 133: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6392, Test Linf Norm: 0.2971\n",
            "Epoch 134: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6383, Test Linf Norm: 0.2971\n",
            "Epoch 135: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6286, Test Linf Norm: 0.2971\n",
            "Epoch 136: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6428, Test Linf Norm: 0.2971\n",
            "Epoch 137: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6123, Test Linf Norm: 0.2971\n",
            "Epoch 138: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6226, Test Linf Norm: 0.2971\n",
            "Epoch 139: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6287, Test Linf Norm: 0.2971\n",
            "Epoch 140: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6308, Test Linf Norm: 0.2971\n",
            "Epoch 141: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6303, Test Linf Norm: 0.2971\n",
            "Epoch 142: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6273, Test Linf Norm: 0.2971\n",
            "Epoch 143: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6397, Test Linf Norm: 0.2971\n",
            "Epoch 144: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6267, Test Linf Norm: 0.2971\n",
            "Epoch 145: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6143, Test Linf Norm: 0.2971\n",
            "Epoch 146: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6309, Test Linf Norm: 0.2971\n",
            "Epoch 147: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6369, Test Linf Norm: 0.2971\n",
            "Epoch 148: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.5989, Test Linf Norm: 0.2971\n",
            "Epoch 149: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6296, Test Linf Norm: 0.2971\n",
            "Epoch 150: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6257, Test Linf Norm: 0.2971\n",
            "Epoch 151: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6272, Test Linf Norm: 0.2971\n",
            "Epoch 152: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6269, Test Linf Norm: 0.2971\n",
            "Epoch 153: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6327, Test Linf Norm: 0.2971\n",
            "Epoch 154: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6347, Test Linf Norm: 0.2971\n",
            "Epoch 155: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6159, Test Linf Norm: 0.2971\n",
            "Epoch 156: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6288, Test Linf Norm: 0.2971\n",
            "Epoch 157: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6198, Test Linf Norm: 0.2971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:03:03,001]\u001b[0m Trial 33 finished with value: 0.0059310026705265044 and parameters: {'n_layers': 4, 'n_units_0': 1574, 'n_units_1': 234, 'n_units_2': 711, 'n_units_3': 376, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0004675611960409402, 'batch_size': 128, 'n_epochs': 158, 'scheduler': 'StepLR', 'weight_decay': 0.001700581622122078, 'beta1': 0.979662308572984, 'beta2': 0.9996810428335005, 'step_size': 15, 'gamma': 0.17780844421512182}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 158: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0242, Test L1 Norm: 0.0059, Train Linf Norm: 2.6384, Test Linf Norm: 0.2971\n",
            "Epoch 1: Train Loss: 0.2015, Test Loss: 0.0637, Train L1 Norm: 0.7250, Test L1 Norm: 0.0467, Train Linf Norm: 76.5601, Test Linf Norm: 1.9310\n",
            "Epoch 2: Train Loss: 0.0423, Test Loss: 0.0754, Train L1 Norm: 0.1169, Test L1 Norm: 0.0381, Train Linf Norm: 11.4668, Test Linf Norm: 0.8932\n",
            "Epoch 3: Train Loss: 0.0386, Test Loss: 0.0470, Train L1 Norm: 0.1190, Test L1 Norm: 0.0375, Train Linf Norm: 12.2026, Test Linf Norm: 1.0456\n",
            "Epoch 4: Train Loss: 0.0413, Test Loss: 0.0182, Train L1 Norm: 0.1224, Test L1 Norm: 0.0198, Train Linf Norm: 12.2228, Test Linf Norm: 1.0070\n",
            "Epoch 5: Train Loss: 0.0279, Test Loss: 0.0168, Train L1 Norm: 0.1117, Test L1 Norm: 0.0217, Train Linf Norm: 12.0639, Test Linf Norm: 1.2427\n",
            "Epoch 6: Train Loss: 0.0213, Test Loss: 0.0344, Train L1 Norm: 0.0826, Test L1 Norm: 0.0322, Train Linf Norm: 8.6845, Test Linf Norm: 1.7508\n",
            "Epoch 7: Train Loss: 0.0304, Test Loss: 0.0395, Train L1 Norm: 0.0667, Test L1 Norm: 0.0338, Train Linf Norm: 6.1927, Test Linf Norm: 1.5935\n",
            "Epoch 8: Train Loss: 0.0219, Test Loss: 0.0298, Train L1 Norm: 0.0594, Test L1 Norm: 0.0197, Train Linf Norm: 5.8094, Test Linf Norm: 0.8693\n",
            "Epoch 9: Train Loss: 0.0223, Test Loss: 0.0252, Train L1 Norm: 0.0535, Test L1 Norm: 0.0156, Train Linf Norm: 5.1073, Test Linf Norm: 0.6332\n",
            "Epoch 10: Train Loss: 0.0293, Test Loss: 0.0359, Train L1 Norm: 0.0727, Test L1 Norm: 0.0355, Train Linf Norm: 7.2674, Test Linf Norm: 1.4759\n",
            "Epoch 11: Train Loss: 0.0251, Test Loss: 0.0193, Train L1 Norm: 0.0582, Test L1 Norm: 0.0157, Train Linf Norm: 5.6438, Test Linf Norm: 0.7768\n",
            "Epoch 12: Train Loss: 0.0184, Test Loss: 0.0340, Train L1 Norm: 0.0478, Test L1 Norm: 0.0228, Train Linf Norm: 4.6005, Test Linf Norm: 0.9415\n",
            "Epoch 13: Train Loss: 0.0339, Test Loss: 0.0461, Train L1 Norm: 0.0644, Test L1 Norm: 0.0266, Train Linf Norm: 5.9765, Test Linf Norm: 1.0183\n",
            "Epoch 14: Train Loss: 0.0286, Test Loss: 0.0207, Train L1 Norm: 0.0504, Test L1 Norm: 0.0172, Train Linf Norm: 4.4892, Test Linf Norm: 0.7502\n",
            "Epoch 15: Train Loss: 0.0105, Test Loss: 0.0112, Train L1 Norm: 0.0493, Test L1 Norm: 0.0117, Train Linf Norm: 5.3974, Test Linf Norm: 0.6891\n",
            "Epoch 16: Train Loss: 0.0101, Test Loss: 0.0071, Train L1 Norm: 0.0412, Test L1 Norm: 0.0111, Train Linf Norm: 4.4027, Test Linf Norm: 0.7436\n",
            "Epoch 17: Train Loss: 0.0080, Test Loss: 0.0078, Train L1 Norm: 0.0342, Test L1 Norm: 0.0097, Train Linf Norm: 3.5946, Test Linf Norm: 0.5504\n",
            "Epoch 18: Train Loss: 0.0082, Test Loss: 0.0079, Train L1 Norm: 0.0330, Test L1 Norm: 0.0098, Train Linf Norm: 3.4633, Test Linf Norm: 0.5656\n",
            "Epoch 19: Train Loss: 0.0079, Test Loss: 0.0068, Train L1 Norm: 0.0271, Test L1 Norm: 0.0092, Train Linf Norm: 2.7175, Test Linf Norm: 0.5435\n",
            "Epoch 20: Train Loss: 0.0079, Test Loss: 0.0083, Train L1 Norm: 0.0287, Test L1 Norm: 0.0098, Train Linf Norm: 2.9201, Test Linf Norm: 0.5911\n",
            "Epoch 21: Train Loss: 0.0076, Test Loss: 0.0064, Train L1 Norm: 0.0274, Test L1 Norm: 0.0092, Train Linf Norm: 2.7685, Test Linf Norm: 0.5877\n",
            "Epoch 22: Train Loss: 0.0085, Test Loss: 0.0072, Train L1 Norm: 0.0235, Test L1 Norm: 0.0087, Train Linf Norm: 2.2198, Test Linf Norm: 0.4726\n",
            "Epoch 23: Train Loss: 0.0073, Test Loss: 0.0069, Train L1 Norm: 0.0189, Test L1 Norm: 0.0085, Train Linf Norm: 1.7174, Test Linf Norm: 0.4771\n",
            "Epoch 24: Train Loss: 0.0095, Test Loss: 0.0095, Train L1 Norm: 0.0203, Test L1 Norm: 0.0092, Train Linf Norm: 1.8002, Test Linf Norm: 0.4874\n",
            "Epoch 25: Train Loss: 0.0087, Test Loss: 0.0086, Train L1 Norm: 0.0240, Test L1 Norm: 0.0087, Train Linf Norm: 2.3278, Test Linf Norm: 0.4264\n",
            "Epoch 26: Train Loss: 0.0081, Test Loss: 0.0080, Train L1 Norm: 0.0184, Test L1 Norm: 0.0101, Train Linf Norm: 1.6381, Test Linf Norm: 0.5943\n",
            "Epoch 27: Train Loss: 0.0084, Test Loss: 0.0072, Train L1 Norm: 0.0208, Test L1 Norm: 0.0081, Train Linf Norm: 1.9610, Test Linf Norm: 0.4504\n",
            "Epoch 28: Train Loss: 0.0081, Test Loss: 0.0068, Train L1 Norm: 0.0196, Test L1 Norm: 0.0080, Train Linf Norm: 1.8110, Test Linf Norm: 0.4469\n",
            "Epoch 29: Train Loss: 0.0057, Test Loss: 0.0058, Train L1 Norm: 0.0184, Test L1 Norm: 0.0075, Train Linf Norm: 1.7821, Test Linf Norm: 0.4290\n",
            "Epoch 30: Train Loss: 0.0057, Test Loss: 0.0056, Train L1 Norm: 0.0174, Test L1 Norm: 0.0078, Train Linf Norm: 1.6482, Test Linf Norm: 0.4702\n",
            "Epoch 31: Train Loss: 0.0055, Test Loss: 0.0052, Train L1 Norm: 0.0163, Test L1 Norm: 0.0074, Train Linf Norm: 1.5033, Test Linf Norm: 0.4335\n",
            "Epoch 32: Train Loss: 0.0053, Test Loss: 0.0053, Train L1 Norm: 0.0168, Test L1 Norm: 0.0073, Train Linf Norm: 1.5921, Test Linf Norm: 0.4204\n",
            "Epoch 33: Train Loss: 0.0053, Test Loss: 0.0054, Train L1 Norm: 0.0179, Test L1 Norm: 0.0072, Train Linf Norm: 1.7549, Test Linf Norm: 0.3965\n",
            "Epoch 34: Train Loss: 0.0054, Test Loss: 0.0058, Train L1 Norm: 0.0165, Test L1 Norm: 0.0078, Train Linf Norm: 1.5591, Test Linf Norm: 0.4751\n",
            "Epoch 35: Train Loss: 0.0055, Test Loss: 0.0057, Train L1 Norm: 0.0166, Test L1 Norm: 0.0078, Train Linf Norm: 1.5656, Test Linf Norm: 0.4676\n",
            "Epoch 36: Train Loss: 0.0054, Test Loss: 0.0059, Train L1 Norm: 0.0162, Test L1 Norm: 0.0075, Train Linf Norm: 1.5307, Test Linf Norm: 0.4374\n",
            "Epoch 37: Train Loss: 0.0053, Test Loss: 0.0052, Train L1 Norm: 0.0153, Test L1 Norm: 0.0072, Train Linf Norm: 1.4201, Test Linf Norm: 0.4098\n",
            "Epoch 38: Train Loss: 0.0052, Test Loss: 0.0055, Train L1 Norm: 0.0147, Test L1 Norm: 0.0073, Train Linf Norm: 1.3369, Test Linf Norm: 0.4314\n",
            "Epoch 39: Train Loss: 0.0055, Test Loss: 0.0054, Train L1 Norm: 0.0152, Test L1 Norm: 0.0070, Train Linf Norm: 1.3973, Test Linf Norm: 0.3961\n",
            "Epoch 40: Train Loss: 0.0055, Test Loss: 0.0056, Train L1 Norm: 0.0138, Test L1 Norm: 0.0072, Train Linf Norm: 1.2292, Test Linf Norm: 0.4200\n",
            "Epoch 41: Train Loss: 0.0055, Test Loss: 0.0065, Train L1 Norm: 0.0140, Test L1 Norm: 0.0071, Train Linf Norm: 1.2428, Test Linf Norm: 0.3738\n",
            "Epoch 42: Train Loss: 0.0058, Test Loss: 0.0051, Train L1 Norm: 0.0154, Test L1 Norm: 0.0069, Train Linf Norm: 1.3950, Test Linf Norm: 0.4071\n",
            "Epoch 43: Train Loss: 0.0049, Test Loss: 0.0049, Train L1 Norm: 0.0138, Test L1 Norm: 0.0069, Train Linf Norm: 1.2483, Test Linf Norm: 0.4095\n",
            "Epoch 44: Train Loss: 0.0048, Test Loss: 0.0049, Train L1 Norm: 0.0142, Test L1 Norm: 0.0070, Train Linf Norm: 1.3273, Test Linf Norm: 0.4161\n",
            "Epoch 45: Train Loss: 0.0049, Test Loss: 0.0051, Train L1 Norm: 0.0138, Test L1 Norm: 0.0069, Train Linf Norm: 1.2680, Test Linf Norm: 0.4029\n",
            "Epoch 46: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0146, Test L1 Norm: 0.0070, Train Linf Norm: 1.3465, Test Linf Norm: 0.4211\n",
            "Epoch 47: Train Loss: 0.0049, Test Loss: 0.0050, Train L1 Norm: 0.0139, Test L1 Norm: 0.0068, Train Linf Norm: 1.2655, Test Linf Norm: 0.3992\n",
            "Epoch 48: Train Loss: 0.0048, Test Loss: 0.0049, Train L1 Norm: 0.0135, Test L1 Norm: 0.0068, Train Linf Norm: 1.2120, Test Linf Norm: 0.4031\n",
            "Epoch 49: Train Loss: 0.0049, Test Loss: 0.0052, Train L1 Norm: 0.0142, Test L1 Norm: 0.0070, Train Linf Norm: 1.2907, Test Linf Norm: 0.4119\n",
            "Epoch 50: Train Loss: 0.0049, Test Loss: 0.0052, Train L1 Norm: 0.0139, Test L1 Norm: 0.0069, Train Linf Norm: 1.2682, Test Linf Norm: 0.3992\n",
            "Epoch 51: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0135, Test L1 Norm: 0.0069, Train Linf Norm: 1.2104, Test Linf Norm: 0.4103\n",
            "Epoch 52: Train Loss: 0.0048, Test Loss: 0.0049, Train L1 Norm: 0.0136, Test L1 Norm: 0.0068, Train Linf Norm: 1.2224, Test Linf Norm: 0.3999\n",
            "Epoch 53: Train Loss: 0.0049, Test Loss: 0.0052, Train L1 Norm: 0.0140, Test L1 Norm: 0.0068, Train Linf Norm: 1.2669, Test Linf Norm: 0.3970\n",
            "Epoch 54: Train Loss: 0.0048, Test Loss: 0.0052, Train L1 Norm: 0.0139, Test L1 Norm: 0.0068, Train Linf Norm: 1.2770, Test Linf Norm: 0.3835\n",
            "Epoch 55: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0137, Test L1 Norm: 0.0067, Train Linf Norm: 1.2324, Test Linf Norm: 0.3841\n",
            "Epoch 56: Train Loss: 0.0049, Test Loss: 0.0052, Train L1 Norm: 0.0136, Test L1 Norm: 0.0068, Train Linf Norm: 1.2255, Test Linf Norm: 0.3882\n",
            "Epoch 57: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0067, Train Linf Norm: 1.1926, Test Linf Norm: 0.3946\n",
            "Epoch 58: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0135, Test L1 Norm: 0.0068, Train Linf Norm: 1.2271, Test Linf Norm: 0.4032\n",
            "Epoch 59: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0136, Test L1 Norm: 0.0067, Train Linf Norm: 1.2294, Test Linf Norm: 0.3923\n",
            "Epoch 60: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2444, Test Linf Norm: 0.4016\n",
            "Epoch 61: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0136, Test L1 Norm: 0.0067, Train Linf Norm: 1.2282, Test Linf Norm: 0.3954\n",
            "Epoch 62: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2536, Test Linf Norm: 0.4013\n",
            "Epoch 63: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0135, Test L1 Norm: 0.0067, Train Linf Norm: 1.2359, Test Linf Norm: 0.3942\n",
            "Epoch 64: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0136, Test L1 Norm: 0.0068, Train Linf Norm: 1.2317, Test Linf Norm: 0.4011\n",
            "Epoch 65: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2657, Test Linf Norm: 0.3988\n",
            "Epoch 66: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0136, Test L1 Norm: 0.0068, Train Linf Norm: 1.2427, Test Linf Norm: 0.4034\n",
            "Epoch 67: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0138, Test L1 Norm: 0.0067, Train Linf Norm: 1.2440, Test Linf Norm: 0.3959\n",
            "Epoch 68: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2583, Test Linf Norm: 0.3987\n",
            "Epoch 69: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0136, Test L1 Norm: 0.0068, Train Linf Norm: 1.2247, Test Linf Norm: 0.3981\n",
            "Epoch 70: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0138, Test L1 Norm: 0.0068, Train Linf Norm: 1.2563, Test Linf Norm: 0.4030\n",
            "Epoch 71: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0138, Test L1 Norm: 0.0068, Train Linf Norm: 1.2592, Test Linf Norm: 0.3980\n",
            "Epoch 72: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0138, Test L1 Norm: 0.0068, Train Linf Norm: 1.2675, Test Linf Norm: 0.3980\n",
            "Epoch 73: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2532, Test Linf Norm: 0.3989\n",
            "Epoch 74: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0138, Test L1 Norm: 0.0068, Train Linf Norm: 1.2633, Test Linf Norm: 0.3992\n",
            "Epoch 75: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2602, Test Linf Norm: 0.3995\n",
            "Epoch 76: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2499, Test Linf Norm: 0.4001\n",
            "Epoch 77: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0138, Test L1 Norm: 0.0067, Train Linf Norm: 1.2603, Test Linf Norm: 0.3959\n",
            "Epoch 78: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2271, Test Linf Norm: 0.3991\n",
            "Epoch 79: Train Loss: 0.0047, Test Loss: 0.0048, Train L1 Norm: 0.0137, Test L1 Norm: 0.0067, Train Linf Norm: 1.2621, Test Linf Norm: 0.3972\n",
            "Epoch 80: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2531, Test Linf Norm: 0.3999\n",
            "Epoch 81: Train Loss: 0.0047, Test Loss: 0.0048, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2483, Test Linf Norm: 0.3981\n",
            "Epoch 82: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0067, Train Linf Norm: 1.2568, Test Linf Norm: 0.3972\n",
            "Epoch 83: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2644, Test Linf Norm: 0.3980\n",
            "Epoch 84: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0067, Train Linf Norm: 1.2710, Test Linf Norm: 0.3976\n",
            "Epoch 85: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2553, Test Linf Norm: 0.3979\n",
            "Epoch 86: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2450, Test Linf Norm: 0.3979\n",
            "Epoch 87: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0067, Train Linf Norm: 1.2066, Test Linf Norm: 0.3977\n",
            "Epoch 88: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0067, Train Linf Norm: 1.2502, Test Linf Norm: 0.3975\n",
            "Epoch 89: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2541, Test Linf Norm: 0.3980\n",
            "Epoch 90: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0067, Train Linf Norm: 1.2522, Test Linf Norm: 0.3978\n",
            "Epoch 91: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2486, Test Linf Norm: 0.3982\n",
            "Epoch 92: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2619, Test Linf Norm: 0.3981\n",
            "Epoch 93: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2528, Test Linf Norm: 0.3981\n",
            "Epoch 94: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2467, Test Linf Norm: 0.3979\n",
            "Epoch 95: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2451, Test Linf Norm: 0.3982\n",
            "Epoch 96: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2582, Test Linf Norm: 0.3979\n",
            "Epoch 97: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2525, Test Linf Norm: 0.3980\n",
            "Epoch 98: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2594, Test Linf Norm: 0.3983\n",
            "Epoch 99: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2571, Test Linf Norm: 0.3982\n",
            "Epoch 100: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2682, Test Linf Norm: 0.3981\n",
            "Epoch 101: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2585, Test Linf Norm: 0.3980\n",
            "Epoch 102: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2450, Test Linf Norm: 0.3980\n",
            "Epoch 103: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2624, Test Linf Norm: 0.3980\n",
            "Epoch 104: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2516, Test Linf Norm: 0.3980\n",
            "Epoch 105: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2644, Test Linf Norm: 0.3980\n",
            "Epoch 106: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2542, Test Linf Norm: 0.3980\n",
            "Epoch 107: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2560, Test Linf Norm: 0.3979\n",
            "Epoch 108: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2498, Test Linf Norm: 0.3980\n",
            "Epoch 109: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2549, Test Linf Norm: 0.3980\n",
            "Epoch 110: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2466, Test Linf Norm: 0.3979\n",
            "Epoch 111: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2531, Test Linf Norm: 0.3979\n",
            "Epoch 112: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2486, Test Linf Norm: 0.3980\n",
            "Epoch 113: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2602, Test Linf Norm: 0.3979\n",
            "Epoch 114: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2468, Test Linf Norm: 0.3980\n",
            "Epoch 115: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2427, Test Linf Norm: 0.3980\n",
            "Epoch 116: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2416, Test Linf Norm: 0.3979\n",
            "Epoch 117: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2624, Test Linf Norm: 0.3979\n",
            "Epoch 118: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2565, Test Linf Norm: 0.3979\n",
            "Epoch 119: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2390, Test Linf Norm: 0.3979\n",
            "Epoch 120: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2373, Test Linf Norm: 0.3979\n",
            "Epoch 121: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2563, Test Linf Norm: 0.3979\n",
            "Epoch 122: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2625, Test Linf Norm: 0.3979\n",
            "Epoch 123: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2520, Test Linf Norm: 0.3979\n",
            "Epoch 124: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2592, Test Linf Norm: 0.3979\n",
            "Epoch 125: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2532, Test Linf Norm: 0.3979\n",
            "Epoch 126: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2565, Test Linf Norm: 0.3979\n",
            "Epoch 127: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2609, Test Linf Norm: 0.3979\n",
            "Epoch 128: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2449, Test Linf Norm: 0.3979\n",
            "Epoch 129: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2515, Test Linf Norm: 0.3979\n",
            "Epoch 130: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2547, Test Linf Norm: 0.3979\n",
            "Epoch 131: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2482, Test Linf Norm: 0.3979\n",
            "Epoch 132: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2527, Test Linf Norm: 0.3979\n",
            "Epoch 133: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2625, Test Linf Norm: 0.3979\n",
            "Epoch 134: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2618, Test Linf Norm: 0.3979\n",
            "Epoch 135: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2427, Test Linf Norm: 0.3979\n",
            "Epoch 136: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2411, Test Linf Norm: 0.3979\n",
            "Epoch 137: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2615, Test Linf Norm: 0.3979\n",
            "Epoch 138: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2625, Test Linf Norm: 0.3979\n",
            "Epoch 139: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2549, Test Linf Norm: 0.3979\n",
            "Epoch 140: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2494, Test Linf Norm: 0.3979\n",
            "Epoch 141: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2379, Test Linf Norm: 0.3979\n",
            "Epoch 142: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2481, Test Linf Norm: 0.3979\n",
            "Epoch 143: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2495, Test Linf Norm: 0.3979\n",
            "Epoch 144: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2583, Test Linf Norm: 0.3979\n",
            "Epoch 145: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2625, Test Linf Norm: 0.3979\n",
            "Epoch 146: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2479, Test Linf Norm: 0.3979\n",
            "Epoch 147: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2528, Test Linf Norm: 0.3979\n",
            "Epoch 148: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2432, Test Linf Norm: 0.3979\n",
            "Epoch 149: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2529, Test Linf Norm: 0.3979\n",
            "Epoch 150: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2443, Test Linf Norm: 0.3979\n",
            "Epoch 151: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2378, Test Linf Norm: 0.3979\n",
            "Epoch 152: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2547, Test Linf Norm: 0.3979\n",
            "Epoch 153: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2479, Test Linf Norm: 0.3979\n",
            "Epoch 154: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2520, Test Linf Norm: 0.3979\n",
            "Epoch 155: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2601, Test Linf Norm: 0.3979\n",
            "Epoch 156: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2489, Test Linf Norm: 0.3979\n",
            "Epoch 157: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2449, Test Linf Norm: 0.3979\n",
            "Epoch 158: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2610, Test Linf Norm: 0.3979\n",
            "Epoch 159: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2679, Test Linf Norm: 0.3979\n",
            "Epoch 160: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2562, Test Linf Norm: 0.3979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:09:00,594]\u001b[0m Trial 34 finished with value: 0.006750774819403887 and parameters: {'n_layers': 4, 'n_units_0': 1553, 'n_units_1': 180, 'n_units_2': 689, 'n_units_3': 267, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0004507198245149182, 'batch_size': 128, 'n_epochs': 161, 'scheduler': 'StepLR', 'weight_decay': 0.0014088473417279098, 'beta1': 0.9838466173272218, 'beta2': 0.9998003649995496, 'step_size': 14, 'gamma': 0.16862613804858897}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 161: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0137, Test L1 Norm: 0.0068, Train Linf Norm: 1.2638, Test Linf Norm: 0.3979\n",
            "Epoch 1: Train Loss: 0.6250, Test Loss: 0.1299, Train L1 Norm: 0.7295, Test L1 Norm: 0.0955, Train Linf Norm: 56.6200, Test Linf Norm: 4.4883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:09:04,905]\u001b[0m Trial 35 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.3399, Test Loss: 0.3435, Train L1 Norm: 0.3731, Test L1 Norm: 0.1246, Train Linf Norm: 29.5772, Test Linf Norm: 2.3084\n",
            "Epoch 1: Train Loss: 0.1312, Test Loss: 0.0267, Train L1 Norm: 0.2292, Test L1 Norm: 0.0344, Train Linf Norm: 8.1428, Test Linf Norm: 0.7257\n",
            "Epoch 2: Train Loss: 0.0656, Test Loss: 0.0817, Train L1 Norm: 0.1960, Test L1 Norm: 0.0455, Train Linf Norm: 7.9293, Test Linf Norm: 0.7019\n",
            "Epoch 3: Train Loss: 0.0462, Test Loss: 0.0337, Train L1 Norm: 0.1429, Test L1 Norm: 0.0370, Train Linf Norm: 5.7470, Test Linf Norm: 0.8699\n",
            "Epoch 4: Train Loss: 0.0450, Test Loss: 0.0201, Train L1 Norm: 0.1477, Test L1 Norm: 0.0339, Train Linf Norm: 6.0884, Test Linf Norm: 1.0035\n",
            "Epoch 5: Train Loss: 0.0396, Test Loss: 0.0216, Train L1 Norm: 0.0780, Test L1 Norm: 0.0362, Train Linf Norm: 2.8302, Test Linf Norm: 1.0146\n",
            "Epoch 6: Train Loss: 0.0345, Test Loss: 0.0403, Train L1 Norm: 0.0714, Test L1 Norm: 0.0303, Train Linf Norm: 2.6207, Test Linf Norm: 0.6121\n",
            "Epoch 7: Train Loss: 0.0393, Test Loss: 0.0587, Train L1 Norm: 0.0724, Test L1 Norm: 0.0274, Train Linf Norm: 2.5865, Test Linf Norm: 0.3817\n",
            "Epoch 8: Train Loss: 0.0345, Test Loss: 0.0229, Train L1 Norm: 0.0764, Test L1 Norm: 0.0250, Train Linf Norm: 2.9004, Test Linf Norm: 0.6003\n",
            "Epoch 9: Train Loss: 0.0342, Test Loss: 0.0313, Train L1 Norm: 0.0747, Test L1 Norm: 0.0302, Train Linf Norm: 2.8569, Test Linf Norm: 0.7323\n",
            "Epoch 10: Train Loss: 0.0353, Test Loss: 0.0191, Train L1 Norm: 0.0914, Test L1 Norm: 0.0301, Train Linf Norm: 3.6176, Test Linf Norm: 0.8291\n",
            "Epoch 11: Train Loss: 0.0323, Test Loss: 0.0316, Train L1 Norm: 0.0605, Test L1 Norm: 0.0209, Train Linf Norm: 2.1950, Test Linf Norm: 0.3204\n",
            "Epoch 12: Train Loss: 0.0322, Test Loss: 0.0825, Train L1 Norm: 0.0614, Test L1 Norm: 0.0679, Train Linf Norm: 2.2590, Test Linf Norm: 1.0601\n",
            "Epoch 13: Train Loss: 0.0345, Test Loss: 0.0294, Train L1 Norm: 0.0840, Test L1 Norm: 0.0281, Train Linf Norm: 3.2585, Test Linf Norm: 0.7350\n",
            "Epoch 14: Train Loss: 0.0329, Test Loss: 0.0394, Train L1 Norm: 0.0975, Test L1 Norm: 0.0338, Train Linf Norm: 3.9698, Test Linf Norm: 0.8692\n",
            "Epoch 15: Train Loss: 0.0321, Test Loss: 0.0285, Train L1 Norm: 0.1231, Test L1 Norm: 0.0253, Train Linf Norm: 5.1968, Test Linf Norm: 0.6721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:10:17,699]\u001b[0m Trial 36 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Loss: 0.0308, Test Loss: 0.0509, Train L1 Norm: 0.0741, Test L1 Norm: 0.0315, Train Linf Norm: 2.8652, Test Linf Norm: 0.5562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:10:20,225]\u001b[0m Trial 37 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.6182, Test Loss: 0.0318, Train L1 Norm: 2.7899, Test L1 Norm: 0.3721, Train Linf Norm: 234.8624, Test Linf Norm: 21.8299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:10:22,542]\u001b[0m Trial 38 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.3562, Test Loss: 0.1705, Train L1 Norm: 0.3955, Test L1 Norm: 0.1110, Train Linf Norm: 27.9178, Test Linf Norm: 4.3563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:10:23,909]\u001b[0m Trial 39 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.2007, Test Loss: 0.7513, Train L1 Norm: 1.9270, Test L1 Norm: 0.3306, Train Linf Norm: 612.4600, Test Linf Norm: 20.2448\n",
            "Epoch 1: Train Loss: 0.1522, Test Loss: 0.0356, Train L1 Norm: 0.2612, Test L1 Norm: 0.0425, Train Linf Norm: 20.5681, Test Linf Norm: 1.8583\n",
            "Epoch 2: Train Loss: 0.0631, Test Loss: 0.1688, Train L1 Norm: 0.1576, Test L1 Norm: 0.0867, Train Linf Norm: 15.4963, Test Linf Norm: 2.8332\n",
            "Epoch 3: Train Loss: 0.0625, Test Loss: 0.0277, Train L1 Norm: 0.1251, Test L1 Norm: 0.0405, Train Linf Norm: 11.3284, Test Linf Norm: 2.0135\n",
            "Epoch 4: Train Loss: 0.0501, Test Loss: 0.0484, Train L1 Norm: 0.1343, Test L1 Norm: 0.0378, Train Linf Norm: 13.3736, Test Linf Norm: 1.7768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:10:35,029]\u001b[0m Trial 40 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.0516, Test Loss: 0.0597, Train L1 Norm: 0.1108, Test L1 Norm: 0.0473, Train Linf Norm: 10.5282, Test Linf Norm: 2.6082\n",
            "Epoch 1: Train Loss: 0.1761, Test Loss: 0.0450, Train L1 Norm: 0.3585, Test L1 Norm: 0.0474, Train Linf Norm: 32.2094, Test Linf Norm: 2.6076\n",
            "Epoch 2: Train Loss: 0.0614, Test Loss: 0.0993, Train L1 Norm: 0.1633, Test L1 Norm: 0.0647, Train Linf Norm: 16.6053, Test Linf Norm: 2.8064\n",
            "Epoch 3: Train Loss: 0.0577, Test Loss: 0.0335, Train L1 Norm: 0.1269, Test L1 Norm: 0.0265, Train Linf Norm: 12.6143, Test Linf Norm: 0.9536\n",
            "Epoch 4: Train Loss: 0.0451, Test Loss: 0.0259, Train L1 Norm: 0.0857, Test L1 Norm: 0.0233, Train Linf Norm: 8.0119, Test Linf Norm: 1.1620\n",
            "Epoch 5: Train Loss: 0.0395, Test Loss: 0.0320, Train L1 Norm: 0.0891, Test L1 Norm: 0.0318, Train Linf Norm: 8.6425, Test Linf Norm: 1.7726\n",
            "Epoch 6: Train Loss: 0.0456, Test Loss: 0.0349, Train L1 Norm: 0.0884, Test L1 Norm: 0.0295, Train Linf Norm: 8.3658, Test Linf Norm: 1.6129\n",
            "Epoch 7: Train Loss: 0.0473, Test Loss: 0.0417, Train L1 Norm: 0.1083, Test L1 Norm: 0.0305, Train Linf Norm: 10.9167, Test Linf Norm: 1.4830\n",
            "Epoch 8: Train Loss: 0.0352, Test Loss: 0.0228, Train L1 Norm: 0.0684, Test L1 Norm: 0.0205, Train Linf Norm: 6.3292, Test Linf Norm: 0.7046\n",
            "Epoch 9: Train Loss: 0.0358, Test Loss: 0.0391, Train L1 Norm: 0.0791, Test L1 Norm: 0.0236, Train Linf Norm: 7.8046, Test Linf Norm: 0.9995\n",
            "Epoch 10: Train Loss: 0.0325, Test Loss: 0.0392, Train L1 Norm: 0.0630, Test L1 Norm: 0.0233, Train Linf Norm: 5.9611, Test Linf Norm: 0.7439\n",
            "Epoch 11: Train Loss: 0.0346, Test Loss: 0.0384, Train L1 Norm: 0.0515, Test L1 Norm: 0.0250, Train Linf Norm: 4.3896, Test Linf Norm: 1.0072\n",
            "Epoch 12: Train Loss: 0.0369, Test Loss: 0.0538, Train L1 Norm: 0.0668, Test L1 Norm: 0.0257, Train Linf Norm: 6.1908, Test Linf Norm: 0.7526\n",
            "Epoch 13: Train Loss: 0.0315, Test Loss: 0.0255, Train L1 Norm: 0.0818, Test L1 Norm: 0.0239, Train Linf Norm: 8.4487, Test Linf Norm: 1.2563\n",
            "Epoch 14: Train Loss: 0.0264, Test Loss: 0.0477, Train L1 Norm: 0.0669, Test L1 Norm: 0.0248, Train Linf Norm: 6.8271, Test Linf Norm: 0.9853\n",
            "Epoch 15: Train Loss: 0.0315, Test Loss: 0.0247, Train L1 Norm: 0.0750, Test L1 Norm: 0.0272, Train Linf Norm: 7.4248, Test Linf Norm: 1.7025\n",
            "Epoch 16: Train Loss: 0.0154, Test Loss: 0.0146, Train L1 Norm: 0.0628, Test L1 Norm: 0.0133, Train Linf Norm: 6.9333, Test Linf Norm: 0.8436\n",
            "Epoch 17: Train Loss: 0.0150, Test Loss: 0.0108, Train L1 Norm: 0.0469, Test L1 Norm: 0.0124, Train Linf Norm: 4.9643, Test Linf Norm: 0.8161\n",
            "Epoch 18: Train Loss: 0.0129, Test Loss: 0.0109, Train L1 Norm: 0.0414, Test L1 Norm: 0.0158, Train Linf Norm: 4.3734, Test Linf Norm: 1.0078\n",
            "Epoch 19: Train Loss: 0.0152, Test Loss: 0.0137, Train L1 Norm: 0.0391, Test L1 Norm: 0.0131, Train Linf Norm: 3.9627, Test Linf Norm: 0.7607\n",
            "Epoch 20: Train Loss: 0.0130, Test Loss: 0.0106, Train L1 Norm: 0.0297, Test L1 Norm: 0.0110, Train Linf Norm: 2.8933, Test Linf Norm: 0.6115\n",
            "Epoch 21: Train Loss: 0.0137, Test Loss: 0.0210, Train L1 Norm: 0.0301, Test L1 Norm: 0.0137, Train Linf Norm: 2.4511, Test Linf Norm: 0.6943\n",
            "Epoch 22: Train Loss: 0.0155, Test Loss: 0.0135, Train L1 Norm: 0.0438, Test L1 Norm: 0.0105, Train Linf Norm: 4.4920, Test Linf Norm: 0.4792\n",
            "Epoch 23: Train Loss: 0.0159, Test Loss: 0.0165, Train L1 Norm: 0.0253, Test L1 Norm: 0.0104, Train Linf Norm: 2.2077, Test Linf Norm: 0.4571\n",
            "Epoch 24: Train Loss: 0.0139, Test Loss: 0.0117, Train L1 Norm: 0.0254, Test L1 Norm: 0.0113, Train Linf Norm: 2.3175, Test Linf Norm: 0.6590\n",
            "Epoch 25: Train Loss: 0.0118, Test Loss: 0.0118, Train L1 Norm: 0.0199, Test L1 Norm: 0.0107, Train Linf Norm: 1.7021, Test Linf Norm: 0.4577\n",
            "Epoch 26: Train Loss: 0.0147, Test Loss: 0.0096, Train L1 Norm: 0.0203, Test L1 Norm: 0.0085, Train Linf Norm: 1.6354, Test Linf Norm: 0.3810\n",
            "Epoch 27: Train Loss: 0.0129, Test Loss: 0.0107, Train L1 Norm: 0.0240, Test L1 Norm: 0.0095, Train Linf Norm: 2.2283, Test Linf Norm: 0.4074\n",
            "Epoch 28: Train Loss: 0.0135, Test Loss: 0.0119, Train L1 Norm: 0.0278, Test L1 Norm: 0.0114, Train Linf Norm: 2.6563, Test Linf Norm: 0.5549\n",
            "Epoch 29: Train Loss: 0.0112, Test Loss: 0.0099, Train L1 Norm: 0.0209, Test L1 Norm: 0.0086, Train Linf Norm: 1.9015, Test Linf Norm: 0.4572\n",
            "Epoch 30: Train Loss: 0.0130, Test Loss: 0.0125, Train L1 Norm: 0.0237, Test L1 Norm: 0.0105, Train Linf Norm: 2.1681, Test Linf Norm: 0.6120\n",
            "Epoch 31: Train Loss: 0.0085, Test Loss: 0.0112, Train L1 Norm: 0.0196, Test L1 Norm: 0.0080, Train Linf Norm: 1.8915, Test Linf Norm: 0.3982\n",
            "Epoch 32: Train Loss: 0.0090, Test Loss: 0.0090, Train L1 Norm: 0.0199, Test L1 Norm: 0.0077, Train Linf Norm: 1.8859, Test Linf Norm: 0.4198\n",
            "Epoch 33: Train Loss: 0.0089, Test Loss: 0.0102, Train L1 Norm: 0.0174, Test L1 Norm: 0.0079, Train Linf Norm: 1.5898, Test Linf Norm: 0.4284\n",
            "Epoch 34: Train Loss: 0.0088, Test Loss: 0.0099, Train L1 Norm: 0.0131, Test L1 Norm: 0.0076, Train Linf Norm: 1.0555, Test Linf Norm: 0.3967\n",
            "Epoch 35: Train Loss: 0.0084, Test Loss: 0.0077, Train L1 Norm: 0.0170, Test L1 Norm: 0.0072, Train Linf Norm: 1.5850, Test Linf Norm: 0.4122\n",
            "Epoch 36: Train Loss: 0.0089, Test Loss: 0.0111, Train L1 Norm: 0.0184, Test L1 Norm: 0.0090, Train Linf Norm: 1.7280, Test Linf Norm: 0.4704\n",
            "Epoch 37: Train Loss: 0.0084, Test Loss: 0.0080, Train L1 Norm: 0.0190, Test L1 Norm: 0.0070, Train Linf Norm: 1.8325, Test Linf Norm: 0.3530\n",
            "Epoch 38: Train Loss: 0.0086, Test Loss: 0.0072, Train L1 Norm: 0.0134, Test L1 Norm: 0.0070, Train Linf Norm: 1.1137, Test Linf Norm: 0.4065\n",
            "Epoch 39: Train Loss: 0.0083, Test Loss: 0.0074, Train L1 Norm: 0.0161, Test L1 Norm: 0.0074, Train Linf Norm: 1.4504, Test Linf Norm: 0.4410\n",
            "Epoch 40: Train Loss: 0.0083, Test Loss: 0.0083, Train L1 Norm: 0.0164, Test L1 Norm: 0.0077, Train Linf Norm: 1.5128, Test Linf Norm: 0.4275\n",
            "Epoch 41: Train Loss: 0.0086, Test Loss: 0.0075, Train L1 Norm: 0.0141, Test L1 Norm: 0.0071, Train Linf Norm: 1.1807, Test Linf Norm: 0.3978\n",
            "Epoch 42: Train Loss: 0.0083, Test Loss: 0.0077, Train L1 Norm: 0.0148, Test L1 Norm: 0.0071, Train Linf Norm: 1.3088, Test Linf Norm: 0.3790\n",
            "Epoch 43: Train Loss: 0.0086, Test Loss: 0.0110, Train L1 Norm: 0.0153, Test L1 Norm: 0.0097, Train Linf Norm: 1.3420, Test Linf Norm: 0.5172\n",
            "Epoch 44: Train Loss: 0.0082, Test Loss: 0.0140, Train L1 Norm: 0.0158, Test L1 Norm: 0.0117, Train Linf Norm: 1.4308, Test Linf Norm: 0.6135\n",
            "Epoch 45: Train Loss: 0.0079, Test Loss: 0.0083, Train L1 Norm: 0.0164, Test L1 Norm: 0.0071, Train Linf Norm: 1.5167, Test Linf Norm: 0.3777\n",
            "Epoch 46: Train Loss: 0.0068, Test Loss: 0.0067, Train L1 Norm: 0.0165, Test L1 Norm: 0.0066, Train Linf Norm: 1.5843, Test Linf Norm: 0.3814\n",
            "Epoch 47: Train Loss: 0.0071, Test Loss: 0.0070, Train L1 Norm: 0.0121, Test L1 Norm: 0.0072, Train Linf Norm: 1.0282, Test Linf Norm: 0.4293\n",
            "Epoch 48: Train Loss: 0.0067, Test Loss: 0.0068, Train L1 Norm: 0.0132, Test L1 Norm: 0.0065, Train Linf Norm: 1.1858, Test Linf Norm: 0.3582\n",
            "Epoch 49: Train Loss: 0.0069, Test Loss: 0.0068, Train L1 Norm: 0.0152, Test L1 Norm: 0.0066, Train Linf Norm: 1.4305, Test Linf Norm: 0.3779\n",
            "Epoch 50: Train Loss: 0.0068, Test Loss: 0.0071, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 0.9796, Test Linf Norm: 0.3480\n",
            "Epoch 51: Train Loss: 0.0069, Test Loss: 0.0074, Train L1 Norm: 0.0129, Test L1 Norm: 0.0072, Train Linf Norm: 1.1306, Test Linf Norm: 0.4117\n",
            "Epoch 52: Train Loss: 0.0068, Test Loss: 0.0073, Train L1 Norm: 0.0133, Test L1 Norm: 0.0065, Train Linf Norm: 1.1906, Test Linf Norm: 0.3554\n",
            "Epoch 53: Train Loss: 0.0069, Test Loss: 0.0066, Train L1 Norm: 0.0154, Test L1 Norm: 0.0067, Train Linf Norm: 1.4754, Test Linf Norm: 0.3958\n",
            "Epoch 54: Train Loss: 0.0067, Test Loss: 0.0074, Train L1 Norm: 0.0129, Test L1 Norm: 0.0070, Train Linf Norm: 1.1481, Test Linf Norm: 0.4012\n",
            "Epoch 55: Train Loss: 0.0069, Test Loss: 0.0076, Train L1 Norm: 0.0115, Test L1 Norm: 0.0070, Train Linf Norm: 0.9591, Test Linf Norm: 0.3926\n",
            "Epoch 56: Train Loss: 0.0074, Test Loss: 0.0069, Train L1 Norm: 0.0145, Test L1 Norm: 0.0064, Train Linf Norm: 1.3113, Test Linf Norm: 0.3532\n",
            "Epoch 57: Train Loss: 0.0068, Test Loss: 0.0067, Train L1 Norm: 0.0133, Test L1 Norm: 0.0064, Train Linf Norm: 1.2082, Test Linf Norm: 0.3636\n",
            "Epoch 58: Train Loss: 0.0067, Test Loss: 0.0066, Train L1 Norm: 0.0129, Test L1 Norm: 0.0064, Train Linf Norm: 1.1574, Test Linf Norm: 0.3629\n",
            "Epoch 59: Train Loss: 0.0068, Test Loss: 0.0066, Train L1 Norm: 0.0148, Test L1 Norm: 0.0063, Train Linf Norm: 1.3755, Test Linf Norm: 0.3541\n",
            "Epoch 60: Train Loss: 0.0065, Test Loss: 0.0064, Train L1 Norm: 0.0120, Test L1 Norm: 0.0064, Train Linf Norm: 1.0382, Test Linf Norm: 0.3739\n",
            "Epoch 61: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0129, Test L1 Norm: 0.0064, Train Linf Norm: 1.1689, Test Linf Norm: 0.3692\n",
            "Epoch 62: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0127, Test L1 Norm: 0.0063, Train Linf Norm: 1.1493, Test Linf Norm: 0.3645\n",
            "Epoch 63: Train Loss: 0.0063, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 1.1198, Test Linf Norm: 0.3688\n",
            "Epoch 64: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0131, Test L1 Norm: 0.0063, Train Linf Norm: 1.2132, Test Linf Norm: 0.3662\n",
            "Epoch 65: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0126, Test L1 Norm: 0.0064, Train Linf Norm: 1.1521, Test Linf Norm: 0.3741\n",
            "Epoch 66: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0126, Test L1 Norm: 0.0065, Train Linf Norm: 1.1421, Test Linf Norm: 0.3766\n",
            "Epoch 67: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0130, Test L1 Norm: 0.0065, Train Linf Norm: 1.1843, Test Linf Norm: 0.3762\n",
            "Epoch 68: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0107, Test L1 Norm: 0.0063, Train Linf Norm: 0.9017, Test Linf Norm: 0.3644\n",
            "Epoch 69: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0128, Test L1 Norm: 0.0064, Train Linf Norm: 1.1463, Test Linf Norm: 0.3719\n",
            "Epoch 70: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0127, Test L1 Norm: 0.0062, Train Linf Norm: 1.1553, Test Linf Norm: 0.3563\n",
            "Epoch 71: Train Loss: 0.0063, Test Loss: 0.0067, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 0.9953, Test Linf Norm: 0.3614\n",
            "Epoch 72: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0118, Test L1 Norm: 0.0065, Train Linf Norm: 1.0337, Test Linf Norm: 0.3780\n",
            "Epoch 73: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0108, Test L1 Norm: 0.0063, Train Linf Norm: 0.9108, Test Linf Norm: 0.3657\n",
            "Epoch 74: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0110, Test L1 Norm: 0.0064, Train Linf Norm: 0.9382, Test Linf Norm: 0.3694\n",
            "Epoch 75: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0118, Test L1 Norm: 0.0064, Train Linf Norm: 1.0385, Test Linf Norm: 0.3719\n",
            "Epoch 76: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0124, Test L1 Norm: 0.0063, Train Linf Norm: 1.1166, Test Linf Norm: 0.3687\n",
            "Epoch 77: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0119, Test L1 Norm: 0.0064, Train Linf Norm: 1.0520, Test Linf Norm: 0.3740\n",
            "Epoch 78: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0118, Test L1 Norm: 0.0063, Train Linf Norm: 1.0495, Test Linf Norm: 0.3705\n",
            "Epoch 79: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0063, Train Linf Norm: 1.1170, Test Linf Norm: 0.3681\n",
            "Epoch 80: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0120, Test L1 Norm: 0.0064, Train Linf Norm: 1.0696, Test Linf Norm: 0.3714\n",
            "Epoch 81: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0122, Test L1 Norm: 0.0064, Train Linf Norm: 1.0874, Test Linf Norm: 0.3694\n",
            "Epoch 82: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0261, Test Linf Norm: 0.3650\n",
            "Epoch 83: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0118, Test L1 Norm: 0.0064, Train Linf Norm: 1.0511, Test Linf Norm: 0.3756\n",
            "Epoch 84: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0091, Test Linf Norm: 0.3666\n",
            "Epoch 85: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0118, Test L1 Norm: 0.0064, Train Linf Norm: 1.0441, Test Linf Norm: 0.3780\n",
            "Epoch 86: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0121, Test L1 Norm: 0.0063, Train Linf Norm: 1.0836, Test Linf Norm: 0.3662\n",
            "Epoch 87: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0063, Train Linf Norm: 1.1314, Test Linf Norm: 0.3661\n",
            "Epoch 88: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0120, Test L1 Norm: 0.0064, Train Linf Norm: 1.0724, Test Linf Norm: 0.3716\n",
            "Epoch 89: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0064, Train Linf Norm: 1.0226, Test Linf Norm: 0.3710\n",
            "Epoch 90: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0112, Test L1 Norm: 0.0063, Train Linf Norm: 0.9615, Test Linf Norm: 0.3697\n",
            "Epoch 91: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0118, Test L1 Norm: 0.0064, Train Linf Norm: 1.0335, Test Linf Norm: 0.3719\n",
            "Epoch 92: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0171, Test Linf Norm: 0.3668\n",
            "Epoch 93: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0155, Test Linf Norm: 0.3677\n",
            "Epoch 94: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0174, Test Linf Norm: 0.3685\n",
            "Epoch 95: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0152, Test Linf Norm: 0.3660\n",
            "Epoch 96: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0120, Test L1 Norm: 0.0064, Train Linf Norm: 1.0694, Test Linf Norm: 0.3724\n",
            "Epoch 97: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0270, Test Linf Norm: 0.3694\n",
            "Epoch 98: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0232, Test Linf Norm: 0.3694\n",
            "Epoch 99: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0117, Test L1 Norm: 0.0063, Train Linf Norm: 1.0415, Test Linf Norm: 0.3675\n",
            "Epoch 100: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0117, Test L1 Norm: 0.0063, Train Linf Norm: 1.0315, Test Linf Norm: 0.3671\n",
            "Epoch 101: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0118, Test L1 Norm: 0.0063, Train Linf Norm: 1.0487, Test Linf Norm: 0.3692\n",
            "Epoch 102: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0117, Test L1 Norm: 0.0063, Train Linf Norm: 1.0368, Test Linf Norm: 0.3678\n",
            "Epoch 103: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0119, Test L1 Norm: 0.0064, Train Linf Norm: 1.0554, Test Linf Norm: 0.3711\n",
            "Epoch 104: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0047, Test Linf Norm: 0.3699\n",
            "Epoch 105: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0114, Test L1 Norm: 0.0063, Train Linf Norm: 0.9855, Test Linf Norm: 0.3695\n",
            "Epoch 106: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0147, Test Linf Norm: 0.3702\n",
            "Epoch 107: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0162, Test Linf Norm: 0.3698\n",
            "Epoch 108: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0117, Test L1 Norm: 0.0063, Train Linf Norm: 1.0368, Test Linf Norm: 0.3699\n",
            "Epoch 109: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0148, Test Linf Norm: 0.3700\n",
            "Epoch 110: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0174, Test Linf Norm: 0.3705\n",
            "Epoch 111: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0233, Test Linf Norm: 0.3709\n",
            "Epoch 112: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0315, Test Linf Norm: 0.3700\n",
            "Epoch 113: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0239, Test Linf Norm: 0.3699\n",
            "Epoch 114: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0077, Test Linf Norm: 0.3706\n",
            "Epoch 115: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0157, Test Linf Norm: 0.3700\n",
            "Epoch 116: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0117, Test L1 Norm: 0.0063, Train Linf Norm: 1.0400, Test Linf Norm: 0.3699\n",
            "Epoch 117: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0183, Test Linf Norm: 0.3711\n",
            "Epoch 118: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0282, Test Linf Norm: 0.3698\n",
            "Epoch 119: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0000, Test Linf Norm: 0.3698\n",
            "Epoch 120: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0209, Test Linf Norm: 0.3704\n",
            "Epoch 121: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0084, Test Linf Norm: 0.3698\n",
            "Epoch 122: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0172, Test Linf Norm: 0.3700\n",
            "Epoch 123: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0187, Test Linf Norm: 0.3700\n",
            "Epoch 124: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0314, Test Linf Norm: 0.3701\n",
            "Epoch 125: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0138, Test Linf Norm: 0.3696\n",
            "Epoch 126: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0253, Test Linf Norm: 0.3699\n",
            "Epoch 127: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0275, Test Linf Norm: 0.3700\n",
            "Epoch 128: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0165, Test Linf Norm: 0.3699\n",
            "Epoch 129: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0171, Test Linf Norm: 0.3699\n",
            "Epoch 130: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0102, Test Linf Norm: 0.3698\n",
            "Epoch 131: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0163, Test Linf Norm: 0.3696\n",
            "Epoch 132: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0201, Test Linf Norm: 0.3702\n",
            "Epoch 133: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0156, Test Linf Norm: 0.3699\n",
            "Epoch 134: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0258, Test Linf Norm: 0.3699\n",
            "Epoch 135: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0245, Test Linf Norm: 0.3700\n",
            "Epoch 136: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0175, Test Linf Norm: 0.3699\n",
            "Epoch 137: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0131, Test Linf Norm: 0.3699\n",
            "Epoch 138: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0201, Test Linf Norm: 0.3699\n",
            "Epoch 139: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0199, Test Linf Norm: 0.3699\n",
            "Epoch 140: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0231, Test Linf Norm: 0.3698\n",
            "Epoch 141: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0008, Test Linf Norm: 0.3699\n",
            "Epoch 142: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0175, Test Linf Norm: 0.3699\n",
            "Epoch 143: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0158, Test Linf Norm: 0.3699\n",
            "Epoch 144: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0217, Test Linf Norm: 0.3699\n",
            "Epoch 145: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0193, Test Linf Norm: 0.3699\n",
            "Epoch 146: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0138, Test Linf Norm: 0.3700\n",
            "Epoch 147: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0170, Test Linf Norm: 0.3699\n",
            "Epoch 148: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0276, Test Linf Norm: 0.3699\n",
            "Epoch 149: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0154, Test Linf Norm: 0.3699\n",
            "Epoch 150: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0062, Test Linf Norm: 0.3699\n",
            "Epoch 151: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0198, Test Linf Norm: 0.3699\n",
            "Epoch 152: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0210, Test Linf Norm: 0.3699\n",
            "Epoch 153: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0191, Test Linf Norm: 0.3699\n",
            "Epoch 154: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0240, Test Linf Norm: 0.3699\n",
            "Epoch 155: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0249, Test Linf Norm: 0.3699\n",
            "Epoch 156: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0162, Test Linf Norm: 0.3699\n",
            "Epoch 157: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0101, Test Linf Norm: 0.3699\n",
            "Epoch 158: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0126, Test Linf Norm: 0.3699\n",
            "Epoch 159: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0081, Test Linf Norm: 0.3699\n",
            "Epoch 160: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0192, Test Linf Norm: 0.3699\n",
            "Epoch 161: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0168, Test Linf Norm: 0.3699\n",
            "Epoch 162: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 1.0067, Test Linf Norm: 0.3699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:16:49,048]\u001b[0m Trial 41 finished with value: 0.006340245017036796 and parameters: {'n_layers': 4, 'n_units_0': 1608, 'n_units_1': 558, 'n_units_2': 421, 'n_units_3': 411, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0008982100022629545, 'batch_size': 128, 'n_epochs': 163, 'scheduler': 'StepLR', 'weight_decay': 0.003722701256931689, 'beta1': 0.9843537860173635, 'beta2': 0.9996126544873354, 'step_size': 15, 'gamma': 0.2558935780041656}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 163: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0063, Train Linf Norm: 1.0104, Test Linf Norm: 0.3699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:16:51,619]\u001b[0m Trial 42 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.2516, Test Loss: 0.0573, Train L1 Norm: 0.8331, Test L1 Norm: 0.1064, Train Linf Norm: 85.1954, Test Linf Norm: 8.2979\n",
            "Epoch 1: Train Loss: 0.1586, Test Loss: 0.0261, Train L1 Norm: 0.3178, Test L1 Norm: 0.0451, Train Linf Norm: 26.8016, Test Linf Norm: 2.8955\n",
            "Epoch 2: Train Loss: 0.0382, Test Loss: 0.0646, Train L1 Norm: 0.1925, Test L1 Norm: 0.0653, Train Linf Norm: 20.8286, Test Linf Norm: 3.4479\n",
            "Epoch 3: Train Loss: 0.0447, Test Loss: 0.0489, Train L1 Norm: 0.1768, Test L1 Norm: 0.0822, Train Linf Norm: 18.5908, Test Linf Norm: 5.4686\n",
            "Epoch 4: Train Loss: 0.0382, Test Loss: 0.0193, Train L1 Norm: 0.1917, Test L1 Norm: 0.0392, Train Linf Norm: 21.1529, Test Linf Norm: 2.8840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:17:02,868]\u001b[0m Trial 43 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.0449, Test Loss: 0.0500, Train L1 Norm: 0.1768, Test L1 Norm: 0.0431, Train Linf Norm: 19.1015, Test Linf Norm: 2.4684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:17:05,618]\u001b[0m Trial 44 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.2294, Test Loss: 0.0527, Train L1 Norm: 1.0166, Test L1 Norm: 0.1541, Train Linf Norm: 108.7433, Test Linf Norm: 12.6172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:17:14,077]\u001b[0m Trial 45 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1139, Test Loss: 0.1282, Train L1 Norm: 0.2528, Test L1 Norm: 0.1035, Train Linf Norm: 6.4929, Test Linf Norm: 1.5756\n",
            "Epoch 1: Train Loss: 0.1021, Test Loss: 0.0043, Train L1 Norm: 0.2881, Test L1 Norm: 0.0531, Train Linf Norm: 16.6391, Test Linf Norm: 2.0430\n",
            "Epoch 2: Train Loss: 0.0072, Test Loss: 0.0120, Train L1 Norm: 0.0799, Test L1 Norm: 0.0338, Train Linf Norm: 4.6020, Test Linf Norm: 0.8531\n",
            "Epoch 3: Train Loss: 0.0034, Test Loss: 0.0011, Train L1 Norm: 0.0748, Test L1 Norm: 0.0270, Train Linf Norm: 4.8787, Test Linf Norm: 1.0460\n",
            "Epoch 4: Train Loss: 0.0027, Test Loss: 0.0007, Train L1 Norm: 0.0643, Test L1 Norm: 0.0227, Train Linf Norm: 4.2920, Test Linf Norm: 0.8463\n",
            "Epoch 5: Train Loss: 0.0016, Test Loss: 0.0008, Train L1 Norm: 0.0565, Test L1 Norm: 0.0217, Train Linf Norm: 3.7940, Test Linf Norm: 0.7215\n",
            "Epoch 6: Train Loss: 0.0015, Test Loss: 0.0005, Train L1 Norm: 0.0513, Test L1 Norm: 0.0177, Train Linf Norm: 3.4555, Test Linf Norm: 0.5966\n",
            "Epoch 7: Train Loss: 0.0016, Test Loss: 0.0009, Train L1 Norm: 0.0602, Test L1 Norm: 0.0211, Train Linf Norm: 4.3283, Test Linf Norm: 0.8075\n",
            "Epoch 8: Train Loss: 0.0015, Test Loss: 0.0004, Train L1 Norm: 0.0464, Test L1 Norm: 0.0164, Train Linf Norm: 3.1328, Test Linf Norm: 0.5785\n",
            "Epoch 9: Train Loss: 0.0013, Test Loss: 0.0003, Train L1 Norm: 0.0448, Test L1 Norm: 0.0161, Train Linf Norm: 3.0117, Test Linf Norm: 0.6172\n",
            "Epoch 10: Train Loss: 0.0013, Test Loss: 0.0005, Train L1 Norm: 0.0401, Test L1 Norm: 0.0198, Train Linf Norm: 2.6246, Test Linf Norm: 0.6635\n",
            "Epoch 11: Train Loss: 0.0008, Test Loss: 0.0004, Train L1 Norm: 0.0366, Test L1 Norm: 0.0162, Train Linf Norm: 2.4289, Test Linf Norm: 0.5880\n",
            "Epoch 12: Train Loss: 0.0007, Test Loss: 0.0010, Train L1 Norm: 0.0470, Test L1 Norm: 0.0267, Train Linf Norm: 3.4551, Test Linf Norm: 0.9222\n",
            "Epoch 13: Train Loss: 0.0008, Test Loss: 0.0102, Train L1 Norm: 0.0319, Test L1 Norm: 0.0453, Train Linf Norm: 1.9925, Test Linf Norm: 1.2372\n",
            "Epoch 14: Train Loss: 0.0008, Test Loss: 0.0005, Train L1 Norm: 0.0328, Test L1 Norm: 0.0153, Train Linf Norm: 2.1041, Test Linf Norm: 0.5247\n",
            "Epoch 15: Train Loss: 0.0008, Test Loss: 0.0002, Train L1 Norm: 0.0374, Test L1 Norm: 0.0137, Train Linf Norm: 2.5821, Test Linf Norm: 0.5355\n",
            "Epoch 16: Train Loss: 0.0007, Test Loss: 0.0002, Train L1 Norm: 0.0384, Test L1 Norm: 0.0152, Train Linf Norm: 2.7013, Test Linf Norm: 0.6037\n",
            "Epoch 17: Train Loss: 0.0007, Test Loss: 0.0002, Train L1 Norm: 0.0341, Test L1 Norm: 0.0163, Train Linf Norm: 2.3289, Test Linf Norm: 0.7050\n",
            "Epoch 18: Train Loss: 0.0006, Test Loss: 0.0002, Train L1 Norm: 0.0318, Test L1 Norm: 0.0135, Train Linf Norm: 2.1181, Test Linf Norm: 0.5332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:05,870]\u001b[0m Trial 46 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Loss: 0.0003, Test Loss: 0.0016, Train L1 Norm: 0.0326, Test L1 Norm: 0.0184, Train Linf Norm: 2.2841, Test Linf Norm: 0.5316\n",
            "Epoch 1: Train Loss: 0.1594, Test Loss: 0.0510, Train L1 Norm: 0.5568, Test L1 Norm: 0.0599, Train Linf Norm: 22.7115, Test Linf Norm: 1.6004\n",
            "Epoch 2: Train Loss: 0.0832, Test Loss: 0.0410, Train L1 Norm: 0.2949, Test L1 Norm: 0.0593, Train Linf Norm: 12.3998, Test Linf Norm: 1.7126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:23,690]\u001b[0m Trial 47 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 0.0642, Test Loss: 0.0480, Train L1 Norm: 0.2169, Test L1 Norm: 0.0526, Train Linf Norm: 8.9760, Test Linf Norm: 1.4470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:25,726]\u001b[0m Trial 48 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.3762, Test Loss: 0.1890, Train L1 Norm: 3.0936, Test L1 Norm: 0.3994, Train Linf Norm: 353.9221, Test Linf Norm: 27.1640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:28,309]\u001b[0m Trial 49 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 636.2337, Test Loss: 3.4125, Train L1 Norm: 661.4454, Test L1 Norm: 1.0000, Train Linf Norm: 44737.1536, Test Linf Norm: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:31,673]\u001b[0m Trial 50 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.3160, Test Loss: 0.0405, Train L1 Norm: 1.3757, Test L1 Norm: 0.1985, Train Linf Norm: 147.8326, Test Linf Norm: 16.5561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:34,037]\u001b[0m Trial 51 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1624, Test Loss: 0.1418, Train L1 Norm: 0.5836, Test L1 Norm: 0.1186, Train Linf Norm: 61.2074, Test Linf Norm: 5.9803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:36,521]\u001b[0m Trial 52 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1653, Test Loss: 0.0704, Train L1 Norm: 0.8691, Test L1 Norm: 0.1367, Train Linf Norm: 94.8835, Test Linf Norm: 10.9279\n",
            "Epoch 1: Train Loss: 0.2043, Test Loss: 0.0385, Train L1 Norm: 0.7329, Test L1 Norm: 0.0767, Train Linf Norm: 77.2361, Test Linf Norm: 5.4437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:41,393]\u001b[0m Trial 53 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.0357, Test Loss: 0.0698, Train L1 Norm: 0.1963, Test L1 Norm: 0.0789, Train Linf Norm: 21.3596, Test Linf Norm: 4.1663\n",
            "Epoch 1: Train Loss: 0.2006, Test Loss: 0.0408, Train L1 Norm: 0.5076, Test L1 Norm: 0.0449, Train Linf Norm: 49.5343, Test Linf Norm: 2.5927\n",
            "Epoch 2: Train Loss: 0.0564, Test Loss: 0.0333, Train L1 Norm: 0.1488, Test L1 Norm: 0.0637, Train Linf Norm: 14.5406, Test Linf Norm: 4.1877\n",
            "Epoch 3: Train Loss: 0.0544, Test Loss: 0.0297, Train L1 Norm: 0.1598, Test L1 Norm: 0.0414, Train Linf Norm: 16.2699, Test Linf Norm: 2.4698\n",
            "Epoch 4: Train Loss: 0.0468, Test Loss: 0.0323, Train L1 Norm: 0.1813, Test L1 Norm: 0.0421, Train Linf Norm: 19.5613, Test Linf Norm: 2.9597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:51,868]\u001b[0m Trial 54 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.0483, Test Loss: 0.0323, Train L1 Norm: 0.1675, Test L1 Norm: 0.0393, Train Linf Norm: 17.8878, Test Linf Norm: 2.7992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:53,104]\u001b[0m Trial 55 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.6834, Test Loss: 0.3921, Train L1 Norm: 1.2641, Test L1 Norm: 0.3060, Train Linf Norm: 454.0744, Test Linf Norm: 28.3315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:18:55,920]\u001b[0m Trial 56 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1677, Test Loss: 0.0864, Train L1 Norm: 0.9285, Test L1 Norm: 0.1122, Train Linf Norm: 104.1032, Test Linf Norm: 7.6953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:19:03,005]\u001b[0m Trial 57 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.2733, Test Loss: 0.1360, Train L1 Norm: 0.6736, Test L1 Norm: 0.2495, Train Linf Norm: 14.9740, Test Linf Norm: 5.1499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:19:07,036]\u001b[0m Trial 58 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 3.3922, Test Loss: 3.4125, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:19:09,520]\u001b[0m Trial 59 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.4095, Test Loss: 0.0564, Train L1 Norm: 3.3700, Test L1 Norm: 0.4130, Train Linf Norm: 362.5839, Test Linf Norm: 29.2727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:19:16,737]\u001b[0m Trial 60 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 16.2005, Test Loss: 0.2082, Train L1 Norm: 0.9690, Test L1 Norm: 0.2046, Train Linf Norm: 6.4484, Test Linf Norm: 1.7714\n",
            "Epoch 1: Train Loss: 0.2045, Test Loss: 0.0438, Train L1 Norm: 0.3936, Test L1 Norm: 0.0585, Train Linf Norm: 34.3021, Test Linf Norm: 3.3323\n",
            "Epoch 2: Train Loss: 0.0414, Test Loss: 0.0436, Train L1 Norm: 0.1693, Test L1 Norm: 0.0464, Train Linf Norm: 18.0698, Test Linf Norm: 2.2506\n",
            "Epoch 3: Train Loss: 0.0350, Test Loss: 0.0195, Train L1 Norm: 0.2145, Test L1 Norm: 0.0239, Train Linf Norm: 24.1948, Test Linf Norm: 1.2525\n",
            "Epoch 4: Train Loss: 0.0476, Test Loss: 0.0294, Train L1 Norm: 0.1247, Test L1 Norm: 0.0365, Train Linf Norm: 12.4701, Test Linf Norm: 2.4866\n",
            "Epoch 5: Train Loss: 0.0278, Test Loss: 0.0135, Train L1 Norm: 0.1269, Test L1 Norm: 0.0245, Train Linf Norm: 13.9061, Test Linf Norm: 1.5917\n",
            "Epoch 6: Train Loss: 0.0314, Test Loss: 0.0190, Train L1 Norm: 0.1188, Test L1 Norm: 0.0252, Train Linf Norm: 12.6680, Test Linf Norm: 1.5102\n",
            "Epoch 7: Train Loss: 0.0295, Test Loss: 0.0315, Train L1 Norm: 0.1077, Test L1 Norm: 0.0300, Train Linf Norm: 11.5108, Test Linf Norm: 1.4477\n",
            "Epoch 8: Train Loss: 0.0266, Test Loss: 0.0515, Train L1 Norm: 0.1042, Test L1 Norm: 0.0292, Train Linf Norm: 11.1580, Test Linf Norm: 1.0518\n",
            "Epoch 9: Train Loss: 0.0230, Test Loss: 0.0158, Train L1 Norm: 0.0643, Test L1 Norm: 0.0155, Train Linf Norm: 6.2950, Test Linf Norm: 0.7638\n",
            "Epoch 10: Train Loss: 0.0208, Test Loss: 0.0128, Train L1 Norm: 0.0563, Test L1 Norm: 0.0149, Train Linf Norm: 5.5945, Test Linf Norm: 0.8796\n",
            "Epoch 11: Train Loss: 0.0265, Test Loss: 0.0191, Train L1 Norm: 0.0585, Test L1 Norm: 0.0167, Train Linf Norm: 5.6626, Test Linf Norm: 0.9417\n",
            "Epoch 12: Train Loss: 0.0199, Test Loss: 0.0131, Train L1 Norm: 0.0498, Test L1 Norm: 0.0172, Train Linf Norm: 4.9361, Test Linf Norm: 1.0088\n",
            "Epoch 13: Train Loss: 0.0251, Test Loss: 0.0155, Train L1 Norm: 0.0568, Test L1 Norm: 0.0253, Train Linf Norm: 5.5793, Test Linf Norm: 1.6207\n",
            "Epoch 14: Train Loss: 0.0277, Test Loss: 0.0256, Train L1 Norm: 0.0497, Test L1 Norm: 0.0170, Train Linf Norm: 4.5880, Test Linf Norm: 0.6938\n",
            "Epoch 15: Train Loss: 0.0164, Test Loss: 0.0151, Train L1 Norm: 0.0467, Test L1 Norm: 0.0197, Train Linf Norm: 4.7429, Test Linf Norm: 1.1145\n",
            "Epoch 16: Train Loss: 0.0086, Test Loss: 0.0072, Train L1 Norm: 0.0288, Test L1 Norm: 0.0088, Train Linf Norm: 2.9261, Test Linf Norm: 0.4775\n",
            "Epoch 17: Train Loss: 0.0081, Test Loss: 0.0074, Train L1 Norm: 0.0244, Test L1 Norm: 0.0085, Train Linf Norm: 2.3848, Test Linf Norm: 0.4421\n",
            "Epoch 18: Train Loss: 0.0079, Test Loss: 0.0107, Train L1 Norm: 0.0210, Test L1 Norm: 0.0095, Train Linf Norm: 1.9521, Test Linf Norm: 0.4734\n",
            "Epoch 19: Train Loss: 0.0084, Test Loss: 0.0071, Train L1 Norm: 0.0213, Test L1 Norm: 0.0084, Train Linf Norm: 1.9728, Test Linf Norm: 0.4458\n",
            "Epoch 20: Train Loss: 0.0076, Test Loss: 0.0092, Train L1 Norm: 0.0228, Test L1 Norm: 0.0087, Train Linf Norm: 2.2079, Test Linf Norm: 0.4186\n",
            "Epoch 21: Train Loss: 0.0086, Test Loss: 0.0070, Train L1 Norm: 0.0200, Test L1 Norm: 0.0088, Train Linf Norm: 1.8139, Test Linf Norm: 0.4932\n",
            "Epoch 22: Train Loss: 0.0080, Test Loss: 0.0068, Train L1 Norm: 0.0189, Test L1 Norm: 0.0084, Train Linf Norm: 1.6923, Test Linf Norm: 0.4451\n",
            "Epoch 23: Train Loss: 0.0092, Test Loss: 0.0088, Train L1 Norm: 0.0230, Test L1 Norm: 0.0088, Train Linf Norm: 2.1769, Test Linf Norm: 0.4613\n",
            "Epoch 24: Train Loss: 0.0081, Test Loss: 0.0061, Train L1 Norm: 0.0218, Test L1 Norm: 0.0085, Train Linf Norm: 2.0862, Test Linf Norm: 0.5189\n",
            "Epoch 25: Train Loss: 0.0084, Test Loss: 0.0069, Train L1 Norm: 0.0221, Test L1 Norm: 0.0080, Train Linf Norm: 2.1195, Test Linf Norm: 0.4499\n",
            "Epoch 26: Train Loss: 0.0072, Test Loss: 0.0067, Train L1 Norm: 0.0176, Test L1 Norm: 0.0079, Train Linf Norm: 1.5549, Test Linf Norm: 0.3938\n",
            "Epoch 27: Train Loss: 0.0082, Test Loss: 0.0116, Train L1 Norm: 0.0211, Test L1 Norm: 0.0100, Train Linf Norm: 1.9798, Test Linf Norm: 0.4968\n",
            "Epoch 28: Train Loss: 0.0093, Test Loss: 0.0071, Train L1 Norm: 0.0180, Test L1 Norm: 0.0083, Train Linf Norm: 1.5708, Test Linf Norm: 0.4231\n",
            "Epoch 29: Train Loss: 0.0078, Test Loss: 0.0137, Train L1 Norm: 0.0164, Test L1 Norm: 0.0100, Train Linf Norm: 1.4119, Test Linf Norm: 0.4480\n",
            "Epoch 30: Train Loss: 0.0092, Test Loss: 0.0132, Train L1 Norm: 0.0184, Test L1 Norm: 0.0104, Train Linf Norm: 1.6082, Test Linf Norm: 0.4258\n",
            "Epoch 31: Train Loss: 0.0056, Test Loss: 0.0053, Train L1 Norm: 0.0153, Test L1 Norm: 0.0073, Train Linf Norm: 1.4026, Test Linf Norm: 0.4307\n",
            "Epoch 32: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0149, Test L1 Norm: 0.0074, Train Linf Norm: 1.3565, Test Linf Norm: 0.4320\n",
            "Epoch 33: Train Loss: 0.0051, Test Loss: 0.0059, Train L1 Norm: 0.0143, Test L1 Norm: 0.0080, Train Linf Norm: 1.2731, Test Linf Norm: 0.4584\n",
            "Epoch 34: Train Loss: 0.0054, Test Loss: 0.0056, Train L1 Norm: 0.0145, Test L1 Norm: 0.0072, Train Linf Norm: 1.2962, Test Linf Norm: 0.3981\n",
            "Epoch 35: Train Loss: 0.0050, Test Loss: 0.0050, Train L1 Norm: 0.0142, Test L1 Norm: 0.0070, Train Linf Norm: 1.2720, Test Linf Norm: 0.4075\n",
            "Epoch 36: Train Loss: 0.0053, Test Loss: 0.0054, Train L1 Norm: 0.0136, Test L1 Norm: 0.0070, Train Linf Norm: 1.1702, Test Linf Norm: 0.3922\n",
            "Epoch 37: Train Loss: 0.0052, Test Loss: 0.0058, Train L1 Norm: 0.0152, Test L1 Norm: 0.0071, Train Linf Norm: 1.4250, Test Linf Norm: 0.3944\n",
            "Epoch 38: Train Loss: 0.0051, Test Loss: 0.0049, Train L1 Norm: 0.0159, Test L1 Norm: 0.0072, Train Linf Norm: 1.4980, Test Linf Norm: 0.4241\n",
            "Epoch 39: Train Loss: 0.0051, Test Loss: 0.0050, Train L1 Norm: 0.0143, Test L1 Norm: 0.0070, Train Linf Norm: 1.3064, Test Linf Norm: 0.4091\n",
            "Epoch 40: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0152, Test L1 Norm: 0.0070, Train Linf Norm: 1.4178, Test Linf Norm: 0.3973\n",
            "Epoch 41: Train Loss: 0.0051, Test Loss: 0.0054, Train L1 Norm: 0.0161, Test L1 Norm: 0.0070, Train Linf Norm: 1.5368, Test Linf Norm: 0.3987\n",
            "Epoch 42: Train Loss: 0.0053, Test Loss: 0.0063, Train L1 Norm: 0.0156, Test L1 Norm: 0.0072, Train Linf Norm: 1.4406, Test Linf Norm: 0.3828\n",
            "Epoch 43: Train Loss: 0.0053, Test Loss: 0.0049, Train L1 Norm: 0.0140, Test L1 Norm: 0.0070, Train Linf Norm: 1.2648, Test Linf Norm: 0.4143\n",
            "Epoch 44: Train Loss: 0.0052, Test Loss: 0.0050, Train L1 Norm: 0.0158, Test L1 Norm: 0.0070, Train Linf Norm: 1.4838, Test Linf Norm: 0.4139\n",
            "Epoch 45: Train Loss: 0.0050, Test Loss: 0.0049, Train L1 Norm: 0.0146, Test L1 Norm: 0.0069, Train Linf Norm: 1.3550, Test Linf Norm: 0.3993\n",
            "Epoch 46: Train Loss: 0.0045, Test Loss: 0.0048, Train L1 Norm: 0.0142, Test L1 Norm: 0.0069, Train Linf Norm: 1.3175, Test Linf Norm: 0.4041\n",
            "Epoch 47: Train Loss: 0.0046, Test Loss: 0.0048, Train L1 Norm: 0.0139, Test L1 Norm: 0.0068, Train Linf Norm: 1.2705, Test Linf Norm: 0.4013\n",
            "Epoch 48: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0144, Test L1 Norm: 0.0068, Train Linf Norm: 1.3533, Test Linf Norm: 0.4038\n",
            "Epoch 49: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0142, Test L1 Norm: 0.0069, Train Linf Norm: 1.2943, Test Linf Norm: 0.4103\n",
            "Epoch 50: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0144, Test L1 Norm: 0.0068, Train Linf Norm: 1.3419, Test Linf Norm: 0.4020\n",
            "Epoch 51: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0143, Test L1 Norm: 0.0068, Train Linf Norm: 1.3325, Test Linf Norm: 0.3996\n",
            "Epoch 52: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3189, Test Linf Norm: 0.4024\n",
            "Epoch 53: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0141, Test L1 Norm: 0.0070, Train Linf Norm: 1.3066, Test Linf Norm: 0.4142\n",
            "Epoch 54: Train Loss: 0.0046, Test Loss: 0.0048, Train L1 Norm: 0.0144, Test L1 Norm: 0.0068, Train Linf Norm: 1.3478, Test Linf Norm: 0.4029\n",
            "Epoch 55: Train Loss: 0.0045, Test Loss: 0.0051, Train L1 Norm: 0.0143, Test L1 Norm: 0.0069, Train Linf Norm: 1.3306, Test Linf Norm: 0.3940\n",
            "Epoch 56: Train Loss: 0.0045, Test Loss: 0.0048, Train L1 Norm: 0.0142, Test L1 Norm: 0.0069, Train Linf Norm: 1.3265, Test Linf Norm: 0.4057\n",
            "Epoch 57: Train Loss: 0.0045, Test Loss: 0.0048, Train L1 Norm: 0.0144, Test L1 Norm: 0.0068, Train Linf Norm: 1.3457, Test Linf Norm: 0.4024\n",
            "Epoch 58: Train Loss: 0.0046, Test Loss: 0.0047, Train L1 Norm: 0.0141, Test L1 Norm: 0.0069, Train Linf Norm: 1.3029, Test Linf Norm: 0.4111\n",
            "Epoch 59: Train Loss: 0.0045, Test Loss: 0.0046, Train L1 Norm: 0.0140, Test L1 Norm: 0.0068, Train Linf Norm: 1.2955, Test Linf Norm: 0.4022\n",
            "Epoch 60: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0138, Test L1 Norm: 0.0068, Train Linf Norm: 1.2596, Test Linf Norm: 0.4012\n",
            "Epoch 61: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0140, Test L1 Norm: 0.0068, Train Linf Norm: 1.3086, Test Linf Norm: 0.4041\n",
            "Epoch 62: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0140, Test L1 Norm: 0.0068, Train Linf Norm: 1.3139, Test Linf Norm: 0.4073\n",
            "Epoch 63: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3186, Test Linf Norm: 0.4035\n",
            "Epoch 64: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3304, Test Linf Norm: 0.4039\n",
            "Epoch 65: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0140, Test L1 Norm: 0.0068, Train Linf Norm: 1.3163, Test Linf Norm: 0.4055\n",
            "Epoch 66: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0143, Test L1 Norm: 0.0068, Train Linf Norm: 1.3379, Test Linf Norm: 0.4021\n",
            "Epoch 67: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3185, Test Linf Norm: 0.4029\n",
            "Epoch 68: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0139, Test L1 Norm: 0.0068, Train Linf Norm: 1.2879, Test Linf Norm: 0.4028\n",
            "Epoch 69: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0143, Test L1 Norm: 0.0068, Train Linf Norm: 1.3331, Test Linf Norm: 0.4035\n",
            "Epoch 70: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0143, Test L1 Norm: 0.0068, Train Linf Norm: 1.3473, Test Linf Norm: 0.4048\n",
            "Epoch 71: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3249, Test Linf Norm: 0.4077\n",
            "Epoch 72: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0145, Test L1 Norm: 0.0069, Train Linf Norm: 1.3746, Test Linf Norm: 0.4099\n",
            "Epoch 73: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3289, Test Linf Norm: 0.4080\n",
            "Epoch 74: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3171, Test Linf Norm: 0.4034\n",
            "Epoch 75: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0143, Test L1 Norm: 0.0068, Train Linf Norm: 1.3219, Test Linf Norm: 0.4003\n",
            "Epoch 76: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3200, Test Linf Norm: 0.4046\n",
            "Epoch 77: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3243, Test Linf Norm: 0.4047\n",
            "Epoch 78: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3363, Test Linf Norm: 0.4042\n",
            "Epoch 79: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3222, Test Linf Norm: 0.4044\n",
            "Epoch 80: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.2998, Test Linf Norm: 0.4049\n",
            "Epoch 81: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3245, Test Linf Norm: 0.4056\n",
            "Epoch 82: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3145, Test Linf Norm: 0.4040\n",
            "Epoch 83: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3215, Test Linf Norm: 0.4044\n",
            "Epoch 84: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3131, Test Linf Norm: 0.4039\n",
            "Epoch 85: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3361, Test Linf Norm: 0.4036\n",
            "Epoch 86: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3337, Test Linf Norm: 0.4045\n",
            "Epoch 87: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3187, Test Linf Norm: 0.4040\n",
            "Epoch 88: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.2998, Test Linf Norm: 0.4037\n",
            "Epoch 89: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3257, Test Linf Norm: 0.4049\n",
            "Epoch 90: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3377, Test Linf Norm: 0.4050\n",
            "Epoch 91: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3258, Test Linf Norm: 0.4046\n",
            "Epoch 92: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3291, Test Linf Norm: 0.4046\n",
            "Epoch 93: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3297, Test Linf Norm: 0.4046\n",
            "Epoch 94: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3297, Test Linf Norm: 0.4044\n",
            "Epoch 95: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3269, Test Linf Norm: 0.4044\n",
            "Epoch 96: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3299, Test Linf Norm: 0.4043\n",
            "Epoch 97: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3176, Test Linf Norm: 0.4043\n",
            "Epoch 98: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3162, Test Linf Norm: 0.4041\n",
            "Epoch 99: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3321, Test Linf Norm: 0.4042\n",
            "Epoch 100: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3379, Test Linf Norm: 0.4041\n",
            "Epoch 101: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3092, Test Linf Norm: 0.4045\n",
            "Epoch 102: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3094, Test Linf Norm: 0.4041\n",
            "Epoch 103: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3388, Test Linf Norm: 0.4043\n",
            "Epoch 104: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3144, Test Linf Norm: 0.4042\n",
            "Epoch 105: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 1.3403, Test Linf Norm: 0.4043\n",
            "Epoch 106: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3278, Test Linf Norm: 0.4043\n",
            "Epoch 107: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3284, Test Linf Norm: 0.4043\n",
            "Epoch 108: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3119, Test Linf Norm: 0.4042\n",
            "Epoch 109: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3327, Test Linf Norm: 0.4042\n",
            "Epoch 110: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3332, Test Linf Norm: 0.4042\n",
            "Epoch 111: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3110, Test Linf Norm: 0.4042\n",
            "Epoch 112: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.2998, Test Linf Norm: 0.4042\n",
            "Epoch 113: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3325, Test Linf Norm: 0.4042\n",
            "Epoch 114: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3158, Test Linf Norm: 0.4042\n",
            "Epoch 115: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3245, Test Linf Norm: 0.4042\n",
            "Epoch 116: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3241, Test Linf Norm: 0.4042\n",
            "Epoch 117: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3120, Test Linf Norm: 0.4041\n",
            "Epoch 118: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3105, Test Linf Norm: 0.4042\n",
            "Epoch 119: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3183, Test Linf Norm: 0.4042\n",
            "Epoch 120: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3295, Test Linf Norm: 0.4042\n",
            "Epoch 121: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3140, Test Linf Norm: 0.4042\n",
            "Epoch 122: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3155, Test Linf Norm: 0.4042\n",
            "Epoch 123: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3276, Test Linf Norm: 0.4042\n",
            "Epoch 124: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3372, Test Linf Norm: 0.4042\n",
            "Epoch 125: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3226, Test Linf Norm: 0.4042\n",
            "Epoch 126: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3128, Test Linf Norm: 0.4042\n",
            "Epoch 127: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3219, Test Linf Norm: 0.4042\n",
            "Epoch 128: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3301, Test Linf Norm: 0.4042\n",
            "Epoch 129: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3293, Test Linf Norm: 0.4042\n",
            "Epoch 130: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3310, Test Linf Norm: 0.4042\n",
            "Epoch 131: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3228, Test Linf Norm: 0.4042\n",
            "Epoch 132: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3245, Test Linf Norm: 0.4042\n",
            "Epoch 133: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3118, Test Linf Norm: 0.4042\n",
            "Epoch 134: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3335, Test Linf Norm: 0.4042\n",
            "Epoch 135: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3398, Test Linf Norm: 0.4042\n",
            "Epoch 136: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3112, Test Linf Norm: 0.4042\n",
            "Epoch 137: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3242, Test Linf Norm: 0.4042\n",
            "Epoch 138: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3314, Test Linf Norm: 0.4042\n",
            "Epoch 139: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3258, Test Linf Norm: 0.4042\n",
            "Epoch 140: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3141, Test Linf Norm: 0.4042\n",
            "Epoch 141: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3287, Test Linf Norm: 0.4042\n",
            "Epoch 142: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3145, Test Linf Norm: 0.4042\n",
            "Epoch 143: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3312, Test Linf Norm: 0.4042\n",
            "Epoch 144: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3289, Test Linf Norm: 0.4042\n",
            "Epoch 145: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3263, Test Linf Norm: 0.4042\n",
            "Epoch 146: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3074, Test Linf Norm: 0.4042\n",
            "Epoch 147: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3288, Test Linf Norm: 0.4042\n",
            "Epoch 148: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3313, Test Linf Norm: 0.4042\n",
            "Epoch 149: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3203, Test Linf Norm: 0.4042\n",
            "Epoch 150: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3260, Test Linf Norm: 0.4042\n",
            "Epoch 151: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3298, Test Linf Norm: 0.4042\n",
            "Epoch 152: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3162, Test Linf Norm: 0.4042\n",
            "Epoch 153: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3320, Test Linf Norm: 0.4042\n",
            "Epoch 154: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3323, Test Linf Norm: 0.4042\n",
            "Epoch 155: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3199, Test Linf Norm: 0.4042\n",
            "Epoch 156: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3162, Test Linf Norm: 0.4042\n",
            "Epoch 157: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3275, Test Linf Norm: 0.4042\n",
            "Epoch 158: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3195, Test Linf Norm: 0.4042\n",
            "Epoch 159: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3141, Test Linf Norm: 0.4042\n",
            "Epoch 160: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3243, Test Linf Norm: 0.4042\n",
            "Epoch 161: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3196, Test Linf Norm: 0.4042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:25:21,722]\u001b[0m Trial 61 finished with value: 0.006777881963923573 and parameters: {'n_layers': 4, 'n_units_0': 1542, 'n_units_1': 192, 'n_units_2': 739, 'n_units_3': 293, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.000461331526604689, 'batch_size': 128, 'n_epochs': 162, 'scheduler': 'StepLR', 'weight_decay': 0.00110493975830318, 'beta1': 0.9822526880920079, 'beta2': 0.9997653657791506, 'step_size': 15, 'gamma': 0.17877968985267206}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 162: Train Loss: 0.0043, Test Loss: 0.0046, Train L1 Norm: 0.0141, Test L1 Norm: 0.0068, Train Linf Norm: 1.3177, Test Linf Norm: 0.4042\n",
            "Epoch 1: Train Loss: 0.1796, Test Loss: 0.0599, Train L1 Norm: 0.7628, Test L1 Norm: 0.0760, Train Linf Norm: 81.6664, Test Linf Norm: 4.7103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:25:25,852]\u001b[0m Trial 62 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.0495, Test Loss: 0.0841, Train L1 Norm: 0.2743, Test L1 Norm: 0.0825, Train Linf Norm: 30.8945, Test Linf Norm: 5.1873\n",
            "Epoch 1: Train Loss: 0.2171, Test Loss: 0.0487, Train L1 Norm: 0.6554, Test L1 Norm: 0.0659, Train Linf Norm: 64.9646, Test Linf Norm: 3.9802\n",
            "Epoch 2: Train Loss: 0.0371, Test Loss: 0.0298, Train L1 Norm: 0.1949, Test L1 Norm: 0.0444, Train Linf Norm: 21.1213, Test Linf Norm: 2.9352\n",
            "Epoch 3: Train Loss: 0.0298, Test Loss: 0.0164, Train L1 Norm: 0.1518, Test L1 Norm: 0.0353, Train Linf Norm: 16.4319, Test Linf Norm: 2.5474\n",
            "Epoch 4: Train Loss: 0.0225, Test Loss: 0.0246, Train L1 Norm: 0.1258, Test L1 Norm: 0.0270, Train Linf Norm: 13.8751, Test Linf Norm: 1.0133\n",
            "Epoch 5: Train Loss: 0.0223, Test Loss: 0.0228, Train L1 Norm: 0.0973, Test L1 Norm: 0.0358, Train Linf Norm: 10.4183, Test Linf Norm: 2.3205\n",
            "Epoch 6: Train Loss: 0.0228, Test Loss: 0.0193, Train L1 Norm: 0.0794, Test L1 Norm: 0.0326, Train Linf Norm: 8.2252, Test Linf Norm: 1.9780\n",
            "Epoch 7: Train Loss: 0.0201, Test Loss: 0.0198, Train L1 Norm: 0.0522, Test L1 Norm: 0.0228, Train Linf Norm: 4.7962, Test Linf Norm: 1.2908\n",
            "Epoch 8: Train Loss: 0.0247, Test Loss: 0.0148, Train L1 Norm: 0.0501, Test L1 Norm: 0.0193, Train Linf Norm: 4.3519, Test Linf Norm: 1.2661\n",
            "Epoch 9: Train Loss: 0.0223, Test Loss: 0.0163, Train L1 Norm: 0.0475, Test L1 Norm: 0.0186, Train Linf Norm: 4.2870, Test Linf Norm: 0.6558\n",
            "Epoch 10: Train Loss: 0.0286, Test Loss: 0.0480, Train L1 Norm: 0.0521, Test L1 Norm: 0.0320, Train Linf Norm: 4.5827, Test Linf Norm: 1.5218\n",
            "Epoch 11: Train Loss: 0.0253, Test Loss: 0.0344, Train L1 Norm: 0.0545, Test L1 Norm: 0.0262, Train Linf Norm: 5.0896, Test Linf Norm: 1.2314\n",
            "Epoch 12: Train Loss: 0.0258, Test Loss: 0.0218, Train L1 Norm: 0.0499, Test L1 Norm: 0.0170, Train Linf Norm: 4.4065, Test Linf Norm: 0.7988\n",
            "Epoch 13: Train Loss: 0.0180, Test Loss: 0.0185, Train L1 Norm: 0.0490, Test L1 Norm: 0.0151, Train Linf Norm: 4.8446, Test Linf Norm: 0.6092\n",
            "Epoch 14: Train Loss: 0.0177, Test Loss: 0.0146, Train L1 Norm: 0.0740, Test L1 Norm: 0.0163, Train Linf Norm: 8.1229, Test Linf Norm: 1.0646\n",
            "Epoch 15: Train Loss: 0.0162, Test Loss: 0.0255, Train L1 Norm: 0.0432, Test L1 Norm: 0.0227, Train Linf Norm: 4.2442, Test Linf Norm: 1.3354\n",
            "Epoch 16: Train Loss: 0.0096, Test Loss: 0.0082, Train L1 Norm: 0.0390, Test L1 Norm: 0.0100, Train Linf Norm: 4.0465, Test Linf Norm: 0.5941\n",
            "Epoch 17: Train Loss: 0.0103, Test Loss: 0.0124, Train L1 Norm: 0.0330, Test L1 Norm: 0.0120, Train Linf Norm: 3.3682, Test Linf Norm: 0.7014\n",
            "Epoch 18: Train Loss: 0.0078, Test Loss: 0.0071, Train L1 Norm: 0.0311, Test L1 Norm: 0.0095, Train Linf Norm: 3.2590, Test Linf Norm: 0.5875\n",
            "Epoch 19: Train Loss: 0.0083, Test Loss: 0.0129, Train L1 Norm: 0.0260, Test L1 Norm: 0.0149, Train Linf Norm: 2.5622, Test Linf Norm: 0.9649\n",
            "Epoch 20: Train Loss: 0.0108, Test Loss: 0.0083, Train L1 Norm: 0.0397, Test L1 Norm: 0.0096, Train Linf Norm: 4.2060, Test Linf Norm: 0.5801\n",
            "Epoch 21: Train Loss: 0.0087, Test Loss: 0.0080, Train L1 Norm: 0.0241, Test L1 Norm: 0.0093, Train Linf Norm: 2.3317, Test Linf Norm: 0.5611\n",
            "Epoch 22: Train Loss: 0.0115, Test Loss: 0.0079, Train L1 Norm: 0.0339, Test L1 Norm: 0.0097, Train Linf Norm: 3.4197, Test Linf Norm: 0.6144\n",
            "Epoch 23: Train Loss: 0.0094, Test Loss: 0.0077, Train L1 Norm: 0.0293, Test L1 Norm: 0.0105, Train Linf Norm: 2.9525, Test Linf Norm: 0.7009\n",
            "Epoch 24: Train Loss: 0.0084, Test Loss: 0.0089, Train L1 Norm: 0.0335, Test L1 Norm: 0.0091, Train Linf Norm: 3.5572, Test Linf Norm: 0.5088\n",
            "Epoch 25: Train Loss: 0.0088, Test Loss: 0.0099, Train L1 Norm: 0.0304, Test L1 Norm: 0.0093, Train Linf Norm: 3.1452, Test Linf Norm: 0.4981\n",
            "Epoch 26: Train Loss: 0.0090, Test Loss: 0.0065, Train L1 Norm: 0.0300, Test L1 Norm: 0.0091, Train Linf Norm: 3.0902, Test Linf Norm: 0.5915\n",
            "Epoch 27: Train Loss: 0.0080, Test Loss: 0.0093, Train L1 Norm: 0.0306, Test L1 Norm: 0.0093, Train Linf Norm: 3.2237, Test Linf Norm: 0.5223\n",
            "Epoch 28: Train Loss: 0.0078, Test Loss: 0.0085, Train L1 Norm: 0.0259, Test L1 Norm: 0.0087, Train Linf Norm: 2.5999, Test Linf Norm: 0.4992\n",
            "Epoch 29: Train Loss: 0.0082, Test Loss: 0.0073, Train L1 Norm: 0.0207, Test L1 Norm: 0.0109, Train Linf Norm: 1.9581, Test Linf Norm: 0.7202\n",
            "Epoch 30: Train Loss: 0.0086, Test Loss: 0.0095, Train L1 Norm: 0.0197, Test L1 Norm: 0.0098, Train Linf Norm: 1.7832, Test Linf Norm: 0.4452\n",
            "Epoch 31: Train Loss: 0.0063, Test Loss: 0.0068, Train L1 Norm: 0.0239, Test L1 Norm: 0.0075, Train Linf Norm: 2.4772, Test Linf Norm: 0.4315\n",
            "Epoch 32: Train Loss: 0.0063, Test Loss: 0.0062, Train L1 Norm: 0.0236, Test L1 Norm: 0.0089, Train Linf Norm: 2.4230, Test Linf Norm: 0.5702\n",
            "Epoch 33: Train Loss: 0.0063, Test Loss: 0.0059, Train L1 Norm: 0.0231, Test L1 Norm: 0.0077, Train Linf Norm: 2.3811, Test Linf Norm: 0.4697\n",
            "Epoch 34: Train Loss: 0.0060, Test Loss: 0.0065, Train L1 Norm: 0.0232, Test L1 Norm: 0.0084, Train Linf Norm: 2.4037, Test Linf Norm: 0.5225\n",
            "Epoch 35: Train Loss: 0.0063, Test Loss: 0.0059, Train L1 Norm: 0.0221, Test L1 Norm: 0.0079, Train Linf Norm: 2.2450, Test Linf Norm: 0.4886\n",
            "Epoch 36: Train Loss: 0.0063, Test Loss: 0.0066, Train L1 Norm: 0.0270, Test L1 Norm: 0.0080, Train Linf Norm: 2.8652, Test Linf Norm: 0.4826\n",
            "Epoch 37: Train Loss: 0.0060, Test Loss: 0.0059, Train L1 Norm: 0.0236, Test L1 Norm: 0.0076, Train Linf Norm: 2.4669, Test Linf Norm: 0.4694\n",
            "Epoch 38: Train Loss: 0.0061, Test Loss: 0.0070, Train L1 Norm: 0.0225, Test L1 Norm: 0.0082, Train Linf Norm: 2.3240, Test Linf Norm: 0.5103\n",
            "Epoch 39: Train Loss: 0.0062, Test Loss: 0.0057, Train L1 Norm: 0.0240, Test L1 Norm: 0.0069, Train Linf Norm: 2.4804, Test Linf Norm: 0.3794\n",
            "Epoch 40: Train Loss: 0.0060, Test Loss: 0.0072, Train L1 Norm: 0.0249, Test L1 Norm: 0.0075, Train Linf Norm: 2.6086, Test Linf Norm: 0.4253\n",
            "Epoch 41: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0229, Test L1 Norm: 0.0073, Train Linf Norm: 2.3637, Test Linf Norm: 0.4116\n",
            "Epoch 42: Train Loss: 0.0060, Test Loss: 0.0061, Train L1 Norm: 0.0233, Test L1 Norm: 0.0068, Train Linf Norm: 2.4265, Test Linf Norm: 0.3731\n",
            "Epoch 43: Train Loss: 0.0062, Test Loss: 0.0063, Train L1 Norm: 0.0235, Test L1 Norm: 0.0071, Train Linf Norm: 2.4549, Test Linf Norm: 0.3658\n",
            "Epoch 44: Train Loss: 0.0062, Test Loss: 0.0060, Train L1 Norm: 0.0188, Test L1 Norm: 0.0073, Train Linf Norm: 1.8363, Test Linf Norm: 0.4216\n",
            "Epoch 45: Train Loss: 0.0064, Test Loss: 0.0067, Train L1 Norm: 0.0263, Test L1 Norm: 0.0073, Train Linf Norm: 2.8022, Test Linf Norm: 0.4200\n",
            "Epoch 46: Train Loss: 0.0055, Test Loss: 0.0054, Train L1 Norm: 0.0216, Test L1 Norm: 0.0071, Train Linf Norm: 2.2306, Test Linf Norm: 0.4257\n",
            "Epoch 47: Train Loss: 0.0054, Test Loss: 0.0054, Train L1 Norm: 0.0229, Test L1 Norm: 0.0070, Train Linf Norm: 2.4095, Test Linf Norm: 0.4233\n",
            "Epoch 48: Train Loss: 0.0054, Test Loss: 0.0055, Train L1 Norm: 0.0211, Test L1 Norm: 0.0070, Train Linf Norm: 2.1905, Test Linf Norm: 0.4147\n",
            "Epoch 49: Train Loss: 0.0054, Test Loss: 0.0054, Train L1 Norm: 0.0210, Test L1 Norm: 0.0070, Train Linf Norm: 2.1469, Test Linf Norm: 0.4258\n",
            "Epoch 50: Train Loss: 0.0054, Test Loss: 0.0055, Train L1 Norm: 0.0221, Test L1 Norm: 0.0071, Train Linf Norm: 2.3097, Test Linf Norm: 0.4332\n",
            "Epoch 51: Train Loss: 0.0054, Test Loss: 0.0055, Train L1 Norm: 0.0207, Test L1 Norm: 0.0070, Train Linf Norm: 2.1197, Test Linf Norm: 0.4163\n",
            "Epoch 52: Train Loss: 0.0054, Test Loss: 0.0059, Train L1 Norm: 0.0217, Test L1 Norm: 0.0074, Train Linf Norm: 2.2357, Test Linf Norm: 0.4533\n",
            "Epoch 53: Train Loss: 0.0054, Test Loss: 0.0057, Train L1 Norm: 0.0210, Test L1 Norm: 0.0071, Train Linf Norm: 2.1656, Test Linf Norm: 0.4190\n",
            "Epoch 54: Train Loss: 0.0056, Test Loss: 0.0056, Train L1 Norm: 0.0225, Test L1 Norm: 0.0072, Train Linf Norm: 2.3661, Test Linf Norm: 0.4407\n",
            "Epoch 55: Train Loss: 0.0054, Test Loss: 0.0054, Train L1 Norm: 0.0219, Test L1 Norm: 0.0070, Train Linf Norm: 2.2816, Test Linf Norm: 0.4170\n",
            "Epoch 56: Train Loss: 0.0054, Test Loss: 0.0055, Train L1 Norm: 0.0211, Test L1 Norm: 0.0070, Train Linf Norm: 2.1912, Test Linf Norm: 0.4200\n",
            "Epoch 57: Train Loss: 0.0055, Test Loss: 0.0054, Train L1 Norm: 0.0215, Test L1 Norm: 0.0070, Train Linf Norm: 2.2354, Test Linf Norm: 0.4204\n",
            "Epoch 58: Train Loss: 0.0054, Test Loss: 0.0055, Train L1 Norm: 0.0210, Test L1 Norm: 0.0069, Train Linf Norm: 2.1694, Test Linf Norm: 0.4117\n",
            "Epoch 59: Train Loss: 0.0055, Test Loss: 0.0054, Train L1 Norm: 0.0212, Test L1 Norm: 0.0072, Train Linf Norm: 2.1912, Test Linf Norm: 0.4423\n",
            "Epoch 60: Train Loss: 0.0054, Test Loss: 0.0053, Train L1 Norm: 0.0203, Test L1 Norm: 0.0070, Train Linf Norm: 2.0617, Test Linf Norm: 0.4236\n",
            "Epoch 61: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0209, Test L1 Norm: 0.0071, Train Linf Norm: 2.1712, Test Linf Norm: 0.4360\n",
            "Epoch 62: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1514, Test Linf Norm: 0.4130\n",
            "Epoch 63: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0209, Test L1 Norm: 0.0068, Train Linf Norm: 2.1594, Test Linf Norm: 0.4084\n",
            "Epoch 64: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0209, Test L1 Norm: 0.0070, Train Linf Norm: 2.1792, Test Linf Norm: 0.4221\n",
            "Epoch 65: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1657, Test Linf Norm: 0.4165\n",
            "Epoch 66: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0211, Test L1 Norm: 0.0070, Train Linf Norm: 2.1850, Test Linf Norm: 0.4233\n",
            "Epoch 67: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0210, Test L1 Norm: 0.0070, Train Linf Norm: 2.1701, Test Linf Norm: 0.4256\n",
            "Epoch 68: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1606, Test Linf Norm: 0.4206\n",
            "Epoch 69: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0070, Train Linf Norm: 2.1447, Test Linf Norm: 0.4244\n",
            "Epoch 70: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0204, Test L1 Norm: 0.0067, Train Linf Norm: 2.1114, Test Linf Norm: 0.3951\n",
            "Epoch 71: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0211, Test L1 Norm: 0.0069, Train Linf Norm: 2.2010, Test Linf Norm: 0.4141\n",
            "Epoch 72: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0207, Test L1 Norm: 0.0070, Train Linf Norm: 2.1351, Test Linf Norm: 0.4214\n",
            "Epoch 73: Train Loss: 0.0052, Test Loss: 0.0054, Train L1 Norm: 0.0213, Test L1 Norm: 0.0070, Train Linf Norm: 2.2106, Test Linf Norm: 0.4313\n",
            "Epoch 74: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0213, Test L1 Norm: 0.0069, Train Linf Norm: 2.2191, Test Linf Norm: 0.4141\n",
            "Epoch 75: Train Loss: 0.0052, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0068, Train Linf Norm: 2.1209, Test Linf Norm: 0.4104\n",
            "Epoch 76: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0207, Test L1 Norm: 0.0068, Train Linf Norm: 2.1471, Test Linf Norm: 0.4054\n",
            "Epoch 77: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0068, Train Linf Norm: 2.1666, Test Linf Norm: 0.4072\n",
            "Epoch 78: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0212, Test L1 Norm: 0.0069, Train Linf Norm: 2.2019, Test Linf Norm: 0.4199\n",
            "Epoch 79: Train Loss: 0.0051, Test Loss: 0.0054, Train L1 Norm: 0.0208, Test L1 Norm: 0.0068, Train Linf Norm: 2.1737, Test Linf Norm: 0.4076\n",
            "Epoch 80: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0068, Train Linf Norm: 2.1635, Test Linf Norm: 0.4079\n",
            "Epoch 81: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0211, Test L1 Norm: 0.0069, Train Linf Norm: 2.2059, Test Linf Norm: 0.4139\n",
            "Epoch 82: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0210, Test L1 Norm: 0.0069, Train Linf Norm: 2.1885, Test Linf Norm: 0.4162\n",
            "Epoch 83: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0070, Train Linf Norm: 2.1650, Test Linf Norm: 0.4236\n",
            "Epoch 84: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0068, Train Linf Norm: 2.1709, Test Linf Norm: 0.4066\n",
            "Epoch 85: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0210, Test L1 Norm: 0.0068, Train Linf Norm: 2.1974, Test Linf Norm: 0.4117\n",
            "Epoch 86: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0210, Test L1 Norm: 0.0069, Train Linf Norm: 2.1850, Test Linf Norm: 0.4160\n",
            "Epoch 87: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0212, Test L1 Norm: 0.0069, Train Linf Norm: 2.1987, Test Linf Norm: 0.4197\n",
            "Epoch 88: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0207, Test L1 Norm: 0.0070, Train Linf Norm: 2.1594, Test Linf Norm: 0.4251\n",
            "Epoch 89: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0068, Train Linf Norm: 2.1725, Test Linf Norm: 0.4115\n",
            "Epoch 90: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0068, Train Linf Norm: 2.1225, Test Linf Norm: 0.4093\n",
            "Epoch 91: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1760, Test Linf Norm: 0.4159\n",
            "Epoch 92: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1658, Test Linf Norm: 0.4164\n",
            "Epoch 93: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1887, Test Linf Norm: 0.4196\n",
            "Epoch 94: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1775, Test Linf Norm: 0.4166\n",
            "Epoch 95: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1775, Test Linf Norm: 0.4132\n",
            "Epoch 96: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1673, Test Linf Norm: 0.4155\n",
            "Epoch 97: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1456, Test Linf Norm: 0.4137\n",
            "Epoch 98: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1702, Test Linf Norm: 0.4160\n",
            "Epoch 99: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1386, Test Linf Norm: 0.4174\n",
            "Epoch 100: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1705, Test Linf Norm: 0.4162\n",
            "Epoch 101: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1711, Test Linf Norm: 0.4134\n",
            "Epoch 102: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1785, Test Linf Norm: 0.4169\n",
            "Epoch 103: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1593, Test Linf Norm: 0.4174\n",
            "Epoch 104: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1634, Test Linf Norm: 0.4143\n",
            "Epoch 105: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1797, Test Linf Norm: 0.4151\n",
            "Epoch 106: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1654, Test Linf Norm: 0.4161\n",
            "Epoch 107: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1473, Test Linf Norm: 0.4162\n",
            "Epoch 108: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1806, Test Linf Norm: 0.4174\n",
            "Epoch 109: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1726, Test Linf Norm: 0.4167\n",
            "Epoch 110: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1490, Test Linf Norm: 0.4161\n",
            "Epoch 111: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1830, Test Linf Norm: 0.4163\n",
            "Epoch 112: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1656, Test Linf Norm: 0.4174\n",
            "Epoch 113: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1307, Test Linf Norm: 0.4164\n",
            "Epoch 114: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1697, Test Linf Norm: 0.4164\n",
            "Epoch 115: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1762, Test Linf Norm: 0.4162\n",
            "Epoch 116: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1859, Test Linf Norm: 0.4171\n",
            "Epoch 117: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1615, Test Linf Norm: 0.4167\n",
            "Epoch 118: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1758, Test Linf Norm: 0.4164\n",
            "Epoch 119: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1648, Test Linf Norm: 0.4161\n",
            "Epoch 120: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1703, Test Linf Norm: 0.4159\n",
            "Epoch 121: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1734, Test Linf Norm: 0.4164\n",
            "Epoch 122: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1686, Test Linf Norm: 0.4168\n",
            "Epoch 123: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1745, Test Linf Norm: 0.4166\n",
            "Epoch 124: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1648, Test Linf Norm: 0.4166\n",
            "Epoch 125: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1742, Test Linf Norm: 0.4166\n",
            "Epoch 126: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1565, Test Linf Norm: 0.4165\n",
            "Epoch 127: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1519, Test Linf Norm: 0.4165\n",
            "Epoch 128: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1810, Test Linf Norm: 0.4165\n",
            "Epoch 129: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0209, Test L1 Norm: 0.0069, Train Linf Norm: 2.1566, Test Linf Norm: 0.4165\n",
            "Epoch 130: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1777, Test Linf Norm: 0.4165\n",
            "Epoch 131: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1682, Test Linf Norm: 0.4164\n",
            "Epoch 132: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1535, Test Linf Norm: 0.4164\n",
            "Epoch 133: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1812, Test Linf Norm: 0.4163\n",
            "Epoch 134: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1748, Test Linf Norm: 0.4164\n",
            "Epoch 135: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1796, Test Linf Norm: 0.4164\n",
            "Epoch 136: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1545, Test Linf Norm: 0.4164\n",
            "Epoch 137: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1659, Test Linf Norm: 0.4164\n",
            "Epoch 138: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1585, Test Linf Norm: 0.4164\n",
            "Epoch 139: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1684, Test Linf Norm: 0.4164\n",
            "Epoch 140: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1589, Test Linf Norm: 0.4164\n",
            "Epoch 141: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1524, Test Linf Norm: 0.4164\n",
            "Epoch 142: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1762, Test Linf Norm: 0.4164\n",
            "Epoch 143: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1684, Test Linf Norm: 0.4164\n",
            "Epoch 144: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1672, Test Linf Norm: 0.4164\n",
            "Epoch 145: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1625, Test Linf Norm: 0.4164\n",
            "Epoch 146: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1739, Test Linf Norm: 0.4164\n",
            "Epoch 147: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1749, Test Linf Norm: 0.4164\n",
            "Epoch 148: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1676, Test Linf Norm: 0.4164\n",
            "Epoch 149: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1642, Test Linf Norm: 0.4164\n",
            "Epoch 150: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1687, Test Linf Norm: 0.4164\n",
            "Epoch 151: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1813, Test Linf Norm: 0.4164\n",
            "Epoch 152: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1660, Test Linf Norm: 0.4164\n",
            "Epoch 153: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1738, Test Linf Norm: 0.4164\n",
            "Epoch 154: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1680, Test Linf Norm: 0.4164\n",
            "Epoch 155: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1704, Test Linf Norm: 0.4164\n",
            "Epoch 156: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1709, Test Linf Norm: 0.4164\n",
            "Epoch 157: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1737, Test Linf Norm: 0.4164\n",
            "Epoch 158: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1533, Test Linf Norm: 0.4164\n",
            "Epoch 159: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1679, Test Linf Norm: 0.4164\n",
            "Epoch 160: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1791, Test Linf Norm: 0.4164\n",
            "Epoch 161: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1689, Test Linf Norm: 0.4164\n",
            "Epoch 162: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1758, Test Linf Norm: 0.4164\n",
            "Epoch 163: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1776, Test Linf Norm: 0.4164\n",
            "Epoch 164: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1678, Test Linf Norm: 0.4164\n",
            "Epoch 165: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1620, Test Linf Norm: 0.4164\n",
            "Epoch 166: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1728, Test Linf Norm: 0.4164\n",
            "Epoch 167: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1744, Test Linf Norm: 0.4164\n",
            "Epoch 168: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1318, Test Linf Norm: 0.4164\n",
            "Epoch 169: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1673, Test Linf Norm: 0.4164\n",
            "Epoch 170: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1757, Test Linf Norm: 0.4164\n",
            "Epoch 171: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1782, Test Linf Norm: 0.4164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:31:21,244]\u001b[0m Trial 63 finished with value: 0.006880137246847153 and parameters: {'n_layers': 3, 'n_units_0': 1335, 'n_units_1': 46, 'n_units_2': 320, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0004369980268101596, 'batch_size': 128, 'n_epochs': 172, 'scheduler': 'StepLR', 'weight_decay': 0.0028245908903644216, 'beta1': 0.9859873290391049, 'beta2': 0.99978084033454, 'step_size': 15, 'gamma': 0.22588569252946436}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 172: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0208, Test L1 Norm: 0.0069, Train Linf Norm: 2.1704, Test Linf Norm: 0.4164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:31:23,356]\u001b[0m Trial 64 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.2238, Test Loss: 0.0550, Train L1 Norm: 0.8373, Test L1 Norm: 0.1216, Train Linf Norm: 83.8441, Test Linf Norm: 9.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:31:26,420]\u001b[0m Trial 65 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1531, Test Loss: 0.0568, Train L1 Norm: 1.0076, Test L1 Norm: 0.0897, Train Linf Norm: 87.2503, Test Linf Norm: 4.9633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:31:28,895]\u001b[0m Trial 66 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.6798, Test Loss: 0.6458, Train L1 Norm: 0.9510, Test L1 Norm: 0.3171, Train Linf Norm: 82.8051, Test Linf Norm: 10.1029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:31:30,968]\u001b[0m Trial 67 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.4194, Test Loss: 0.2593, Train L1 Norm: 0.2914, Test L1 Norm: 0.1035, Train Linf Norm: 22.2664, Test Linf Norm: 1.3720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:31:33,002]\u001b[0m Trial 68 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.4555, Test Loss: 0.8804, Train L1 Norm: 4.8830, Test L1 Norm: 1.6273, Train Linf Norm: 489.7177, Test Linf Norm: 93.8685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:31:34,172]\u001b[0m Trial 69 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.7453, Test Loss: 0.5649, Train L1 Norm: 2.1423, Test L1 Norm: 0.5564, Train Linf Norm: 954.5975, Test Linf Norm: 99.9439\n",
            "Epoch 1: Train Loss: 0.0862, Test Loss: 0.0035, Train L1 Norm: 0.6215, Test L1 Norm: 0.0525, Train Linf Norm: 62.5174, Test Linf Norm: 1.8331\n",
            "Epoch 2: Train Loss: 0.0055, Test Loss: 0.0023, Train L1 Norm: 0.2275, Test L1 Norm: 0.0661, Train Linf Norm: 22.7938, Test Linf Norm: 4.3775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:31:41,770]\u001b[0m Trial 70 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 0.0107, Test Loss: 0.0086, Train L1 Norm: 0.2311, Test L1 Norm: 0.0684, Train Linf Norm: 22.8725, Test Linf Norm: 3.6638\n",
            "Epoch 1: Train Loss: 0.1445, Test Loss: 0.0348, Train L1 Norm: 0.2965, Test L1 Norm: 0.0378, Train Linf Norm: 25.8125, Test Linf Norm: 1.7572\n",
            "Epoch 2: Train Loss: 0.0434, Test Loss: 0.0585, Train L1 Norm: 0.1044, Test L1 Norm: 0.0396, Train Linf Norm: 9.6229, Test Linf Norm: 0.9876\n",
            "Epoch 3: Train Loss: 0.0625, Test Loss: 0.0348, Train L1 Norm: 0.1354, Test L1 Norm: 0.0298, Train Linf Norm: 13.0101, Test Linf Norm: 1.5680\n",
            "Epoch 4: Train Loss: 0.0311, Test Loss: 0.0191, Train L1 Norm: 0.0808, Test L1 Norm: 0.0286, Train Linf Norm: 7.6897, Test Linf Norm: 1.8208\n",
            "Epoch 5: Train Loss: 0.0239, Test Loss: 0.0385, Train L1 Norm: 0.0893, Test L1 Norm: 0.0246, Train Linf Norm: 9.1891, Test Linf Norm: 0.9229\n",
            "Epoch 6: Train Loss: 0.0369, Test Loss: 0.0302, Train L1 Norm: 0.0903, Test L1 Norm: 0.0293, Train Linf Norm: 8.7296, Test Linf Norm: 1.6512\n",
            "Epoch 7: Train Loss: 0.0292, Test Loss: 0.0323, Train L1 Norm: 0.1079, Test L1 Norm: 0.0242, Train Linf Norm: 11.3725, Test Linf Norm: 1.1047\n",
            "Epoch 8: Train Loss: 0.0283, Test Loss: 0.0356, Train L1 Norm: 0.1031, Test L1 Norm: 0.0354, Train Linf Norm: 11.0419, Test Linf Norm: 2.0139\n",
            "Epoch 9: Train Loss: 0.0303, Test Loss: 0.0586, Train L1 Norm: 0.0854, Test L1 Norm: 0.0388, Train Linf Norm: 8.6435, Test Linf Norm: 1.5403\n",
            "Epoch 10: Train Loss: 0.0250, Test Loss: 0.0149, Train L1 Norm: 0.0878, Test L1 Norm: 0.0178, Train Linf Norm: 9.3441, Test Linf Norm: 1.0368\n",
            "Epoch 11: Train Loss: 0.0289, Test Loss: 0.0290, Train L1 Norm: 0.0738, Test L1 Norm: 0.0231, Train Linf Norm: 7.4203, Test Linf Norm: 1.2486\n",
            "Epoch 12: Train Loss: 0.0274, Test Loss: 0.0326, Train L1 Norm: 0.0750, Test L1 Norm: 0.0234, Train Linf Norm: 7.6335, Test Linf Norm: 1.2035\n",
            "Epoch 13: Train Loss: 0.0336, Test Loss: 0.0162, Train L1 Norm: 0.0874, Test L1 Norm: 0.0198, Train Linf Norm: 8.9211, Test Linf Norm: 1.1901\n",
            "Epoch 14: Train Loss: 0.0212, Test Loss: 0.0142, Train L1 Norm: 0.0759, Test L1 Norm: 0.0185, Train Linf Norm: 8.1394, Test Linf Norm: 1.2261\n",
            "Epoch 15: Train Loss: 0.0288, Test Loss: 0.0249, Train L1 Norm: 0.0581, Test L1 Norm: 0.0211, Train Linf Norm: 5.4518, Test Linf Norm: 1.1041\n",
            "Epoch 16: Train Loss: 0.0096, Test Loss: 0.0087, Train L1 Norm: 0.0474, Test L1 Norm: 0.0127, Train Linf Norm: 5.1632, Test Linf Norm: 0.8618\n",
            "Epoch 17: Train Loss: 0.0091, Test Loss: 0.0090, Train L1 Norm: 0.0453, Test L1 Norm: 0.0125, Train Linf Norm: 4.9299, Test Linf Norm: 0.8550\n",
            "Epoch 18: Train Loss: 0.0082, Test Loss: 0.0091, Train L1 Norm: 0.0469, Test L1 Norm: 0.0113, Train Linf Norm: 5.2106, Test Linf Norm: 0.7173\n",
            "Epoch 19: Train Loss: 0.0082, Test Loss: 0.0074, Train L1 Norm: 0.0467, Test L1 Norm: 0.0109, Train Linf Norm: 5.1491, Test Linf Norm: 0.7396\n",
            "Epoch 20: Train Loss: 0.0094, Test Loss: 0.0092, Train L1 Norm: 0.0379, Test L1 Norm: 0.0136, Train Linf Norm: 3.9727, Test Linf Norm: 0.9677\n",
            "Epoch 21: Train Loss: 0.0090, Test Loss: 0.0079, Train L1 Norm: 0.0385, Test L1 Norm: 0.0102, Train Linf Norm: 4.0730, Test Linf Norm: 0.6214\n",
            "Epoch 22: Train Loss: 0.0084, Test Loss: 0.0075, Train L1 Norm: 0.0445, Test L1 Norm: 0.0107, Train Linf Norm: 4.8912, Test Linf Norm: 0.7115\n",
            "Epoch 23: Train Loss: 0.0087, Test Loss: 0.0068, Train L1 Norm: 0.0382, Test L1 Norm: 0.0105, Train Linf Norm: 4.1131, Test Linf Norm: 0.7204\n",
            "Epoch 24: Train Loss: 0.0079, Test Loss: 0.0089, Train L1 Norm: 0.0382, Test L1 Norm: 0.0103, Train Linf Norm: 4.1369, Test Linf Norm: 0.6063\n",
            "Epoch 25: Train Loss: 0.0078, Test Loss: 0.0105, Train L1 Norm: 0.0343, Test L1 Norm: 0.0116, Train Linf Norm: 3.6716, Test Linf Norm: 0.7350\n",
            "Epoch 26: Train Loss: 0.0090, Test Loss: 0.0155, Train L1 Norm: 0.0352, Test L1 Norm: 0.0107, Train Linf Norm: 3.6691, Test Linf Norm: 0.4925\n",
            "Epoch 27: Train Loss: 0.0111, Test Loss: 0.0080, Train L1 Norm: 0.0290, Test L1 Norm: 0.0119, Train Linf Norm: 2.8290, Test Linf Norm: 0.8072\n",
            "Epoch 28: Train Loss: 0.0081, Test Loss: 0.0076, Train L1 Norm: 0.0287, Test L1 Norm: 0.0098, Train Linf Norm: 2.9417, Test Linf Norm: 0.6223\n",
            "Epoch 29: Train Loss: 0.0088, Test Loss: 0.0064, Train L1 Norm: 0.0307, Test L1 Norm: 0.0092, Train Linf Norm: 3.1696, Test Linf Norm: 0.5540\n",
            "Epoch 30: Train Loss: 0.0098, Test Loss: 0.0103, Train L1 Norm: 0.0281, Test L1 Norm: 0.0097, Train Linf Norm: 2.8069, Test Linf Norm: 0.5417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:32:53,659]\u001b[0m Trial 71 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: Train Loss: 0.0060, Test Loss: 0.0058, Train L1 Norm: 0.0289, Test L1 Norm: 0.0087, Train Linf Norm: 3.0585, Test Linf Norm: 0.5611\n",
            "Epoch 1: Train Loss: 0.2131, Test Loss: 0.0829, Train L1 Norm: 0.2837, Test L1 Norm: 0.0525, Train Linf Norm: 19.9902, Test Linf Norm: 2.2569\n",
            "Epoch 2: Train Loss: 0.0463, Test Loss: 0.0326, Train L1 Norm: 0.0948, Test L1 Norm: 0.0309, Train Linf Norm: 8.3104, Test Linf Norm: 1.2109\n",
            "Epoch 3: Train Loss: 0.0344, Test Loss: 0.0219, Train L1 Norm: 0.1086, Test L1 Norm: 0.0244, Train Linf Norm: 10.8960, Test Linf Norm: 1.0031\n",
            "Epoch 4: Train Loss: 0.0258, Test Loss: 0.0169, Train L1 Norm: 0.1588, Test L1 Norm: 0.0255, Train Linf Norm: 17.7277, Test Linf Norm: 1.5261\n",
            "Epoch 5: Train Loss: 0.0277, Test Loss: 0.0236, Train L1 Norm: 0.0709, Test L1 Norm: 0.0345, Train Linf Norm: 6.6318, Test Linf Norm: 2.0598\n",
            "Epoch 6: Train Loss: 0.0274, Test Loss: 0.0149, Train L1 Norm: 0.0694, Test L1 Norm: 0.0276, Train Linf Norm: 6.6207, Test Linf Norm: 1.9507\n",
            "Epoch 7: Train Loss: 0.0277, Test Loss: 0.0148, Train L1 Norm: 0.0872, Test L1 Norm: 0.0205, Train Linf Norm: 8.8735, Test Linf Norm: 1.1560\n",
            "Epoch 8: Train Loss: 0.0232, Test Loss: 0.0173, Train L1 Norm: 0.0702, Test L1 Norm: 0.0207, Train Linf Norm: 7.0634, Test Linf Norm: 1.2303\n",
            "Epoch 9: Train Loss: 0.0234, Test Loss: 0.0144, Train L1 Norm: 0.0714, Test L1 Norm: 0.0262, Train Linf Norm: 7.2320, Test Linf Norm: 1.5390\n",
            "Epoch 10: Train Loss: 0.0306, Test Loss: 0.0169, Train L1 Norm: 0.0682, Test L1 Norm: 0.0254, Train Linf Norm: 6.4009, Test Linf Norm: 1.4702\n",
            "Epoch 11: Train Loss: 0.0186, Test Loss: 0.0256, Train L1 Norm: 0.0654, Test L1 Norm: 0.0194, Train Linf Norm: 6.7786, Test Linf Norm: 0.6901\n",
            "Epoch 12: Train Loss: 0.0285, Test Loss: 0.0158, Train L1 Norm: 0.0563, Test L1 Norm: 0.0156, Train Linf Norm: 5.1093, Test Linf Norm: 0.7668\n",
            "Epoch 13: Train Loss: 0.0236, Test Loss: 0.0130, Train L1 Norm: 0.0515, Test L1 Norm: 0.0152, Train Linf Norm: 4.7540, Test Linf Norm: 0.6176\n",
            "Epoch 14: Train Loss: 0.0170, Test Loss: 0.0221, Train L1 Norm: 0.0429, Test L1 Norm: 0.0193, Train Linf Norm: 3.9830, Test Linf Norm: 1.0435\n",
            "Epoch 15: Train Loss: 0.0180, Test Loss: 0.0258, Train L1 Norm: 0.0446, Test L1 Norm: 0.0178, Train Linf Norm: 4.3067, Test Linf Norm: 0.8475\n",
            "Epoch 16: Train Loss: 0.0115, Test Loss: 0.0081, Train L1 Norm: 0.0366, Test L1 Norm: 0.0123, Train Linf Norm: 3.6513, Test Linf Norm: 0.7696\n",
            "Epoch 17: Train Loss: 0.0111, Test Loss: 0.0224, Train L1 Norm: 0.0359, Test L1 Norm: 0.0149, Train Linf Norm: 3.5975, Test Linf Norm: 0.6252\n",
            "Epoch 18: Train Loss: 0.0103, Test Loss: 0.0087, Train L1 Norm: 0.0351, Test L1 Norm: 0.0107, Train Linf Norm: 3.5396, Test Linf Norm: 0.6047\n",
            "Epoch 19: Train Loss: 0.0078, Test Loss: 0.0074, Train L1 Norm: 0.0304, Test L1 Norm: 0.0100, Train Linf Norm: 3.0595, Test Linf Norm: 0.5770\n",
            "Epoch 20: Train Loss: 0.0078, Test Loss: 0.0079, Train L1 Norm: 0.0313, Test L1 Norm: 0.0094, Train Linf Norm: 3.1989, Test Linf Norm: 0.4818\n",
            "Epoch 21: Train Loss: 0.0078, Test Loss: 0.0070, Train L1 Norm: 0.0288, Test L1 Norm: 0.0095, Train Linf Norm: 2.8807, Test Linf Norm: 0.4897\n",
            "Epoch 22: Train Loss: 0.0078, Test Loss: 0.0066, Train L1 Norm: 0.0311, Test L1 Norm: 0.0095, Train Linf Norm: 3.1543, Test Linf Norm: 0.5504\n",
            "Epoch 23: Train Loss: 0.0084, Test Loss: 0.0077, Train L1 Norm: 0.0319, Test L1 Norm: 0.0095, Train Linf Norm: 3.2675, Test Linf Norm: 0.4982\n",
            "Epoch 24: Train Loss: 0.0085, Test Loss: 0.0131, Train L1 Norm: 0.0283, Test L1 Norm: 0.0110, Train Linf Norm: 2.7915, Test Linf Norm: 0.3982\n",
            "Epoch 25: Train Loss: 0.0099, Test Loss: 0.0080, Train L1 Norm: 0.0298, Test L1 Norm: 0.0092, Train Linf Norm: 2.9271, Test Linf Norm: 0.4430\n",
            "Epoch 26: Train Loss: 0.0079, Test Loss: 0.0066, Train L1 Norm: 0.0347, Test L1 Norm: 0.0100, Train Linf Norm: 3.6373, Test Linf Norm: 0.5942\n",
            "Epoch 27: Train Loss: 0.0082, Test Loss: 0.0092, Train L1 Norm: 0.0296, Test L1 Norm: 0.0104, Train Linf Norm: 2.9768, Test Linf Norm: 0.5592\n",
            "Epoch 28: Train Loss: 0.0092, Test Loss: 0.0092, Train L1 Norm: 0.0294, Test L1 Norm: 0.0100, Train Linf Norm: 2.9095, Test Linf Norm: 0.5266\n",
            "Epoch 29: Train Loss: 0.0079, Test Loss: 0.0074, Train L1 Norm: 0.0260, Test L1 Norm: 0.0093, Train Linf Norm: 2.5797, Test Linf Norm: 0.4937\n",
            "Epoch 30: Train Loss: 0.0091, Test Loss: 0.0120, Train L1 Norm: 0.0270, Test L1 Norm: 0.0101, Train Linf Norm: 2.5886, Test Linf Norm: 0.3813\n",
            "Epoch 31: Train Loss: 0.0067, Test Loss: 0.0064, Train L1 Norm: 0.0265, Test L1 Norm: 0.0079, Train Linf Norm: 2.6537, Test Linf Norm: 0.4150\n",
            "Epoch 32: Train Loss: 0.0056, Test Loss: 0.0055, Train L1 Norm: 0.0236, Test L1 Norm: 0.0076, Train Linf Norm: 2.3950, Test Linf Norm: 0.4043\n",
            "Epoch 33: Train Loss: 0.0058, Test Loss: 0.0056, Train L1 Norm: 0.0232, Test L1 Norm: 0.0077, Train Linf Norm: 2.3364, Test Linf Norm: 0.4141\n",
            "Epoch 34: Train Loss: 0.0057, Test Loss: 0.0056, Train L1 Norm: 0.0236, Test L1 Norm: 0.0076, Train Linf Norm: 2.3468, Test Linf Norm: 0.4066\n",
            "Epoch 35: Train Loss: 0.0057, Test Loss: 0.0056, Train L1 Norm: 0.0230, Test L1 Norm: 0.0075, Train Linf Norm: 2.2977, Test Linf Norm: 0.3949\n",
            "Epoch 36: Train Loss: 0.0056, Test Loss: 0.0064, Train L1 Norm: 0.0232, Test L1 Norm: 0.0084, Train Linf Norm: 2.3541, Test Linf Norm: 0.4594\n",
            "Epoch 37: Train Loss: 0.0055, Test Loss: 0.0056, Train L1 Norm: 0.0235, Test L1 Norm: 0.0074, Train Linf Norm: 2.3778, Test Linf Norm: 0.3670\n",
            "Epoch 38: Train Loss: 0.0059, Test Loss: 0.0058, Train L1 Norm: 0.0236, Test L1 Norm: 0.0080, Train Linf Norm: 2.3836, Test Linf Norm: 0.4355\n",
            "Epoch 39: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0245, Test L1 Norm: 0.0079, Train Linf Norm: 2.5034, Test Linf Norm: 0.4190\n",
            "Epoch 40: Train Loss: 0.0056, Test Loss: 0.0055, Train L1 Norm: 0.0220, Test L1 Norm: 0.0081, Train Linf Norm: 2.1881, Test Linf Norm: 0.4513\n",
            "Epoch 41: Train Loss: 0.0054, Test Loss: 0.0058, Train L1 Norm: 0.0228, Test L1 Norm: 0.0074, Train Linf Norm: 2.2855, Test Linf Norm: 0.3889\n",
            "Epoch 42: Train Loss: 0.0061, Test Loss: 0.0075, Train L1 Norm: 0.0226, Test L1 Norm: 0.0078, Train Linf Norm: 2.2527, Test Linf Norm: 0.3810\n",
            "Epoch 43: Train Loss: 0.0059, Test Loss: 0.0070, Train L1 Norm: 0.0226, Test L1 Norm: 0.0079, Train Linf Norm: 2.2769, Test Linf Norm: 0.4105\n",
            "Epoch 44: Train Loss: 0.0057, Test Loss: 0.0059, Train L1 Norm: 0.0227, Test L1 Norm: 0.0074, Train Linf Norm: 2.2858, Test Linf Norm: 0.3834\n",
            "Epoch 45: Train Loss: 0.0063, Test Loss: 0.0058, Train L1 Norm: 0.0233, Test L1 Norm: 0.0075, Train Linf Norm: 2.3460, Test Linf Norm: 0.3961\n",
            "Epoch 46: Train Loss: 0.0051, Test Loss: 0.0051, Train L1 Norm: 0.0221, Test L1 Norm: 0.0071, Train Linf Norm: 2.2419, Test Linf Norm: 0.3717\n",
            "Epoch 47: Train Loss: 0.0051, Test Loss: 0.0057, Train L1 Norm: 0.0225, Test L1 Norm: 0.0072, Train Linf Norm: 2.3050, Test Linf Norm: 0.3723\n",
            "Epoch 48: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0219, Test L1 Norm: 0.0071, Train Linf Norm: 2.2298, Test Linf Norm: 0.3656\n",
            "Epoch 49: Train Loss: 0.0051, Test Loss: 0.0052, Train L1 Norm: 0.0217, Test L1 Norm: 0.0071, Train Linf Norm: 2.1840, Test Linf Norm: 0.3746\n",
            "Epoch 50: Train Loss: 0.0050, Test Loss: 0.0053, Train L1 Norm: 0.0220, Test L1 Norm: 0.0072, Train Linf Norm: 2.2335, Test Linf Norm: 0.3844\n",
            "Epoch 51: Train Loss: 0.0049, Test Loss: 0.0051, Train L1 Norm: 0.0218, Test L1 Norm: 0.0072, Train Linf Norm: 2.2326, Test Linf Norm: 0.3831\n",
            "Epoch 52: Train Loss: 0.0049, Test Loss: 0.0051, Train L1 Norm: 0.0217, Test L1 Norm: 0.0072, Train Linf Norm: 2.1962, Test Linf Norm: 0.3855\n",
            "Epoch 53: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0222, Test L1 Norm: 0.0072, Train Linf Norm: 2.2484, Test Linf Norm: 0.3857\n",
            "Epoch 54: Train Loss: 0.0051, Test Loss: 0.0051, Train L1 Norm: 0.0220, Test L1 Norm: 0.0071, Train Linf Norm: 2.2296, Test Linf Norm: 0.3838\n",
            "Epoch 55: Train Loss: 0.0050, Test Loss: 0.0052, Train L1 Norm: 0.0218, Test L1 Norm: 0.0070, Train Linf Norm: 2.1972, Test Linf Norm: 0.3661\n",
            "Epoch 56: Train Loss: 0.0050, Test Loss: 0.0054, Train L1 Norm: 0.0218, Test L1 Norm: 0.0072, Train Linf Norm: 2.2196, Test Linf Norm: 0.3851\n",
            "Epoch 57: Train Loss: 0.0050, Test Loss: 0.0050, Train L1 Norm: 0.0216, Test L1 Norm: 0.0071, Train Linf Norm: 2.1987, Test Linf Norm: 0.3815\n",
            "Epoch 58: Train Loss: 0.0049, Test Loss: 0.0052, Train L1 Norm: 0.0219, Test L1 Norm: 0.0070, Train Linf Norm: 2.2299, Test Linf Norm: 0.3691\n",
            "Epoch 59: Train Loss: 0.0049, Test Loss: 0.0051, Train L1 Norm: 0.0215, Test L1 Norm: 0.0069, Train Linf Norm: 2.1702, Test Linf Norm: 0.3641\n",
            "Epoch 60: Train Loss: 0.0049, Test Loss: 0.0050, Train L1 Norm: 0.0220, Test L1 Norm: 0.0071, Train Linf Norm: 2.2503, Test Linf Norm: 0.3770\n",
            "Epoch 61: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0218, Test L1 Norm: 0.0070, Train Linf Norm: 2.2272, Test Linf Norm: 0.3690\n",
            "Epoch 62: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0217, Test L1 Norm: 0.0069, Train Linf Norm: 2.2257, Test Linf Norm: 0.3644\n",
            "Epoch 63: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.1999, Test Linf Norm: 0.3622\n",
            "Epoch 64: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0218, Test L1 Norm: 0.0070, Train Linf Norm: 2.1934, Test Linf Norm: 0.3736\n",
            "Epoch 65: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0216, Test L1 Norm: 0.0070, Train Linf Norm: 2.2065, Test Linf Norm: 0.3735\n",
            "Epoch 66: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2077, Test Linf Norm: 0.3681\n",
            "Epoch 67: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2110, Test Linf Norm: 0.3643\n",
            "Epoch 68: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0217, Test L1 Norm: 0.0070, Train Linf Norm: 2.1889, Test Linf Norm: 0.3699\n",
            "Epoch 69: Train Loss: 0.0048, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.1956, Test Linf Norm: 0.3606\n",
            "Epoch 70: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0215, Test L1 Norm: 0.0069, Train Linf Norm: 2.1613, Test Linf Norm: 0.3692\n",
            "Epoch 71: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0217, Test L1 Norm: 0.0070, Train Linf Norm: 2.2301, Test Linf Norm: 0.3694\n",
            "Epoch 72: Train Loss: 0.0048, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2126, Test Linf Norm: 0.3686\n",
            "Epoch 73: Train Loss: 0.0048, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0070, Train Linf Norm: 2.2054, Test Linf Norm: 0.3740\n",
            "Epoch 74: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0217, Test L1 Norm: 0.0070, Train Linf Norm: 2.2138, Test Linf Norm: 0.3677\n",
            "Epoch 75: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0215, Test L1 Norm: 0.0069, Train Linf Norm: 2.1936, Test Linf Norm: 0.3654\n",
            "Epoch 76: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.1788, Test Linf Norm: 0.3687\n",
            "Epoch 77: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2105, Test Linf Norm: 0.3678\n",
            "Epoch 78: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2030, Test Linf Norm: 0.3662\n",
            "Epoch 79: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2119, Test Linf Norm: 0.3655\n",
            "Epoch 80: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2016, Test Linf Norm: 0.3675\n",
            "Epoch 81: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.1950, Test Linf Norm: 0.3657\n",
            "Epoch 82: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2086, Test Linf Norm: 0.3687\n",
            "Epoch 83: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2190, Test Linf Norm: 0.3683\n",
            "Epoch 84: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2226, Test Linf Norm: 0.3699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:36:14,159]\u001b[0m Trial 72 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0216, Test L1 Norm: 0.0069, Train Linf Norm: 2.2144, Test Linf Norm: 0.3660\n",
            "Epoch 1: Train Loss: 0.2488, Test Loss: 0.0266, Train L1 Norm: 0.5354, Test L1 Norm: 0.0342, Train Linf Norm: 45.9309, Test Linf Norm: 1.3166\n",
            "Epoch 2: Train Loss: 0.0316, Test Loss: 0.0231, Train L1 Norm: 0.3125, Test L1 Norm: 0.0393, Train Linf Norm: 36.4863, Test Linf Norm: 2.2848\n",
            "Epoch 3: Train Loss: 0.0266, Test Loss: 0.0298, Train L1 Norm: 0.1808, Test L1 Norm: 0.0609, Train Linf Norm: 20.1795, Test Linf Norm: 3.6436\n",
            "Epoch 4: Train Loss: 0.0301, Test Loss: 0.0195, Train L1 Norm: 0.1722, Test L1 Norm: 0.0242, Train Linf Norm: 19.2232, Test Linf Norm: 0.9989\n",
            "Epoch 5: Train Loss: 0.0375, Test Loss: 0.0618, Train L1 Norm: 0.2068, Test L1 Norm: 0.0364, Train Linf Norm: 23.0778, Test Linf Norm: 1.1393\n",
            "Epoch 6: Train Loss: 0.0251, Test Loss: 0.0314, Train L1 Norm: 0.1819, Test L1 Norm: 0.0382, Train Linf Norm: 20.5353, Test Linf Norm: 2.5206\n",
            "Epoch 7: Train Loss: 0.0322, Test Loss: 0.0219, Train L1 Norm: 0.1081, Test L1 Norm: 0.0312, Train Linf Norm: 10.8773, Test Linf Norm: 2.1552\n",
            "Epoch 8: Train Loss: 0.0231, Test Loss: 0.0255, Train L1 Norm: 0.1056, Test L1 Norm: 0.0305, Train Linf Norm: 11.2117, Test Linf Norm: 2.0029\n",
            "Epoch 9: Train Loss: 0.0254, Test Loss: 0.0250, Train L1 Norm: 0.1569, Test L1 Norm: 0.0241, Train Linf Norm: 17.5659, Test Linf Norm: 1.2333\n",
            "Epoch 10: Train Loss: 0.0208, Test Loss: 0.0195, Train L1 Norm: 0.0907, Test L1 Norm: 0.0410, Train Linf Norm: 9.5146, Test Linf Norm: 2.9439\n",
            "Epoch 11: Train Loss: 0.0243, Test Loss: 0.0614, Train L1 Norm: 0.1327, Test L1 Norm: 0.0403, Train Linf Norm: 14.7312, Test Linf Norm: 2.0886\n",
            "Epoch 12: Train Loss: 0.0288, Test Loss: 0.0213, Train L1 Norm: 0.1553, Test L1 Norm: 0.0424, Train Linf Norm: 17.4299, Test Linf Norm: 2.8993\n",
            "Epoch 13: Train Loss: 0.0210, Test Loss: 0.0276, Train L1 Norm: 0.1179, Test L1 Norm: 0.0235, Train Linf Norm: 12.9904, Test Linf Norm: 1.1519\n",
            "Epoch 14: Train Loss: 0.0196, Test Loss: 0.0176, Train L1 Norm: 0.1319, Test L1 Norm: 0.0247, Train Linf Norm: 15.0847, Test Linf Norm: 1.6009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:36:50,121]\u001b[0m Trial 73 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss: 0.0201, Test Loss: 0.0114, Train L1 Norm: 0.1189, Test L1 Norm: 0.0385, Train Linf Norm: 13.2349, Test Linf Norm: 3.0362\n",
            "Epoch 1: Train Loss: 0.1766, Test Loss: 0.0322, Train L1 Norm: 0.6745, Test L1 Norm: 0.0529, Train Linf Norm: 65.0015, Test Linf Norm: 3.3171\n",
            "Epoch 2: Train Loss: 0.0283, Test Loss: 0.0310, Train L1 Norm: 0.2025, Test L1 Norm: 0.0385, Train Linf Norm: 22.5508, Test Linf Norm: 2.2527\n",
            "Epoch 3: Train Loss: 0.0225, Test Loss: 0.0169, Train L1 Norm: 0.0805, Test L1 Norm: 0.0313, Train Linf Norm: 7.8366, Test Linf Norm: 2.2576\n",
            "Epoch 4: Train Loss: 0.0263, Test Loss: 0.0494, Train L1 Norm: 0.0685, Test L1 Norm: 0.0438, Train Linf Norm: 6.5159, Test Linf Norm: 2.3377\n",
            "Epoch 5: Train Loss: 0.0241, Test Loss: 0.0179, Train L1 Norm: 0.1060, Test L1 Norm: 0.0188, Train Linf Norm: 11.4816, Test Linf Norm: 1.0200\n",
            "Epoch 6: Train Loss: 0.0154, Test Loss: 0.0130, Train L1 Norm: 0.0510, Test L1 Norm: 0.0144, Train Linf Norm: 5.0151, Test Linf Norm: 0.7752\n",
            "Epoch 7: Train Loss: 0.0193, Test Loss: 0.0174, Train L1 Norm: 0.0804, Test L1 Norm: 0.0177, Train Linf Norm: 8.7001, Test Linf Norm: 1.0117\n",
            "Epoch 8: Train Loss: 0.0191, Test Loss: 0.0117, Train L1 Norm: 0.0734, Test L1 Norm: 0.0168, Train Linf Norm: 7.7380, Test Linf Norm: 1.0929\n",
            "Epoch 9: Train Loss: 0.0165, Test Loss: 0.0161, Train L1 Norm: 0.0826, Test L1 Norm: 0.0178, Train Linf Norm: 9.0929, Test Linf Norm: 0.9117\n",
            "Epoch 10: Train Loss: 0.0199, Test Loss: 0.0162, Train L1 Norm: 0.0749, Test L1 Norm: 0.0140, Train Linf Norm: 7.9659, Test Linf Norm: 0.6363\n",
            "Epoch 11: Train Loss: 0.0246, Test Loss: 0.0274, Train L1 Norm: 0.0748, Test L1 Norm: 0.0267, Train Linf Norm: 7.5152, Test Linf Norm: 1.1659\n",
            "Epoch 12: Train Loss: 0.0344, Test Loss: 0.0230, Train L1 Norm: 0.0610, Test L1 Norm: 0.0303, Train Linf Norm: 5.4868, Test Linf Norm: 1.8535\n",
            "Epoch 13: Train Loss: 0.0212, Test Loss: 0.0128, Train L1 Norm: 0.0970, Test L1 Norm: 0.0217, Train Linf Norm: 10.7380, Test Linf Norm: 1.5798\n",
            "Epoch 14: Train Loss: 0.0162, Test Loss: 0.0303, Train L1 Norm: 0.0765, Test L1 Norm: 0.0195, Train Linf Norm: 7.3041, Test Linf Norm: 0.9393\n",
            "Epoch 15: Train Loss: 0.0382, Test Loss: 0.0252, Train L1 Norm: 0.0601, Test L1 Norm: 0.0250, Train Linf Norm: 5.2547, Test Linf Norm: 1.4077\n",
            "Epoch 16: Train Loss: 0.0140, Test Loss: 0.0114, Train L1 Norm: 0.0716, Test L1 Norm: 0.0131, Train Linf Norm: 8.0102, Test Linf Norm: 0.7808\n",
            "Epoch 17: Train Loss: 0.0104, Test Loss: 0.0145, Train L1 Norm: 0.0503, Test L1 Norm: 0.0146, Train Linf Norm: 5.5903, Test Linf Norm: 0.9707\n",
            "Epoch 18: Train Loss: 0.0109, Test Loss: 0.0101, Train L1 Norm: 0.0392, Test L1 Norm: 0.0112, Train Linf Norm: 4.1390, Test Linf Norm: 0.7146\n",
            "Epoch 19: Train Loss: 0.0103, Test Loss: 0.0123, Train L1 Norm: 0.0446, Test L1 Norm: 0.0110, Train Linf Norm: 4.8756, Test Linf Norm: 0.6799\n",
            "Epoch 20: Train Loss: 0.0100, Test Loss: 0.0097, Train L1 Norm: 0.0384, Test L1 Norm: 0.0103, Train Linf Norm: 4.0049, Test Linf Norm: 0.6261\n",
            "Epoch 21: Train Loss: 0.0107, Test Loss: 0.0084, Train L1 Norm: 0.0414, Test L1 Norm: 0.0094, Train Linf Norm: 4.4764, Test Linf Norm: 0.5818\n",
            "Epoch 22: Train Loss: 0.0092, Test Loss: 0.0079, Train L1 Norm: 0.0371, Test L1 Norm: 0.0106, Train Linf Norm: 3.9667, Test Linf Norm: 0.7187\n",
            "Epoch 23: Train Loss: 0.0108, Test Loss: 0.0149, Train L1 Norm: 0.0380, Test L1 Norm: 0.0127, Train Linf Norm: 4.0213, Test Linf Norm: 0.7663\n",
            "Epoch 24: Train Loss: 0.0098, Test Loss: 0.0088, Train L1 Norm: 0.0395, Test L1 Norm: 0.0103, Train Linf Norm: 4.2731, Test Linf Norm: 0.5560\n",
            "Epoch 25: Train Loss: 0.0111, Test Loss: 0.0087, Train L1 Norm: 0.0292, Test L1 Norm: 0.0086, Train Linf Norm: 2.9058, Test Linf Norm: 0.4901\n",
            "Epoch 26: Train Loss: 0.0087, Test Loss: 0.0096, Train L1 Norm: 0.0350, Test L1 Norm: 0.0091, Train Linf Norm: 3.5996, Test Linf Norm: 0.4966\n",
            "Epoch 27: Train Loss: 0.0101, Test Loss: 0.0078, Train L1 Norm: 0.0340, Test L1 Norm: 0.0113, Train Linf Norm: 3.5764, Test Linf Norm: 0.7511\n",
            "Epoch 28: Train Loss: 0.0072, Test Loss: 0.0069, Train L1 Norm: 0.0312, Test L1 Norm: 0.0081, Train Linf Norm: 3.3200, Test Linf Norm: 0.5139\n",
            "Epoch 29: Train Loss: 0.0073, Test Loss: 0.0085, Train L1 Norm: 0.0344, Test L1 Norm: 0.0086, Train Linf Norm: 3.7605, Test Linf Norm: 0.5181\n",
            "Epoch 30: Train Loss: 0.0074, Test Loss: 0.0069, Train L1 Norm: 0.0333, Test L1 Norm: 0.0080, Train Linf Norm: 3.6165, Test Linf Norm: 0.4777\n",
            "Epoch 31: Train Loss: 0.0058, Test Loss: 0.0056, Train L1 Norm: 0.0265, Test L1 Norm: 0.0080, Train Linf Norm: 2.8580, Test Linf Norm: 0.5246\n",
            "Epoch 32: Train Loss: 0.0061, Test Loss: 0.0056, Train L1 Norm: 0.0276, Test L1 Norm: 0.0070, Train Linf Norm: 2.9728, Test Linf Norm: 0.4355\n",
            "Epoch 33: Train Loss: 0.0053, Test Loss: 0.0054, Train L1 Norm: 0.0223, Test L1 Norm: 0.0074, Train Linf Norm: 2.3419, Test Linf Norm: 0.4703\n",
            "Epoch 34: Train Loss: 0.0055, Test Loss: 0.0055, Train L1 Norm: 0.0231, Test L1 Norm: 0.0069, Train Linf Norm: 2.4385, Test Linf Norm: 0.4192\n",
            "Epoch 35: Train Loss: 0.0054, Test Loss: 0.0059, Train L1 Norm: 0.0254, Test L1 Norm: 0.0073, Train Linf Norm: 2.7546, Test Linf Norm: 0.4610\n",
            "Epoch 36: Train Loss: 0.0060, Test Loss: 0.0071, Train L1 Norm: 0.0237, Test L1 Norm: 0.0073, Train Linf Norm: 2.5070, Test Linf Norm: 0.4268\n",
            "Epoch 37: Train Loss: 0.0056, Test Loss: 0.0052, Train L1 Norm: 0.0228, Test L1 Norm: 0.0068, Train Linf Norm: 2.4049, Test Linf Norm: 0.4177\n",
            "Epoch 38: Train Loss: 0.0056, Test Loss: 0.0055, Train L1 Norm: 0.0209, Test L1 Norm: 0.0070, Train Linf Norm: 2.1704, Test Linf Norm: 0.4407\n",
            "Epoch 39: Train Loss: 0.0054, Test Loss: 0.0076, Train L1 Norm: 0.0220, Test L1 Norm: 0.0073, Train Linf Norm: 2.3223, Test Linf Norm: 0.3887\n",
            "Epoch 40: Train Loss: 0.0071, Test Loss: 0.0064, Train L1 Norm: 0.0228, Test L1 Norm: 0.0074, Train Linf Norm: 2.3312, Test Linf Norm: 0.4397\n",
            "Epoch 41: Train Loss: 0.0062, Test Loss: 0.0050, Train L1 Norm: 0.0226, Test L1 Norm: 0.0069, Train Linf Norm: 2.3686, Test Linf Norm: 0.4501\n",
            "Epoch 42: Train Loss: 0.0051, Test Loss: 0.0054, Train L1 Norm: 0.0225, Test L1 Norm: 0.0069, Train Linf Norm: 2.4029, Test Linf Norm: 0.4251\n",
            "Epoch 43: Train Loss: 0.0052, Test Loss: 0.0051, Train L1 Norm: 0.0204, Test L1 Norm: 0.0062, Train Linf Norm: 2.1152, Test Linf Norm: 0.3618\n",
            "Epoch 44: Train Loss: 0.0051, Test Loss: 0.0053, Train L1 Norm: 0.0195, Test L1 Norm: 0.0068, Train Linf Norm: 2.0281, Test Linf Norm: 0.4211\n",
            "Epoch 45: Train Loss: 0.0059, Test Loss: 0.0066, Train L1 Norm: 0.0214, Test L1 Norm: 0.0068, Train Linf Norm: 2.2073, Test Linf Norm: 0.3527\n",
            "Epoch 46: Train Loss: 0.0050, Test Loss: 0.0049, Train L1 Norm: 0.0180, Test L1 Norm: 0.0061, Train Linf Norm: 1.8400, Test Linf Norm: 0.3579\n",
            "Epoch 47: Train Loss: 0.0048, Test Loss: 0.0050, Train L1 Norm: 0.0176, Test L1 Norm: 0.0062, Train Linf Norm: 1.8073, Test Linf Norm: 0.3706\n",
            "Epoch 48: Train Loss: 0.0048, Test Loss: 0.0051, Train L1 Norm: 0.0191, Test L1 Norm: 0.0062, Train Linf Norm: 1.9735, Test Linf Norm: 0.3683\n",
            "Epoch 49: Train Loss: 0.0047, Test Loss: 0.0048, Train L1 Norm: 0.0179, Test L1 Norm: 0.0064, Train Linf Norm: 1.8425, Test Linf Norm: 0.3932\n",
            "Epoch 50: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0186, Test L1 Norm: 0.0062, Train Linf Norm: 1.9402, Test Linf Norm: 0.3648\n",
            "Epoch 51: Train Loss: 0.0047, Test Loss: 0.0048, Train L1 Norm: 0.0170, Test L1 Norm: 0.0062, Train Linf Norm: 1.7098, Test Linf Norm: 0.3731\n",
            "Epoch 52: Train Loss: 0.0046, Test Loss: 0.0051, Train L1 Norm: 0.0170, Test L1 Norm: 0.0063, Train Linf Norm: 1.7117, Test Linf Norm: 0.3791\n",
            "Epoch 53: Train Loss: 0.0047, Test Loss: 0.0048, Train L1 Norm: 0.0180, Test L1 Norm: 0.0062, Train Linf Norm: 1.8600, Test Linf Norm: 0.3784\n",
            "Epoch 54: Train Loss: 0.0047, Test Loss: 0.0048, Train L1 Norm: 0.0181, Test L1 Norm: 0.0061, Train Linf Norm: 1.8399, Test Linf Norm: 0.3688\n",
            "Epoch 55: Train Loss: 0.0046, Test Loss: 0.0047, Train L1 Norm: 0.0176, Test L1 Norm: 0.0061, Train Linf Norm: 1.8008, Test Linf Norm: 0.3627\n",
            "Epoch 56: Train Loss: 0.0046, Test Loss: 0.0049, Train L1 Norm: 0.0189, Test L1 Norm: 0.0062, Train Linf Norm: 1.9635, Test Linf Norm: 0.3747\n",
            "Epoch 57: Train Loss: 0.0048, Test Loss: 0.0047, Train L1 Norm: 0.0175, Test L1 Norm: 0.0061, Train Linf Norm: 1.7958, Test Linf Norm: 0.3646\n",
            "Epoch 58: Train Loss: 0.0047, Test Loss: 0.0049, Train L1 Norm: 0.0168, Test L1 Norm: 0.0062, Train Linf Norm: 1.6950, Test Linf Norm: 0.3761\n",
            "Epoch 59: Train Loss: 0.0047, Test Loss: 0.0047, Train L1 Norm: 0.0162, Test L1 Norm: 0.0061, Train Linf Norm: 1.6214, Test Linf Norm: 0.3705\n",
            "Epoch 60: Train Loss: 0.0048, Test Loss: 0.0047, Train L1 Norm: 0.0180, Test L1 Norm: 0.0061, Train Linf Norm: 1.8379, Test Linf Norm: 0.3630\n",
            "Epoch 61: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0179, Test L1 Norm: 0.0061, Train Linf Norm: 1.8541, Test Linf Norm: 0.3648\n",
            "Epoch 62: Train Loss: 0.0045, Test Loss: 0.0048, Train L1 Norm: 0.0177, Test L1 Norm: 0.0060, Train Linf Norm: 1.8230, Test Linf Norm: 0.3566\n",
            "Epoch 63: Train Loss: 0.0045, Test Loss: 0.0048, Train L1 Norm: 0.0178, Test L1 Norm: 0.0061, Train Linf Norm: 1.8420, Test Linf Norm: 0.3657\n",
            "Epoch 64: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0174, Test L1 Norm: 0.0060, Train Linf Norm: 1.7715, Test Linf Norm: 0.3607\n",
            "Epoch 65: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0174, Test L1 Norm: 0.0060, Train Linf Norm: 1.7923, Test Linf Norm: 0.3599\n",
            "Epoch 66: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0176, Test L1 Norm: 0.0060, Train Linf Norm: 1.7755, Test Linf Norm: 0.3562\n",
            "Epoch 67: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0168, Test L1 Norm: 0.0060, Train Linf Norm: 1.7124, Test Linf Norm: 0.3588\n",
            "Epoch 68: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0173, Test L1 Norm: 0.0061, Train Linf Norm: 1.7507, Test Linf Norm: 0.3681\n",
            "Epoch 69: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0171, Test L1 Norm: 0.0060, Train Linf Norm: 1.7498, Test Linf Norm: 0.3636\n",
            "Epoch 70: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0169, Test L1 Norm: 0.0060, Train Linf Norm: 1.7162, Test Linf Norm: 0.3611\n",
            "Epoch 71: Train Loss: 0.0046, Test Loss: 0.0047, Train L1 Norm: 0.0171, Test L1 Norm: 0.0060, Train Linf Norm: 1.7443, Test Linf Norm: 0.3547\n",
            "Epoch 72: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0175, Test L1 Norm: 0.0060, Train Linf Norm: 1.8076, Test Linf Norm: 0.3518\n",
            "Epoch 73: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0175, Test L1 Norm: 0.0060, Train Linf Norm: 1.7988, Test Linf Norm: 0.3592\n",
            "Epoch 74: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0165, Test L1 Norm: 0.0060, Train Linf Norm: 1.6791, Test Linf Norm: 0.3584\n",
            "Epoch 75: Train Loss: 0.0045, Test Loss: 0.0047, Train L1 Norm: 0.0175, Test L1 Norm: 0.0060, Train Linf Norm: 1.8079, Test Linf Norm: 0.3607\n",
            "Epoch 76: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0176, Test L1 Norm: 0.0060, Train Linf Norm: 1.8197, Test Linf Norm: 0.3622\n",
            "Epoch 77: Train Loss: 0.0044, Test Loss: 0.0047, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7730, Test Linf Norm: 0.3567\n",
            "Epoch 78: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7431, Test Linf Norm: 0.3578\n",
            "Epoch 79: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0173, Test L1 Norm: 0.0060, Train Linf Norm: 1.7738, Test Linf Norm: 0.3604\n",
            "Epoch 80: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7692, Test Linf Norm: 0.3550\n",
            "Epoch 81: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7676, Test Linf Norm: 0.3587\n",
            "Epoch 82: Train Loss: 0.0044, Test Loss: 0.0047, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7638, Test Linf Norm: 0.3550\n",
            "Epoch 83: Train Loss: 0.0044, Test Loss: 0.0047, Train L1 Norm: 0.0174, Test L1 Norm: 0.0060, Train Linf Norm: 1.8030, Test Linf Norm: 0.3586\n",
            "Epoch 84: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0171, Test L1 Norm: 0.0060, Train Linf Norm: 1.7412, Test Linf Norm: 0.3610\n",
            "Epoch 85: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0173, Test L1 Norm: 0.0060, Train Linf Norm: 1.7422, Test Linf Norm: 0.3618\n",
            "Epoch 86: Train Loss: 0.0044, Test Loss: 0.0047, Train L1 Norm: 0.0173, Test L1 Norm: 0.0060, Train Linf Norm: 1.7687, Test Linf Norm: 0.3548\n",
            "Epoch 87: Train Loss: 0.0044, Test Loss: 0.0047, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7651, Test Linf Norm: 0.3554\n",
            "Epoch 88: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7686, Test Linf Norm: 0.3584\n",
            "Epoch 89: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7511, Test Linf Norm: 0.3578\n",
            "Epoch 90: Train Loss: 0.0044, Test Loss: 0.0047, Train L1 Norm: 0.0171, Test L1 Norm: 0.0060, Train Linf Norm: 1.7581, Test Linf Norm: 0.3583\n",
            "Epoch 91: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7533, Test Linf Norm: 0.3574\n",
            "Epoch 92: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7613, Test Linf Norm: 0.3585\n",
            "Epoch 93: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7712, Test Linf Norm: 0.3578\n",
            "Epoch 94: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7448, Test Linf Norm: 0.3580\n",
            "Epoch 95: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7631, Test Linf Norm: 0.3584\n",
            "Epoch 96: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7429, Test Linf Norm: 0.3584\n",
            "Epoch 97: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7692, Test Linf Norm: 0.3586\n",
            "Epoch 98: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7551, Test Linf Norm: 0.3582\n",
            "Epoch 99: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7444, Test Linf Norm: 0.3578\n",
            "Epoch 100: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7686, Test Linf Norm: 0.3581\n",
            "Epoch 101: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7721, Test Linf Norm: 0.3577\n",
            "Epoch 102: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7766, Test Linf Norm: 0.3575\n",
            "Epoch 103: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7707, Test Linf Norm: 0.3581\n",
            "Epoch 104: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7766, Test Linf Norm: 0.3585\n",
            "Epoch 105: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7658, Test Linf Norm: 0.3577\n",
            "Epoch 106: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7606, Test Linf Norm: 0.3579\n",
            "Epoch 107: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7696, Test Linf Norm: 0.3581\n",
            "Epoch 108: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7582, Test Linf Norm: 0.3581\n",
            "Epoch 109: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7638, Test Linf Norm: 0.3581\n",
            "Epoch 110: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7606, Test Linf Norm: 0.3580\n",
            "Epoch 111: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7649, Test Linf Norm: 0.3580\n",
            "Epoch 112: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7630, Test Linf Norm: 0.3583\n",
            "Epoch 113: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7599, Test Linf Norm: 0.3579\n",
            "Epoch 114: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7588, Test Linf Norm: 0.3580\n",
            "Epoch 115: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7665, Test Linf Norm: 0.3581\n",
            "Epoch 116: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7523, Test Linf Norm: 0.3581\n",
            "Epoch 117: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7529, Test Linf Norm: 0.3580\n",
            "Epoch 118: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7525, Test Linf Norm: 0.3582\n",
            "Epoch 119: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7515, Test Linf Norm: 0.3581\n",
            "Epoch 120: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7717, Test Linf Norm: 0.3581\n",
            "Epoch 121: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7687, Test Linf Norm: 0.3581\n",
            "Epoch 122: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7735, Test Linf Norm: 0.3581\n",
            "Epoch 123: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7714, Test Linf Norm: 0.3581\n",
            "Epoch 124: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7635, Test Linf Norm: 0.3581\n",
            "Epoch 125: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7714, Test Linf Norm: 0.3581\n",
            "Epoch 126: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7536, Test Linf Norm: 0.3581\n",
            "Epoch 127: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7649, Test Linf Norm: 0.3581\n",
            "Epoch 128: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7685, Test Linf Norm: 0.3581\n",
            "Epoch 129: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7664, Test Linf Norm: 0.3581\n",
            "Epoch 130: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7570, Test Linf Norm: 0.3581\n",
            "Epoch 131: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7701, Test Linf Norm: 0.3581\n",
            "Epoch 132: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7709, Test Linf Norm: 0.3581\n",
            "Epoch 133: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7601, Test Linf Norm: 0.3581\n",
            "Epoch 134: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7592, Test Linf Norm: 0.3581\n",
            "Epoch 135: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7590, Test Linf Norm: 0.3581\n",
            "Epoch 136: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7697, Test Linf Norm: 0.3581\n",
            "Epoch 137: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7497, Test Linf Norm: 0.3581\n",
            "Epoch 138: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7375, Test Linf Norm: 0.3581\n",
            "Epoch 139: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7625, Test Linf Norm: 0.3581\n",
            "Epoch 140: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7648, Test Linf Norm: 0.3581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:41:49,902]\u001b[0m Trial 74 finished with value: 0.0059798791565001015 and parameters: {'n_layers': 3, 'n_units_0': 1433, 'n_units_1': 170, 'n_units_2': 689, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0007221560096896734, 'batch_size': 128, 'n_epochs': 141, 'scheduler': 'StepLR', 'weight_decay': 0.0012565018083404765, 'beta1': 0.9954667977248475, 'beta2': 0.9996651831749753, 'step_size': 15, 'gamma': 0.2000592885268373}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 141: Train Loss: 0.0044, Test Loss: 0.0046, Train L1 Norm: 0.0172, Test L1 Norm: 0.0060, Train Linf Norm: 1.7688, Test Linf Norm: 0.3581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:41:50,991]\u001b[0m Trial 75 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.4086, Test Loss: 0.1156, Train L1 Norm: 1.1528, Test L1 Norm: 0.2283, Train Linf Norm: 410.3320, Test Linf Norm: 45.7499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:41:53,058]\u001b[0m Trial 76 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 2.3054, Test Loss: 0.1329, Train L1 Norm: 1.2826, Test L1 Norm: 0.3542, Train Linf Norm: 122.8068, Test Linf Norm: 18.8072\n",
            "Epoch 1: Train Loss: 0.1406, Test Loss: 0.0338, Train L1 Norm: 0.2557, Test L1 Norm: 0.0310, Train Linf Norm: 11.6632, Test Linf Norm: 0.9951\n",
            "Epoch 2: Train Loss: 0.0519, Test Loss: 0.0258, Train L1 Norm: 0.0811, Test L1 Norm: 0.0403, Train Linf Norm: 3.5863, Test Linf Norm: 1.5567\n",
            "Epoch 3: Train Loss: 0.0367, Test Loss: 0.0300, Train L1 Norm: 0.1232, Test L1 Norm: 0.0302, Train Linf Norm: 6.7293, Test Linf Norm: 1.1622\n",
            "Epoch 4: Train Loss: 0.0344, Test Loss: 0.0356, Train L1 Norm: 0.1228, Test L1 Norm: 0.0425, Train Linf Norm: 6.7366, Test Linf Norm: 1.5764\n",
            "Epoch 5: Train Loss: 0.0351, Test Loss: 0.0199, Train L1 Norm: 0.1151, Test L1 Norm: 0.0335, Train Linf Norm: 6.2660, Test Linf Norm: 1.2809\n",
            "Epoch 6: Train Loss: 0.0249, Test Loss: 0.0181, Train L1 Norm: 0.1145, Test L1 Norm: 0.0234, Train Linf Norm: 6.4858, Test Linf Norm: 0.9569\n",
            "Epoch 7: Train Loss: 0.0313, Test Loss: 0.0188, Train L1 Norm: 0.1295, Test L1 Norm: 0.0249, Train Linf Norm: 7.3003, Test Linf Norm: 1.0349\n",
            "Epoch 8: Train Loss: 0.0294, Test Loss: 0.0193, Train L1 Norm: 0.1323, Test L1 Norm: 0.0210, Train Linf Norm: 7.5386, Test Linf Norm: 0.7501\n",
            "Epoch 9: Train Loss: 0.0262, Test Loss: 0.0316, Train L1 Norm: 0.0968, Test L1 Norm: 0.0241, Train Linf Norm: 5.3716, Test Linf Norm: 0.8352\n",
            "Epoch 10: Train Loss: 0.0257, Test Loss: 0.0242, Train L1 Norm: 0.0975, Test L1 Norm: 0.0179, Train Linf Norm: 5.4147, Test Linf Norm: 0.3607\n",
            "Epoch 11: Train Loss: 0.0206, Test Loss: 0.0432, Train L1 Norm: 0.0721, Test L1 Norm: 0.0203, Train Linf Norm: 3.9210, Test Linf Norm: 0.4000\n",
            "Epoch 12: Train Loss: 0.0247, Test Loss: 0.0267, Train L1 Norm: 0.0640, Test L1 Norm: 0.0239, Train Linf Norm: 3.2764, Test Linf Norm: 0.7421\n",
            "Epoch 13: Train Loss: 0.0255, Test Loss: 0.0193, Train L1 Norm: 0.0438, Test L1 Norm: 0.0226, Train Linf Norm: 1.9986, Test Linf Norm: 0.7977\n",
            "Epoch 14: Train Loss: 0.0251, Test Loss: 0.0186, Train L1 Norm: 0.0933, Test L1 Norm: 0.0175, Train Linf Norm: 5.2003, Test Linf Norm: 0.5761\n",
            "Epoch 15: Train Loss: 0.0131, Test Loss: 0.0110, Train L1 Norm: 0.0570, Test L1 Norm: 0.0117, Train Linf Norm: 3.1814, Test Linf Norm: 0.3576\n",
            "Epoch 16: Train Loss: 0.0159, Test Loss: 0.0191, Train L1 Norm: 0.0402, Test L1 Norm: 0.0166, Train Linf Norm: 2.0525, Test Linf Norm: 0.5783\n",
            "Epoch 17: Train Loss: 0.0158, Test Loss: 0.0118, Train L1 Norm: 0.0397, Test L1 Norm: 0.0175, Train Linf Norm: 2.0507, Test Linf Norm: 0.6720\n",
            "Epoch 18: Train Loss: 0.0129, Test Loss: 0.0141, Train L1 Norm: 0.0429, Test L1 Norm: 0.0109, Train Linf Norm: 2.3070, Test Linf Norm: 0.2961\n",
            "Epoch 19: Train Loss: 0.0124, Test Loss: 0.0126, Train L1 Norm: 0.0378, Test L1 Norm: 0.0114, Train Linf Norm: 1.9826, Test Linf Norm: 0.3082\n",
            "Epoch 20: Train Loss: 0.0168, Test Loss: 0.0245, Train L1 Norm: 0.0510, Test L1 Norm: 0.0183, Train Linf Norm: 2.7409, Test Linf Norm: 0.4769\n",
            "Epoch 21: Train Loss: 0.0143, Test Loss: 0.0131, Train L1 Norm: 0.0417, Test L1 Norm: 0.0110, Train Linf Norm: 2.2169, Test Linf Norm: 0.3224\n",
            "Epoch 22: Train Loss: 0.0111, Test Loss: 0.0087, Train L1 Norm: 0.0336, Test L1 Norm: 0.0106, Train Linf Norm: 1.7648, Test Linf Norm: 0.3786\n",
            "Epoch 23: Train Loss: 0.0110, Test Loss: 0.0101, Train L1 Norm: 0.0353, Test L1 Norm: 0.0118, Train Linf Norm: 1.8834, Test Linf Norm: 0.4377\n",
            "Epoch 24: Train Loss: 0.0136, Test Loss: 0.0101, Train L1 Norm: 0.0264, Test L1 Norm: 0.0102, Train Linf Norm: 1.2645, Test Linf Norm: 0.3356\n",
            "Epoch 25: Train Loss: 0.0116, Test Loss: 0.0145, Train L1 Norm: 0.0252, Test L1 Norm: 0.0110, Train Linf Norm: 1.2386, Test Linf Norm: 0.3177\n",
            "Epoch 26: Train Loss: 0.0122, Test Loss: 0.0116, Train L1 Norm: 0.0258, Test L1 Norm: 0.0099, Train Linf Norm: 1.2557, Test Linf Norm: 0.2851\n",
            "Epoch 27: Train Loss: 0.0122, Test Loss: 0.0190, Train L1 Norm: 0.0255, Test L1 Norm: 0.0157, Train Linf Norm: 1.2471, Test Linf Norm: 0.4710\n",
            "Epoch 28: Train Loss: 0.0115, Test Loss: 0.0112, Train L1 Norm: 0.0405, Test L1 Norm: 0.0094, Train Linf Norm: 2.2040, Test Linf Norm: 0.2942\n",
            "Epoch 29: Train Loss: 0.0091, Test Loss: 0.0112, Train L1 Norm: 0.0199, Test L1 Norm: 0.0093, Train Linf Norm: 0.9741, Test Linf Norm: 0.2797\n",
            "Epoch 30: Train Loss: 0.0083, Test Loss: 0.0080, Train L1 Norm: 0.0253, Test L1 Norm: 0.0080, Train Linf Norm: 1.3311, Test Linf Norm: 0.2416\n",
            "Epoch 31: Train Loss: 0.0082, Test Loss: 0.0081, Train L1 Norm: 0.0298, Test L1 Norm: 0.0086, Train Linf Norm: 1.6220, Test Linf Norm: 0.2819\n",
            "Epoch 32: Train Loss: 0.0088, Test Loss: 0.0068, Train L1 Norm: 0.0257, Test L1 Norm: 0.0075, Train Linf Norm: 1.3608, Test Linf Norm: 0.2498\n",
            "Epoch 33: Train Loss: 0.0074, Test Loss: 0.0079, Train L1 Norm: 0.0201, Test L1 Norm: 0.0075, Train Linf Norm: 1.0272, Test Linf Norm: 0.2394\n",
            "Epoch 34: Train Loss: 0.0088, Test Loss: 0.0089, Train L1 Norm: 0.0258, Test L1 Norm: 0.0076, Train Linf Norm: 1.3647, Test Linf Norm: 0.2242\n",
            "Epoch 35: Train Loss: 0.0097, Test Loss: 0.0078, Train L1 Norm: 0.0233, Test L1 Norm: 0.0074, Train Linf Norm: 1.1808, Test Linf Norm: 0.2334\n",
            "Epoch 36: Train Loss: 0.0078, Test Loss: 0.0095, Train L1 Norm: 0.0228, Test L1 Norm: 0.0076, Train Linf Norm: 1.1906, Test Linf Norm: 0.2091\n",
            "Epoch 37: Train Loss: 0.0083, Test Loss: 0.0082, Train L1 Norm: 0.0227, Test L1 Norm: 0.0075, Train Linf Norm: 1.1703, Test Linf Norm: 0.2279\n",
            "Epoch 38: Train Loss: 0.0075, Test Loss: 0.0070, Train L1 Norm: 0.0228, Test L1 Norm: 0.0068, Train Linf Norm: 1.1994, Test Linf Norm: 0.1903\n",
            "Epoch 39: Train Loss: 0.0073, Test Loss: 0.0077, Train L1 Norm: 0.0239, Test L1 Norm: 0.0068, Train Linf Norm: 1.2611, Test Linf Norm: 0.2023\n",
            "Epoch 40: Train Loss: 0.0078, Test Loss: 0.0082, Train L1 Norm: 0.0220, Test L1 Norm: 0.0067, Train Linf Norm: 1.1311, Test Linf Norm: 0.1828\n",
            "Epoch 41: Train Loss: 0.0088, Test Loss: 0.0072, Train L1 Norm: 0.0192, Test L1 Norm: 0.0066, Train Linf Norm: 0.9507, Test Linf Norm: 0.1963\n",
            "Epoch 42: Train Loss: 0.0070, Test Loss: 0.0074, Train L1 Norm: 0.0163, Test L1 Norm: 0.0084, Train Linf Norm: 0.7891, Test Linf Norm: 0.2460\n",
            "Epoch 43: Train Loss: 0.0065, Test Loss: 0.0065, Train L1 Norm: 0.0154, Test L1 Norm: 0.0064, Train Linf Norm: 0.7563, Test Linf Norm: 0.1919\n",
            "Epoch 44: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0195, Test L1 Norm: 0.0070, Train Linf Norm: 1.0100, Test Linf Norm: 0.2243\n",
            "Epoch 45: Train Loss: 0.0065, Test Loss: 0.0069, Train L1 Norm: 0.0194, Test L1 Norm: 0.0066, Train Linf Norm: 1.0148, Test Linf Norm: 0.1956\n",
            "Epoch 46: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0189, Test L1 Norm: 0.0065, Train Linf Norm: 0.9864, Test Linf Norm: 0.1989\n",
            "Epoch 47: Train Loss: 0.0065, Test Loss: 0.0070, Train L1 Norm: 0.0200, Test L1 Norm: 0.0066, Train Linf Norm: 1.0512, Test Linf Norm: 0.1916\n",
            "Epoch 48: Train Loss: 0.0064, Test Loss: 0.0063, Train L1 Norm: 0.0178, Test L1 Norm: 0.0067, Train Linf Norm: 0.9135, Test Linf Norm: 0.2155\n",
            "Epoch 49: Train Loss: 0.0065, Test Loss: 0.0071, Train L1 Norm: 0.0187, Test L1 Norm: 0.0068, Train Linf Norm: 0.9601, Test Linf Norm: 0.2070\n",
            "Epoch 50: Train Loss: 0.0065, Test Loss: 0.0063, Train L1 Norm: 0.0191, Test L1 Norm: 0.0063, Train Linf Norm: 0.9887, Test Linf Norm: 0.1953\n",
            "Epoch 51: Train Loss: 0.0065, Test Loss: 0.0061, Train L1 Norm: 0.0173, Test L1 Norm: 0.0067, Train Linf Norm: 0.8726, Test Linf Norm: 0.2156\n",
            "Epoch 52: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0163, Test L1 Norm: 0.0072, Train Linf Norm: 0.8207, Test Linf Norm: 0.2355\n",
            "Epoch 53: Train Loss: 0.0062, Test Loss: 0.0062, Train L1 Norm: 0.0169, Test L1 Norm: 0.0062, Train Linf Norm: 0.8614, Test Linf Norm: 0.1901\n",
            "Epoch 54: Train Loss: 0.0062, Test Loss: 0.0062, Train L1 Norm: 0.0156, Test L1 Norm: 0.0067, Train Linf Norm: 0.7782, Test Linf Norm: 0.2132\n",
            "Epoch 55: Train Loss: 0.0064, Test Loss: 0.0070, Train L1 Norm: 0.0167, Test L1 Norm: 0.0066, Train Linf Norm: 0.8467, Test Linf Norm: 0.2006\n",
            "Epoch 56: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0171, Test L1 Norm: 0.0065, Train Linf Norm: 0.8689, Test Linf Norm: 0.2030\n",
            "Epoch 57: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0175, Test L1 Norm: 0.0062, Train Linf Norm: 0.9033, Test Linf Norm: 0.1898\n",
            "Epoch 58: Train Loss: 0.0060, Test Loss: 0.0061, Train L1 Norm: 0.0166, Test L1 Norm: 0.0062, Train Linf Norm: 0.8469, Test Linf Norm: 0.1899\n",
            "Epoch 59: Train Loss: 0.0059, Test Loss: 0.0061, Train L1 Norm: 0.0163, Test L1 Norm: 0.0062, Train Linf Norm: 0.8341, Test Linf Norm: 0.1879\n",
            "Epoch 60: Train Loss: 0.0060, Test Loss: 0.0061, Train L1 Norm: 0.0157, Test L1 Norm: 0.0062, Train Linf Norm: 0.7925, Test Linf Norm: 0.1913\n",
            "Epoch 61: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0159, Test L1 Norm: 0.0063, Train Linf Norm: 0.7931, Test Linf Norm: 0.1931\n",
            "Epoch 62: Train Loss: 0.0059, Test Loss: 0.0061, Train L1 Norm: 0.0167, Test L1 Norm: 0.0061, Train Linf Norm: 0.8608, Test Linf Norm: 0.1876\n",
            "Epoch 63: Train Loss: 0.0060, Test Loss: 0.0061, Train L1 Norm: 0.0150, Test L1 Norm: 0.0062, Train Linf Norm: 0.7365, Test Linf Norm: 0.1931\n",
            "Epoch 64: Train Loss: 0.0060, Test Loss: 0.0061, Train L1 Norm: 0.0164, Test L1 Norm: 0.0062, Train Linf Norm: 0.8373, Test Linf Norm: 0.1901\n",
            "Epoch 65: Train Loss: 0.0059, Test Loss: 0.0061, Train L1 Norm: 0.0156, Test L1 Norm: 0.0063, Train Linf Norm: 0.7813, Test Linf Norm: 0.1935\n",
            "Epoch 66: Train Loss: 0.0059, Test Loss: 0.0060, Train L1 Norm: 0.0156, Test L1 Norm: 0.0062, Train Linf Norm: 0.7876, Test Linf Norm: 0.1918\n",
            "Epoch 67: Train Loss: 0.0059, Test Loss: 0.0062, Train L1 Norm: 0.0150, Test L1 Norm: 0.0062, Train Linf Norm: 0.7515, Test Linf Norm: 0.1909\n",
            "Epoch 68: Train Loss: 0.0059, Test Loss: 0.0061, Train L1 Norm: 0.0154, Test L1 Norm: 0.0062, Train Linf Norm: 0.7663, Test Linf Norm: 0.1893\n",
            "Epoch 69: Train Loss: 0.0059, Test Loss: 0.0064, Train L1 Norm: 0.0152, Test L1 Norm: 0.0063, Train Linf Norm: 0.7647, Test Linf Norm: 0.1879\n",
            "Epoch 70: Train Loss: 0.0059, Test Loss: 0.0064, Train L1 Norm: 0.0152, Test L1 Norm: 0.0062, Train Linf Norm: 0.7619, Test Linf Norm: 0.1873\n",
            "Epoch 71: Train Loss: 0.0059, Test Loss: 0.0060, Train L1 Norm: 0.0152, Test L1 Norm: 0.0061, Train Linf Norm: 0.7585, Test Linf Norm: 0.1886\n",
            "Epoch 72: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0154, Test L1 Norm: 0.0061, Train Linf Norm: 0.7765, Test Linf Norm: 0.1873\n",
            "Epoch 73: Train Loss: 0.0058, Test Loss: 0.0061, Train L1 Norm: 0.0154, Test L1 Norm: 0.0062, Train Linf Norm: 0.7726, Test Linf Norm: 0.1886\n",
            "Epoch 74: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0155, Test L1 Norm: 0.0061, Train Linf Norm: 0.7728, Test Linf Norm: 0.1874\n",
            "Epoch 75: Train Loss: 0.0058, Test Loss: 0.0061, Train L1 Norm: 0.0153, Test L1 Norm: 0.0061, Train Linf Norm: 0.7708, Test Linf Norm: 0.1874\n",
            "Epoch 76: Train Loss: 0.0059, Test Loss: 0.0061, Train L1 Norm: 0.0154, Test L1 Norm: 0.0062, Train Linf Norm: 0.7740, Test Linf Norm: 0.1879\n",
            "Epoch 77: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0153, Test L1 Norm: 0.0061, Train Linf Norm: 0.7730, Test Linf Norm: 0.1881\n",
            "Epoch 78: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7467, Test Linf Norm: 0.1876\n",
            "Epoch 79: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0152, Test L1 Norm: 0.0062, Train Linf Norm: 0.7668, Test Linf Norm: 0.1902\n",
            "Epoch 80: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7432, Test Linf Norm: 0.1870\n",
            "Epoch 81: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0153, Test L1 Norm: 0.0062, Train Linf Norm: 0.7690, Test Linf Norm: 0.1906\n",
            "Epoch 82: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0145, Test L1 Norm: 0.0061, Train Linf Norm: 0.7131, Test Linf Norm: 0.1879\n",
            "Epoch 83: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0062, Train Linf Norm: 0.7511, Test Linf Norm: 0.1916\n",
            "Epoch 84: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0152, Test L1 Norm: 0.0061, Train Linf Norm: 0.7662, Test Linf Norm: 0.1882\n",
            "Epoch 85: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0154, Test L1 Norm: 0.0061, Train Linf Norm: 0.7823, Test Linf Norm: 0.1875\n",
            "Epoch 86: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0152, Test L1 Norm: 0.0062, Train Linf Norm: 0.7585, Test Linf Norm: 0.1891\n",
            "Epoch 87: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0153, Test L1 Norm: 0.0061, Train Linf Norm: 0.7685, Test Linf Norm: 0.1879\n",
            "Epoch 88: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0152, Test L1 Norm: 0.0061, Train Linf Norm: 0.7650, Test Linf Norm: 0.1884\n",
            "Epoch 89: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7529, Test Linf Norm: 0.1880\n",
            "Epoch 90: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0152, Test L1 Norm: 0.0061, Train Linf Norm: 0.7634, Test Linf Norm: 0.1877\n",
            "Epoch 91: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0151, Test L1 Norm: 0.0061, Train Linf Norm: 0.7577, Test Linf Norm: 0.1883\n",
            "Epoch 92: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7512, Test Linf Norm: 0.1877\n",
            "Epoch 93: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0151, Test L1 Norm: 0.0061, Train Linf Norm: 0.7493, Test Linf Norm: 0.1878\n",
            "Epoch 94: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7439, Test Linf Norm: 0.1883\n",
            "Epoch 95: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7581, Test Linf Norm: 0.1878\n",
            "Epoch 96: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7487, Test Linf Norm: 0.1881\n",
            "Epoch 97: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0151, Test L1 Norm: 0.0061, Train Linf Norm: 0.7605, Test Linf Norm: 0.1876\n",
            "Epoch 98: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7506, Test Linf Norm: 0.1878\n",
            "Epoch 99: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7535, Test Linf Norm: 0.1879\n",
            "Epoch 100: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7535, Test Linf Norm: 0.1879\n",
            "Epoch 101: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7526, Test Linf Norm: 0.1878\n",
            "Epoch 102: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7465, Test Linf Norm: 0.1877\n",
            "Epoch 103: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7506, Test Linf Norm: 0.1877\n",
            "Epoch 104: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7511, Test Linf Norm: 0.1877\n",
            "Epoch 105: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7501, Test Linf Norm: 0.1876\n",
            "Epoch 106: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7412, Test Linf Norm: 0.1878\n",
            "Epoch 107: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7494, Test Linf Norm: 0.1878\n",
            "Epoch 108: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7514, Test Linf Norm: 0.1877\n",
            "Epoch 109: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7497, Test Linf Norm: 0.1878\n",
            "Epoch 110: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7394, Test Linf Norm: 0.1877\n",
            "Epoch 111: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7497, Test Linf Norm: 0.1877\n",
            "Epoch 112: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7489, Test Linf Norm: 0.1878\n",
            "Epoch 113: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0150, Test L1 Norm: 0.0061, Train Linf Norm: 0.7501, Test Linf Norm: 0.1878\n",
            "Epoch 114: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7499, Test Linf Norm: 0.1878\n",
            "Epoch 115: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7520, Test Linf Norm: 0.1878\n",
            "Epoch 116: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7375, Test Linf Norm: 0.1878\n",
            "Epoch 117: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7500, Test Linf Norm: 0.1878\n",
            "Epoch 118: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7444, Test Linf Norm: 0.1878\n",
            "Epoch 119: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7482, Test Linf Norm: 0.1878\n",
            "Epoch 120: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7487, Test Linf Norm: 0.1878\n",
            "Epoch 121: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7453, Test Linf Norm: 0.1878\n",
            "Epoch 122: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7504, Test Linf Norm: 0.1878\n",
            "Epoch 123: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7445, Test Linf Norm: 0.1878\n",
            "Epoch 124: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7440, Test Linf Norm: 0.1878\n",
            "Epoch 125: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7494, Test Linf Norm: 0.1878\n",
            "Epoch 126: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7366, Test Linf Norm: 0.1878\n",
            "Epoch 127: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7525, Test Linf Norm: 0.1878\n",
            "Epoch 128: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7529, Test Linf Norm: 0.1878\n",
            "Epoch 129: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7510, Test Linf Norm: 0.1878\n",
            "Epoch 130: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7477, Test Linf Norm: 0.1878\n",
            "Epoch 131: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7513, Test Linf Norm: 0.1878\n",
            "Epoch 132: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7450, Test Linf Norm: 0.1878\n",
            "Epoch 133: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7454, Test Linf Norm: 0.1878\n",
            "Epoch 134: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7430, Test Linf Norm: 0.1878\n",
            "Epoch 135: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7453, Test Linf Norm: 0.1878\n",
            "Epoch 136: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7509, Test Linf Norm: 0.1878\n",
            "Epoch 137: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7449, Test Linf Norm: 0.1878\n",
            "Epoch 138: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7418, Test Linf Norm: 0.1878\n",
            "Epoch 139: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7476, Test Linf Norm: 0.1878\n",
            "Epoch 140: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7466, Test Linf Norm: 0.1878\n",
            "Epoch 141: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7499, Test Linf Norm: 0.1878\n",
            "Epoch 142: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7469, Test Linf Norm: 0.1878\n",
            "Epoch 143: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7504, Test Linf Norm: 0.1878\n",
            "Epoch 144: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7497, Test Linf Norm: 0.1878\n",
            "Epoch 145: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7497, Test Linf Norm: 0.1878\n",
            "Epoch 146: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7449, Test Linf Norm: 0.1878\n",
            "Epoch 147: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7491, Test Linf Norm: 0.1878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:50:40,028]\u001b[0m Trial 77 finished with value: 0.0061300765838474035 and parameters: {'n_layers': 3, 'n_units_0': 967, 'n_units_1': 527, 'n_units_2': 680, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.001249611608245466, 'batch_size': 64, 'n_epochs': 148, 'scheduler': 'StepLR', 'weight_decay': 0.0028578186470269596, 'beta1': 0.9963614633325685, 'beta2': 0.9995431183726031, 'step_size': 14, 'gamma': 0.2227628973891036}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 148: Train Loss: 0.0058, Test Loss: 0.0060, Train L1 Norm: 0.0149, Test L1 Norm: 0.0061, Train Linf Norm: 0.7494, Test Linf Norm: 0.1878\n",
            "Epoch 1: Train Loss: 0.1513, Test Loss: 0.0523, Train L1 Norm: 0.2097, Test L1 Norm: 0.0355, Train Linf Norm: 8.3095, Test Linf Norm: 0.7474\n",
            "Epoch 2: Train Loss: 0.0329, Test Loss: 0.0501, Train L1 Norm: 0.1020, Test L1 Norm: 0.0383, Train Linf Norm: 5.4367, Test Linf Norm: 1.1009\n",
            "Epoch 3: Train Loss: 0.0389, Test Loss: 0.0275, Train L1 Norm: 0.1214, Test L1 Norm: 0.0251, Train Linf Norm: 6.5566, Test Linf Norm: 0.7531\n",
            "Epoch 4: Train Loss: 0.0389, Test Loss: 0.0410, Train L1 Norm: 0.1112, Test L1 Norm: 0.0429, Train Linf Norm: 5.9187, Test Linf Norm: 1.4462\n",
            "Epoch 5: Train Loss: 0.0370, Test Loss: 0.0247, Train L1 Norm: 0.0985, Test L1 Norm: 0.0244, Train Linf Norm: 5.1798, Test Linf Norm: 0.8306\n",
            "Epoch 6: Train Loss: 0.0345, Test Loss: 0.0289, Train L1 Norm: 0.0825, Test L1 Norm: 0.0238, Train Linf Norm: 4.2301, Test Linf Norm: 0.7243\n",
            "Epoch 7: Train Loss: 0.0265, Test Loss: 0.0409, Train L1 Norm: 0.0566, Test L1 Norm: 0.0245, Train Linf Norm: 2.8009, Test Linf Norm: 0.5792\n",
            "Epoch 8: Train Loss: 0.0297, Test Loss: 0.0501, Train L1 Norm: 0.1450, Test L1 Norm: 0.0386, Train Linf Norm: 8.2774, Test Linf Norm: 0.8025\n",
            "Epoch 9: Train Loss: 0.0292, Test Loss: 0.0243, Train L1 Norm: 0.0812, Test L1 Norm: 0.0281, Train Linf Norm: 4.2905, Test Linf Norm: 1.0012\n",
            "Epoch 10: Train Loss: 0.0295, Test Loss: 0.0216, Train L1 Norm: 0.0685, Test L1 Norm: 0.0363, Train Linf Norm: 3.4894, Test Linf Norm: 1.4221\n",
            "Epoch 11: Train Loss: 0.0311, Test Loss: 0.0192, Train L1 Norm: 0.0720, Test L1 Norm: 0.0209, Train Linf Norm: 3.6593, Test Linf Norm: 0.7289\n",
            "Epoch 12: Train Loss: 0.0173, Test Loss: 0.0141, Train L1 Norm: 0.0624, Test L1 Norm: 0.0198, Train Linf Norm: 3.4048, Test Linf Norm: 0.7811\n",
            "Epoch 13: Train Loss: 0.0151, Test Loss: 0.0186, Train L1 Norm: 0.0557, Test L1 Norm: 0.0144, Train Linf Norm: 3.0260, Test Linf Norm: 0.4184\n",
            "Epoch 14: Train Loss: 0.0158, Test Loss: 0.0134, Train L1 Norm: 0.0487, Test L1 Norm: 0.0138, Train Linf Norm: 2.5867, Test Linf Norm: 0.4625\n",
            "Epoch 15: Train Loss: 0.0125, Test Loss: 0.0119, Train L1 Norm: 0.0482, Test L1 Norm: 0.0109, Train Linf Norm: 2.6012, Test Linf Norm: 0.2762\n",
            "Epoch 16: Train Loss: 0.0160, Test Loss: 0.0245, Train L1 Norm: 0.0257, Test L1 Norm: 0.0166, Train Linf Norm: 1.1297, Test Linf Norm: 0.4306\n",
            "Epoch 17: Train Loss: 0.0129, Test Loss: 0.0118, Train L1 Norm: 0.0284, Test L1 Norm: 0.0135, Train Linf Norm: 1.3534, Test Linf Norm: 0.4600\n",
            "Epoch 18: Train Loss: 0.0120, Test Loss: 0.0125, Train L1 Norm: 0.0369, Test L1 Norm: 0.0114, Train Linf Norm: 1.9405, Test Linf Norm: 0.2961\n",
            "Epoch 19: Train Loss: 0.0122, Test Loss: 0.0130, Train L1 Norm: 0.0201, Test L1 Norm: 0.0111, Train Linf Norm: 0.8733, Test Linf Norm: 0.2983\n",
            "Epoch 20: Train Loss: 0.0124, Test Loss: 0.0088, Train L1 Norm: 0.0208, Test L1 Norm: 0.0104, Train Linf Norm: 0.9302, Test Linf Norm: 0.3504\n",
            "Epoch 21: Train Loss: 0.0144, Test Loss: 0.0155, Train L1 Norm: 0.0374, Test L1 Norm: 0.0147, Train Linf Norm: 1.9432, Test Linf Norm: 0.3814\n",
            "Epoch 22: Train Loss: 0.0132, Test Loss: 0.0146, Train L1 Norm: 0.0576, Test L1 Norm: 0.0173, Train Linf Norm: 3.2524, Test Linf Norm: 0.6467\n",
            "Epoch 23: Train Loss: 0.0096, Test Loss: 0.0079, Train L1 Norm: 0.0262, Test L1 Norm: 0.0093, Train Linf Norm: 1.3375, Test Linf Norm: 0.3118\n",
            "Epoch 24: Train Loss: 0.0081, Test Loss: 0.0091, Train L1 Norm: 0.0171, Test L1 Norm: 0.0093, Train Linf Norm: 0.8009, Test Linf Norm: 0.3059\n",
            "Epoch 25: Train Loss: 0.0079, Test Loss: 0.0077, Train L1 Norm: 0.0167, Test L1 Norm: 0.0076, Train Linf Norm: 0.7844, Test Linf Norm: 0.2196\n",
            "Epoch 26: Train Loss: 0.0084, Test Loss: 0.0083, Train L1 Norm: 0.0200, Test L1 Norm: 0.0076, Train Linf Norm: 0.9827, Test Linf Norm: 0.2169\n",
            "Epoch 27: Train Loss: 0.0093, Test Loss: 0.0100, Train L1 Norm: 0.0196, Test L1 Norm: 0.0095, Train Linf Norm: 0.9349, Test Linf Norm: 0.2904\n",
            "Epoch 28: Train Loss: 0.0090, Test Loss: 0.0086, Train L1 Norm: 0.0158, Test L1 Norm: 0.0076, Train Linf Norm: 0.6952, Test Linf Norm: 0.2037\n",
            "Epoch 29: Train Loss: 0.0086, Test Loss: 0.0100, Train L1 Norm: 0.0174, Test L1 Norm: 0.0089, Train Linf Norm: 0.8172, Test Linf Norm: 0.2369\n",
            "Epoch 30: Train Loss: 0.0086, Test Loss: 0.0077, Train L1 Norm: 0.0183, Test L1 Norm: 0.0083, Train Linf Norm: 0.8714, Test Linf Norm: 0.2643\n",
            "Epoch 31: Train Loss: 0.0080, Test Loss: 0.0092, Train L1 Norm: 0.0215, Test L1 Norm: 0.0077, Train Linf Norm: 1.0861, Test Linf Norm: 0.2086\n",
            "Epoch 32: Train Loss: 0.0095, Test Loss: 0.0095, Train L1 Norm: 0.0151, Test L1 Norm: 0.0081, Train Linf Norm: 0.6532, Test Linf Norm: 0.2377\n",
            "Epoch 33: Train Loss: 0.0078, Test Loss: 0.0085, Train L1 Norm: 0.0183, Test L1 Norm: 0.0078, Train Linf Norm: 0.8940, Test Linf Norm: 0.2087\n",
            "Epoch 34: Train Loss: 0.0069, Test Loss: 0.0069, Train L1 Norm: 0.0147, Test L1 Norm: 0.0070, Train Linf Norm: 0.6839, Test Linf Norm: 0.2121\n",
            "Epoch 35: Train Loss: 0.0068, Test Loss: 0.0067, Train L1 Norm: 0.0178, Test L1 Norm: 0.0070, Train Linf Norm: 0.8962, Test Linf Norm: 0.2137\n",
            "Epoch 36: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0145, Test L1 Norm: 0.0072, Train Linf Norm: 0.6890, Test Linf Norm: 0.2191\n",
            "Epoch 37: Train Loss: 0.0069, Test Loss: 0.0078, Train L1 Norm: 0.0151, Test L1 Norm: 0.0072, Train Linf Norm: 0.7173, Test Linf Norm: 0.2118\n",
            "Epoch 38: Train Loss: 0.0068, Test Loss: 0.0076, Train L1 Norm: 0.0181, Test L1 Norm: 0.0070, Train Linf Norm: 0.9167, Test Linf Norm: 0.2040\n",
            "Epoch 39: Train Loss: 0.0071, Test Loss: 0.0079, Train L1 Norm: 0.0188, Test L1 Norm: 0.0075, Train Linf Norm: 0.9470, Test Linf Norm: 0.2250\n",
            "Epoch 40: Train Loss: 0.0067, Test Loss: 0.0067, Train L1 Norm: 0.0148, Test L1 Norm: 0.0069, Train Linf Norm: 0.7083, Test Linf Norm: 0.2073\n",
            "Epoch 41: Train Loss: 0.0068, Test Loss: 0.0073, Train L1 Norm: 0.0140, Test L1 Norm: 0.0071, Train Linf Norm: 0.6419, Test Linf Norm: 0.2075\n",
            "Epoch 42: Train Loss: 0.0068, Test Loss: 0.0066, Train L1 Norm: 0.0158, Test L1 Norm: 0.0072, Train Linf Norm: 0.7692, Test Linf Norm: 0.2249\n",
            "Epoch 43: Train Loss: 0.0068, Test Loss: 0.0070, Train L1 Norm: 0.0138, Test L1 Norm: 0.0077, Train Linf Norm: 0.6415, Test Linf Norm: 0.2466\n",
            "Epoch 44: Train Loss: 0.0069, Test Loss: 0.0066, Train L1 Norm: 0.0144, Test L1 Norm: 0.0068, Train Linf Norm: 0.6740, Test Linf Norm: 0.2042\n",
            "Epoch 45: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0126, Test L1 Norm: 0.0069, Train Linf Norm: 0.5738, Test Linf Norm: 0.2113\n",
            "Epoch 46: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0142, Test L1 Norm: 0.0067, Train Linf Norm: 0.6711, Test Linf Norm: 0.2032\n",
            "Epoch 47: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0143, Test L1 Norm: 0.0069, Train Linf Norm: 0.6854, Test Linf Norm: 0.2118\n",
            "Epoch 48: Train Loss: 0.0064, Test Loss: 0.0067, Train L1 Norm: 0.0147, Test L1 Norm: 0.0070, Train Linf Norm: 0.7067, Test Linf Norm: 0.2165\n",
            "Epoch 49: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0128, Test L1 Norm: 0.0066, Train Linf Norm: 0.5848, Test Linf Norm: 0.1993\n",
            "Epoch 50: Train Loss: 0.0064, Test Loss: 0.0069, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5663, Test Linf Norm: 0.1891\n",
            "Epoch 51: Train Loss: 0.0065, Test Loss: 0.0066, Train L1 Norm: 0.0136, Test L1 Norm: 0.0067, Train Linf Norm: 0.6308, Test Linf Norm: 0.1990\n",
            "Epoch 52: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0146, Test L1 Norm: 0.0068, Train Linf Norm: 0.7010, Test Linf Norm: 0.2082\n",
            "Epoch 53: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0134, Test L1 Norm: 0.0065, Train Linf Norm: 0.6332, Test Linf Norm: 0.1897\n",
            "Epoch 54: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0127, Test L1 Norm: 0.0066, Train Linf Norm: 0.5795, Test Linf Norm: 0.1986\n",
            "Epoch 55: Train Loss: 0.0064, Test Loss: 0.0065, Train L1 Norm: 0.0137, Test L1 Norm: 0.0067, Train Linf Norm: 0.6422, Test Linf Norm: 0.2011\n",
            "Epoch 56: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0126, Test L1 Norm: 0.0066, Train Linf Norm: 0.5782, Test Linf Norm: 0.1975\n",
            "Epoch 57: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0131, Test L1 Norm: 0.0067, Train Linf Norm: 0.6024, Test Linf Norm: 0.2033\n",
            "Epoch 58: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0129, Test L1 Norm: 0.0066, Train Linf Norm: 0.5978, Test Linf Norm: 0.1952\n",
            "Epoch 59: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5698, Test Linf Norm: 0.1952\n",
            "Epoch 60: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0131, Test L1 Norm: 0.0066, Train Linf Norm: 0.6077, Test Linf Norm: 0.1996\n",
            "Epoch 61: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0130, Test L1 Norm: 0.0067, Train Linf Norm: 0.6005, Test Linf Norm: 0.2004\n",
            "Epoch 62: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0067, Train Linf Norm: 0.5641, Test Linf Norm: 0.2016\n",
            "Epoch 63: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0126, Test L1 Norm: 0.0066, Train Linf Norm: 0.5761, Test Linf Norm: 0.1956\n",
            "Epoch 64: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0126, Test L1 Norm: 0.0067, Train Linf Norm: 0.5789, Test Linf Norm: 0.2006\n",
            "Epoch 65: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5718, Test Linf Norm: 0.1972\n",
            "Epoch 66: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0126, Test L1 Norm: 0.0066, Train Linf Norm: 0.5755, Test Linf Norm: 0.1966\n",
            "Epoch 67: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0127, Test L1 Norm: 0.0066, Train Linf Norm: 0.5789, Test Linf Norm: 0.1990\n",
            "Epoch 68: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0126, Test L1 Norm: 0.0066, Train Linf Norm: 0.5755, Test Linf Norm: 0.1980\n",
            "Epoch 69: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0126, Test L1 Norm: 0.0066, Train Linf Norm: 0.5704, Test Linf Norm: 0.1983\n",
            "Epoch 70: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5765, Test Linf Norm: 0.1991\n",
            "Epoch 71: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5733, Test Linf Norm: 0.1981\n",
            "Epoch 72: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0126, Test L1 Norm: 0.0066, Train Linf Norm: 0.5758, Test Linf Norm: 0.1992\n",
            "Epoch 73: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5695, Test Linf Norm: 0.1970\n",
            "Epoch 74: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0067, Train Linf Norm: 0.5702, Test Linf Norm: 0.2012\n",
            "Epoch 75: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5627, Test Linf Norm: 0.2006\n",
            "Epoch 76: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0126, Test L1 Norm: 0.0066, Train Linf Norm: 0.5797, Test Linf Norm: 0.1990\n",
            "Epoch 77: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5710, Test Linf Norm: 0.1974\n",
            "Epoch 78: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5655, Test Linf Norm: 0.1981\n",
            "Epoch 79: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5728, Test Linf Norm: 0.1995\n",
            "Epoch 80: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5690, Test Linf Norm: 0.1988\n",
            "Epoch 81: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5719, Test Linf Norm: 0.1993\n",
            "Epoch 82: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5699, Test Linf Norm: 0.1992\n",
            "Epoch 83: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5645, Test Linf Norm: 0.1991\n",
            "Epoch 84: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5666, Test Linf Norm: 0.1982\n",
            "Epoch 85: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5672, Test Linf Norm: 0.1981\n",
            "Epoch 86: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5701, Test Linf Norm: 0.1988\n",
            "Epoch 87: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5649, Test Linf Norm: 0.1985\n",
            "Epoch 88: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5699, Test Linf Norm: 0.1985\n",
            "Epoch 89: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5658, Test Linf Norm: 0.1987\n",
            "Epoch 90: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5670, Test Linf Norm: 0.1989\n",
            "Epoch 91: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5730, Test Linf Norm: 0.1991\n",
            "Epoch 92: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5700, Test Linf Norm: 0.1988\n",
            "Epoch 93: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5680, Test Linf Norm: 0.1989\n",
            "Epoch 94: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5704, Test Linf Norm: 0.1989\n",
            "Epoch 95: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5692, Test Linf Norm: 0.1988\n",
            "Epoch 96: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5712, Test Linf Norm: 0.1988\n",
            "Epoch 97: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5685, Test Linf Norm: 0.1988\n",
            "Epoch 98: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5691, Test Linf Norm: 0.1988\n",
            "Epoch 99: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5720, Test Linf Norm: 0.1988\n",
            "Epoch 100: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5669, Test Linf Norm: 0.1988\n",
            "Epoch 101: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5723, Test Linf Norm: 0.1988\n",
            "Epoch 102: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5694, Test Linf Norm: 0.1988\n",
            "Epoch 103: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5707, Test Linf Norm: 0.1988\n",
            "Epoch 104: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5697, Test Linf Norm: 0.1988\n",
            "Epoch 105: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5647, Test Linf Norm: 0.1988\n",
            "Epoch 106: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5663, Test Linf Norm: 0.1988\n",
            "Epoch 107: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0125, Test L1 Norm: 0.0066, Train Linf Norm: 0.5679, Test Linf Norm: 0.1988\n",
            "Epoch 108: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5688, Test Linf Norm: 0.1988\n",
            "Epoch 109: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5720, Test Linf Norm: 0.1988\n",
            "Epoch 110: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5687, Test Linf Norm: 0.1988\n",
            "Epoch 111: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5663, Test Linf Norm: 0.1988\n",
            "Epoch 112: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5713, Test Linf Norm: 0.1988\n",
            "Epoch 113: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5684, Test Linf Norm: 0.1988\n",
            "Epoch 114: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5584, Test Linf Norm: 0.1988\n",
            "Epoch 115: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5671, Test Linf Norm: 0.1988\n",
            "Epoch 116: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5630, Test Linf Norm: 0.1988\n",
            "Epoch 117: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5690, Test Linf Norm: 0.1988\n",
            "Epoch 118: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5708, Test Linf Norm: 0.1988\n",
            "Epoch 119: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5678, Test Linf Norm: 0.1988\n",
            "Epoch 120: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5671, Test Linf Norm: 0.1988\n",
            "Epoch 121: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5690, Test Linf Norm: 0.1988\n",
            "Epoch 122: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5668, Test Linf Norm: 0.1988\n",
            "Epoch 123: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5726, Test Linf Norm: 0.1988\n",
            "Epoch 124: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5677, Test Linf Norm: 0.1988\n",
            "Epoch 125: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5681, Test Linf Norm: 0.1988\n",
            "Epoch 126: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5717, Test Linf Norm: 0.1988\n",
            "Epoch 127: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5682, Test Linf Norm: 0.1988\n",
            "Epoch 128: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5692, Test Linf Norm: 0.1988\n",
            "Epoch 129: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5652, Test Linf Norm: 0.1988\n",
            "Epoch 130: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5671, Test Linf Norm: 0.1988\n",
            "Epoch 131: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5599, Test Linf Norm: 0.1988\n",
            "Epoch 132: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5680, Test Linf Norm: 0.1988\n",
            "Epoch 133: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5713, Test Linf Norm: 0.1988\n",
            "Epoch 134: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5637, Test Linf Norm: 0.1988\n",
            "Epoch 135: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5668, Test Linf Norm: 0.1988\n",
            "Epoch 136: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5638, Test Linf Norm: 0.1988\n",
            "Epoch 137: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5613, Test Linf Norm: 0.1988\n",
            "Epoch 138: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5680, Test Linf Norm: 0.1988\n",
            "Epoch 139: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5643, Test Linf Norm: 0.1988\n",
            "Epoch 140: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5667, Test Linf Norm: 0.1988\n",
            "Epoch 141: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5712, Test Linf Norm: 0.1988\n",
            "Epoch 142: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5686, Test Linf Norm: 0.1988\n",
            "Epoch 143: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5612, Test Linf Norm: 0.1988\n",
            "Epoch 144: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5657, Test Linf Norm: 0.1988\n",
            "Epoch 145: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5708, Test Linf Norm: 0.1988\n",
            "Epoch 146: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5615, Test Linf Norm: 0.1988\n",
            "Epoch 147: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5683, Test Linf Norm: 0.1988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 13:59:39,265]\u001b[0m Trial 78 finished with value: 0.006615368639677763 and parameters: {'n_layers': 3, 'n_units_0': 1006, 'n_units_1': 627, 'n_units_2': 294, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0012662116839385774, 'batch_size': 64, 'n_epochs': 148, 'scheduler': 'StepLR', 'weight_decay': 0.0031231593588057216, 'beta1': 0.9969707451935885, 'beta2': 0.9995471670310562, 'step_size': 11, 'gamma': 0.22255014303485787}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 148: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0124, Test L1 Norm: 0.0066, Train Linf Norm: 0.5638, Test Linf Norm: 0.1988\n",
            "Epoch 1: Train Loss: 0.2020, Test Loss: 0.0419, Train L1 Norm: 0.3609, Test L1 Norm: 0.0352, Train Linf Norm: 16.3228, Test Linf Norm: 0.9533\n",
            "Epoch 2: Train Loss: 0.0275, Test Loss: 0.0267, Train L1 Norm: 0.0473, Test L1 Norm: 0.0224, Train Linf Norm: 2.0336, Test Linf Norm: 0.6215\n",
            "Epoch 3: Train Loss: 0.0257, Test Loss: 0.0271, Train L1 Norm: 0.0728, Test L1 Norm: 0.0208, Train Linf Norm: 3.7699, Test Linf Norm: 0.5232\n",
            "Epoch 4: Train Loss: 0.0241, Test Loss: 0.0213, Train L1 Norm: 0.0364, Test L1 Norm: 0.0192, Train Linf Norm: 1.5428, Test Linf Norm: 0.5466\n",
            "Epoch 5: Train Loss: 0.0286, Test Loss: 0.0169, Train L1 Norm: 0.0737, Test L1 Norm: 0.0180, Train Linf Norm: 3.7852, Test Linf Norm: 0.5814\n",
            "Epoch 6: Train Loss: 0.0324, Test Loss: 0.0333, Train L1 Norm: 0.0693, Test L1 Norm: 0.0208, Train Linf Norm: 3.4533, Test Linf Norm: 0.4598\n",
            "Epoch 7: Train Loss: 0.0301, Test Loss: 0.0218, Train L1 Norm: 0.0663, Test L1 Norm: 0.0167, Train Linf Norm: 3.2842, Test Linf Norm: 0.4432\n",
            "Epoch 8: Train Loss: 0.0205, Test Loss: 0.0238, Train L1 Norm: 0.0750, Test L1 Norm: 0.0248, Train Linf Norm: 4.1328, Test Linf Norm: 0.7721\n",
            "Epoch 9: Train Loss: 0.0253, Test Loss: 0.0352, Train L1 Norm: 0.0861, Test L1 Norm: 0.0229, Train Linf Norm: 4.7290, Test Linf Norm: 0.5835\n",
            "Epoch 10: Train Loss: 0.0288, Test Loss: 0.0311, Train L1 Norm: 0.0361, Test L1 Norm: 0.0234, Train Linf Norm: 1.4485, Test Linf Norm: 0.6112\n",
            "Epoch 11: Train Loss: 0.0262, Test Loss: 0.0465, Train L1 Norm: 0.0415, Test L1 Norm: 0.0331, Train Linf Norm: 1.8056, Test Linf Norm: 0.7862\n",
            "Epoch 12: Train Loss: 0.0264, Test Loss: 0.0163, Train L1 Norm: 0.0453, Test L1 Norm: 0.0176, Train Linf Norm: 2.1145, Test Linf Norm: 0.6177\n",
            "Epoch 13: Train Loss: 0.0137, Test Loss: 0.0103, Train L1 Norm: 0.0369, Test L1 Norm: 0.0119, Train Linf Norm: 1.9059, Test Linf Norm: 0.4195\n",
            "Epoch 14: Train Loss: 0.0111, Test Loss: 0.0139, Train L1 Norm: 0.0278, Test L1 Norm: 0.0121, Train Linf Norm: 1.3807, Test Linf Norm: 0.4005\n",
            "Epoch 15: Train Loss: 0.0126, Test Loss: 0.0128, Train L1 Norm: 0.0294, Test L1 Norm: 0.0140, Train Linf Norm: 1.4670, Test Linf Norm: 0.4715\n",
            "Epoch 16: Train Loss: 0.0129, Test Loss: 0.0152, Train L1 Norm: 0.0262, Test L1 Norm: 0.0176, Train Linf Norm: 1.2512, Test Linf Norm: 0.4886\n",
            "Epoch 17: Train Loss: 0.0162, Test Loss: 0.0142, Train L1 Norm: 0.0410, Test L1 Norm: 0.0128, Train Linf Norm: 2.0937, Test Linf Norm: 0.4092\n",
            "Epoch 18: Train Loss: 0.0120, Test Loss: 0.0106, Train L1 Norm: 0.0373, Test L1 Norm: 0.0115, Train Linf Norm: 1.9855, Test Linf Norm: 0.3892\n",
            "Epoch 19: Train Loss: 0.0120, Test Loss: 0.0120, Train L1 Norm: 0.0283, Test L1 Norm: 0.0109, Train Linf Norm: 1.4291, Test Linf Norm: 0.3502\n",
            "Epoch 20: Train Loss: 0.0117, Test Loss: 0.0139, Train L1 Norm: 0.0193, Test L1 Norm: 0.0103, Train Linf Norm: 0.8494, Test Linf Norm: 0.2937\n",
            "Epoch 21: Train Loss: 0.0164, Test Loss: 0.0129, Train L1 Norm: 0.0346, Test L1 Norm: 0.0185, Train Linf Norm: 1.7179, Test Linf Norm: 0.6740\n",
            "Epoch 22: Train Loss: 0.0111, Test Loss: 0.0133, Train L1 Norm: 0.0236, Test L1 Norm: 0.0124, Train Linf Norm: 1.1069, Test Linf Norm: 0.3880\n",
            "Epoch 23: Train Loss: 0.0097, Test Loss: 0.0080, Train L1 Norm: 0.0192, Test L1 Norm: 0.0078, Train Linf Norm: 0.9128, Test Linf Norm: 0.2507\n",
            "Epoch 24: Train Loss: 0.0079, Test Loss: 0.0083, Train L1 Norm: 0.0250, Test L1 Norm: 0.0082, Train Linf Norm: 1.3229, Test Linf Norm: 0.2748\n",
            "Epoch 25: Train Loss: 0.0078, Test Loss: 0.0078, Train L1 Norm: 0.0119, Test L1 Norm: 0.0081, Train Linf Norm: 0.5043, Test Linf Norm: 0.2668\n",
            "Epoch 26: Train Loss: 0.0085, Test Loss: 0.0084, Train L1 Norm: 0.0170, Test L1 Norm: 0.0094, Train Linf Norm: 0.8028, Test Linf Norm: 0.3236\n",
            "Epoch 27: Train Loss: 0.0085, Test Loss: 0.0106, Train L1 Norm: 0.0153, Test L1 Norm: 0.0088, Train Linf Norm: 0.7001, Test Linf Norm: 0.2763\n",
            "Epoch 28: Train Loss: 0.0081, Test Loss: 0.0085, Train L1 Norm: 0.0131, Test L1 Norm: 0.0077, Train Linf Norm: 0.5798, Test Linf Norm: 0.2289\n",
            "Epoch 29: Train Loss: 0.0111, Test Loss: 0.0097, Train L1 Norm: 0.0170, Test L1 Norm: 0.0088, Train Linf Norm: 0.7654, Test Linf Norm: 0.2976\n",
            "Epoch 30: Train Loss: 0.0078, Test Loss: 0.0072, Train L1 Norm: 0.0128, Test L1 Norm: 0.0073, Train Linf Norm: 0.5548, Test Linf Norm: 0.2450\n",
            "Epoch 31: Train Loss: 0.0078, Test Loss: 0.0084, Train L1 Norm: 0.0201, Test L1 Norm: 0.0081, Train Linf Norm: 1.0320, Test Linf Norm: 0.2360\n",
            "Epoch 32: Train Loss: 0.0080, Test Loss: 0.0077, Train L1 Norm: 0.0122, Test L1 Norm: 0.0071, Train Linf Norm: 0.5187, Test Linf Norm: 0.2120\n",
            "Epoch 33: Train Loss: 0.0080, Test Loss: 0.0074, Train L1 Norm: 0.0149, Test L1 Norm: 0.0080, Train Linf Norm: 0.6934, Test Linf Norm: 0.2796\n",
            "Epoch 34: Train Loss: 0.0068, Test Loss: 0.0067, Train L1 Norm: 0.0165, Test L1 Norm: 0.0071, Train Linf Norm: 0.8267, Test Linf Norm: 0.2484\n",
            "Epoch 35: Train Loss: 0.0067, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0066, Train Linf Norm: 0.4914, Test Linf Norm: 0.2171\n",
            "Epoch 36: Train Loss: 0.0065, Test Loss: 0.0066, Train L1 Norm: 0.0133, Test L1 Norm: 0.0067, Train Linf Norm: 0.6290, Test Linf Norm: 0.2274\n",
            "Epoch 37: Train Loss: 0.0065, Test Loss: 0.0065, Train L1 Norm: 0.0143, Test L1 Norm: 0.0070, Train Linf Norm: 0.6966, Test Linf Norm: 0.2427\n",
            "Epoch 38: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0122, Test L1 Norm: 0.0067, Train Linf Norm: 0.5620, Test Linf Norm: 0.2265\n",
            "Epoch 39: Train Loss: 0.0066, Test Loss: 0.0068, Train L1 Norm: 0.0163, Test L1 Norm: 0.0063, Train Linf Norm: 0.8239, Test Linf Norm: 0.2027\n",
            "Epoch 40: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0153, Test L1 Norm: 0.0065, Train Linf Norm: 0.7595, Test Linf Norm: 0.2160\n",
            "Epoch 41: Train Loss: 0.0065, Test Loss: 0.0076, Train L1 Norm: 0.0133, Test L1 Norm: 0.0070, Train Linf Norm: 0.6345, Test Linf Norm: 0.2310\n",
            "Epoch 42: Train Loss: 0.0067, Test Loss: 0.0068, Train L1 Norm: 0.0140, Test L1 Norm: 0.0069, Train Linf Norm: 0.6749, Test Linf Norm: 0.2305\n",
            "Epoch 43: Train Loss: 0.0069, Test Loss: 0.0070, Train L1 Norm: 0.0133, Test L1 Norm: 0.0065, Train Linf Norm: 0.6286, Test Linf Norm: 0.2055\n",
            "Epoch 44: Train Loss: 0.0065, Test Loss: 0.0065, Train L1 Norm: 0.0118, Test L1 Norm: 0.0066, Train Linf Norm: 0.5424, Test Linf Norm: 0.2247\n",
            "Epoch 45: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0115, Test L1 Norm: 0.0063, Train Linf Norm: 0.5303, Test Linf Norm: 0.2087\n",
            "Epoch 46: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0127, Test L1 Norm: 0.0065, Train Linf Norm: 0.6127, Test Linf Norm: 0.2190\n",
            "Epoch 47: Train Loss: 0.0061, Test Loss: 0.0066, Train L1 Norm: 0.0119, Test L1 Norm: 0.0070, Train Linf Norm: 0.5527, Test Linf Norm: 0.2375\n",
            "Epoch 48: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0126, Test L1 Norm: 0.0063, Train Linf Norm: 0.6025, Test Linf Norm: 0.2113\n",
            "Epoch 49: Train Loss: 0.0062, Test Loss: 0.0066, Train L1 Norm: 0.0127, Test L1 Norm: 0.0067, Train Linf Norm: 0.6093, Test Linf Norm: 0.2245\n",
            "Epoch 50: Train Loss: 0.0064, Test Loss: 0.0064, Train L1 Norm: 0.0131, Test L1 Norm: 0.0063, Train Linf Norm: 0.6323, Test Linf Norm: 0.2041\n",
            "Epoch 51: Train Loss: 0.0062, Test Loss: 0.0066, Train L1 Norm: 0.0134, Test L1 Norm: 0.0063, Train Linf Norm: 0.6495, Test Linf Norm: 0.2085\n",
            "Epoch 52: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0118, Test L1 Norm: 0.0062, Train Linf Norm: 0.5566, Test Linf Norm: 0.2062\n",
            "Epoch 53: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0118, Test L1 Norm: 0.0062, Train Linf Norm: 0.5480, Test Linf Norm: 0.2021\n",
            "Epoch 54: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0115, Test L1 Norm: 0.0064, Train Linf Norm: 0.5280, Test Linf Norm: 0.2140\n",
            "Epoch 55: Train Loss: 0.0062, Test Loss: 0.0065, Train L1 Norm: 0.0122, Test L1 Norm: 0.0062, Train Linf Norm: 0.5743, Test Linf Norm: 0.2036\n",
            "Epoch 56: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0118, Test L1 Norm: 0.0062, Train Linf Norm: 0.5541, Test Linf Norm: 0.2033\n",
            "Epoch 57: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0122, Test L1 Norm: 0.0062, Train Linf Norm: 0.5804, Test Linf Norm: 0.2078\n",
            "Epoch 58: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0121, Test L1 Norm: 0.0062, Train Linf Norm: 0.5732, Test Linf Norm: 0.2064\n",
            "Epoch 59: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0118, Test L1 Norm: 0.0063, Train Linf Norm: 0.5535, Test Linf Norm: 0.2084\n",
            "Epoch 60: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0119, Test L1 Norm: 0.0062, Train Linf Norm: 0.5617, Test Linf Norm: 0.2074\n",
            "Epoch 61: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0113, Test L1 Norm: 0.0061, Train Linf Norm: 0.5234, Test Linf Norm: 0.2025\n",
            "Epoch 62: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5404, Test Linf Norm: 0.2020\n",
            "Epoch 63: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0117, Test L1 Norm: 0.0061, Train Linf Norm: 0.5451, Test Linf Norm: 0.1997\n",
            "Epoch 64: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0120, Test L1 Norm: 0.0062, Train Linf Norm: 0.5673, Test Linf Norm: 0.2067\n",
            "Epoch 65: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0112, Test L1 Norm: 0.0061, Train Linf Norm: 0.5139, Test Linf Norm: 0.2019\n",
            "Epoch 66: Train Loss: 0.0060, Test Loss: 0.0063, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5439, Test Linf Norm: 0.2031\n",
            "Epoch 67: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0118, Test L1 Norm: 0.0062, Train Linf Norm: 0.5561, Test Linf Norm: 0.2045\n",
            "Epoch 68: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0115, Test L1 Norm: 0.0062, Train Linf Norm: 0.5379, Test Linf Norm: 0.2040\n",
            "Epoch 69: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0061, Train Linf Norm: 0.5492, Test Linf Norm: 0.2033\n",
            "Epoch 70: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0118, Test L1 Norm: 0.0062, Train Linf Norm: 0.5544, Test Linf Norm: 0.2041\n",
            "Epoch 71: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0062, Train Linf Norm: 0.5544, Test Linf Norm: 0.2041\n",
            "Epoch 72: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0115, Test L1 Norm: 0.0061, Train Linf Norm: 0.5316, Test Linf Norm: 0.2032\n",
            "Epoch 73: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0119, Test L1 Norm: 0.0062, Train Linf Norm: 0.5601, Test Linf Norm: 0.2040\n",
            "Epoch 74: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0062, Train Linf Norm: 0.5395, Test Linf Norm: 0.2042\n",
            "Epoch 75: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0062, Train Linf Norm: 0.5514, Test Linf Norm: 0.2041\n",
            "Epoch 76: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5467, Test Linf Norm: 0.2034\n",
            "Epoch 77: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0118, Test L1 Norm: 0.0062, Train Linf Norm: 0.5590, Test Linf Norm: 0.2052\n",
            "Epoch 78: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0118, Test L1 Norm: 0.0062, Train Linf Norm: 0.5582, Test Linf Norm: 0.2043\n",
            "Epoch 79: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0061, Train Linf Norm: 0.5478, Test Linf Norm: 0.2034\n",
            "Epoch 80: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0062, Train Linf Norm: 0.5484, Test Linf Norm: 0.2037\n",
            "Epoch 81: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0062, Train Linf Norm: 0.5477, Test Linf Norm: 0.2037\n",
            "Epoch 82: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5445, Test Linf Norm: 0.2033\n",
            "Epoch 83: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0061, Train Linf Norm: 0.5500, Test Linf Norm: 0.2031\n",
            "Epoch 84: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0062, Train Linf Norm: 0.5416, Test Linf Norm: 0.2038\n",
            "Epoch 85: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0061, Train Linf Norm: 0.5478, Test Linf Norm: 0.2034\n",
            "Epoch 86: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5444, Test Linf Norm: 0.2033\n",
            "Epoch 87: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0061, Train Linf Norm: 0.5460, Test Linf Norm: 0.2033\n",
            "Epoch 88: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5380, Test Linf Norm: 0.2034\n",
            "Epoch 89: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5376, Test Linf Norm: 0.2034\n",
            "Epoch 90: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5440, Test Linf Norm: 0.2033\n",
            "Epoch 91: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5496, Test Linf Norm: 0.2034\n",
            "Epoch 92: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5486, Test Linf Norm: 0.2034\n",
            "Epoch 93: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5464, Test Linf Norm: 0.2034\n",
            "Epoch 94: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0061, Train Linf Norm: 0.5449, Test Linf Norm: 0.2035\n",
            "Epoch 95: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5505, Test Linf Norm: 0.2034\n",
            "Epoch 96: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0117, Test L1 Norm: 0.0061, Train Linf Norm: 0.5508, Test Linf Norm: 0.2034\n",
            "Epoch 97: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5453, Test Linf Norm: 0.2034\n",
            "Epoch 98: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5454, Test Linf Norm: 0.2034\n",
            "Epoch 99: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5390, Test Linf Norm: 0.2034\n",
            "Epoch 100: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5430, Test Linf Norm: 0.2034\n",
            "Epoch 101: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5457, Test Linf Norm: 0.2034\n",
            "Epoch 102: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5514, Test Linf Norm: 0.2034\n",
            "Epoch 103: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5439, Test Linf Norm: 0.2034\n",
            "Epoch 104: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5474, Test Linf Norm: 0.2034\n",
            "Epoch 105: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5484, Test Linf Norm: 0.2034\n",
            "Epoch 106: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5475, Test Linf Norm: 0.2034\n",
            "Epoch 107: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5473, Test Linf Norm: 0.2034\n",
            "Epoch 108: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5464, Test Linf Norm: 0.2034\n",
            "Epoch 109: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5474, Test Linf Norm: 0.2034\n",
            "Epoch 110: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5486, Test Linf Norm: 0.2034\n",
            "Epoch 111: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5418, Test Linf Norm: 0.2034\n",
            "Epoch 112: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5444, Test Linf Norm: 0.2034\n",
            "Epoch 113: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5462, Test Linf Norm: 0.2034\n",
            "Epoch 114: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5462, Test Linf Norm: 0.2034\n",
            "Epoch 115: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5486, Test Linf Norm: 0.2034\n",
            "Epoch 116: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5463, Test Linf Norm: 0.2034\n",
            "Epoch 117: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5465, Test Linf Norm: 0.2034\n",
            "Epoch 118: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5476, Test Linf Norm: 0.2034\n",
            "Epoch 119: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5448, Test Linf Norm: 0.2034\n",
            "Epoch 120: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5399, Test Linf Norm: 0.2034\n",
            "Epoch 121: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5454, Test Linf Norm: 0.2034\n",
            "Epoch 122: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5471, Test Linf Norm: 0.2034\n",
            "Epoch 123: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5489, Test Linf Norm: 0.2034\n",
            "Epoch 124: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5459, Test Linf Norm: 0.2034\n",
            "Epoch 125: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5443, Test Linf Norm: 0.2034\n",
            "Epoch 126: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5413, Test Linf Norm: 0.2034\n",
            "Epoch 127: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5496, Test Linf Norm: 0.2034\n",
            "Epoch 128: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5467, Test Linf Norm: 0.2034\n",
            "Epoch 129: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5510, Test Linf Norm: 0.2034\n",
            "Epoch 130: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5480, Test Linf Norm: 0.2034\n",
            "Epoch 131: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5469, Test Linf Norm: 0.2034\n",
            "Epoch 132: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5494, Test Linf Norm: 0.2034\n",
            "Epoch 133: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5439, Test Linf Norm: 0.2034\n",
            "Epoch 134: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5447, Test Linf Norm: 0.2034\n",
            "Epoch 135: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5457, Test Linf Norm: 0.2034\n",
            "Epoch 136: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5506, Test Linf Norm: 0.2034\n",
            "Epoch 137: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5442, Test Linf Norm: 0.2034\n",
            "Epoch 138: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5488, Test Linf Norm: 0.2034\n",
            "Epoch 139: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5462, Test Linf Norm: 0.2034\n",
            "Epoch 140: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5446, Test Linf Norm: 0.2034\n",
            "Epoch 141: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5467, Test Linf Norm: 0.2034\n",
            "Epoch 142: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5465, Test Linf Norm: 0.2034\n",
            "Epoch 143: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5493, Test Linf Norm: 0.2034\n",
            "Epoch 144: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5494, Test Linf Norm: 0.2034\n",
            "Epoch 145: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5410, Test Linf Norm: 0.2034\n",
            "Epoch 146: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5475, Test Linf Norm: 0.2034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:07:33,515]\u001b[0m Trial 79 finished with value: 0.006148638860136271 and parameters: {'n_layers': 2, 'n_units_0': 996, 'n_units_1': 795, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0012076549318604508, 'batch_size': 64, 'n_epochs': 147, 'scheduler': 'StepLR', 'weight_decay': 0.002831958497488261, 'beta1': 0.9981559725027322, 'beta2': 0.9995332162329172, 'step_size': 11, 'gamma': 0.22109178200342477}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 147: Train Loss: 0.0060, Test Loss: 0.0062, Train L1 Norm: 0.0116, Test L1 Norm: 0.0061, Train Linf Norm: 0.5454, Test Linf Norm: 0.2034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:07:36,730]\u001b[0m Trial 80 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.7968, Test Loss: 0.2059, Train L1 Norm: 1.0619, Test L1 Norm: 0.1571, Train Linf Norm: 45.7479, Test Linf Norm: 3.7184\n",
            "Epoch 1: Train Loss: 0.1937, Test Loss: 0.0299, Train L1 Norm: 0.3937, Test L1 Norm: 0.0388, Train Linf Norm: 18.3350, Test Linf Norm: 1.3555\n",
            "Epoch 2: Train Loss: 0.0314, Test Loss: 0.0257, Train L1 Norm: 0.0593, Test L1 Norm: 0.0256, Train Linf Norm: 2.6521, Test Linf Norm: 0.7808\n",
            "Epoch 3: Train Loss: 0.0309, Test Loss: 0.0387, Train L1 Norm: 0.0875, Test L1 Norm: 0.0277, Train Linf Norm: 4.5135, Test Linf Norm: 0.7201\n",
            "Epoch 4: Train Loss: 0.0287, Test Loss: 0.0330, Train L1 Norm: 0.0616, Test L1 Norm: 0.0236, Train Linf Norm: 3.0113, Test Linf Norm: 0.5971\n",
            "Epoch 5: Train Loss: 0.0322, Test Loss: 0.0215, Train L1 Norm: 0.0393, Test L1 Norm: 0.0282, Train Linf Norm: 1.4870, Test Linf Norm: 0.9776\n",
            "Epoch 6: Train Loss: 0.0266, Test Loss: 0.0386, Train L1 Norm: 0.0673, Test L1 Norm: 0.0267, Train Linf Norm: 3.4677, Test Linf Norm: 0.7184\n",
            "Epoch 7: Train Loss: 0.0334, Test Loss: 0.0181, Train L1 Norm: 0.0585, Test L1 Norm: 0.0196, Train Linf Norm: 2.6664, Test Linf Norm: 0.6821\n",
            "Epoch 8: Train Loss: 0.0302, Test Loss: 0.0205, Train L1 Norm: 0.0721, Test L1 Norm: 0.0287, Train Linf Norm: 3.5924, Test Linf Norm: 1.1261\n",
            "Epoch 9: Train Loss: 0.0270, Test Loss: 0.0390, Train L1 Norm: 0.0645, Test L1 Norm: 0.0239, Train Linf Norm: 3.2728, Test Linf Norm: 0.5023\n",
            "Epoch 10: Train Loss: 0.0324, Test Loss: 0.0200, Train L1 Norm: 0.0417, Test L1 Norm: 0.0182, Train Linf Norm: 1.6228, Test Linf Norm: 0.5597\n",
            "Epoch 11: Train Loss: 0.0330, Test Loss: 0.0163, Train L1 Norm: 0.0612, Test L1 Norm: 0.0199, Train Linf Norm: 2.9077, Test Linf Norm: 0.7110\n",
            "Epoch 12: Train Loss: 0.0153, Test Loss: 0.0136, Train L1 Norm: 0.0269, Test L1 Norm: 0.0159, Train Linf Norm: 1.1830, Test Linf Norm: 0.5808\n",
            "Epoch 13: Train Loss: 0.0227, Test Loss: 0.0175, Train L1 Norm: 0.0302, Test L1 Norm: 0.0190, Train Linf Norm: 1.2578, Test Linf Norm: 0.6442\n",
            "Epoch 14: Train Loss: 0.0171, Test Loss: 0.0173, Train L1 Norm: 0.0441, Test L1 Norm: 0.0178, Train Linf Norm: 2.2724, Test Linf Norm: 0.5967\n",
            "Epoch 15: Train Loss: 0.0164, Test Loss: 0.0166, Train L1 Norm: 0.0519, Test L1 Norm: 0.0144, Train Linf Norm: 2.7949, Test Linf Norm: 0.4530\n",
            "Epoch 16: Train Loss: 0.0144, Test Loss: 0.0125, Train L1 Norm: 0.0383, Test L1 Norm: 0.0123, Train Linf Norm: 1.9380, Test Linf Norm: 0.3804\n",
            "Epoch 17: Train Loss: 0.0141, Test Loss: 0.0130, Train L1 Norm: 0.0360, Test L1 Norm: 0.0124, Train Linf Norm: 1.8260, Test Linf Norm: 0.3397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:08:33,642]\u001b[0m Trial 81 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss: 0.0188, Test Loss: 0.0144, Train L1 Norm: 0.0504, Test L1 Norm: 0.0122, Train Linf Norm: 2.6397, Test Linf Norm: 0.3698\n",
            "Epoch 1: Train Loss: 0.1271, Test Loss: 0.0252, Train L1 Norm: 0.3145, Test L1 Norm: 0.0292, Train Linf Norm: 15.4664, Test Linf Norm: 0.9690\n",
            "Epoch 2: Train Loss: 0.0377, Test Loss: 0.0546, Train L1 Norm: 0.1047, Test L1 Norm: 0.0321, Train Linf Norm: 5.4108, Test Linf Norm: 0.8175\n",
            "Epoch 3: Train Loss: 0.0409, Test Loss: 0.0386, Train L1 Norm: 0.0794, Test L1 Norm: 0.0326, Train Linf Norm: 3.8050, Test Linf Norm: 1.0849\n",
            "Epoch 4: Train Loss: 0.0310, Test Loss: 0.0534, Train L1 Norm: 0.0685, Test L1 Norm: 0.0307, Train Linf Norm: 3.4056, Test Linf Norm: 0.7691\n",
            "Epoch 5: Train Loss: 0.0299, Test Loss: 0.0238, Train L1 Norm: 0.0744, Test L1 Norm: 0.0255, Train Linf Norm: 3.7861, Test Linf Norm: 0.8919\n",
            "Epoch 6: Train Loss: 0.0319, Test Loss: 0.0246, Train L1 Norm: 0.0743, Test L1 Norm: 0.0202, Train Linf Norm: 3.8071, Test Linf Norm: 0.5844\n",
            "Epoch 7: Train Loss: 0.0269, Test Loss: 0.0250, Train L1 Norm: 0.0513, Test L1 Norm: 0.0198, Train Linf Norm: 2.4561, Test Linf Norm: 0.5519\n",
            "Epoch 8: Train Loss: 0.0218, Test Loss: 0.0211, Train L1 Norm: 0.0426, Test L1 Norm: 0.0166, Train Linf Norm: 2.0269, Test Linf Norm: 0.4558\n",
            "Epoch 9: Train Loss: 0.0255, Test Loss: 0.0214, Train L1 Norm: 0.0486, Test L1 Norm: 0.0174, Train Linf Norm: 2.2963, Test Linf Norm: 0.4418\n",
            "Epoch 10: Train Loss: 0.0299, Test Loss: 0.0194, Train L1 Norm: 0.0576, Test L1 Norm: 0.0250, Train Linf Norm: 2.7726, Test Linf Norm: 0.8335\n",
            "Epoch 11: Train Loss: 0.0152, Test Loss: 0.0109, Train L1 Norm: 0.0229, Test L1 Norm: 0.0127, Train Linf Norm: 0.9701, Test Linf Norm: 0.4415\n",
            "Epoch 12: Train Loss: 0.0125, Test Loss: 0.0107, Train L1 Norm: 0.0277, Test L1 Norm: 0.0104, Train Linf Norm: 1.3581, Test Linf Norm: 0.3282\n",
            "Epoch 13: Train Loss: 0.0183, Test Loss: 0.0183, Train L1 Norm: 0.0276, Test L1 Norm: 0.0141, Train Linf Norm: 1.2270, Test Linf Norm: 0.4090\n",
            "Epoch 14: Train Loss: 0.0160, Test Loss: 0.0108, Train L1 Norm: 0.0240, Test L1 Norm: 0.0097, Train Linf Norm: 1.0443, Test Linf Norm: 0.3012\n",
            "Epoch 15: Train Loss: 0.0114, Test Loss: 0.0104, Train L1 Norm: 0.0261, Test L1 Norm: 0.0099, Train Linf Norm: 1.3139, Test Linf Norm: 0.3379\n",
            "Epoch 16: Train Loss: 0.0107, Test Loss: 0.0094, Train L1 Norm: 0.0169, Test L1 Norm: 0.0113, Train Linf Norm: 0.7261, Test Linf Norm: 0.4128\n",
            "Epoch 17: Train Loss: 0.0122, Test Loss: 0.0178, Train L1 Norm: 0.0175, Test L1 Norm: 0.0105, Train Linf Norm: 0.7367, Test Linf Norm: 0.2555\n",
            "Epoch 18: Train Loss: 0.0134, Test Loss: 0.0102, Train L1 Norm: 0.0217, Test L1 Norm: 0.0090, Train Linf Norm: 0.9637, Test Linf Norm: 0.2681\n",
            "Epoch 19: Train Loss: 0.0132, Test Loss: 0.0143, Train L1 Norm: 0.0267, Test L1 Norm: 0.0116, Train Linf Norm: 1.3075, Test Linf Norm: 0.2955\n",
            "Epoch 20: Train Loss: 0.0113, Test Loss: 0.0097, Train L1 Norm: 0.0210, Test L1 Norm: 0.0097, Train Linf Norm: 0.9826, Test Linf Norm: 0.3053\n",
            "Epoch 21: Train Loss: 0.0084, Test Loss: 0.0103, Train L1 Norm: 0.0133, Test L1 Norm: 0.0086, Train Linf Norm: 0.5717, Test Linf Norm: 0.2602\n",
            "Epoch 22: Train Loss: 0.0092, Test Loss: 0.0101, Train L1 Norm: 0.0159, Test L1 Norm: 0.0099, Train Linf Norm: 0.7329, Test Linf Norm: 0.3233\n",
            "Epoch 23: Train Loss: 0.0081, Test Loss: 0.0077, Train L1 Norm: 0.0177, Test L1 Norm: 0.0077, Train Linf Norm: 0.8690, Test Linf Norm: 0.2423\n",
            "Epoch 24: Train Loss: 0.0083, Test Loss: 0.0077, Train L1 Norm: 0.0190, Test L1 Norm: 0.0074, Train Linf Norm: 0.9472, Test Linf Norm: 0.2342\n",
            "Epoch 25: Train Loss: 0.0090, Test Loss: 0.0098, Train L1 Norm: 0.0210, Test L1 Norm: 0.0074, Train Linf Norm: 1.0543, Test Linf Norm: 0.2001\n",
            "Epoch 26: Train Loss: 0.0081, Test Loss: 0.0080, Train L1 Norm: 0.0189, Test L1 Norm: 0.0076, Train Linf Norm: 0.9471, Test Linf Norm: 0.2391\n",
            "Epoch 27: Train Loss: 0.0075, Test Loss: 0.0086, Train L1 Norm: 0.0132, Test L1 Norm: 0.0075, Train Linf Norm: 0.5958, Test Linf Norm: 0.2334\n",
            "Epoch 28: Train Loss: 0.0082, Test Loss: 0.0094, Train L1 Norm: 0.0163, Test L1 Norm: 0.0076, Train Linf Norm: 0.7760, Test Linf Norm: 0.2255\n",
            "Epoch 29: Train Loss: 0.0077, Test Loss: 0.0074, Train L1 Norm: 0.0182, Test L1 Norm: 0.0080, Train Linf Norm: 0.9144, Test Linf Norm: 0.2715\n",
            "Epoch 30: Train Loss: 0.0076, Test Loss: 0.0074, Train L1 Norm: 0.0176, Test L1 Norm: 0.0074, Train Linf Norm: 0.8805, Test Linf Norm: 0.2481\n",
            "Epoch 31: Train Loss: 0.0070, Test Loss: 0.0071, Train L1 Norm: 0.0127, Test L1 Norm: 0.0068, Train Linf Norm: 0.5854, Test Linf Norm: 0.2185\n",
            "Epoch 32: Train Loss: 0.0071, Test Loss: 0.0072, Train L1 Norm: 0.0154, Test L1 Norm: 0.0068, Train Linf Norm: 0.7573, Test Linf Norm: 0.2099\n",
            "Epoch 33: Train Loss: 0.0069, Test Loss: 0.0075, Train L1 Norm: 0.0141, Test L1 Norm: 0.0069, Train Linf Norm: 0.6765, Test Linf Norm: 0.2218\n",
            "Epoch 34: Train Loss: 0.0069, Test Loss: 0.0070, Train L1 Norm: 0.0142, Test L1 Norm: 0.0068, Train Linf Norm: 0.6826, Test Linf Norm: 0.2210\n",
            "Epoch 35: Train Loss: 0.0071, Test Loss: 0.0074, Train L1 Norm: 0.0149, Test L1 Norm: 0.0070, Train Linf Norm: 0.7202, Test Linf Norm: 0.2214\n",
            "Epoch 36: Train Loss: 0.0072, Test Loss: 0.0072, Train L1 Norm: 0.0126, Test L1 Norm: 0.0068, Train Linf Norm: 0.5747, Test Linf Norm: 0.2151\n",
            "Epoch 37: Train Loss: 0.0069, Test Loss: 0.0071, Train L1 Norm: 0.0155, Test L1 Norm: 0.0069, Train Linf Norm: 0.7713, Test Linf Norm: 0.2245\n",
            "Epoch 38: Train Loss: 0.0069, Test Loss: 0.0074, Train L1 Norm: 0.0114, Test L1 Norm: 0.0067, Train Linf Norm: 0.5126, Test Linf Norm: 0.2089\n",
            "Epoch 39: Train Loss: 0.0069, Test Loss: 0.0075, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4858, Test Linf Norm: 0.1881\n",
            "Epoch 40: Train Loss: 0.0069, Test Loss: 0.0069, Train L1 Norm: 0.0129, Test L1 Norm: 0.0068, Train Linf Norm: 0.6043, Test Linf Norm: 0.2197\n",
            "Epoch 41: Train Loss: 0.0066, Test Loss: 0.0072, Train L1 Norm: 0.0121, Test L1 Norm: 0.0065, Train Linf Norm: 0.5622, Test Linf Norm: 0.1989\n",
            "Epoch 42: Train Loss: 0.0066, Test Loss: 0.0068, Train L1 Norm: 0.0126, Test L1 Norm: 0.0066, Train Linf Norm: 0.5928, Test Linf Norm: 0.2119\n",
            "Epoch 43: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0128, Test L1 Norm: 0.0065, Train Linf Norm: 0.5988, Test Linf Norm: 0.2031\n",
            "Epoch 44: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0125, Test L1 Norm: 0.0067, Train Linf Norm: 0.5858, Test Linf Norm: 0.2159\n",
            "Epoch 45: Train Loss: 0.0065, Test Loss: 0.0069, Train L1 Norm: 0.0132, Test L1 Norm: 0.0066, Train Linf Norm: 0.6298, Test Linf Norm: 0.2126\n",
            "Epoch 46: Train Loss: 0.0066, Test Loss: 0.0070, Train L1 Norm: 0.0127, Test L1 Norm: 0.0066, Train Linf Norm: 0.6019, Test Linf Norm: 0.2099\n",
            "Epoch 47: Train Loss: 0.0066, Test Loss: 0.0069, Train L1 Norm: 0.0121, Test L1 Norm: 0.0065, Train Linf Norm: 0.5567, Test Linf Norm: 0.2004\n",
            "Epoch 48: Train Loss: 0.0065, Test Loss: 0.0069, Train L1 Norm: 0.0120, Test L1 Norm: 0.0065, Train Linf Norm: 0.5534, Test Linf Norm: 0.2050\n",
            "Epoch 49: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0115, Test L1 Norm: 0.0065, Train Linf Norm: 0.5210, Test Linf Norm: 0.2004\n",
            "Epoch 50: Train Loss: 0.0065, Test Loss: 0.0069, Train L1 Norm: 0.0121, Test L1 Norm: 0.0066, Train Linf Norm: 0.5603, Test Linf Norm: 0.2078\n",
            "Epoch 51: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0125, Test L1 Norm: 0.0065, Train Linf Norm: 0.5920, Test Linf Norm: 0.2066\n",
            "Epoch 52: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0128, Test L1 Norm: 0.0065, Train Linf Norm: 0.6132, Test Linf Norm: 0.2094\n",
            "Epoch 53: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0126, Test L1 Norm: 0.0065, Train Linf Norm: 0.5958, Test Linf Norm: 0.2047\n",
            "Epoch 54: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0126, Test L1 Norm: 0.0065, Train Linf Norm: 0.5899, Test Linf Norm: 0.2042\n",
            "Epoch 55: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0126, Test L1 Norm: 0.0064, Train Linf Norm: 0.5829, Test Linf Norm: 0.2032\n",
            "Epoch 56: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0123, Test L1 Norm: 0.0065, Train Linf Norm: 0.5767, Test Linf Norm: 0.2049\n",
            "Epoch 57: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0126, Test L1 Norm: 0.0065, Train Linf Norm: 0.5899, Test Linf Norm: 0.2059\n",
            "Epoch 58: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0125, Test L1 Norm: 0.0065, Train Linf Norm: 0.5812, Test Linf Norm: 0.2053\n",
            "Epoch 59: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0127, Test L1 Norm: 0.0064, Train Linf Norm: 0.5975, Test Linf Norm: 0.2031\n",
            "Epoch 60: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0123, Test L1 Norm: 0.0065, Train Linf Norm: 0.5748, Test Linf Norm: 0.2049\n",
            "Epoch 61: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0123, Test L1 Norm: 0.0064, Train Linf Norm: 0.5736, Test Linf Norm: 0.2028\n",
            "Epoch 62: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5807, Test Linf Norm: 0.2039\n",
            "Epoch 63: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5818, Test Linf Norm: 0.2036\n",
            "Epoch 64: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5789, Test Linf Norm: 0.2046\n",
            "Epoch 65: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5821, Test Linf Norm: 0.2032\n",
            "Epoch 66: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0123, Test L1 Norm: 0.0064, Train Linf Norm: 0.5706, Test Linf Norm: 0.2037\n",
            "Epoch 67: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5816, Test Linf Norm: 0.2041\n",
            "Epoch 68: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5854, Test Linf Norm: 0.2035\n",
            "Epoch 69: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5825, Test Linf Norm: 0.2039\n",
            "Epoch 70: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5810, Test Linf Norm: 0.2039\n",
            "Epoch 71: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5816, Test Linf Norm: 0.2038\n",
            "Epoch 72: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5787, Test Linf Norm: 0.2039\n",
            "Epoch 73: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5651, Test Linf Norm: 0.2039\n",
            "Epoch 74: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5687, Test Linf Norm: 0.2041\n",
            "Epoch 75: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5803, Test Linf Norm: 0.2039\n",
            "Epoch 76: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5780, Test Linf Norm: 0.2040\n",
            "Epoch 77: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0064, Train Linf Norm: 0.5840, Test Linf Norm: 0.2040\n",
            "Epoch 78: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5831, Test Linf Norm: 0.2042\n",
            "Epoch 79: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5815, Test Linf Norm: 0.2041\n",
            "Epoch 80: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5776, Test Linf Norm: 0.2041\n",
            "Epoch 81: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5648, Test Linf Norm: 0.2041\n",
            "Epoch 82: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5803, Test Linf Norm: 0.2041\n",
            "Epoch 83: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5727, Test Linf Norm: 0.2041\n",
            "Epoch 84: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5661, Test Linf Norm: 0.2041\n",
            "Epoch 85: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5832, Test Linf Norm: 0.2041\n",
            "Epoch 86: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5800, Test Linf Norm: 0.2041\n",
            "Epoch 87: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5835, Test Linf Norm: 0.2041\n",
            "Epoch 88: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5821, Test Linf Norm: 0.2041\n",
            "Epoch 89: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5843, Test Linf Norm: 0.2041\n",
            "Epoch 90: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5826, Test Linf Norm: 0.2041\n",
            "Epoch 91: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5834, Test Linf Norm: 0.2041\n",
            "Epoch 92: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5849, Test Linf Norm: 0.2041\n",
            "Epoch 93: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5839, Test Linf Norm: 0.2041\n",
            "Epoch 94: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5764, Test Linf Norm: 0.2041\n",
            "Epoch 95: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5831, Test Linf Norm: 0.2041\n",
            "Epoch 96: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5833, Test Linf Norm: 0.2041\n",
            "Epoch 97: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5824, Test Linf Norm: 0.2041\n",
            "Epoch 98: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5829, Test Linf Norm: 0.2041\n",
            "Epoch 99: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5747, Test Linf Norm: 0.2041\n",
            "Epoch 100: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5764, Test Linf Norm: 0.2041\n",
            "Epoch 101: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5792, Test Linf Norm: 0.2041\n",
            "Epoch 102: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5804, Test Linf Norm: 0.2041\n",
            "Epoch 103: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5815, Test Linf Norm: 0.2041\n",
            "Epoch 104: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5832, Test Linf Norm: 0.2041\n",
            "Epoch 105: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5855, Test Linf Norm: 0.2041\n",
            "Epoch 106: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5859, Test Linf Norm: 0.2041\n",
            "Epoch 107: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5809, Test Linf Norm: 0.2041\n",
            "Epoch 108: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5779, Test Linf Norm: 0.2041\n",
            "Epoch 109: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5796, Test Linf Norm: 0.2041\n",
            "Epoch 110: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5796, Test Linf Norm: 0.2041\n",
            "Epoch 111: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5795, Test Linf Norm: 0.2041\n",
            "Epoch 112: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5796, Test Linf Norm: 0.2041\n",
            "Epoch 113: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5840, Test Linf Norm: 0.2041\n",
            "Epoch 114: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5798, Test Linf Norm: 0.2041\n",
            "Epoch 115: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5778, Test Linf Norm: 0.2041\n",
            "Epoch 116: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5816, Test Linf Norm: 0.2041\n",
            "Epoch 117: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5793, Test Linf Norm: 0.2041\n",
            "Epoch 118: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5847, Test Linf Norm: 0.2041\n",
            "Epoch 119: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5803, Test Linf Norm: 0.2041\n",
            "Epoch 120: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5823, Test Linf Norm: 0.2041\n",
            "Epoch 121: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5832, Test Linf Norm: 0.2041\n",
            "Epoch 122: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5822, Test Linf Norm: 0.2041\n",
            "Epoch 123: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5814, Test Linf Norm: 0.2041\n",
            "Epoch 124: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5792, Test Linf Norm: 0.2041\n",
            "Epoch 125: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5838, Test Linf Norm: 0.2041\n",
            "Epoch 126: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5837, Test Linf Norm: 0.2041\n",
            "Epoch 127: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5805, Test Linf Norm: 0.2041\n",
            "Epoch 128: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5844, Test Linf Norm: 0.2041\n",
            "Epoch 129: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5846, Test Linf Norm: 0.2041\n",
            "Epoch 130: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5785, Test Linf Norm: 0.2041\n",
            "Epoch 131: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5834, Test Linf Norm: 0.2041\n",
            "Epoch 132: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5866, Test Linf Norm: 0.2041\n",
            "Epoch 133: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5810, Test Linf Norm: 0.2041\n",
            "Epoch 134: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5834, Test Linf Norm: 0.2041\n",
            "Epoch 135: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5817, Test Linf Norm: 0.2041\n",
            "Epoch 136: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5839, Test Linf Norm: 0.2041\n",
            "Epoch 137: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5849, Test Linf Norm: 0.2041\n",
            "Epoch 138: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5799, Test Linf Norm: 0.2041\n",
            "Epoch 139: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5847, Test Linf Norm: 0.2041\n",
            "Epoch 140: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5792, Test Linf Norm: 0.2041\n",
            "Epoch 141: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5810, Test Linf Norm: 0.2041\n",
            "Epoch 142: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5813, Test Linf Norm: 0.2041\n",
            "Epoch 143: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5782, Test Linf Norm: 0.2041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:16:58,454]\u001b[0m Trial 82 finished with value: 0.006450714644044638 and parameters: {'n_layers': 3, 'n_units_0': 1032, 'n_units_1': 711, 'n_units_2': 89, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0011410132088858769, 'batch_size': 64, 'n_epochs': 144, 'scheduler': 'StepLR', 'weight_decay': 0.0027343638393524756, 'beta1': 0.9982823747676893, 'beta2': 0.9995220393021045, 'step_size': 10, 'gamma': 0.19317739374055842}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 144: Train Loss: 0.0064, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0065, Train Linf Norm: 0.5805, Test Linf Norm: 0.2041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:17:02,153]\u001b[0m Trial 83 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1268, Test Loss: 0.0475, Train L1 Norm: 0.2647, Test L1 Norm: 0.0794, Train Linf Norm: 12.3954, Test Linf Norm: 3.2001\n",
            "Epoch 1: Train Loss: 0.2264, Test Loss: 0.0275, Train L1 Norm: 0.2310, Test L1 Norm: 0.0222, Train Linf Norm: 7.5887, Test Linf Norm: 0.6416\n",
            "Epoch 2: Train Loss: 0.0386, Test Loss: 0.0564, Train L1 Norm: 0.0988, Test L1 Norm: 0.0386, Train Linf Norm: 4.9648, Test Linf Norm: 0.9257\n",
            "Epoch 3: Train Loss: 0.0486, Test Loss: 0.0440, Train L1 Norm: 0.0995, Test L1 Norm: 0.0446, Train Linf Norm: 4.7726, Test Linf Norm: 1.3396\n",
            "Epoch 4: Train Loss: 0.0409, Test Loss: 0.0547, Train L1 Norm: 0.0672, Test L1 Norm: 0.0652, Train Linf Norm: 2.9514, Test Linf Norm: 2.0454\n",
            "Epoch 5: Train Loss: 0.0321, Test Loss: 0.0236, Train L1 Norm: 0.0836, Test L1 Norm: 0.0262, Train Linf Norm: 4.3008, Test Linf Norm: 0.9584\n",
            "Epoch 6: Train Loss: 0.0320, Test Loss: 0.0207, Train L1 Norm: 0.1027, Test L1 Norm: 0.0223, Train Linf Norm: 5.5139, Test Linf Norm: 0.7761\n",
            "Epoch 7: Train Loss: 0.0282, Test Loss: 0.0282, Train L1 Norm: 0.0635, Test L1 Norm: 0.0236, Train Linf Norm: 3.1313, Test Linf Norm: 0.6465\n",
            "Epoch 8: Train Loss: 0.0336, Test Loss: 0.0356, Train L1 Norm: 0.0805, Test L1 Norm: 0.0295, Train Linf Norm: 4.0359, Test Linf Norm: 0.6723\n",
            "Epoch 9: Train Loss: 0.0357, Test Loss: 0.0319, Train L1 Norm: 0.1034, Test L1 Norm: 0.0336, Train Linf Norm: 5.4829, Test Linf Norm: 1.2300\n",
            "Epoch 10: Train Loss: 0.0301, Test Loss: 0.0277, Train L1 Norm: 0.0712, Test L1 Norm: 0.0265, Train Linf Norm: 3.5913, Test Linf Norm: 0.7668\n",
            "Epoch 11: Train Loss: 0.0164, Test Loss: 0.0119, Train L1 Norm: 0.0706, Test L1 Norm: 0.0169, Train Linf Norm: 3.9538, Test Linf Norm: 0.6709\n",
            "Epoch 12: Train Loss: 0.0141, Test Loss: 0.0135, Train L1 Norm: 0.0666, Test L1 Norm: 0.0149, Train Linf Norm: 3.7765, Test Linf Norm: 0.5090\n",
            "Epoch 13: Train Loss: 0.0141, Test Loss: 0.0158, Train L1 Norm: 0.0566, Test L1 Norm: 0.0150, Train Linf Norm: 3.1208, Test Linf Norm: 0.5015\n",
            "Epoch 14: Train Loss: 0.0140, Test Loss: 0.0097, Train L1 Norm: 0.0481, Test L1 Norm: 0.0126, Train Linf Norm: 2.6114, Test Linf Norm: 0.4825\n",
            "Epoch 15: Train Loss: 0.0145, Test Loss: 0.0194, Train L1 Norm: 0.0424, Test L1 Norm: 0.0157, Train Linf Norm: 2.2302, Test Linf Norm: 0.5128\n",
            "Epoch 16: Train Loss: 0.0127, Test Loss: 0.0106, Train L1 Norm: 0.0268, Test L1 Norm: 0.0123, Train Linf Norm: 1.2735, Test Linf Norm: 0.4452\n",
            "Epoch 17: Train Loss: 0.0136, Test Loss: 0.0128, Train L1 Norm: 0.0296, Test L1 Norm: 0.0113, Train Linf Norm: 1.4569, Test Linf Norm: 0.3336\n",
            "Epoch 18: Train Loss: 0.0140, Test Loss: 0.0154, Train L1 Norm: 0.0366, Test L1 Norm: 0.0136, Train Linf Norm: 1.8872, Test Linf Norm: 0.4383\n",
            "Epoch 19: Train Loss: 0.0136, Test Loss: 0.0223, Train L1 Norm: 0.0319, Test L1 Norm: 0.0205, Train Linf Norm: 1.5870, Test Linf Norm: 0.6109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:18:05,941]\u001b[0m Trial 84 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss: 0.0155, Test Loss: 0.0141, Train L1 Norm: 0.0349, Test L1 Norm: 0.0133, Train Linf Norm: 1.7263, Test Linf Norm: 0.4507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:18:09,688]\u001b[0m Trial 85 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1373, Test Loss: 0.0514, Train L1 Norm: 0.9643, Test L1 Norm: 0.1589, Train Linf Norm: 56.3630, Test Linf Norm: 7.6974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:18:13,114]\u001b[0m Trial 86 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.2168, Test Loss: 0.1267, Train L1 Norm: 0.1759, Test L1 Norm: 0.0979, Train Linf Norm: 5.2055, Test Linf Norm: 2.3895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:18:16,235]\u001b[0m Trial 87 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1133, Test Loss: 0.0159, Train L1 Norm: 1.7432, Test L1 Norm: 0.0725, Train Linf Norm: 102.9174, Test Linf Norm: 1.8687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:18:19,509]\u001b[0m Trial 88 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.4631, Test Loss: 0.1471, Train L1 Norm: 1.0031, Test L1 Norm: 0.2198, Train Linf Norm: 49.6299, Test Linf Norm: 7.5930\n",
            "Epoch 1: Train Loss: 0.2570, Test Loss: 0.0323, Train L1 Norm: 0.5416, Test L1 Norm: 0.0400, Train Linf Norm: 25.3119, Test Linf Norm: 1.2088\n",
            "Epoch 2: Train Loss: 0.0406, Test Loss: 0.0264, Train L1 Norm: 0.0814, Test L1 Norm: 0.0339, Train Linf Norm: 3.7081, Test Linf Norm: 1.1363\n",
            "Epoch 3: Train Loss: 0.0438, Test Loss: 0.0339, Train L1 Norm: 0.1162, Test L1 Norm: 0.0278, Train Linf Norm: 5.9745, Test Linf Norm: 0.5848\n",
            "Epoch 4: Train Loss: 0.0357, Test Loss: 0.0268, Train L1 Norm: 0.0745, Test L1 Norm: 0.0350, Train Linf Norm: 3.5631, Test Linf Norm: 1.2768\n",
            "Epoch 5: Train Loss: 0.0316, Test Loss: 0.0290, Train L1 Norm: 0.0660, Test L1 Norm: 0.0268, Train Linf Norm: 3.1568, Test Linf Norm: 0.8194\n",
            "Epoch 6: Train Loss: 0.0367, Test Loss: 0.0333, Train L1 Norm: 0.0668, Test L1 Norm: 0.0220, Train Linf Norm: 3.0605, Test Linf Norm: 0.4987\n",
            "Epoch 7: Train Loss: 0.0365, Test Loss: 0.0190, Train L1 Norm: 0.1030, Test L1 Norm: 0.0225, Train Linf Norm: 5.4523, Test Linf Norm: 0.8329\n",
            "Epoch 8: Train Loss: 0.0317, Test Loss: 0.0335, Train L1 Norm: 0.0827, Test L1 Norm: 0.0294, Train Linf Norm: 4.1379, Test Linf Norm: 0.9117\n",
            "Epoch 9: Train Loss: 0.0304, Test Loss: 0.0225, Train L1 Norm: 0.0780, Test L1 Norm: 0.0218, Train Linf Norm: 4.0084, Test Linf Norm: 0.7016\n",
            "Epoch 10: Train Loss: 0.0341, Test Loss: 0.0488, Train L1 Norm: 0.0514, Test L1 Norm: 0.0394, Train Linf Norm: 2.2295, Test Linf Norm: 1.0144\n",
            "Epoch 11: Train Loss: 0.0289, Test Loss: 0.0394, Train L1 Norm: 0.0531, Test L1 Norm: 0.0339, Train Linf Norm: 2.4769, Test Linf Norm: 1.0019\n",
            "Epoch 12: Train Loss: 0.0310, Test Loss: 0.0173, Train L1 Norm: 0.0711, Test L1 Norm: 0.0154, Train Linf Norm: 3.5439, Test Linf Norm: 0.4420\n",
            "Epoch 13: Train Loss: 0.0301, Test Loss: 0.0305, Train L1 Norm: 0.0600, Test L1 Norm: 0.0232, Train Linf Norm: 2.9200, Test Linf Norm: 0.5836\n",
            "Epoch 14: Train Loss: 0.0268, Test Loss: 0.0320, Train L1 Norm: 0.0467, Test L1 Norm: 0.0282, Train Linf Norm: 2.1368, Test Linf Norm: 0.9083\n",
            "Epoch 15: Train Loss: 0.0181, Test Loss: 0.0202, Train L1 Norm: 0.0511, Test L1 Norm: 0.0172, Train Linf Norm: 2.6880, Test Linf Norm: 0.3976\n",
            "Epoch 16: Train Loss: 0.0145, Test Loss: 0.0104, Train L1 Norm: 0.0333, Test L1 Norm: 0.0105, Train Linf Norm: 1.6403, Test Linf Norm: 0.3234\n",
            "Epoch 17: Train Loss: 0.0161, Test Loss: 0.0141, Train L1 Norm: 0.0308, Test L1 Norm: 0.0110, Train Linf Norm: 1.4587, Test Linf Norm: 0.3210\n",
            "Epoch 18: Train Loss: 0.0141, Test Loss: 0.0178, Train L1 Norm: 0.0345, Test L1 Norm: 0.0134, Train Linf Norm: 1.7551, Test Linf Norm: 0.3656\n",
            "Epoch 19: Train Loss: 0.0142, Test Loss: 0.0128, Train L1 Norm: 0.0262, Test L1 Norm: 0.0118, Train Linf Norm: 1.2090, Test Linf Norm: 0.3505\n",
            "Epoch 20: Train Loss: 0.0134, Test Loss: 0.0115, Train L1 Norm: 0.0209, Test L1 Norm: 0.0098, Train Linf Norm: 0.8786, Test Linf Norm: 0.2774\n",
            "Epoch 21: Train Loss: 0.0142, Test Loss: 0.0165, Train L1 Norm: 0.0217, Test L1 Norm: 0.0141, Train Linf Norm: 0.9281, Test Linf Norm: 0.3191\n",
            "Epoch 22: Train Loss: 0.0127, Test Loss: 0.0109, Train L1 Norm: 0.0252, Test L1 Norm: 0.0099, Train Linf Norm: 1.1866, Test Linf Norm: 0.3064\n",
            "Epoch 23: Train Loss: 0.0142, Test Loss: 0.0122, Train L1 Norm: 0.0276, Test L1 Norm: 0.0138, Train Linf Norm: 1.2976, Test Linf Norm: 0.4297\n",
            "Epoch 24: Train Loss: 0.0136, Test Loss: 0.0114, Train L1 Norm: 0.0216, Test L1 Norm: 0.0099, Train Linf Norm: 0.9403, Test Linf Norm: 0.2734\n",
            "Epoch 25: Train Loss: 0.0160, Test Loss: 0.0119, Train L1 Norm: 0.0308, Test L1 Norm: 0.0136, Train Linf Norm: 1.4728, Test Linf Norm: 0.4396\n",
            "Epoch 26: Train Loss: 0.0130, Test Loss: 0.0141, Train L1 Norm: 0.0263, Test L1 Norm: 0.0094, Train Linf Norm: 1.2611, Test Linf Norm: 0.1998\n",
            "Epoch 27: Train Loss: 0.0123, Test Loss: 0.0155, Train L1 Norm: 0.0276, Test L1 Norm: 0.0120, Train Linf Norm: 1.3621, Test Linf Norm: 0.3420\n",
            "Epoch 28: Train Loss: 0.0142, Test Loss: 0.0174, Train L1 Norm: 0.0243, Test L1 Norm: 0.0106, Train Linf Norm: 1.1176, Test Linf Norm: 0.2022\n",
            "Epoch 29: Train Loss: 0.0085, Test Loss: 0.0083, Train L1 Norm: 0.0194, Test L1 Norm: 0.0075, Train Linf Norm: 0.9521, Test Linf Norm: 0.2172\n",
            "Epoch 30: Train Loss: 0.0084, Test Loss: 0.0091, Train L1 Norm: 0.0141, Test L1 Norm: 0.0080, Train Linf Norm: 0.6229, Test Linf Norm: 0.2328\n",
            "Epoch 31: Train Loss: 0.0088, Test Loss: 0.0075, Train L1 Norm: 0.0140, Test L1 Norm: 0.0075, Train Linf Norm: 0.6027, Test Linf Norm: 0.2306\n",
            "Epoch 32: Train Loss: 0.0081, Test Loss: 0.0081, Train L1 Norm: 0.0177, Test L1 Norm: 0.0071, Train Linf Norm: 0.8566, Test Linf Norm: 0.1831\n",
            "Epoch 33: Train Loss: 0.0091, Test Loss: 0.0080, Train L1 Norm: 0.0151, Test L1 Norm: 0.0068, Train Linf Norm: 0.6675, Test Linf Norm: 0.1671\n",
            "Epoch 34: Train Loss: 0.0085, Test Loss: 0.0090, Train L1 Norm: 0.0132, Test L1 Norm: 0.0071, Train Linf Norm: 0.5584, Test Linf Norm: 0.1550\n",
            "Epoch 35: Train Loss: 0.0087, Test Loss: 0.0077, Train L1 Norm: 0.0125, Test L1 Norm: 0.0078, Train Linf Norm: 0.5088, Test Linf Norm: 0.2396\n",
            "Epoch 36: Train Loss: 0.0080, Test Loss: 0.0074, Train L1 Norm: 0.0148, Test L1 Norm: 0.0062, Train Linf Norm: 0.6692, Test Linf Norm: 0.1470\n",
            "Epoch 37: Train Loss: 0.0082, Test Loss: 0.0081, Train L1 Norm: 0.0200, Test L1 Norm: 0.0078, Train Linf Norm: 0.9979, Test Linf Norm: 0.2422\n",
            "Epoch 38: Train Loss: 0.0087, Test Loss: 0.0072, Train L1 Norm: 0.0132, Test L1 Norm: 0.0079, Train Linf Norm: 0.5593, Test Linf Norm: 0.2474\n",
            "Epoch 39: Train Loss: 0.0079, Test Loss: 0.0091, Train L1 Norm: 0.0130, Test L1 Norm: 0.0076, Train Linf Norm: 0.5626, Test Linf Norm: 0.2150\n",
            "Epoch 40: Train Loss: 0.0082, Test Loss: 0.0077, Train L1 Norm: 0.0148, Test L1 Norm: 0.0066, Train Linf Norm: 0.6693, Test Linf Norm: 0.1746\n",
            "Epoch 41: Train Loss: 0.0081, Test Loss: 0.0087, Train L1 Norm: 0.0137, Test L1 Norm: 0.0075, Train Linf Norm: 0.5923, Test Linf Norm: 0.2155\n",
            "Epoch 42: Train Loss: 0.0082, Test Loss: 0.0121, Train L1 Norm: 0.0194, Test L1 Norm: 0.0078, Train Linf Norm: 0.9664, Test Linf Norm: 0.1891\n",
            "Epoch 43: Train Loss: 0.0071, Test Loss: 0.0071, Train L1 Norm: 0.0124, Test L1 Norm: 0.0063, Train Linf Norm: 0.5549, Test Linf Norm: 0.1777\n",
            "Epoch 44: Train Loss: 0.0067, Test Loss: 0.0067, Train L1 Norm: 0.0114, Test L1 Norm: 0.0061, Train Linf Norm: 0.4906, Test Linf Norm: 0.1724\n",
            "Epoch 45: Train Loss: 0.0068, Test Loss: 0.0073, Train L1 Norm: 0.0122, Test L1 Norm: 0.0062, Train Linf Norm: 0.5427, Test Linf Norm: 0.1687\n",
            "Epoch 46: Train Loss: 0.0068, Test Loss: 0.0076, Train L1 Norm: 0.0119, Test L1 Norm: 0.0063, Train Linf Norm: 0.5272, Test Linf Norm: 0.1733\n",
            "Epoch 47: Train Loss: 0.0070, Test Loss: 0.0075, Train L1 Norm: 0.0139, Test L1 Norm: 0.0061, Train Linf Norm: 0.6484, Test Linf Norm: 0.1607\n",
            "Epoch 48: Train Loss: 0.0067, Test Loss: 0.0070, Train L1 Norm: 0.0120, Test L1 Norm: 0.0066, Train Linf Norm: 0.5317, Test Linf Norm: 0.1963\n",
            "Epoch 49: Train Loss: 0.0067, Test Loss: 0.0066, Train L1 Norm: 0.0120, Test L1 Norm: 0.0058, Train Linf Norm: 0.5307, Test Linf Norm: 0.1572\n",
            "Epoch 50: Train Loss: 0.0068, Test Loss: 0.0068, Train L1 Norm: 0.0124, Test L1 Norm: 0.0059, Train Linf Norm: 0.5605, Test Linf Norm: 0.1600\n",
            "Epoch 51: Train Loss: 0.0067, Test Loss: 0.0081, Train L1 Norm: 0.0137, Test L1 Norm: 0.0061, Train Linf Norm: 0.6455, Test Linf Norm: 0.1481\n",
            "Epoch 52: Train Loss: 0.0067, Test Loss: 0.0076, Train L1 Norm: 0.0120, Test L1 Norm: 0.0060, Train Linf Norm: 0.5397, Test Linf Norm: 0.1408\n",
            "Epoch 53: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0122, Test L1 Norm: 0.0070, Train Linf Norm: 0.5429, Test Linf Norm: 0.2126\n",
            "Epoch 54: Train Loss: 0.0067, Test Loss: 0.0069, Train L1 Norm: 0.0119, Test L1 Norm: 0.0058, Train Linf Norm: 0.5259, Test Linf Norm: 0.1526\n",
            "Epoch 55: Train Loss: 0.0068, Test Loss: 0.0074, Train L1 Norm: 0.0122, Test L1 Norm: 0.0065, Train Linf Norm: 0.5485, Test Linf Norm: 0.1827\n",
            "Epoch 56: Train Loss: 0.0066, Test Loss: 0.0066, Train L1 Norm: 0.0118, Test L1 Norm: 0.0060, Train Linf Norm: 0.5252, Test Linf Norm: 0.1697\n",
            "Epoch 57: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0102, Test L1 Norm: 0.0056, Train Linf Norm: 0.4335, Test Linf Norm: 0.1428\n",
            "Epoch 58: Train Loss: 0.0063, Test Loss: 0.0067, Train L1 Norm: 0.0107, Test L1 Norm: 0.0058, Train Linf Norm: 0.4701, Test Linf Norm: 0.1596\n",
            "Epoch 59: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0113, Test L1 Norm: 0.0058, Train Linf Norm: 0.4971, Test Linf Norm: 0.1617\n",
            "Epoch 60: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0112, Test L1 Norm: 0.0058, Train Linf Norm: 0.4984, Test Linf Norm: 0.1599\n",
            "Epoch 61: Train Loss: 0.0063, Test Loss: 0.0066, Train L1 Norm: 0.0106, Test L1 Norm: 0.0056, Train Linf Norm: 0.4536, Test Linf Norm: 0.1413\n",
            "Epoch 62: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0106, Test L1 Norm: 0.0059, Train Linf Norm: 0.4624, Test Linf Norm: 0.1698\n",
            "Epoch 63: Train Loss: 0.0063, Test Loss: 0.0066, Train L1 Norm: 0.0107, Test L1 Norm: 0.0056, Train Linf Norm: 0.4616, Test Linf Norm: 0.1451\n",
            "Epoch 64: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0114, Test L1 Norm: 0.0058, Train Linf Norm: 0.5062, Test Linf Norm: 0.1662\n",
            "Epoch 65: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0105, Test L1 Norm: 0.0058, Train Linf Norm: 0.4529, Test Linf Norm: 0.1655\n",
            "Epoch 66: Train Loss: 0.0063, Test Loss: 0.0065, Train L1 Norm: 0.0100, Test L1 Norm: 0.0058, Train Linf Norm: 0.4284, Test Linf Norm: 0.1625\n",
            "Epoch 67: Train Loss: 0.0063, Test Loss: 0.0064, Train L1 Norm: 0.0103, Test L1 Norm: 0.0055, Train Linf Norm: 0.4404, Test Linf Norm: 0.1459\n",
            "Epoch 68: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0107, Test L1 Norm: 0.0061, Train Linf Norm: 0.4660, Test Linf Norm: 0.1807\n",
            "Epoch 69: Train Loss: 0.0062, Test Loss: 0.0065, Train L1 Norm: 0.0110, Test L1 Norm: 0.0057, Train Linf Norm: 0.4843, Test Linf Norm: 0.1562\n",
            "Epoch 70: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0112, Test L1 Norm: 0.0056, Train Linf Norm: 0.4992, Test Linf Norm: 0.1528\n",
            "Epoch 71: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0101, Test L1 Norm: 0.0057, Train Linf Norm: 0.4284, Test Linf Norm: 0.1614\n",
            "Epoch 72: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0108, Test L1 Norm: 0.0057, Train Linf Norm: 0.4812, Test Linf Norm: 0.1571\n",
            "Epoch 73: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0106, Test L1 Norm: 0.0057, Train Linf Norm: 0.4637, Test Linf Norm: 0.1599\n",
            "Epoch 74: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0105, Test L1 Norm: 0.0056, Train Linf Norm: 0.4573, Test Linf Norm: 0.1552\n",
            "Epoch 75: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0106, Test L1 Norm: 0.0057, Train Linf Norm: 0.4572, Test Linf Norm: 0.1601\n",
            "Epoch 76: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0104, Test L1 Norm: 0.0056, Train Linf Norm: 0.4505, Test Linf Norm: 0.1535\n",
            "Epoch 77: Train Loss: 0.0062, Test Loss: 0.0064, Train L1 Norm: 0.0103, Test L1 Norm: 0.0056, Train Linf Norm: 0.4506, Test Linf Norm: 0.1552\n",
            "Epoch 78: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0101, Test L1 Norm: 0.0057, Train Linf Norm: 0.4339, Test Linf Norm: 0.1565\n",
            "Epoch 79: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4306, Test Linf Norm: 0.1513\n",
            "Epoch 80: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4329, Test Linf Norm: 0.1539\n",
            "Epoch 81: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0108, Test L1 Norm: 0.0058, Train Linf Norm: 0.4779, Test Linf Norm: 0.1641\n",
            "Epoch 82: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0104, Test L1 Norm: 0.0056, Train Linf Norm: 0.4529, Test Linf Norm: 0.1535\n",
            "Epoch 83: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0103, Test L1 Norm: 0.0055, Train Linf Norm: 0.4476, Test Linf Norm: 0.1494\n",
            "Epoch 84: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0102, Test L1 Norm: 0.0057, Train Linf Norm: 0.4378, Test Linf Norm: 0.1587\n",
            "Epoch 85: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0101, Test L1 Norm: 0.0057, Train Linf Norm: 0.4320, Test Linf Norm: 0.1615\n",
            "Epoch 86: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0057, Train Linf Norm: 0.4306, Test Linf Norm: 0.1589\n",
            "Epoch 87: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0103, Test L1 Norm: 0.0056, Train Linf Norm: 0.4469, Test Linf Norm: 0.1552\n",
            "Epoch 88: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0100, Test L1 Norm: 0.0057, Train Linf Norm: 0.4265, Test Linf Norm: 0.1583\n",
            "Epoch 89: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4367, Test Linf Norm: 0.1555\n",
            "Epoch 90: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0102, Test L1 Norm: 0.0056, Train Linf Norm: 0.4400, Test Linf Norm: 0.1559\n",
            "Epoch 91: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0103, Test L1 Norm: 0.0056, Train Linf Norm: 0.4438, Test Linf Norm: 0.1556\n",
            "Epoch 92: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4350, Test Linf Norm: 0.1531\n",
            "Epoch 93: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0103, Test L1 Norm: 0.0056, Train Linf Norm: 0.4440, Test Linf Norm: 0.1570\n",
            "Epoch 94: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0100, Test L1 Norm: 0.0056, Train Linf Norm: 0.4274, Test Linf Norm: 0.1550\n",
            "Epoch 95: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4299, Test Linf Norm: 0.1554\n",
            "Epoch 96: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0099, Test L1 Norm: 0.0057, Train Linf Norm: 0.4148, Test Linf Norm: 0.1582\n",
            "Epoch 97: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0100, Test L1 Norm: 0.0057, Train Linf Norm: 0.4311, Test Linf Norm: 0.1589\n",
            "Epoch 98: Train Loss: 0.0061, Test Loss: 0.0064, Train L1 Norm: 0.0102, Test L1 Norm: 0.0056, Train Linf Norm: 0.4372, Test Linf Norm: 0.1565\n",
            "Epoch 99: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4307, Test Linf Norm: 0.1550\n",
            "Epoch 100: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0100, Test L1 Norm: 0.0056, Train Linf Norm: 0.4259, Test Linf Norm: 0.1561\n",
            "Epoch 101: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4358, Test Linf Norm: 0.1566\n",
            "Epoch 102: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0100, Test L1 Norm: 0.0056, Train Linf Norm: 0.4236, Test Linf Norm: 0.1560\n",
            "Epoch 103: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4338, Test Linf Norm: 0.1571\n",
            "Epoch 104: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4351, Test Linf Norm: 0.1557\n",
            "Epoch 105: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0100, Test L1 Norm: 0.0056, Train Linf Norm: 0.4247, Test Linf Norm: 0.1561\n",
            "Epoch 106: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4312, Test Linf Norm: 0.1553\n",
            "Epoch 107: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0100, Test L1 Norm: 0.0056, Train Linf Norm: 0.4267, Test Linf Norm: 0.1561\n",
            "Epoch 108: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4277, Test Linf Norm: 0.1554\n",
            "Epoch 109: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0100, Test L1 Norm: 0.0056, Train Linf Norm: 0.4291, Test Linf Norm: 0.1569\n",
            "Epoch 110: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4376, Test Linf Norm: 0.1558\n",
            "Epoch 111: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0100, Test L1 Norm: 0.0056, Train Linf Norm: 0.4275, Test Linf Norm: 0.1562\n",
            "Epoch 112: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0102, Test L1 Norm: 0.0056, Train Linf Norm: 0.4383, Test Linf Norm: 0.1557\n",
            "Epoch 113: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4360, Test Linf Norm: 0.1557\n",
            "Epoch 114: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4352, Test Linf Norm: 0.1560\n",
            "Epoch 115: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4379, Test Linf Norm: 0.1564\n",
            "Epoch 116: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4336, Test Linf Norm: 0.1565\n",
            "Epoch 117: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4364, Test Linf Norm: 0.1564\n",
            "Epoch 118: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4333, Test Linf Norm: 0.1565\n",
            "Epoch 119: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4292, Test Linf Norm: 0.1563\n",
            "Epoch 120: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4281, Test Linf Norm: 0.1563\n",
            "Epoch 121: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4398, Test Linf Norm: 0.1566\n",
            "Epoch 122: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4364, Test Linf Norm: 0.1564\n",
            "Epoch 123: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4330, Test Linf Norm: 0.1566\n",
            "Epoch 124: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4381, Test Linf Norm: 0.1563\n",
            "Epoch 125: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4361, Test Linf Norm: 0.1563\n",
            "Epoch 126: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4379, Test Linf Norm: 0.1564\n",
            "Epoch 127: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4394, Test Linf Norm: 0.1564\n",
            "Epoch 128: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4330, Test Linf Norm: 0.1563\n",
            "Epoch 129: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4299, Test Linf Norm: 0.1563\n",
            "Epoch 130: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4284, Test Linf Norm: 0.1563\n",
            "Epoch 131: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4328, Test Linf Norm: 0.1562\n",
            "Epoch 132: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4323, Test Linf Norm: 0.1562\n",
            "Epoch 133: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4323, Test Linf Norm: 0.1562\n",
            "Epoch 134: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4272, Test Linf Norm: 0.1562\n",
            "Epoch 135: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4322, Test Linf Norm: 0.1562\n",
            "Epoch 136: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4310, Test Linf Norm: 0.1562\n",
            "Epoch 137: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4305, Test Linf Norm: 0.1562\n",
            "Epoch 138: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4342, Test Linf Norm: 0.1562\n",
            "Epoch 139: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4332, Test Linf Norm: 0.1562\n",
            "Epoch 140: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4333, Test Linf Norm: 0.1562\n",
            "Epoch 141: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4311, Test Linf Norm: 0.1562\n",
            "Epoch 142: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4294, Test Linf Norm: 0.1562\n",
            "Epoch 143: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4305, Test Linf Norm: 0.1562\n",
            "Epoch 144: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4285, Test Linf Norm: 0.1562\n",
            "Epoch 145: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4310, Test Linf Norm: 0.1562\n",
            "Epoch 146: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4269, Test Linf Norm: 0.1562\n",
            "Epoch 147: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4338, Test Linf Norm: 0.1562\n",
            "Epoch 148: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4259, Test Linf Norm: 0.1562\n",
            "Epoch 149: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4325, Test Linf Norm: 0.1562\n",
            "Epoch 150: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4341, Test Linf Norm: 0.1562\n",
            "Epoch 151: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4302, Test Linf Norm: 0.1562\n",
            "Epoch 152: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4322, Test Linf Norm: 0.1562\n",
            "Epoch 153: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4317, Test Linf Norm: 0.1562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:26:53,706]\u001b[0m Trial 89 finished with value: 0.005626617263257504 and parameters: {'n_layers': 2, 'n_units_0': 1125, 'n_units_1': 407, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0017328032207362322, 'batch_size': 64, 'n_epochs': 154, 'scheduler': 'StepLR', 'weight_decay': 0.0012683111267260243, 'beta1': 0.9892964505347602, 'beta2': 0.9994151411817437, 'step_size': 14, 'gamma': 0.23809780476518533}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 154: Train Loss: 0.0061, Test Loss: 0.0063, Train L1 Norm: 0.0101, Test L1 Norm: 0.0056, Train Linf Norm: 0.4340, Test Linf Norm: 0.1562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:27:01,161]\u001b[0m Trial 90 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 4.3134, Test Loss: 0.1186, Train L1 Norm: 1.1333, Test L1 Norm: 0.3619, Train Linf Norm: 29.4771, Test Linf Norm: 7.1164\n",
            "Epoch 1: Train Loss: 0.2871, Test Loss: 0.0367, Train L1 Norm: 0.5030, Test L1 Norm: 0.0546, Train Linf Norm: 22.5696, Test Linf Norm: 2.1915\n",
            "Epoch 2: Train Loss: 0.0363, Test Loss: 0.0272, Train L1 Norm: 0.2502, Test L1 Norm: 0.0427, Train Linf Norm: 14.4826, Test Linf Norm: 1.6219\n",
            "Epoch 3: Train Loss: 0.0286, Test Loss: 0.0206, Train L1 Norm: 0.0808, Test L1 Norm: 0.0322, Train Linf Norm: 4.0519, Test Linf Norm: 1.2801\n",
            "Epoch 4: Train Loss: 0.0359, Test Loss: 0.0296, Train L1 Norm: 0.0602, Test L1 Norm: 0.0219, Train Linf Norm: 2.6326, Test Linf Norm: 0.6000\n",
            "Epoch 5: Train Loss: 0.0239, Test Loss: 0.0195, Train L1 Norm: 0.1001, Test L1 Norm: 0.0223, Train Linf Norm: 5.5494, Test Linf Norm: 0.6995\n",
            "Epoch 6: Train Loss: 0.0215, Test Loss: 0.0211, Train L1 Norm: 0.0571, Test L1 Norm: 0.0178, Train Linf Norm: 2.8767, Test Linf Norm: 0.5330\n",
            "Epoch 7: Train Loss: 0.0234, Test Loss: 0.0250, Train L1 Norm: 0.0881, Test L1 Norm: 0.0292, Train Linf Norm: 4.7641, Test Linf Norm: 0.7771\n",
            "Epoch 8: Train Loss: 0.0356, Test Loss: 0.0245, Train L1 Norm: 0.1027, Test L1 Norm: 0.0223, Train Linf Norm: 5.4178, Test Linf Norm: 0.6487\n",
            "Epoch 9: Train Loss: 0.0250, Test Loss: 0.0163, Train L1 Norm: 0.0909, Test L1 Norm: 0.0261, Train Linf Norm: 4.9907, Test Linf Norm: 0.9779\n",
            "Epoch 10: Train Loss: 0.0319, Test Loss: 0.0546, Train L1 Norm: 0.0584, Test L1 Norm: 0.0368, Train Linf Norm: 2.7336, Test Linf Norm: 0.8166\n",
            "Epoch 11: Train Loss: 0.0290, Test Loss: 0.0199, Train L1 Norm: 0.0411, Test L1 Norm: 0.0232, Train Linf Norm: 1.6717, Test Linf Norm: 0.8173\n",
            "Epoch 12: Train Loss: 0.0227, Test Loss: 0.0217, Train L1 Norm: 0.0737, Test L1 Norm: 0.0209, Train Linf Norm: 3.9606, Test Linf Norm: 0.6313\n",
            "Epoch 13: Train Loss: 0.0334, Test Loss: 0.0324, Train L1 Norm: 0.0510, Test L1 Norm: 0.0250, Train Linf Norm: 2.2196, Test Linf Norm: 0.7259\n",
            "Epoch 14: Train Loss: 0.0253, Test Loss: 0.0279, Train L1 Norm: 0.1058, Test L1 Norm: 0.0325, Train Linf Norm: 5.9250, Test Linf Norm: 1.2397\n",
            "Epoch 15: Train Loss: 0.0271, Test Loss: 0.0184, Train L1 Norm: 0.0391, Test L1 Norm: 0.0161, Train Linf Norm: 1.6305, Test Linf Norm: 0.4164\n",
            "Epoch 16: Train Loss: 0.0156, Test Loss: 0.0121, Train L1 Norm: 0.0559, Test L1 Norm: 0.0126, Train Linf Norm: 3.0604, Test Linf Norm: 0.4046\n",
            "Epoch 17: Train Loss: 0.0132, Test Loss: 0.0177, Train L1 Norm: 0.0387, Test L1 Norm: 0.0141, Train Linf Norm: 2.0210, Test Linf Norm: 0.4138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:27:56,832]\u001b[0m Trial 91 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss: 0.0151, Test Loss: 0.0170, Train L1 Norm: 0.0268, Test L1 Norm: 0.0142, Train Linf Norm: 1.2282, Test Linf Norm: 0.4657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:27:59,879]\u001b[0m Trial 92 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1584, Test Loss: 0.0586, Train L1 Norm: 0.3019, Test L1 Norm: 0.0676, Train Linf Norm: 13.8620, Test Linf Norm: 1.7002\n",
            "Epoch 1: Train Loss: 0.1157, Test Loss: 0.0754, Train L1 Norm: 0.2221, Test L1 Norm: 0.0418, Train Linf Norm: 10.3139, Test Linf Norm: 0.8229\n",
            "Epoch 2: Train Loss: 0.0478, Test Loss: 0.0586, Train L1 Norm: 0.0700, Test L1 Norm: 0.0412, Train Linf Norm: 2.9428, Test Linf Norm: 0.5489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:28:10,750]\u001b[0m Trial 93 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 0.0561, Test Loss: 0.0671, Train L1 Norm: 0.1142, Test L1 Norm: 0.0358, Train Linf Norm: 5.6842, Test Linf Norm: 0.5428\n",
            "Epoch 1: Train Loss: 0.1215, Test Loss: 0.0510, Train L1 Norm: 0.2739, Test L1 Norm: 0.0528, Train Linf Norm: 13.3097, Test Linf Norm: 1.7228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:28:17,500]\u001b[0m Trial 94 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.0554, Test Loss: 0.0272, Train L1 Norm: 0.1627, Test L1 Norm: 0.0493, Train Linf Norm: 8.6153, Test Linf Norm: 1.9554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:28:27,321]\u001b[0m Trial 95 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.3131, Test Loss: 0.1628, Train L1 Norm: 4.0502, Test L1 Norm: 0.3185, Train Linf Norm: 179.1403, Test Linf Norm: 9.7123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:28:30,576]\u001b[0m Trial 96 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.2128, Test Loss: 0.0444, Train L1 Norm: 0.4549, Test L1 Norm: 0.1017, Train Linf Norm: 30.4372, Test Linf Norm: 6.0118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:28:31,565]\u001b[0m Trial 97 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.8034, Test Loss: 0.4586, Train L1 Norm: 0.8700, Test L1 Norm: 0.3143, Train Linf Norm: 379.8084, Test Linf Norm: 36.6319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:28:33,405]\u001b[0m Trial 98 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.6057, Test Loss: 0.1054, Train L1 Norm: 0.9561, Test L1 Norm: 0.1531, Train Linf Norm: 151.5568, Test Linf Norm: 15.1242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:28:38,569]\u001b[0m Trial 99 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.1983, Test Loss: 0.0929, Train L1 Norm: 0.7922, Test L1 Norm: 0.0978, Train Linf Norm: 42.8997, Test Linf Norm: 3.6293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:28:39,497]\u001b[0m Trial 100 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.6526, Test Loss: 0.6906, Train L1 Norm: 1.5909, Test L1 Norm: 0.2573, Train Linf Norm: 290.7152, Test Linf Norm: 12.5328\n",
            "Epoch 1: Train Loss: 0.1575, Test Loss: 0.0753, Train L1 Norm: 0.3577, Test L1 Norm: 0.0621, Train Linf Norm: 17.6599, Test Linf Norm: 1.6217\n",
            "Epoch 2: Train Loss: 0.0417, Test Loss: 0.0261, Train L1 Norm: 0.1727, Test L1 Norm: 0.0346, Train Linf Norm: 9.4975, Test Linf Norm: 1.3038\n",
            "Epoch 3: Train Loss: 0.0396, Test Loss: 0.0800, Train L1 Norm: 0.1954, Test L1 Norm: 0.0577, Train Linf Norm: 11.1726, Test Linf Norm: 1.8104\n",
            "Epoch 4: Train Loss: 0.0419, Test Loss: 0.0253, Train L1 Norm: 0.1711, Test L1 Norm: 0.0354, Train Linf Norm: 9.5675, Test Linf Norm: 1.3703\n",
            "Epoch 5: Train Loss: 0.0290, Test Loss: 0.0235, Train L1 Norm: 0.1710, Test L1 Norm: 0.0288, Train Linf Norm: 9.9509, Test Linf Norm: 1.1221\n",
            "Epoch 6: Train Loss: 0.0339, Test Loss: 0.0326, Train L1 Norm: 0.1381, Test L1 Norm: 0.0339, Train Linf Norm: 7.7511, Test Linf Norm: 1.2642\n",
            "Epoch 7: Train Loss: 0.0297, Test Loss: 0.0285, Train L1 Norm: 0.0840, Test L1 Norm: 0.0251, Train Linf Norm: 4.4007, Test Linf Norm: 0.5573\n",
            "Epoch 8: Train Loss: 0.0263, Test Loss: 0.0177, Train L1 Norm: 0.0842, Test L1 Norm: 0.0342, Train Linf Norm: 4.5255, Test Linf Norm: 1.3834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:29:10,267]\u001b[0m Trial 101 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss: 0.0305, Test Loss: 0.0401, Train L1 Norm: 0.0855, Test L1 Norm: 0.0322, Train Linf Norm: 4.5313, Test Linf Norm: 0.7935\n",
            "Epoch 1: Train Loss: 0.1511, Test Loss: 0.0274, Train L1 Norm: 0.3574, Test L1 Norm: 0.0507, Train Linf Norm: 17.0945, Test Linf Norm: 2.0744\n",
            "Epoch 2: Train Loss: 0.0321, Test Loss: 0.0284, Train L1 Norm: 0.1247, Test L1 Norm: 0.0318, Train Linf Norm: 6.7660, Test Linf Norm: 1.0829\n",
            "Epoch 3: Train Loss: 0.0349, Test Loss: 0.0268, Train L1 Norm: 0.0893, Test L1 Norm: 0.0282, Train Linf Norm: 4.5406, Test Linf Norm: 0.9352\n",
            "Epoch 4: Train Loss: 0.0263, Test Loss: 0.0429, Train L1 Norm: 0.0673, Test L1 Norm: 0.0383, Train Linf Norm: 3.4248, Test Linf Norm: 1.1731\n",
            "Epoch 5: Train Loss: 0.0367, Test Loss: 0.0417, Train L1 Norm: 0.0673, Test L1 Norm: 0.0313, Train Linf Norm: 3.1363, Test Linf Norm: 0.8168\n",
            "Epoch 6: Train Loss: 0.0212, Test Loss: 0.0168, Train L1 Norm: 0.1168, Test L1 Norm: 0.0211, Train Linf Norm: 6.7181, Test Linf Norm: 0.7774\n",
            "Epoch 7: Train Loss: 0.0243, Test Loss: 0.0274, Train L1 Norm: 0.0530, Test L1 Norm: 0.0247, Train Linf Norm: 2.5852, Test Linf Norm: 0.6438\n",
            "Epoch 8: Train Loss: 0.0275, Test Loss: 0.0184, Train L1 Norm: 0.0570, Test L1 Norm: 0.0173, Train Linf Norm: 2.7757, Test Linf Norm: 0.5602\n",
            "Epoch 9: Train Loss: 0.0215, Test Loss: 0.0529, Train L1 Norm: 0.0741, Test L1 Norm: 0.0230, Train Linf Norm: 4.0186, Test Linf Norm: 0.3152\n",
            "Epoch 10: Train Loss: 0.0451, Test Loss: 0.0178, Train L1 Norm: 0.0821, Test L1 Norm: 0.0212, Train Linf Norm: 3.9862, Test Linf Norm: 0.7318\n",
            "Epoch 11: Train Loss: 0.0195, Test Loss: 0.0181, Train L1 Norm: 0.0679, Test L1 Norm: 0.0153, Train Linf Norm: 3.6844, Test Linf Norm: 0.4736\n",
            "Epoch 12: Train Loss: 0.0135, Test Loss: 0.0139, Train L1 Norm: 0.0389, Test L1 Norm: 0.0142, Train Linf Norm: 2.0270, Test Linf Norm: 0.4662\n",
            "Epoch 13: Train Loss: 0.0123, Test Loss: 0.0151, Train L1 Norm: 0.0299, Test L1 Norm: 0.0136, Train Linf Norm: 1.4791, Test Linf Norm: 0.4302\n",
            "Epoch 14: Train Loss: 0.0129, Test Loss: 0.0135, Train L1 Norm: 0.0260, Test L1 Norm: 0.0126, Train Linf Norm: 1.2341, Test Linf Norm: 0.4204\n",
            "Epoch 15: Train Loss: 0.0123, Test Loss: 0.0147, Train L1 Norm: 0.0314, Test L1 Norm: 0.0129, Train Linf Norm: 1.6014, Test Linf Norm: 0.3285\n",
            "Epoch 16: Train Loss: 0.0119, Test Loss: 0.0118, Train L1 Norm: 0.0288, Test L1 Norm: 0.0101, Train Linf Norm: 1.4531, Test Linf Norm: 0.2816\n",
            "Epoch 17: Train Loss: 0.0133, Test Loss: 0.0123, Train L1 Norm: 0.0257, Test L1 Norm: 0.0107, Train Linf Norm: 1.1899, Test Linf Norm: 0.3087\n",
            "Epoch 18: Train Loss: 0.0121, Test Loss: 0.0100, Train L1 Norm: 0.0205, Test L1 Norm: 0.0091, Train Linf Norm: 0.8862, Test Linf Norm: 0.2625\n",
            "Epoch 19: Train Loss: 0.0126, Test Loss: 0.0150, Train L1 Norm: 0.0239, Test L1 Norm: 0.0113, Train Linf Norm: 1.1303, Test Linf Norm: 0.2706\n",
            "Epoch 20: Train Loss: 0.0134, Test Loss: 0.0100, Train L1 Norm: 0.0270, Test L1 Norm: 0.0083, Train Linf Norm: 1.3146, Test Linf Norm: 0.2135\n",
            "Epoch 21: Train Loss: 0.0118, Test Loss: 0.0098, Train L1 Norm: 0.0179, Test L1 Norm: 0.0088, Train Linf Norm: 0.7823, Test Linf Norm: 0.2319\n",
            "Epoch 22: Train Loss: 0.0100, Test Loss: 0.0088, Train L1 Norm: 0.0161, Test L1 Norm: 0.0104, Train Linf Norm: 0.6969, Test Linf Norm: 0.3633\n",
            "Epoch 23: Train Loss: 0.0084, Test Loss: 0.0079, Train L1 Norm: 0.0159, Test L1 Norm: 0.0080, Train Linf Norm: 0.7242, Test Linf Norm: 0.2498\n",
            "Epoch 24: Train Loss: 0.0081, Test Loss: 0.0079, Train L1 Norm: 0.0172, Test L1 Norm: 0.0075, Train Linf Norm: 0.8228, Test Linf Norm: 0.2241\n",
            "Epoch 25: Train Loss: 0.0088, Test Loss: 0.0077, Train L1 Norm: 0.0142, Test L1 Norm: 0.0076, Train Linf Norm: 0.6235, Test Linf Norm: 0.2284\n",
            "Epoch 26: Train Loss: 0.0077, Test Loss: 0.0077, Train L1 Norm: 0.0161, Test L1 Norm: 0.0075, Train Linf Norm: 0.7676, Test Linf Norm: 0.2337\n",
            "Epoch 27: Train Loss: 0.0085, Test Loss: 0.0092, Train L1 Norm: 0.0203, Test L1 Norm: 0.0082, Train Linf Norm: 1.0199, Test Linf Norm: 0.2315\n",
            "Epoch 28: Train Loss: 0.0080, Test Loss: 0.0073, Train L1 Norm: 0.0183, Test L1 Norm: 0.0072, Train Linf Norm: 0.8992, Test Linf Norm: 0.2243\n",
            "Epoch 29: Train Loss: 0.0077, Test Loss: 0.0080, Train L1 Norm: 0.0144, Test L1 Norm: 0.0081, Train Linf Norm: 0.6516, Test Linf Norm: 0.2516\n",
            "Epoch 30: Train Loss: 0.0078, Test Loss: 0.0076, Train L1 Norm: 0.0133, Test L1 Norm: 0.0076, Train Linf Norm: 0.5741, Test Linf Norm: 0.2165\n",
            "Epoch 31: Train Loss: 0.0081, Test Loss: 0.0075, Train L1 Norm: 0.0133, Test L1 Norm: 0.0073, Train Linf Norm: 0.5727, Test Linf Norm: 0.2141\n",
            "Epoch 32: Train Loss: 0.0084, Test Loss: 0.0085, Train L1 Norm: 0.0131, Test L1 Norm: 0.0076, Train Linf Norm: 0.5506, Test Linf Norm: 0.2323\n",
            "Epoch 33: Train Loss: 0.0082, Test Loss: 0.0077, Train L1 Norm: 0.0138, Test L1 Norm: 0.0072, Train Linf Norm: 0.6183, Test Linf Norm: 0.2172\n",
            "Epoch 34: Train Loss: 0.0069, Test Loss: 0.0070, Train L1 Norm: 0.0137, Test L1 Norm: 0.0067, Train Linf Norm: 0.6451, Test Linf Norm: 0.2081\n",
            "Epoch 35: Train Loss: 0.0068, Test Loss: 0.0072, Train L1 Norm: 0.0142, Test L1 Norm: 0.0071, Train Linf Norm: 0.6684, Test Linf Norm: 0.2147\n",
            "Epoch 36: Train Loss: 0.0068, Test Loss: 0.0070, Train L1 Norm: 0.0122, Test L1 Norm: 0.0067, Train Linf Norm: 0.5462, Test Linf Norm: 0.2058\n",
            "Epoch 37: Train Loss: 0.0068, Test Loss: 0.0072, Train L1 Norm: 0.0133, Test L1 Norm: 0.0067, Train Linf Norm: 0.6140, Test Linf Norm: 0.2065\n",
            "Epoch 38: Train Loss: 0.0073, Test Loss: 0.0078, Train L1 Norm: 0.0125, Test L1 Norm: 0.0069, Train Linf Norm: 0.5417, Test Linf Norm: 0.2139\n",
            "Epoch 39: Train Loss: 0.0075, Test Loss: 0.0070, Train L1 Norm: 0.0139, Test L1 Norm: 0.0068, Train Linf Norm: 0.6437, Test Linf Norm: 0.2132\n",
            "Epoch 40: Train Loss: 0.0074, Test Loss: 0.0070, Train L1 Norm: 0.0128, Test L1 Norm: 0.0068, Train Linf Norm: 0.5790, Test Linf Norm: 0.2037\n",
            "Epoch 41: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0155, Test L1 Norm: 0.0067, Train Linf Norm: 0.7569, Test Linf Norm: 0.2118\n",
            "Epoch 42: Train Loss: 0.0068, Test Loss: 0.0068, Train L1 Norm: 0.0138, Test L1 Norm: 0.0068, Train Linf Norm: 0.6457, Test Linf Norm: 0.2107\n",
            "Epoch 43: Train Loss: 0.0068, Test Loss: 0.0069, Train L1 Norm: 0.0119, Test L1 Norm: 0.0066, Train Linf Norm: 0.5346, Test Linf Norm: 0.2009\n",
            "Epoch 44: Train Loss: 0.0068, Test Loss: 0.0074, Train L1 Norm: 0.0112, Test L1 Norm: 0.0068, Train Linf Norm: 0.4823, Test Linf Norm: 0.2096\n",
            "Epoch 45: Train Loss: 0.0067, Test Loss: 0.0067, Train L1 Norm: 0.0114, Test L1 Norm: 0.0066, Train Linf Norm: 0.5044, Test Linf Norm: 0.2091\n",
            "Epoch 46: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0126, Test L1 Norm: 0.0065, Train Linf Norm: 0.5806, Test Linf Norm: 0.2040\n",
            "Epoch 47: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0118, Test L1 Norm: 0.0065, Train Linf Norm: 0.5315, Test Linf Norm: 0.2044\n",
            "Epoch 48: Train Loss: 0.0065, Test Loss: 0.0068, Train L1 Norm: 0.0119, Test L1 Norm: 0.0067, Train Linf Norm: 0.5343, Test Linf Norm: 0.2120\n",
            "Epoch 49: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0117, Test L1 Norm: 0.0066, Train Linf Norm: 0.5280, Test Linf Norm: 0.2101\n",
            "Epoch 50: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0121, Test L1 Norm: 0.0067, Train Linf Norm: 0.5510, Test Linf Norm: 0.2171\n",
            "Epoch 51: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0115, Test L1 Norm: 0.0065, Train Linf Norm: 0.5099, Test Linf Norm: 0.1998\n",
            "Epoch 52: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0117, Test L1 Norm: 0.0065, Train Linf Norm: 0.5208, Test Linf Norm: 0.2005\n",
            "Epoch 53: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0113, Test L1 Norm: 0.0065, Train Linf Norm: 0.5007, Test Linf Norm: 0.1988\n",
            "Epoch 54: Train Loss: 0.0065, Test Loss: 0.0067, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4969, Test Linf Norm: 0.2000\n",
            "Epoch 55: Train Loss: 0.0065, Test Loss: 0.0066, Train L1 Norm: 0.0117, Test L1 Norm: 0.0064, Train Linf Norm: 0.5331, Test Linf Norm: 0.2008\n",
            "Epoch 56: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0110, Test L1 Norm: 0.0065, Train Linf Norm: 0.4870, Test Linf Norm: 0.2032\n",
            "Epoch 57: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4959, Test Linf Norm: 0.2030\n",
            "Epoch 58: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0109, Test L1 Norm: 0.0065, Train Linf Norm: 0.4825, Test Linf Norm: 0.1995\n",
            "Epoch 59: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0113, Test L1 Norm: 0.0065, Train Linf Norm: 0.5060, Test Linf Norm: 0.2005\n",
            "Epoch 60: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0113, Test L1 Norm: 0.0065, Train Linf Norm: 0.5080, Test Linf Norm: 0.2017\n",
            "Epoch 61: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0114, Test L1 Norm: 0.0064, Train Linf Norm: 0.5067, Test Linf Norm: 0.1996\n",
            "Epoch 62: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4954, Test Linf Norm: 0.2030\n",
            "Epoch 63: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0113, Test L1 Norm: 0.0065, Train Linf Norm: 0.5020, Test Linf Norm: 0.2017\n",
            "Epoch 64: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0115, Test L1 Norm: 0.0065, Train Linf Norm: 0.5194, Test Linf Norm: 0.2024\n",
            "Epoch 65: Train Loss: 0.0064, Test Loss: 0.0067, Train L1 Norm: 0.0108, Test L1 Norm: 0.0065, Train Linf Norm: 0.4772, Test Linf Norm: 0.2075\n",
            "Epoch 66: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0109, Test L1 Norm: 0.0065, Train Linf Norm: 0.4713, Test Linf Norm: 0.2010\n",
            "Epoch 67: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0111, Test L1 Norm: 0.0065, Train Linf Norm: 0.4959, Test Linf Norm: 0.2027\n",
            "Epoch 68: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0113, Test L1 Norm: 0.0065, Train Linf Norm: 0.5014, Test Linf Norm: 0.2020\n",
            "Epoch 69: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0113, Test L1 Norm: 0.0065, Train Linf Norm: 0.4999, Test Linf Norm: 0.2029\n",
            "Epoch 70: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5003, Test Linf Norm: 0.2018\n",
            "Epoch 71: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5003, Test Linf Norm: 0.2018\n",
            "Epoch 72: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0113, Test L1 Norm: 0.0065, Train Linf Norm: 0.4985, Test Linf Norm: 0.2025\n",
            "Epoch 73: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5008, Test Linf Norm: 0.2024\n",
            "Epoch 74: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0113, Test L1 Norm: 0.0065, Train Linf Norm: 0.5022, Test Linf Norm: 0.2027\n",
            "Epoch 75: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4961, Test Linf Norm: 0.2020\n",
            "Epoch 76: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5048, Test Linf Norm: 0.2025\n",
            "Epoch 77: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0111, Test L1 Norm: 0.0065, Train Linf Norm: 0.4905, Test Linf Norm: 0.2023\n",
            "Epoch 78: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4929, Test Linf Norm: 0.2018\n",
            "Epoch 79: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0111, Test L1 Norm: 0.0065, Train Linf Norm: 0.4871, Test Linf Norm: 0.2018\n",
            "Epoch 80: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4966, Test Linf Norm: 0.2022\n",
            "Epoch 81: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4983, Test Linf Norm: 0.2022\n",
            "Epoch 82: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4952, Test Linf Norm: 0.2021\n",
            "Epoch 83: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4928, Test Linf Norm: 0.2022\n",
            "Epoch 84: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5029, Test Linf Norm: 0.2023\n",
            "Epoch 85: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5008, Test Linf Norm: 0.2022\n",
            "Epoch 86: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4996, Test Linf Norm: 0.2022\n",
            "Epoch 87: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5053, Test Linf Norm: 0.2022\n",
            "Epoch 88: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5016, Test Linf Norm: 0.2021\n",
            "Epoch 89: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5030, Test Linf Norm: 0.2021\n",
            "Epoch 90: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5031, Test Linf Norm: 0.2021\n",
            "Epoch 91: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4975, Test Linf Norm: 0.2021\n",
            "Epoch 92: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4955, Test Linf Norm: 0.2021\n",
            "Epoch 93: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4967, Test Linf Norm: 0.2021\n",
            "Epoch 94: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4925, Test Linf Norm: 0.2021\n",
            "Epoch 95: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4985, Test Linf Norm: 0.2021\n",
            "Epoch 96: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4979, Test Linf Norm: 0.2021\n",
            "Epoch 97: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4872, Test Linf Norm: 0.2021\n",
            "Epoch 98: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4936, Test Linf Norm: 0.2021\n",
            "Epoch 99: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4986, Test Linf Norm: 0.2021\n",
            "Epoch 100: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4942, Test Linf Norm: 0.2021\n",
            "Epoch 101: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5015, Test Linf Norm: 0.2021\n",
            "Epoch 102: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5004, Test Linf Norm: 0.2021\n",
            "Epoch 103: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4999, Test Linf Norm: 0.2021\n",
            "Epoch 104: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5010, Test Linf Norm: 0.2021\n",
            "Epoch 105: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4969, Test Linf Norm: 0.2021\n",
            "Epoch 106: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4994, Test Linf Norm: 0.2021\n",
            "Epoch 107: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5026, Test Linf Norm: 0.2021\n",
            "Epoch 108: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4973, Test Linf Norm: 0.2021\n",
            "Epoch 109: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4996, Test Linf Norm: 0.2021\n",
            "Epoch 110: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5006, Test Linf Norm: 0.2021\n",
            "Epoch 111: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4987, Test Linf Norm: 0.2021\n",
            "Epoch 112: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5021, Test Linf Norm: 0.2021\n",
            "Epoch 113: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4955, Test Linf Norm: 0.2021\n",
            "Epoch 114: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4937, Test Linf Norm: 0.2021\n",
            "Epoch 115: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4873, Test Linf Norm: 0.2021\n",
            "Epoch 116: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4955, Test Linf Norm: 0.2021\n",
            "Epoch 117: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4931, Test Linf Norm: 0.2021\n",
            "Epoch 118: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4984, Test Linf Norm: 0.2021\n",
            "Epoch 119: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5009, Test Linf Norm: 0.2021\n",
            "Epoch 120: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4989, Test Linf Norm: 0.2021\n",
            "Epoch 121: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5013, Test Linf Norm: 0.2021\n",
            "Epoch 122: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5007, Test Linf Norm: 0.2021\n",
            "Epoch 123: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4947, Test Linf Norm: 0.2021\n",
            "Epoch 124: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4996, Test Linf Norm: 0.2021\n",
            "Epoch 125: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5014, Test Linf Norm: 0.2021\n",
            "Epoch 126: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4894, Test Linf Norm: 0.2021\n",
            "Epoch 127: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4941, Test Linf Norm: 0.2021\n",
            "Epoch 128: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4995, Test Linf Norm: 0.2021\n",
            "Epoch 129: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4984, Test Linf Norm: 0.2021\n",
            "Epoch 130: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4866, Test Linf Norm: 0.2021\n",
            "Epoch 131: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4643, Test Linf Norm: 0.2021\n",
            "Epoch 132: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4936, Test Linf Norm: 0.2021\n",
            "Epoch 133: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4995, Test Linf Norm: 0.2021\n",
            "Epoch 134: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4962, Test Linf Norm: 0.2021\n",
            "Epoch 135: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4940, Test Linf Norm: 0.2021\n",
            "Epoch 136: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4933, Test Linf Norm: 0.2021\n",
            "Epoch 137: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4873, Test Linf Norm: 0.2021\n",
            "Epoch 138: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4976, Test Linf Norm: 0.2021\n",
            "Epoch 139: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4958, Test Linf Norm: 0.2021\n",
            "Epoch 140: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4943, Test Linf Norm: 0.2021\n",
            "Epoch 141: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4986, Test Linf Norm: 0.2021\n",
            "Epoch 142: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5027, Test Linf Norm: 0.2021\n",
            "Epoch 143: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.4975, Test Linf Norm: 0.2021\n",
            "Epoch 144: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5033, Test Linf Norm: 0.2021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-21 14:37:23,706]\u001b[0m Trial 102 finished with value: 0.006458121202141047 and parameters: {'n_layers': 3, 'n_units_0': 878, 'n_units_1': 606, 'n_units_2': 46, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'Adam', 'lr': 0.0012675691667619839, 'batch_size': 64, 'n_epochs': 145, 'scheduler': 'StepLR', 'weight_decay': 0.002208190199772827, 'beta1': 0.9988068899142324, 'beta2': 0.9995759484729847, 'step_size': 11, 'gamma': 0.20022219998253318}. Best is trial 25 with value: 0.005237087005376816.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 145: Train Loss: 0.0064, Test Loss: 0.0066, Train L1 Norm: 0.0112, Test L1 Norm: 0.0065, Train Linf Norm: 0.5020, Test Linf Norm: 0.2021\n",
            "Epoch 1: Train Loss: 0.1430, Test Loss: 0.0331, Train L1 Norm: 0.5771, Test L1 Norm: 0.0335, Train Linf Norm: 28.8828, Test Linf Norm: 0.8995\n",
            "Epoch 2: Train Loss: 0.0496, Test Loss: 0.0374, Train L1 Norm: 0.2218, Test L1 Norm: 0.0284, Train Linf Norm: 12.1262, Test Linf Norm: 0.5808\n",
            "Epoch 3: Train Loss: 0.0517, Test Loss: 0.0243, Train L1 Norm: 0.2260, Test L1 Norm: 0.0348, Train Linf Norm: 12.8025, Test Linf Norm: 1.3089\n",
            "Epoch 4: Train Loss: 0.0436, Test Loss: 0.0545, Train L1 Norm: 0.1291, Test L1 Norm: 0.0724, Train Linf Norm: 6.7732, Test Linf Norm: 2.3492\n",
            "Epoch 5: Train Loss: 0.0416, Test Loss: 0.0646, Train L1 Norm: 0.0845, Test L1 Norm: 0.0431, Train Linf Norm: 4.0138, Test Linf Norm: 1.1525\n",
            "Epoch 6: Train Loss: 0.0427, Test Loss: 0.0659, Train L1 Norm: 0.1234, Test L1 Norm: 0.0322, Train Linf Norm: 6.5969, Test Linf Norm: 0.6911\n",
            "Epoch 7: Train Loss: 0.0389, Test Loss: 0.0238, Train L1 Norm: 0.1123, Test L1 Norm: 0.0233, Train Linf Norm: 5.8988, Test Linf Norm: 0.7585\n",
            "Epoch 8: Train Loss: 0.0373, Test Loss: 0.0674, Train L1 Norm: 0.0817, Test L1 Norm: 0.0375, Train Linf Norm: 4.0579, Test Linf Norm: 0.9159\n",
            "Epoch 9: Train Loss: 0.0384, Test Loss: 0.0295, Train L1 Norm: 0.1115, Test L1 Norm: 0.0265, Train Linf Norm: 5.9270, Test Linf Norm: 0.8185\n",
            "Epoch 10: Train Loss: 0.0356, Test Loss: 0.0337, Train L1 Norm: 0.1290, Test L1 Norm: 0.0263, Train Linf Norm: 7.1261, Test Linf Norm: 0.7824\n",
            "Epoch 11: Train Loss: 0.0318, Test Loss: 0.0567, Train L1 Norm: 0.1065, Test L1 Norm: 0.0347, Train Linf Norm: 5.7745, Test Linf Norm: 0.9405\n",
            "Epoch 12: Train Loss: 0.0198, Test Loss: 0.0194, Train L1 Norm: 0.0724, Test L1 Norm: 0.0195, Train Linf Norm: 4.0124, Test Linf Norm: 0.6429\n",
            "Epoch 13: Train Loss: 0.0174, Test Loss: 0.0164, Train L1 Norm: 0.0507, Test L1 Norm: 0.0144, Train Linf Norm: 2.6735, Test Linf Norm: 0.4105\n",
            "Epoch 14: Train Loss: 0.0177, Test Loss: 0.0238, Train L1 Norm: 0.0542, Test L1 Norm: 0.0164, Train Linf Norm: 2.9110, Test Linf Norm: 0.4224\n",
            "Epoch 15: Train Loss: 0.0203, Test Loss: 0.0156, Train L1 Norm: 0.0425, Test L1 Norm: 0.0124, Train Linf Norm: 2.1018, Test Linf Norm: 0.3697\n"
          ]
        }
      ],
      "source": [
        "if OPTIMIZE:\n",
        "    # Creating a study object with Optuna with TPE sampler and median pruner \n",
        "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
        "\n",
        "    # Running Optuna with 100 trials when we are optimizing.\n",
        "    study.optimize(objective, n_trials=N_TRIALS)\n",
        "\n",
        "    # Printing the best trial information\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "    print(\"  Value: \", trial.value)\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(f\"    {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmMfE9_dUZiS"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phyiHlWEUZiT"
      },
      "outputs": [],
      "source": [
        "# Creating the best network and optimizer using the best hyperparameters\n",
        "if OPTIMIZE:\n",
        "    net, \\\n",
        "    loss_fn, \\\n",
        "    optimizer, \\\n",
        "    batch_size, \\\n",
        "    n_epochs, \\\n",
        "    scheduler, \\\n",
        "    loss_name, \\\n",
        "    optimizer_name, \\\n",
        "    scheduler_name, \\\n",
        "    n_units, \\\n",
        "    n_layers, \\\n",
        "    hidden_activation, \\\n",
        "    output_activation, \\\n",
        "    lr = create_model(trial, optimize=True)\n",
        "# Creating the network with predefined hyperparameters\n",
        "else:\n",
        "    net, \\\n",
        "    loss_fn, \\\n",
        "    optimizer, \\\n",
        "    batch_size, \\\n",
        "    n_epochs, \\\n",
        "    scheduler, \\\n",
        "    loss_name, \\\n",
        "    optimizer_name, \\\n",
        "    scheduler_name, \\\n",
        "    n_units, \\\n",
        "    n_layers, \\\n",
        "    hidden_activation, \\\n",
        "    output_activation, \\\n",
        "    lr = create_model(trial=None, optimize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yq-oY81UZiU"
      },
      "outputs": [],
      "source": [
        "print(\"loss_fn:\", loss_fn)\n",
        "print(\"batch_size:\", batch_size)\n",
        "print(\"n_epochs:\", n_epochs)\n",
        "print(\"scheduler:\", scheduler)\n",
        "print(\"loss_name:\", loss_name)\n",
        "print(\"optimizer_name:\", optimizer_name)\n",
        "print(\"scheduler_name:\", scheduler_name)\n",
        "print(\"n_units:\", n_units)\n",
        "print(\"n_layers:\", n_layers)\n",
        "print(\"hidden_activation:\", hidden_activation)\n",
        "print(\"output_activation:\", output_activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7aLWdZyUZiW"
      },
      "outputs": [],
      "source": [
        "# Training and evaluating the network using the train_and_eval function\n",
        "train_losses, test_losses, train_metrics, test_metrics = train_and_eval(\n",
        "    net, loss_fn, optimizer, batch_size, n_epochs, scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akNucrgMUZiW"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHsrs2Y-UZic"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# save the network to a .pth file\n",
        "torch.save(net.state_dict(), \"net.pth\")\n",
        "save_file(\"net.pth\")\n",
        "\n",
        "# save the optimizer to a .pth file\n",
        "torch.save(optimizer.state_dict(), \"optimizer.pth\")\n",
        "save_file(\"optimizer.pth\")\n",
        "\n",
        "# save the scheduler to a .pth file if it is not None\n",
        "if scheduler is not None:\n",
        "  torch.save(scheduler.state_dict(), \"scheduler.pth\")\n",
        "  save_file(\"scheduler.pth\")\n",
        "\n",
        "# create a dictionary to store the rest of the variables\n",
        "var_dict = {\n",
        "  \"batch_size\": batch_size,\n",
        "  \"n_epochs\": n_epochs,\n",
        "  \"loss_name\": loss_name,\n",
        "  \"optimizer_name\": optimizer_name,\n",
        "  \"scheduler_name\": scheduler_name,\n",
        "  \"n_units\": n_units,\n",
        "  \"n_layers\": n_layers,\n",
        "  \"hidden_activation_name\": hidden_activation.__class__.__name__,\n",
        "  \"output_activation_name\": output_activation.__class__.__name__,\n",
        "  \"lr\": lr,\n",
        "}\n",
        "\n",
        "# save the dictionary to a .json file\n",
        "with open(\"var_dict.json\", \"w\") as f:\n",
        "  json.dump(var_dict, f)\n",
        "save_file(\"var_dict.json\")\n",
        "\n",
        "# Saving the output of the training using pandas\n",
        "train_df = pd.DataFrame(\n",
        "    {\n",
        "        \"train_loss\": train_losses,\n",
        "        \"test_loss\": test_losses,\n",
        "        \"train_l1_norm\": [m[\"l1_norm\"] for m in train_metrics],\n",
        "        \"test_l1_norm\": [m[\"l1_norm\"] for m in test_metrics],\n",
        "        \"train_linf_norm\": [m[\"linf_norm\"] for m in train_metrics],\n",
        "        \"test_linf_norm\": [m[\"linf_norm\"] for m in test_metrics],\n",
        "    }\n",
        ")\n",
        "train_df.to_csv(\"train_output.csv\", index=False)\n",
        "save_file(\"train_output.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU23l7dIUZie"
      },
      "source": [
        "## Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cippWZS6UZie"
      },
      "outputs": [],
      "source": [
        "# Plotting the losses and metrics for the best network \n",
        "plt.figure(figsize=(12, 8))\n",
        "#plt.subplot(2, 2, 1)\n",
        "#plt.plot(train_losses, label=\"Train Loss\")\n",
        "#plt.plot(test_losses, label=\"Test Loss\")\n",
        "#plt.xlabel(\"Epoch\")\n",
        "#plt.ylabel(\"Loss\")\n",
        "#plt.legend()\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot([m[\"l1_norm\"] for m in train_metrics], label=\"Train L1 Norm\")\n",
        "plt.plot([m[\"l1_norm\"] for m in test_metrics], label=\"Test L1 Norm\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"L1 Norm\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-3, 1e2)\n",
        "plt.legend()\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot([m[\"linf_norm\"] for m in train_metrics], label=\"Train Linf Norm\")\n",
        "plt.plot([m[\"linf_norm\"] for m in test_metrics], label=\"Test Linf Norm\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Linf Norm\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-3, 1e2)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Added plotting MSE of training data and MSE of test data in one plot \n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_losses,label=\"training data\")\n",
        "plt.plot(test_losses,label=\"test data\")\n",
        "#if scheduler is not None:\n",
        "#    plt.plot([scheduler.get_last_lr()[0] for _ in range(n_epochs)], label=\"Learning rate\") \n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-7, 1e0)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiEDutxIUZig"
      },
      "source": [
        "## Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7Mj990wUZih"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# load the dictionary from the .json file\n",
        "with open(\"var_dict.json\", \"r\") as f:\n",
        "  var_dict_loaded = json.load(f)\n",
        "\n",
        "# extract the variables from the dictionary\n",
        "batch_size_loaded = var_dict_loaded[\"batch_size\"]\n",
        "n_epochs_loaded = var_dict_loaded[\"n_epochs\"]\n",
        "loss_name_loaded = var_dict_loaded[\"loss_name\"]\n",
        "optimizer_name_loaded = var_dict_loaded[\"optimizer_name\"]\n",
        "scheduler_name_loaded = var_dict_loaded[\"scheduler_name\"]\n",
        "n_units_loaded = var_dict_loaded[\"n_units\"]\n",
        "n_layers_loaded = var_dict_loaded[\"n_layers\"]\n",
        "hidden_activation_name_loaded = var_dict_loaded[\"hidden_activation_name\"]\n",
        "output_activation_name_loaded = var_dict_loaded[\"output_activation_name\"]\n",
        "lr_loaded = var_dict_loaded[\"lr\"]\n",
        "\n",
        "# create the activation functions from their names\n",
        "if hidden_activation_name_loaded == \"ReLU\":\n",
        "  hidden_activation_loaded = nn.ReLU()\n",
        "elif hidden_activation_name_loaded == \"LeakyReLU\":\n",
        "  hidden_activation_loaded = nn.LeakyReLU() \n",
        "elif hidden_activation_name_loaded == \"ELU\":\n",
        "  hidden_activation_loaded = nn.ELU() \n",
        "elif hidden_activation_name_loaded == \"Tanh\":\n",
        "  hidden_activation_loaded = nn.Tanh()\n",
        "else:\n",
        "  hidden_activation_loaded = nn.Sigmoid()\n",
        "\n",
        "if output_activation_name_loaded == \"ReLU\":\n",
        "    output_activation_loaded = nn.ReLU()\n",
        "elif output_activation_name_loaded == \"Softplus\":\n",
        "    output_activation_loaded = nn.Softplus()\n",
        "else:\n",
        "    output_activation_loaded = nn.Identity()\n",
        "\n",
        "\n",
        "\n",
        "# load the network from the .pth file\n",
        "net_loaded = Net(n_layers_loaded, n_units_loaded, hidden_activation_loaded, output_activation_loaded).to(device)\n",
        "if torch.cuda.is_available():\n",
        " net_loaded.load_state_dict(torch.load(\"net.pth\"))\n",
        "else: \n",
        "  net_loaded.load_state_dict(torch.load(\"net.pth\", map_location=torch.device('cpu')))\n",
        "\n",
        "# create the loss function from its name\n",
        "if loss_name_loaded == \"MSE\":\n",
        "  loss_fn_loaded = nn.MSELoss()\n",
        "elif loss_name_loaded == \"MAE\":\n",
        "  loss_fn_loaded = nn.L1Loss()\n",
        "elif loss_name_loaded == \"Huber\":\n",
        "  loss_fn_loaded = nn.SmoothL1Loss() \n",
        "else:\n",
        "  # create the log-cosh loss function\n",
        "  def log_cosh_loss_loaded(y_pred, y_true):\n",
        "    return torch.mean(torch.log(torch.cosh(y_pred - y_true)))\n",
        "  loss_fn_loaded = log_cosh_loss_loaded\n",
        "\n",
        "# load the optimizer from the .pth file\n",
        "if torch.cuda.is_available():\n",
        "  optimizer_loaded_state_dict = torch.load(\"optimizer.pth\")\n",
        "else:\n",
        "  optimizer_loaded_state_dict = torch.load(\"optimizer.pth\", map_location=torch.device('cpu'))\n",
        "\n",
        "if optimizer_name_loaded == \"SGD\":\n",
        "  # Added getting the weight decay and momentum parameters from the state dict\n",
        "  weight_decay_loaded = optimizer_loaded_state_dict[\"param_groups\"][0][\"weight_decay\"]\n",
        "  momentum_loaded = optimizer_loaded_state_dict[\"param_groups\"][0][\"momentum\"]\n",
        "  optimizer_loaded = optim.SGD(net_loaded.parameters(), lr=lr_loaded, weight_decay=weight_decay_loaded, momentum=momentum_loaded)\n",
        "elif optimizer_name_loaded == \"Adam\":\n",
        "  # Added getting the weight decay and beta parameters from the state dict\n",
        "  weight_decay_loaded = optimizer_loaded_state_dict[\"param_groups\"][0][\"weight_decay\"]\n",
        "  beta1_loaded = optimizer_loaded_state_dict[\"param_groups\"][0][\"betas\"][0]\n",
        "  beta2_loaded = optimizer_loaded_state_dict[\"param_groups\"][0][\"betas\"][1]\n",
        "  optimizer_loaded = optim.Adam(net_loaded.parameters(), lr=lr_loaded, weight_decay=weight_decay_loaded, betas=(beta1_loaded, beta2_loaded))\n",
        "elif optimizer_name_loaded == \"RMSprop\":\n",
        "  optimizer_loaded = optim.RMSprop(net_loaded.parameters(), lr=lr_loaded)\n",
        "else:\n",
        "  # Added loading the Adagrad optimizer\n",
        "  optimizer_loaded = optim.Adagrad(net_loaded.parameters(), lr=lr_loaded)\n",
        "optimizer_loaded.load_state_dict(optimizer_loaded_state_dict)\n",
        "\n",
        "# load the scheduler from the .pth file\n",
        "if torch.cuda.is_available():\n",
        "  scheduler_loaded_state_dict = torch.load(\"scheduler.pth\")\n",
        "else: \n",
        "  scheduler_loaded_state_dict = torch.load(\"scheduler.pth\", map_location=torch.device('cpu'))\n",
        "\n",
        "if scheduler_name_loaded == \"StepLR\":\n",
        "  # Added getting the step_size and gamma parameters from the state dict\n",
        "  step_size_loaded = scheduler_loaded_state_dict[\"step_size\"]\n",
        "  gamma_loaded = scheduler_loaded_state_dict[\"gamma\"]\n",
        "  scheduler_loaded = optim.lr_scheduler.StepLR(optimizer_loaded, step_size=step_size_loaded, gamma=gamma_loaded)\n",
        "elif scheduler_name_loaded == \"ExponentialLR\":\n",
        "  # Added getting the gamma parameter from the state dict\n",
        "  gamma_loaded = scheduler_loaded_state_dict[\"gamma\"]\n",
        "  scheduler_loaded = optim.lr_scheduler.ExponentialLR(optimizer_loaded, gamma=gamma_loaded)\n",
        "elif scheduler_name_loaded == \"CosineAnnealingLR\":\n",
        "  # Added getting the T_max parameter from the state dict\n",
        "  T_max_loaded = scheduler_loaded_state_dict[\"T_max\"]\n",
        "  scheduler_loaded = optim.lr_scheduler.CosineAnnealingLR(optimizer_loaded, T_max=T_max_loaded)\n",
        "elif scheduler_name_loaded == \"ReduceLROnPlateau\":\n",
        "  # Added getting the mode, factor, patience, threshold and min_lr parameters from the state dict\n",
        "  mode_loaded = scheduler_loaded_state_dict[\"mode\"]\n",
        "  factor_loaded = scheduler_loaded_state_dict[\"factor\"]\n",
        "  patience_loaded = scheduler_loaded_state_dict[\"patience\"]\n",
        "  threshold_loaded = scheduler_loaded_state_dict[\"threshold\"]\n",
        "  min_lr_loaded = scheduler_loaded_state_dict[\"min_lrs\"][0]\n",
        "  scheduler_loaded = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                    optimizer_loaded, mode=mode_loaded, factor=factor_loaded, patience=patience_loaded, threshold=threshold_loaded, min_lr=min_lr_loaded\n",
        "                )\n",
        "# elif scheduler_name_loaded == \"OneCycleLR\":\n",
        "#   max_lr_loaded = scheduler_loaded_state_dict[\"max_lr\"]\n",
        "#   epochs_loaded = scheduler_loaded_state_dict[\"epochs\"]\n",
        "#   steps_per_epoch_loaded = scheduler_loaded_state_dict[\"steps_per_epoch\"]\n",
        "#   pct_start_loaded = scheduler_loaded_state_dict[\"pct_start\"]\n",
        "#   max_lr_loaded = scheduler_loaded_state_dict[\"max_lr\"]\n",
        "#   scheduler_loaded = optim.lr_scheduler.OneCycleLR(\n",
        "#                     optimizer_loaded, max_lr=max_lr_loaded, epochs=epochs_loaded, steps_per_epoch=steps_per_epoch_loaded, pct_start=pct_start_loaded\n",
        "#                 )\n",
        "else:\n",
        "  scheduler_loaded = None\n",
        "\n",
        "if scheduler_loaded is not None:\n",
        "  # Added loading the state dict to the scheduler_loaded\n",
        "  scheduler_loaded.load_state_dict(scheduler_loaded_state_dict)\n",
        "\n",
        "# Loading the output of the training using pandas\n",
        "train_df_loaded = pd.read_csv(\"train_output.csv\")\n",
        "train_losses_loaded = train_df_loaded[\"train_loss\"].tolist()\n",
        "test_losses_loaded = train_df_loaded[\"test_loss\"].tolist()\n",
        "train_metrics_loaded = [\n",
        "    {\n",
        "        \"l1_norm\": train_df_loaded[\"train_l1_norm\"][i],\n",
        "        \"linf_norm\": train_df_loaded[\"train_linf_norm\"][i],\n",
        "    }\n",
        "    for i in range(len(train_df_loaded))\n",
        "]\n",
        "test_metrics_loaded = [\n",
        "    {\n",
        "        \"l1_norm\": train_df_loaded[\"test_l1_norm\"][i],\n",
        "        \"linf_norm\": train_df_loaded[\"test_linf_norm\"][i],\n",
        "    }\n",
        "    for i in range(len(train_df_loaded))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ_fcj7zUZii"
      },
      "outputs": [],
      "source": [
        "%%script echo skipping\n",
        "\n",
        "batch_size_loaded\n",
        "n_epochs_loaded\n",
        "loss_name_loaded\n",
        "optimizer_name_loaded\n",
        "scheduler_name_loaded\n",
        "n_units_loaded\n",
        "n_layers_loaded\n",
        "hidden_activation_name_loaded\n",
        "output_activation_name_loaded\n",
        "lr_loaded\n",
        "hidden_activation_loaded\n",
        "output_activation_loaded\n",
        "net_loaded\n",
        "net_loaded.__dict__ # print the subparameters of the network\n",
        "loss_fn_loaded\n",
        "optimizer_loaded\n",
        "optimizer_loaded.__dict__ # print the subparameters of the optimizer\n",
        "scheduler_loaded\n",
        "scheduler_loaded.__dict__ # print the subparameters of the scheduler\n",
        "train_losses_loaded\n",
        "test_losses_loaded\n",
        "train_metrics_loaded\n",
        "test_metrics_loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B0SHa5SvExY"
      },
      "outputs": [],
      "source": [
        "train_losses_loaded[-1]\n",
        "test_losses_loaded[-1]\n",
        "test_metrics_loaded[-1]['l1_norm']\n",
        "test_metrics_loaded[-1]['linf_norm']\n",
        "print(f'Error is {test_metrics_loaded[-1][\"l1_norm\"] / (3.84e-4)} times bigger than in Dieselhorst et al.')\n",
        "print(f'Error is {test_metrics_loaded[-1][\"linf_norm\"] / (8.14e-3)} times bigger than in Dieselhorst et al.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj2XBdtmvExY"
      },
      "source": [
        "### Visualize loaded results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwLGR1aSUZik"
      },
      "source": [
        "Let us verify correct loading of the train and test metrics by visualizing them again but now through the loaded values. Likewise for the train and test losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXiNgLsmUZil"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"last_expr_or_assign\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgq4WfSiUZil"
      },
      "outputs": [],
      "source": [
        "# Plotting the losses and metrics for the best network plt.figure(figsize=(12, \n",
        "#plt.subplot(2, 2, 1)\n",
        "#plt.plot(train_losses_loaded, label=\"Train Loss\")\n",
        "#plt.plot(test_losses_loaded, label=\"Test Loss\")\n",
        "#plt.xlabel(\"Epoch\")\n",
        "#plt.ylabel(\"Loss\")\n",
        "#plt.legend()\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot([m[\"l1_norm\"] for m in train_metrics_loaded], label=\"Train L1 Norm\")\n",
        "plt.plot([m[\"l1_norm\"] for m in test_metrics_loaded], label=\"Test L1 Norm\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"L1 Norm\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-3, 1e2)\n",
        "plt.legend()\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot([m[\"linf_norm\"] for m in train_metrics_loaded], label=\"Train Linf Norm\")\n",
        "plt.plot([m[\"linf_norm\"] for m in test_metrics_loaded], label=\"Test Linf Norm\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Linf Norm\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-3, 1e2)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Added plotting MSE of training data and MSE of test data in one plot \n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_losses_loaded,label=\"training data\")\n",
        "plt.plot(test_losses_loaded,label=\"test data\")\n",
        "#if scheduler is not None:\n",
        "#    plt.plot([scheduler.get_last_lr()[0] for _ in range(n_epochs)], label=\"Learning rate\") \n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-7, 1e0)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkgLqJ_UUZim"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EZQMUK8vExY"
      },
      "source": [
        "## Counting the number of parameters in the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWToFZmnvExZ"
      },
      "outputs": [],
      "source": [
        "net_loaded.eval()\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {count_parameters(net_loaded)} parameters.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxuzVSnlUZin"
      },
      "source": [
        "## Evaluating the network on arbirary input\n",
        "### Comparing `net` and `net_loaded`\n",
        "\n",
        "We compare `net` and `net_loaded` to confirm correct loading of the network. Note that `net` is only available if we have trained the model in this session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0PLAA0DUZin"
      },
      "outputs": [],
      "source": [
        "%%script echo skipping\n",
        "\n",
        "print(list(net.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NZ8iVA7UZio"
      },
      "outputs": [],
      "source": [
        "print(list(net_loaded.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXLYbm8uUZio"
      },
      "outputs": [],
      "source": [
        "%%script echo skipping\n",
        "\n",
        "# Set the network to evaluation mode\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InGW0Xq6UZip"
      },
      "outputs": [],
      "source": [
        "rho_example, vx_example, vy_example, vz_example, epsilon_example = sample_primitive_variables(20)\n",
        "\n",
        "# Create arbitrary input\n",
        "inputs =  generate_input_data(rho_example, vx_example, vy_example, vz_example, epsilon_example)\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVa1upmFUZip"
      },
      "outputs": [],
      "source": [
        "%%script echo skipping\n",
        "\n",
        "# Pass the inputs to the network and get the outputs\n",
        "outputs = [net(input) for input in inputs]\n",
        "# Print the outputs\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih9p2bosUZiq"
      },
      "outputs": [],
      "source": [
        "# Set the network to evaluation mode\n",
        "net_loaded.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-Xjfo7VUZir"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Pass the inputs to the network and get the outputs\n",
        "outputs = [net_loaded(input) for input in inputs]\n",
        "# Print the outputs\n",
        "outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjpIvdybUZis"
      },
      "source": [
        "## Porting the model to C++"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMlEd4RoUZis"
      },
      "outputs": [],
      "source": [
        "import torch.jit\n",
        "\n",
        "# Creating a dummy input tensor of shape (1, 5) to trace the model\n",
        "dummy_input = torch.randn(1, 5).to(device)\n",
        "dummy_input\n",
        "\n",
        "# Ensure that net_loaded is in evaluation mode.\n",
        "net_loaded.eval()\n",
        "\n",
        "# Tracing the model using the torch.jit.trace function\n",
        "traced_model = torch.jit.trace(net_loaded, dummy_input)\n",
        "\n",
        "# Saving the traced model to a file named \"net.pt\"\n",
        "traced_model.save(\"net.pt\")\n",
        "save_file(\"net.pt\")\n",
        "\n",
        "example_input_to_validate_correct_export_and_import = generate_input_data(*sample_primitive_variables(1))\n",
        "example_input_to_validate_correct_export_and_import\n",
        "net_loaded(example_input_to_validate_correct_export_and_import)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "bsc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TPvB1xoSUZhR"
      },
      "source": [
        "# Neural network to learn conservative-to-primitive conversion in relativistic hydrodynamics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to use this notebook\n",
        "\n",
        "### Local installation\n",
        "\n",
        "1. Install required packages with `pip install -r requirements.txt` to your desired environment.\n",
        "2. If a script version of this notebook is desired, comment (not uncomment) the first line of `nbconvert` cell.\n",
        "\n",
        "### Colab installation\n",
        "\n",
        "1.  Comment (not uncomment) the first line of the drive mounting cell.\n",
        "2.  Comment (not uncomment) the first line of the `pip install` cell.\n",
        "\n",
        "<!-- - For colab we also want to set the runtime to GPU by clicking _Change runtime_ in the _Runtime_ menu, and -->\n",
        "<!-- - We want to wait for the google drive connection popup to appear and follow the instructions. -->\n",
        "\n",
        "### Loading / Generating data\n",
        "3. Set `LOAD_DATA_FROM_CSV` to `True` / `False` to load data from csv files / generate data in this notebook.\n",
        "\n",
        "### Training without optimization\n",
        "\n",
        "4. Set `OPTIMIZE = False` in section _Constants and flags to set_.\n",
        "5. Run the entire notebook.\n",
        "\n",
        "### Training with optimization\n",
        "\n",
        "4. Set `OPTIMIZE = True` in section _Constants and flags to set_.\n",
        "5. Run the entire notebook.\n",
        "\n",
        "### Loading an already trained model\n",
        "\n",
        "4. Run cells in section _Initialization_.\n",
        "5. Run cells with definitions in section _Input data and labels_.\n",
        "6. Run cell with the definition of _Net_ in section _Defining the neural network_.\n",
        "7. Make sure the `net.pth`, `optimizer.pth`, `scheduler.pth`, `var_dict.json` and `train_output.csv` files are in the directory containing this notebook.\n",
        "8. Run the cells in section _Loading_ and continue from there.\n",
        "\n",
        "### Generating the C++ model\n",
        "\n",
        "9. Run section _Porting the model to C++_, this requires a model to be loaded.\n",
        "10. Set the path to the `net.pt` file in the C++ source file.\n",
        "11. `mkdir build && cd build`,\n",
        "12. Configure a `CMakeLists.txt` file as is done [here](https://pytorch.org/cppdocs/installing.html).\n",
        "13. `cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch/ ..`,\n",
        "14. Compile and run, e.g. `cmake --build . --config release && ./<executable name>`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialization"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Use this first cell to **convert this notebook** to a python script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqdgdNLHUZhV",
        "outputId": "30907b9d-56c3-44d7-cd43-6387a991a46a",
        "tags": [
          "remove_cell"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook pt1_before_restructuring.ipynb to script\n",
            "[NbConvertApp] Writing 64257 bytes to pt1_before_restructuring.py\n"
          ]
        }
      ],
      "source": [
        "%%script echo skipping\n",
        "\n",
        "!jupyter nbconvert pt1_before_restructuring.ipynb --TagRemovePreprocessor.enabled=True --TagRemovePreprocessor.remove_cell_tags='{\"remove_cell\"}' --to script"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nzcUr0LnUZhw"
      },
      "source": [
        "Next some cells for working on **google colab**,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# check if the drive is mounted\n",
        "drive_mounted = os.path.exists(\"/content/drive\")\n",
        "# change this to your desired folder\n",
        "drive_folder = \"/content/drive/My Drive/bsc/con2prim_GRMHD\"\n",
        "\n",
        "# define a function to save a file to the drive or the current directory\n",
        "def save_file(file_name):\n",
        "  if drive_mounted:\n",
        "    # save the file to the drive folder\n",
        "    file_path = os.path.join(drive_folder, file_name)\n",
        "    # copy the file from the current directory to the drive folder\n",
        "    shutil.copyfile(file_name, file_path)\n",
        "  else:\n",
        "    # do nothing as the file is already in the current directory\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecHw2_xlUZhx",
        "outputId": "462a57cd-ee19-4961-d3aa-ff2407b2bde0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skipping\n"
          ]
        }
      ],
      "source": [
        "%%script echo skipping\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1rcStMLUZhy",
        "outputId": "7ea7311f-f054-4a29-d0ff-12849095ab6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skipping\n"
          ]
        }
      ],
      "source": [
        "%%script echo skipping\n",
        "\n",
        "!pip install optuna tensorboard tensorboardX"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing the **libraries**,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tREdWQUVUZhz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import optuna\n",
        "import tensorboardX as tbx\n",
        "import pandas as pd"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "38GvmerjUZhz"
      },
      "source": [
        "### Constants and flags to set\n",
        "Defining some constants and parameters for convenience.\n",
        "\n",
        "**NOTE**: Some **subparameters** still need to be adjusted in the `create_model` function itself as of (Tue May 16 07:42:45 AM CEST 2023) in the case the model is being trained without optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ei6VZDYKUZh0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Checking if GPU is available and setting the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "N_TRIALS = 250 # Number of trials for hyperparameter optimization\n",
        "OPTIMIZE = False # Whether to optimize the hyperparameters or to use predetermined values from Dieseldorst et al..\n",
        "ZSCORE_NORMALIZATION = False # Whether to z-score normalize the input data.\n",
        "LOAD_DATA_FROM_CSV = False  # If not true we generate the data in this file and save to {x_train,y_train,x_test,y_test}.csv, otherwise we load the data from files of the same name.\n",
        "\n",
        "csv_filenames = { # File names to load input data and labels from if LOAD_DATA_FROM_CSV is True.\n",
        "    \"x_train\": \"x_train.csv\",\n",
        "    \"y_train\": \"y_train.csv\",\n",
        "    \"x_test\": \"x_test.csv\",\n",
        "    \"y_test\": \"y_test.csv\",\n",
        "}\n",
        "\n",
        "# Values to use for hyperparameters if OPTIMIZE is False.\n",
        "N_LAYERS_NO_OPT = 3\n",
        "N_UNITS_NO_OPT = [555, 458, 115]\n",
        "HIDDEN_ACTIVATION_NAME_NO_OPT = \"ReLU\"\n",
        "OUTPUT_ACTIVATION_NAME_NO_OPT = \"ReLU\"\n",
        "LOSS_NAME_NO_OPT = \"Huber\"\n",
        "OPTIMIZER_NAME_NO_OPT = \"RMSprop\"\n",
        "LR_NO_OPT = 0.000122770896701404\n",
        "BATCH_SIZE_NO_OPT = 49\n",
        "N_EPOCHS_NO_OPT = 100\n",
        "SCHEDULER_NAME_NO_OPT = \"ReduceLROnPlateau\"\n",
        "\n",
        "Gamma = 5 / 3  # Adiabatic index\n",
        "n_train_samples = 80000 # Number of training samples\n",
        "n_test_samples = 20000 # Number of test samples\n",
        "rho_interval = (0, 2) # sample in linear space\n",
        "epsilon_interval = (1e-2, 2000)  # Will be sampled in log space\n",
        "vx_interval = (0, 0.999)  # sample in linear space\n",
        "vy_interval = (0, 0.999)  # sample in linear space\n",
        "vz_interval = (0, 0.999)  # sample in linear space\n",
        "Bx_interval = (-10, 10)  # sample in linear space\n",
        "By_interval = (-10, 10)  # sample in linear space\n",
        "Bz_interval = (-10, 10)  # sample in linear space\n",
        "gxx_interval = (0.9, 1.1)\n",
        "gxy_interval = (0, 0.1)\n",
        "gxz_interval = (0, 0.1)\n",
        "gyy_interval = (0.9, 1.1)\n",
        "gyz_interval = (0, 0.1)\n",
        "gzz_interval = (0.9, 1.1)\n",
        "\n",
        "\n",
        "N_INPUTS = 14  # Number of input features.\n",
        "\n",
        "np.random.seed(48) # Comment for true random data.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dlaP5UL2UZh1"
      },
      "source": [
        "## Input data and labels\n",
        "\n",
        "We either generate the data or load the data. First the definitions for generating the data come below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s_EvGFZcUZh1"
      },
      "outputs": [],
      "source": [
        "# Defining an analytic equation of state (EOS) for an ideal gas\n",
        "def eos_analytic(rho, epsilon):\n",
        "    # Adding some assertions to check that the input tensors are valid and have \n",
        "    # the expected shape and type \n",
        "    assert isinstance(rho, torch.Tensor), \"rho must be a torch.Tensor\"\n",
        "    assert isinstance(epsilon, torch.Tensor), \"epsilon must be a torch.Tensor\"\n",
        "    print('rho.shape: ', rho.shape)\n",
        "    print('epsilon.shape: ', epsilon.shape)\n",
        "    assert rho.shape == epsilon.shape, \"rho and epsilon must have the same shape\"\n",
        "    assert rho.ndim == 1, \"rho and epsilon must be one-dimensional tensors\"\n",
        "    assert rho.dtype == torch.float32, \"rho and epsilon must have dtype torch.float32\"\n",
        "\n",
        "    return (Gamma - 1) * rho * epsilon\n",
        "\n",
        "\n",
        "\n",
        "def sample_primitive_variables():\n",
        "    rho = np.random.uniform(*rho_interval)  \n",
        "    epsilon = 10 ** np.random.uniform(*np.log10(epsilon_interval))\n",
        "    vx = np.random.uniform(*vx_interval)  \n",
        "    vy = np.random.uniform(*vy_interval)  \n",
        "    vz = np.random.uniform(*vz_interval)  \n",
        "    Bx = np.random.uniform(*Bx_interval)  \n",
        "    By = np.random.uniform(*By_interval)  \n",
        "    Bz = np.random.uniform(*Bz_interval)  \n",
        "    gxx = np.random.uniform(*gxx_interval)\n",
        "    gxy = np.random.uniform(*gxy_interval)\n",
        "    gxz = np.random.uniform(*gxz_interval)\n",
        "    gyy = np.random.uniform(*gyy_interval)\n",
        "    gyz = np.random.uniform(*gyz_interval)\n",
        "    gzz = np.random.uniform(*gzz_interval)\n",
        "\n",
        "    return rho, epsilon, vx, vy, vz, Bx, By, Bz, gxx, gxy, gxz, gyy, gyz, gzz\n",
        "\n",
        "def check_sample(rho, epsilon, vx, vy, vz, Bx, By, Bz, gxx, gxy, gxz, gyy, gyz, gzz):\n",
        "    wtemp_expr = 1 - (gxx * vx**2 + gyy * vy**2 + gzz * vz**2 + 2 * gxy * vx * vy + 2 * gxz * vx * vz + 2 * gyz * vy * vz)\n",
        "    sdet_expr = gxx * gyy * gzz + 2 * gxy * gxz * gyz - gxx * gyz ** 2 - gyy * gxz ** 2 - gzz * gxy ** 2\n",
        "    if vx**2 + vy**2 + vz**2 >= 1 or wtemp_expr < 0 or sdet_expr < 0:\n",
        "        print(f\"Sample failed checks. vx^2+vy^2+vz^2: {vx**2 + vy**2 + vz**2}, wtemp_expr: {wtemp_expr}, sdet_expr: {sdet_expr}\")\n",
        "        return False\n",
        "    else:\n",
        "        print(f\"Sample passed checks. vx^2+vy^2+vz^2: {vx**2 + vy**2 + vz**2}, wtemp_expr: {wtemp_expr}, sdet_expr: {sdet_expr}\")\n",
        "        return True\n",
        "\n",
        "def generate_samples(n_samples):\n",
        "    samples = []\n",
        "    while len(samples) < n_samples:\n",
        "        sample = sample_primitive_variables()\n",
        "        if check_sample(*sample):\n",
        "            samples.append(sample)\n",
        "        print(f\"Number of valid samples: {len(samples)}\")\n",
        "    return zip(*samples)\n",
        "\n",
        "\n",
        "def sdet(gxx, gxy, gxz, gyy, gyz, gzz):\n",
        "    # Determinant of the three metric.\n",
        "    return (gxx * gyy * gzz + 2 * gxy * gxz * gyz - gxx * gyz ** 2 - gyy * gxz ** 2 - gzz * gxy ** 2) ** 0.5\n",
        "\n",
        "# Defining a function that computes conserved variables from primitive variables\n",
        "# We follow the source code of GRaM-X: A new GPU-accelerated dynamical spacetime GRMHD code for Exascale\n",
        "# computing with the Einstein Toolkit of Shankar et al.\n",
        "def compute_conserved_variables(rho, epsilon, vx, vy, vz, Bx, By, Bz, gxx, gxy, gxz, gyy, gyz, gzz):\n",
        "    pres = eos_analytic(rho, epsilon)\n",
        "    wtemp = 1 / (1 - (gxx * vx**2 + gyy * vy**2 + gzz * vz**2 +\n",
        "        2 * gxy * vx * vy + 2 * gxz * vx * vz +\n",
        "        2 * gyz * vy * vz))**0.5\n",
        "\n",
        "    vlowx = gxx * vx + gxy * vy + gxz * vz\n",
        "    vlowy = gxy * vx + gyy * vy + gyz * vz\n",
        "    vlowz = gxz * vx + gyz * vy + gzz * vz\n",
        "\n",
        "    Bxlow = gxx * Bx + gxy * By + gxz * Bz\n",
        "    Bylow = gxy * Bx + gyy * By + gyz * Bz\n",
        "    Bzlow = gxz * Bx + gyz * By + gzz * Bz\n",
        "\n",
        "    B2 = Bxlow * Bx + Bylow * By + Bzlow * Bz\n",
        "\n",
        "    Bdotv = Bxlow * vx + Bylow * vy + Bzlow * vz\n",
        "    Bdotv2 = Bdotv * Bdotv\n",
        "    wtemp2 = wtemp * wtemp\n",
        "    b2 = B2 / wtemp2 + Bdotv2\n",
        "    ab0 = wtemp * Bdotv\n",
        "\n",
        "    blowx = (gxx * Bx + gxy * By + gxz * Bz) / wtemp + wtemp * Bdotv * vlowx\n",
        "    blowy = (gxy * Bx + gyy * By + gyz * Bz) / wtemp + wtemp * Bdotv * vlowy\n",
        "    blowz = (gxz * Bx + gyz * By + gzz * Bz) / wtemp + wtemp * Bdotv * vlowz\n",
        "\n",
        "    hrhow2 = (rho * (1 + epsilon) + pres + b2) * (wtemp) * (wtemp)\n",
        "\n",
        "    D = sdet(gxx, gxy, gxz, gyy, gyz, gzz) * rho * (wtemp)\n",
        "    Sx = sdet(gxx, gxy, gxz, gyy, gyz, gzz) * (hrhow2 * vlowx - ab0 * blowx)\n",
        "    Sy = sdet(gxx, gxy, gxz, gyy, gyz, gzz) * (hrhow2 * vlowy - ab0 * blowy)\n",
        "    Sz = sdet(gxx, gxy, gxz, gyy, gyz, gzz) * (hrhow2 * vlowz - ab0 * blowz)\n",
        "    tau = sdet(gxx, gxy, gxz, gyy, gyz, gzz) * (hrhow2 - pres - b2 / 2 - ab0 * ab0) - D\n",
        "    Bconsx = sdet(gxx, gxy, gxz, gyy, gyz, gzz) * Bx\n",
        "    Bconsy = sdet(gxx, gxy, gxz, gyy, gyz, gzz) * By\n",
        "    Bconsz = sdet(gxx, gxy, gxz, gyy, gyz, gzz) * Bz\n",
        "\n",
        "    return D, Sx, Sy, Sz, tau, Bconsx, Bconsy, Bconsz\n",
        "\n",
        "\n",
        "def generate_input_data(rho, epsilon, vx, vy, vz, Bx, By, Bz, gxx, gxy, gxz, gyy, gyz, gzz):\n",
        "    rho = torch.tensor(np.array(rho), dtype=torch.float32).to(device)\n",
        "    epsilon = torch.tensor(np.array(epsilon), dtype=torch.float32).to(device)\n",
        "    vx = torch.tensor(np.array(vx), dtype=torch.float32).to(device)\n",
        "    vy = torch.tensor(np.array(vy), dtype=torch.float32).to(device)\n",
        "    vz = torch.tensor(np.array(vz), dtype=torch.float32).to(device)\n",
        "    Bx = torch.tensor(np.array(Bx), dtype=torch.float32).to(device)\n",
        "    By = torch.tensor(np.array(By), dtype=torch.float32).to(device)\n",
        "    Bz = torch.tensor(np.array(Bz), dtype=torch.float32).to(device)\n",
        "    gxx = torch.tensor(np.array(gxx), dtype=torch.float32).to(device)\n",
        "    gxy = torch.tensor(np.array(gxy), dtype=torch.float32).to(device)\n",
        "    gxz = torch.tensor(np.array(gxz), dtype=torch.float32).to(device)\n",
        "    gyy = torch.tensor(np.array(gyy), dtype=torch.float32).to(device)\n",
        "    gyz = torch.tensor(np.array(gyz), dtype=torch.float32).to(device)\n",
        "    gzz = torch.tensor(np.array(gzz), dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "    \n",
        "    D, Sx, Sy, Sz, tau, Bscriptx, Bscripty, Bscriptz = compute_conserved_variables(\n",
        "        rho, epsilon, vx, vy, vz, Bx, By, Bz, gxx, gxy, gxz, gyy, gyz, gzz\n",
        "    ) \n",
        "\n",
        "    # Add gxx, gxy, gxz, gyy, gyz, gzz to the tensor\n",
        "    x = torch.stack([D, Sx, Sy, Sz, tau, Bscriptx, Bscripty, Bscriptz, gxx, gxy, gxz, gyy, gyz, gzz], axis=1)\n",
        "    return x\n",
        "\n",
        "\n",
        "# Defining a function that generates output data (labels) from given samples of primitive variables\n",
        "# We use the definitions as given in Recovery schemes for primitive variables in\n",
        "# general-relativistic magnetohydrodynamics of Siegel et al.\n",
        "def generate_labels(rho, epsilon, vx, vy, vz):\n",
        "    # Converting the numpy arrays to torch tensors and moving them to the device\n",
        "    rho = torch.tensor(np.array(rho), dtype=torch.float32).to(device)\n",
        "    epsilon = torch.tensor(np.array(epsilon), dtype=torch.float32).to(device)\n",
        "    vx = torch.tensor(np.array(vx), dtype=torch.float32).to(device)\n",
        "    vy = torch.tensor(np.array(vy), dtype=torch.float32).to(device)\n",
        "    vz = torch.tensor(np.array(vz), dtype=torch.float32).to(device)\n",
        "\n",
        "    # Computing the required quantities\n",
        "    pres = eos_analytic(rho, epsilon)\n",
        "    h = 1 + epsilon + pres / rho\n",
        "    W = 1 / torch.sqrt(1 - (vx * vx + vy * vy + vz * vz))\n",
        "\n",
        "    # Returning the output data tensor\n",
        "    return h * W\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating or loading input data and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cKubR6C8UZh4"
      },
      "outputs": [],
      "source": [
        "if LOAD_DATA_FROM_CSV:\n",
        "    # Load the data from CSV files\n",
        "    x_train = pd.read_csv(csv_filenames[\"x_train\"]).values\n",
        "    y_train = pd.read_csv(csv_filenames[\"y_train\"]).values.squeeze()  # reshape to 1D\n",
        "    x_test = pd.read_csv(csv_filenames[\"x_test\"]).values\n",
        "    y_test = pd.read_csv(csv_filenames[\"y_test\"]).values.squeeze()  # reshape to 1D\n",
        "\n",
        "    # Convert numpy arrays to tensors\n",
        "    x_train = torch.from_numpy(x_train).float().to(device)\n",
        "    y_train = torch.from_numpy(y_train).float().to(device)\n",
        "    x_test = torch.from_numpy(x_test).float().to(device)\n",
        "    y_test = torch.from_numpy(y_test).float().to(device)\n",
        "\n",
        "    # This is an alternative to having if clauses  around the cells that visualize these variables.\n",
        "    rho_train = epsilon_train = vx_train = vy_train = vz_train = Bx_train = By_train = Bz_train = gxx_train = gxy_train = gxz_train = gyy_train = gyz_train = gzz_train = None\n",
        "    rho_test = epsilon_test = vx_test = vy_test = vz_test = Bx_test = By_test = Bz_test = gxx_test = gxy_test = gxz_test = gyy_test = gyz_test = gzz_test = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not LOAD_DATA_FROM_CSV:\n",
        "    # Sample primitive variables\n",
        "    rho_train, epsilon_train, vx_train, vy_train, vz_train, Bx_train, By_train, Bz_train, gxx_train, gxy_train, gxz_train, gyy_train, gyz_train, gzz_train = generate_samples(n_train_samples)\n",
        "    rho_test, epsilon_test, vx_test, vy_test, vz_test, Bx_test, By_test, Bz_test, gxx_test, gxy_test, gxz_test, gyy_test, gyz_test, gzz_test = generate_samples(n_test_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not LOAD_DATA_FROM_CSV:\n",
        "    # Generate data and labels.\n",
        "    x_train = generate_input_data(rho_train, epsilon_train, vx_train, vy_train,\n",
        "                                vz_train, Bx_train, By_train, Bz_train,\n",
        "                                gxx_train,gxy_train,gxz_train,\n",
        "                                gyy_train,gyz_train,gzz_train)\n",
        "    y_train = generate_labels(rho_train, epsilon_train, vx_train, vy_train, vz_train)\n",
        "    x_test = generate_input_data(rho_test, epsilon_test,vx_test,\n",
        "                                vy_test,vz_test,Bx_test,\n",
        "                                By_test,Bz_test,gxx_test,\n",
        "                                gxy_test,gxz_test,\n",
        "                                gyy_test,\n",
        "                                gyz_test,gzz_test)\n",
        "    y_test = generate_labels(rho_test, epsilon_test, vx_test, vy_test, vz_test)\n",
        "\n",
        "\n",
        "    # Save the data to CSV files, tensors need to be converted numpy arrays for saving in CSV.\n",
        "    pd.DataFrame(x_train.cpu().numpy()).to_csv(csv_filenames[\"x_train\"], index=False)\n",
        "    save_file(csv_filenames[\"x_train\"])\n",
        "    pd.DataFrame(y_train.cpu().numpy()).to_csv(csv_filenames[\"y_train\"], index=False)\n",
        "    save_file(csv_filenames[\"y_train\"])\n",
        "    pd.DataFrame(x_test.cpu().numpy()).to_csv(csv_filenames[\"x_test\"], index=False)\n",
        "    save_file(csv_filenames[\"x_test\"])\n",
        "    pd.DataFrame(y_test.cpu().numpy()).to_csv(csv_filenames[\"y_test\"], index=False)\n",
        "    save_file(csv_filenames[\"y_test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([80000, 14])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([80000])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([20000, 14])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([20000])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.8716e-01,  7.5934e+01,  3.0697e+02,  ...,  1.0898e+00,\n",
              "          8.5216e-02,  9.1937e-01],\n",
              "        [ 7.3964e-01,  4.0687e+00,  2.6314e+00,  ...,  1.0757e+00,\n",
              "          9.3174e-03,  1.0479e+00],\n",
              "        [ 1.4281e+00, -5.6663e+00,  5.6765e+00,  ...,  9.2143e-01,\n",
              "          4.2960e-02,  9.4379e-01],\n",
              "        ...,\n",
              "        [ 4.1816e+00,  1.1259e+02, -1.9415e+00,  ...,  9.8020e-01,\n",
              "          2.9073e-02,  9.5646e-01],\n",
              "        [ 2.5769e+00,  2.8073e+01,  2.7713e+01,  ...,  1.0462e+00,\n",
              "          4.8189e-02,  1.0549e+00],\n",
              "        [ 8.0853e-01,  2.2680e+02,  2.1269e+02,  ...,  1.0365e+00,\n",
              "          6.5952e-02,  9.9179e-01]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "tensor([1.9615e+03, 1.7365e+00, 1.1416e+00,  ..., 2.5371e+00, 2.3193e+00,\n",
              "        5.2725e+02])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0115e+00, -5.5370e+00,  1.9948e+01,  ...,  9.7624e-01,\n",
              "          8.5910e-02,  9.9501e-01],\n",
              "        [ 1.9448e+00,  4.4434e+01,  2.5474e+01,  ...,  1.0081e+00,\n",
              "          4.0891e-02,  1.0872e+00],\n",
              "        [ 5.3569e-01,  3.6203e+01,  6.6400e+01,  ...,  9.3537e-01,\n",
              "          7.4418e-02,  1.0006e+00],\n",
              "        ...,\n",
              "        [ 3.3717e+00,  1.3276e+02,  1.4400e+02,  ...,  1.0096e+00,\n",
              "          5.2414e-02,  1.0323e+00],\n",
              "        [ 5.5446e+00,  3.3080e+01,  6.7095e+01,  ...,  1.0597e+00,\n",
              "          3.5000e-02,  1.0338e+00],\n",
              "        [ 1.7135e-01,  3.2854e+01, -6.0162e+00,  ...,  9.7208e-01,\n",
              "          6.6548e-02,  9.4791e-01]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "tensor([185.2968,   1.9312,   1.3596,  ...,   1.9870,   2.3008,   2.2992])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "x_train.shape\n",
        "y_train.shape\n",
        "x_test.shape\n",
        "y_test.shape\n",
        "x_train\n",
        "y_train\n",
        "x_test\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.isnan(x_train).any()\n",
        "torch.isnan(x_test).any()\n",
        "torch.isnan(y_train).any()\n",
        "torch.isnan(y_test).any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([], dtype=torch.int64), tensor([], dtype=torch.int64))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(tensor([], dtype=torch.int64), tensor([], dtype=torch.int64))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nan_mask_train = torch.isnan(x_train)     # get a boolean mask indicating NaN values\n",
        "nan_indices_train = torch.where(nan_mask_train)  # get the indices of the NaN values\n",
        "nan_indices_train\n",
        "# len(nan_indices_train)\n",
        "\n",
        "nan_mask_test = torch.isnan(x_test)     # get a boolean mask indicating NaN values\n",
        "nan_indices_test = torch.where(nan_mask_train)  # get the indices of the NaN values\n",
        "nan_indices_test\n",
        "# len(nan_indices_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing sampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not LOAD_DATA_FROM_CSV:\n",
        "    rho_train\n",
        "    epsilon_train\n",
        "    vx_train\n",
        "    vy_train\n",
        "    vz_train \n",
        "    Bx_train\n",
        "    By_train\n",
        "    Bz_train\n",
        "    rho_test\n",
        "    epsilon_test\n",
        "    vx_test \n",
        "    vy_test \n",
        "    vz_test \n",
        "    Bx_test\n",
        "    By_test\n",
        "    Bz_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VMp6XJ6RUZh4"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"last_expr_or_assign\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "E5YFdqKjUZh5",
        "outputId": "fe67d113-f369-495f-9aba-201c71058eb7"
      },
      "outputs": [],
      "source": [
        "if not LOAD_DATA_FROM_CSV:\n",
        "    def plot_histogram(data, xlabel, ylabel, position, bins=20, log_scale=False):\n",
        "        plt.subplot(4, 5, position)\n",
        "        plt.hist(data, bins=bins)\n",
        "        plt.xlabel(xlabel)\n",
        "        plt.ylabel(ylabel)\n",
        "        if log_scale:\n",
        "            plt.yscale(\"log\")\n",
        "\n",
        "    # Plotting the histograms of rho, vx, epsilon, b0, b1, b2, and b3\n",
        "    plt.figure(figsize=(20, 16))\n",
        "\n",
        "    plot_histogram(rho_train, \"rho\", \"Frequency\", 1)\n",
        "    plot_histogram(epsilon_train, \"epsilon\", \"Frequency\", 2)\n",
        "    plot_histogram(vx_train, \"vx\", \"Frequency\", 3)\n",
        "    plot_histogram(vy_train, \"vy\", \"Frequency\", 4)\n",
        "    plot_histogram(vz_train, \"vz\", \"Frequency\", 5)\n",
        "    plot_histogram(Bx_train, \"Bx\", \"Frequency\", 6)\n",
        "    plot_histogram(By_train, \"By\", \"Frequency\", 7)\n",
        "    plot_histogram(Bz_train, \"Bz\", \"Frequency\", 8)\n",
        "    \n",
        "    # Plot these\n",
        "    plot_histogram(gxx_train, \"gxx\", \"Frequency\", 9)\n",
        "    plot_histogram(gxy_train, \"gxy\", \"Frequency\", 10)\n",
        "    plot_histogram(gxz_train, \"gxz\", \"Frequency\", 11)\n",
        "    plot_histogram(gyy_train, \"gyy\", \"Frequency\", 12)\n",
        "    plot_histogram(gyz_train, \"gyz\", \"Frequency\", 13)\n",
        "    plot_histogram(gzz_train, \"gzz\", \"Frequency\", 14)\n",
        "    # Adjust the layout as needed for the additional plots\n",
        "\n",
        "    plt.suptitle(\"Primitive variables\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"last_expr_or_assign\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not LOAD_DATA_FROM_CSV:\n",
        "    # List of variable names\n",
        "    variable_names = [\"D\", \"Sx\", \"Sy\", \"Sz\", \"tau\", \"Bconsx\", \"Bconsy\", \"Bconsz\"]\n",
        "\n",
        "    # Note how we are only plotting train and not test here. \n",
        "    # Plotting histograms of the input variables before z-score normalization\n",
        "    plt.figure(figsize=(16, 16))\n",
        "    plt.suptitle('Histograms of input variables before (or without at all) z-score normalization', y=1.03)\n",
        "    for i in range(8):\n",
        "        plt.subplot(4, 2, i+1)\n",
        "        plt.hist(x_train[:, i].cpu(), bins=50) # Must be converted to cpu() for plotting.\n",
        "        plt.xlabel(variable_names[i])\n",
        "    plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "    plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary statistics of input variables before z-score normalization\n",
            "tensor([[ 9.7052e-05,  3.7091e+02,  2.2732e+00,  1.6640e+00,  3.8177e+00],\n",
            "        [-1.0271e+02,  2.9075e+07,  1.2100e+03,  2.9006e+01,  1.1198e+05],\n",
            "        [-1.1450e+02,  8.8010e+07,  1.9362e+03,  2.9005e+01,  3.1443e+05],\n",
            "        [-1.1251e+02,  3.3182e+07,  1.5666e+03,  2.8695e+01,  1.6428e+05],\n",
            "        [ 9.1172e-02,  9.2603e+07,  3.0230e+03,  7.9949e+01,  3.5179e+05],\n",
            "        [-1.1122e+01,  1.1157e+01, -3.2049e-02, -2.0577e-02,  5.7435e+00],\n",
            "        [-1.1184e+01,  1.1075e+01,  4.5558e-03,  6.5811e-03,  5.7127e+00],\n",
            "        [-1.1186e+01,  1.1202e+01, -8.1075e-03, -1.0597e-03,  5.7419e+00],\n",
            "        [ 9.0000e-01,  1.1000e+00,  9.9841e-01,  9.9768e-01,  5.7839e-02],\n",
            "        [ 3.5574e-06,  9.9999e-02,  4.9444e-02,  4.9061e-02,  2.8869e-02],\n",
            "        [ 3.0095e-07,  9.9994e-02,  4.9509e-02,  4.9396e-02,  2.8867e-02],\n",
            "        [ 9.0000e-01,  1.1000e+00,  9.9840e-01,  9.9731e-01,  5.7798e-02],\n",
            "        [ 2.7129e-06,  9.9999e-02,  4.9647e-02,  4.9551e-02,  2.8913e-02],\n",
            "        [ 9.0000e-01,  1.1000e+00,  9.9869e-01,  9.9799e-01,  5.7425e-02]])\n"
          ]
        }
      ],
      "source": [
        "# Computing summary statistics of the input variables before and after z-score normalization\n",
        "print('Summary statistics of input variables before z-score normalization')\n",
        "print(torch.stack([torch.min(x_train, dim=0).values, torch.max(x_train, dim=0).values, torch.nanmean(x_train, dim=0), torch.median(x_train, dim=0).values, torch.std(x_train, dim=0)], dim=1))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xTEmkR1SUZh7"
      },
      "source": [
        "Perform z-score normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yPOv6DxhUZh7"
      },
      "outputs": [],
      "source": [
        "if ZSCORE_NORMALIZATION:\n",
        "    \n",
        "    # TODO: Add magnetic field variables to the normalization if I decide to use the old code that is commented out here.\n",
        "    # # Computing the median of each input variable from the training set using torch.nanmedian function\n",
        "    # D_median = torch.nanmedian(x_train[:, 0])\n",
        "    # Sx_median = torch.nanmedian(x_train[:, 1])\n",
        "    # Sy_median = torch.nanmedian(x_train[:, 2])\n",
        "    # Sz_median = torch.nanmedian(x_train[:, 3])\n",
        "    # tau_median = torch.nanmedian(x_train[:, 4])\n",
        "\n",
        "    # # Computing the standard deviation of each input variable from the training set using torch.std function with a boolean mask to ignore nan values\n",
        "    # D_std = torch.std(x_train[~torch.isnan(x_train[:, 0]), 0])\n",
        "    # Sx_std = torch.std(x_train[~torch.isnan(x_train[:, 1]), 1])\n",
        "    # Sy_std = torch.std(x_train[~torch.isnan(x_train[:, 2]), 2])\n",
        "    # Sz_std = torch.std(x_train[~torch.isnan(x_train[:, 3]), 3])\n",
        "    # tau_std = torch.std(x_train[~torch.isnan(x_train[:, 4]), 4])\n",
        "\n",
        "\n",
        "    # # Applying z-score normalization to both train and test sets using the statistics from the training set\n",
        "    # x_train[:, 0] = torch.sub(x_train[:, 0], D_median).div(D_std)\n",
        "    # x_train[:, 1] = torch.sub(x_train[:, 1], Sx_median).div(Sx_std)\n",
        "    # x_train[:, 2] = torch.sub(x_train[:, 2], Sy_median).div(Sy_std)\n",
        "    # x_train[:, 3] = torch.sub(x_train[:, 3], Sz_median).div(Sz_std)\n",
        "    # x_train[:, 4] = torch.sub(x_train[:, 4], tau_median).div(tau_std)\n",
        "\n",
        "    # x_test[:, 0] = torch.sub(x_test[:, 0], D_median).div(D_std)\n",
        "    # x_test[:, 1] = torch.sub(x_test[:, 1], Sx_median).div(Sx_std)\n",
        "    # x_test[:, 2] = torch.sub(x_test[:, 2], Sy_median).div(Sy_std)\n",
        "    # x_test[:, 3] = torch.sub(x_test[:, 3], Sz_median).div(Sz_std)\n",
        "    # x_test[:, 4] = torch.sub(x_test[:, 4], tau_median).div(tau_std)\n",
        "\n",
        "    # Computing the mean and standard deviation of each column\n",
        "    mean = x_train.mean(dim=0)\n",
        "    std = x_train.std(dim=0)\n",
        "\n",
        "    # Applying z-score normalization\n",
        "    x_train = (x_train - mean) / std\n",
        "    # Use the same mean and std from the training data as we don't want test data leakage.\n",
        "    x_test = (x_test - mean) / std\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the histograms of the input data after normalization if z-score normalization was performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"last_expr_or_assign\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not LOAD_DATA_FROM_CSV:\n",
        "    if ZSCORE_NORMALIZATION:\n",
        "        # List of variable names\n",
        "        variable_names = [\"D\", \"Sx\", \"Sy\", \"Sz\", \"tau\", \"Bconsx\", \"Bconsy\", \"Bconsz\"]\n",
        "\n",
        "        # Note how we are only plotting train and not test here. \n",
        "        # Plotting histograms of the input variables before z-score normalization\n",
        "        plt.figure(figsize=(16, 16))\n",
        "        plt.suptitle('Histograms of input variables after z-score normalization', y=1.03)\n",
        "        for i in range(8):\n",
        "            plt.subplot(4, 2, i+1)\n",
        "            plt.hist(x_train[:, i].cpu(), bins=50) # Must be converted to cpu() for plotting.\n",
        "            plt.xlabel(variable_names[i])\n",
        "        plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ZSCORE_NORMALIZATION:\n",
        "    # Computing summary statistics of the input variables after z-score normalization\n",
        "    print('Summary statistics of input variables after z-score normalization')\n",
        "    print(torch.stack([torch.min(x_train, dim=0).values, torch.max(x_train, dim=0).values, torch.mean(x_train, dim=0), torch.median(x_train, dim=0).values, torch.std(x_train, dim=0)], dim=1))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing input data and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([185.2968,   1.9312,   1.3596,  ...,   1.9870,   2.3008,   2.2992])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train\n",
        "y_train\n",
        "x_test\n",
        "y_test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "E96p_MsOUZh9",
        "outputId": "4b95bad0-8f3a-4364-eed1-008e0ce2a5e3"
      },
      "source": [
        "Checking if our output is always positive by plotting a histogram of y_train and y_test tensors "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Note how we are only plotting train.\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(y_train.cpu().numpy(), bins=20) # must be cpu here.\n",
        "plt.xlabel(\"y_train\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.yscale(\"log\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(y_test.cpu().numpy(), bins=20) # must be cpu here\n",
        "plt.xlabel(\"y_test\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.yscale(\"log\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FEgjk--AUZh9"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r2b9GecHUZh9"
      },
      "source": [
        "## Defining the neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Iv8HA-ZXUZh-"
      },
      "outputs": [],
      "source": [
        "# Defining a class for the network\n",
        "class Net(nn.Module):\n",
        "    \"\"\"A class for creating a network with a\n",
        "    variable number of hidden layers and units.\n",
        "\n",
        "    Attributes:\n",
        "        n_layers (int): The number of hidden layers in the network.\n",
        "        n_units (list): A list of integers representing the number of units in each hidden layer.\n",
        "        hidden_activation (torch.nn.Module): The activation function for the hidden layers.\n",
        "        output_activation (torch.nn.Module): The activation function for the output layer.\n",
        "        layers (torch.nn.ModuleList): A list of linear layers in the network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_layers, n_units, hidden_activation, output_activation):\n",
        "        \"\"\"Initializes the network with the given hyperparameters.\n",
        "\n",
        "        Args:\n",
        "            n_layers (int): The number of hidden layers in the network.\n",
        "            n_units (list): A list of integers representing the number of units in each hidden layer.\n",
        "            hidden_activation (torch.nn.Module): The activation function for the hidden layers.\n",
        "            output_activation (torch.nn.Module): The activation function for the output layer.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.n_units = n_units\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.output_activation = output_activation\n",
        "\n",
        "        # Creating a list of linear layers with different numbers of units for each layer\n",
        "        self.layers = nn.ModuleList([nn.Linear(N_INPUTS, n_units[0])])\n",
        "        for i in range(1, n_layers):\n",
        "            self.layers.append(nn.Linear(n_units[i - 1], n_units[i]))\n",
        "        self.layers.append(nn.Linear(n_units[-1], 1))\n",
        "\n",
        "        # Adding some assertions to check that the input arguments are valid\n",
        "        assert isinstance(n_layers, int) and n_layers > 0, \"n_layers must be a positive integer\"\n",
        "        assert isinstance(n_units, list) and len(n_units) == n_layers, \"n_units must be a list of length n_layers\"\n",
        "        assert all(isinstance(n, int) and n > 0 for n in n_units), \"n_units must contain positive integers\"\n",
        "        assert isinstance(hidden_activation, nn.Module), \"hidden_activation must be a torch.nn.Module\"\n",
        "        assert isinstance(output_activation, nn.Module), \"output_activation must be a torch.nn.Module\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Performs a forward pass on the input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor of shape (batch_size, N_INPUTS).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output tensor of shape (batch_size, 1).\n",
        "        \"\"\"\n",
        "        # Adding an assertion to check that the input tensor has the expected shape and type\n",
        "        assert isinstance(x, torch.Tensor), \"x must be a torch.Tensor\"\n",
        "        assert x.shape[1] == N_INPUTS, f\"x must have shape (batch_size, {N_INPUTS})\"\n",
        "\n",
        "        # Looping over the hidden layers and applying the linear transformation and the activation function\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = self.hidden_activation(layer(x))\n",
        "        # Applying the linear transformation and the activation function on the output layer\n",
        "        x = self.output_activation(self.layers[-1](x))\n",
        "\n",
        "        # Returning the output tensor\n",
        "        return x\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6GNvp55PUZh_"
      },
      "source": [
        "## Defining the model and search space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9a1opluOUZh_"
      },
      "outputs": [],
      "source": [
        "# Defining a function to create a trial network and optimizer\n",
        "def create_model(trial, optimize):\n",
        "    \"\"\"Creates a trial network and optimizer based on the sampled hyperparameters.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): The trial object that contains the hyperparameters.\n",
        "        optimize (boolean): Whether to optimize the hyperparameters or to use predefined values.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple of (net, loss_fn, optimizer, batch_size, n_epochs,\n",
        "            scheduler, loss_name, optimizer_name, scheduler_name,\n",
        "            n_units, n_layers, hidden_activation, output_activation),\n",
        "            where net is the trial network,\n",
        "            loss_fn is the loss function,\n",
        "            optimizer is the optimizer,\n",
        "            batch_size is the batch size,\n",
        "            n_epochs is the number of epochs,\n",
        "            scheduler is the learning rate scheduler,\n",
        "            loss_name is the name of the loss function,\n",
        "            optimizer_name is the name of the optimizer,\n",
        "            scheduler_name is the name of the scheduler,\n",
        "            n_units is a list of integers representing\n",
        "            the number of units in each hidden layer,\n",
        "            n_layers is an integer representing the number of hidden layers in the network,\n",
        "            hidden_activation is a torch.nn.Module representing the activation function for the hidden layers,\n",
        "            output_activation is a torch.nn.Module representing the activation function for the output layer,\n",
        "            lr is the (initial) learning rate.\n",
        "    \"\"\"\n",
        "    # If optimize is True, sample the hyperparameters from the search space\n",
        "    if OPTIMIZE:\n",
        "        # Sampling the hyperparameters from the search space\n",
        "        n_layers = trial.suggest_int(\"n_layers\", 2, 6)\n",
        "        n_units = [trial.suggest_int(f\"n_units_{i}\", 16, 2048) for i in range(n_layers)] \n",
        "        hidden_activation_name = trial.suggest_categorical(\n",
        "            #\"hidden_activation\", [\"ReLU\", \"LeakyReLU\", \"ELU\", \"Tanh\", \"Sigmoid\"]\n",
        "            #\"hidden_activation\", [\"ReLU\", \"LeakyReLU\"]\n",
        "            \"hidden_activation\", [\"ReLU\", \"LeakyReLU\", \"ELU\"]\n",
        "        )\n",
        "        output_activation_name = trial.suggest_categorical(\n",
        "            #\"output_activation\", [\"Linear\", \"ReLU\", \"Softplus\"]\n",
        "            # Assuming pressure cannot be negative, linear output activation is not an option.\n",
        "            #\"output_activation\", [\"ReLU\", \"Softplus\", \"Linear\"]\n",
        "            \"output_activation\", [\"ReLU\", \"Linear\"]\n",
        "        ) \n",
        "        loss_name = trial.suggest_categorical(\n",
        "            #\"loss\", [\"MSE\", \"MAE\", \"Huber\", \"LogCosh\"] \n",
        "            \"loss\", [\"MSE\", \"MAE\", \"Huber\"] \n",
        "        )\n",
        "        optimizer_name = trial.suggest_categorical(\n",
        "            \"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\", \"Adagrad\"] \n",
        "        )\n",
        "        lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2) \n",
        "\n",
        "        batch_size_list = [32, 48, 64, 96, 128, 256, 512, 1048]\n",
        "        batch_size = trial.suggest_categorical(\"batch_size\", batch_size_list)\n",
        "        #batch_size = trial.suggest_int(\"batch_size\", 64, 1048)\n",
        "        n_epochs = trial.suggest_int(\"n_epochs\", 100, 300) \n",
        "        scheduler_name = trial.suggest_categorical(\n",
        "            \"scheduler\",\n",
        "            # [\"None\", \"CosineAnnealingLR\", \"ReduceLROnPlateau\", \"StepLR\", \"ExponentialLR\"],\n",
        "            [\"CosineAnnealingLR\", \"ReduceLROnPlateau\", \"StepLR\"],\n",
        "        )\n",
        "\n",
        "    # If optimize is False, use the predefined values\n",
        "    else:\n",
        "        # Setting the hyperparameters to the predefined values\n",
        "        n_layers = N_LAYERS_NO_OPT\n",
        "        n_units = N_UNITS_NO_OPT\n",
        "        hidden_activation_name = HIDDEN_ACTIVATION_NAME_NO_OPT\n",
        "        output_activation_name = OUTPUT_ACTIVATION_NAME_NO_OPT\n",
        "        loss_name = LOSS_NAME_NO_OPT\n",
        "        optimizer_name = OPTIMIZER_NAME_NO_OPT\n",
        "        lr = LR_NO_OPT\n",
        "        batch_size = BATCH_SIZE_NO_OPT\n",
        "        n_epochs = N_EPOCHS_NO_OPT\n",
        "        scheduler_name = SCHEDULER_NAME_NO_OPT\n",
        "\n",
        "\n",
        "    # Creating the activation functions from their names\n",
        "    if hidden_activation_name == \"ReLU\":\n",
        "        hidden_activation = nn.ReLU()\n",
        "    elif hidden_activation_name == \"LeakyReLU\":\n",
        "        hidden_activation = nn.LeakyReLU() \n",
        "    elif hidden_activation_name == \"ELU\":\n",
        "        hidden_activation = nn.ELU() \n",
        "    elif hidden_activation_name == \"Tanh\":\n",
        "        hidden_activation = nn.Tanh()\n",
        "    else:\n",
        "        hidden_activation = nn.Sigmoid()\n",
        "\n",
        "    if output_activation_name == \"ReLU\":\n",
        "        output_activation = nn.ReLU()\n",
        "    elif output_activation_name == \"Softplus\":\n",
        "        output_activation = nn.Softplus()\n",
        "    else:\n",
        "        output_activation = nn.Identity()\n",
        "\n",
        "    # Creating the loss function from its name\n",
        "    if loss_name == \"MSE\":\n",
        "        loss_fn = nn.MSELoss()\n",
        "    elif loss_name == \"MAE\":\n",
        "        loss_fn = nn.L1Loss()\n",
        "    elif loss_name == \"Huber\":\n",
        "        loss_fn = nn.SmoothL1Loss() \n",
        "    else:\n",
        "        # Creating the log-cosh loss function\n",
        "        def log_cosh_loss(y_pred, y_true):\n",
        "            return torch.mean(torch.log(torch.cosh(y_pred - y_true)))\n",
        "            \n",
        "        loss_fn = log_cosh_loss\n",
        "\n",
        "    # Creating the network with the sampled hyperparameters\n",
        "    net = Net(\n",
        "        n_layers, n_units, hidden_activation, output_activation\n",
        "    ).to(device)\n",
        "\n",
        "    if OPTIMIZE:\n",
        "        # Creating the optimizer from its name\n",
        "        if optimizer_name == \"SGD\":\n",
        "            # Added sampling the weight decay and momentum for SGD\n",
        "            weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)\n",
        "            momentum = trial.suggest_uniform(\"momentum\", 0.0, 0.99)\n",
        "            optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
        "        elif optimizer_name == \"Adam\":\n",
        "            # Added sampling the weight decay and beta parameters for Adam\n",
        "            weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)\n",
        "            beta1 = trial.suggest_uniform(\"beta1\", 0.9, 0.999)\n",
        "            beta2 = trial.suggest_uniform(\"beta2\", 0.999, 0.9999)\n",
        "            optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay, betas=(beta1, beta2))\n",
        "        elif optimizer_name == \"RMSprop\":\n",
        "            optimizer = optim.RMSprop(net.parameters(), lr=lr)\n",
        "        else:\n",
        "            # Added creating the Adagrad optimizer\n",
        "            optimizer = optim.Adagrad(net.parameters(), lr=lr)\n",
        "\n",
        "        # Creating the learning rate scheduler from its name\n",
        "        if scheduler_name == \"StepLR\":\n",
        "            step_size = trial.suggest_int(\"step_size\", 5, 15)\n",
        "            gamma = trial.suggest_uniform(\"gamma\", 0.1, 0.5)\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "        elif scheduler_name == \"ExponentialLR\":\n",
        "            gamma = trial.suggest_uniform(\"gamma\", 0.8, 0.99)\n",
        "            scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
        "        elif scheduler_name == \"CosineAnnealingLR\":\n",
        "            if n_epochs < 150:\n",
        "                t_max_fraction = trial.suggest_uniform('t_max_fraction', 0.1, 0.3)\n",
        "            elif n_epochs > 250:\n",
        "                t_max_fraction = trial.suggest_uniform('t_max_fraction', 0.05, 0.1)\n",
        "            else:\n",
        "                t_max_fraction = trial.suggest_uniform('t_max_fraction', 0.1, 0.2)\n",
        "\n",
        "            T_max = int(n_epochs * t_max_fraction)\n",
        "            eta_min = trial.suggest_loguniform(\"eta_min\", 1e-7, 1e-2)\n",
        "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n",
        "        elif scheduler_name == \"ReduceLROnPlateau\":\n",
        "            # Added sampling the factor, patience and threshold for ReduceLROnPlateau\n",
        "            factor = trial.suggest_uniform(\"factor\", 0.1, 0.5)\n",
        "            patience = trial.suggest_int(\"patience\", 5, 10)\n",
        "            threshold = trial.suggest_loguniform(\"threshold\", 1e-4, 1e-2)\n",
        "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                optimizer, mode=\"min\", factor=factor, patience=patience, threshold=threshold\n",
        "            )\n",
        "        # # Added using OneCycleLR scheduler as an option\n",
        "        # elif scheduler_name == \"OneCycleLR\":\n",
        "        #         # Added sampling the max_lr and pct_start for OneCycleLR\n",
        "        #         max_lr = trial.suggest_loguniform(\"max_lr\", lr, 10 * lr) \n",
        "        #         pct_start = trial.suggest_uniform(\"pct_start\", 0.1, 0.9)\n",
        "        #         scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "        #             optimizer,\n",
        "        #             max_lr=max_lr,\n",
        "        #             epochs=n_epochs,\n",
        "        #             steps_per_epoch=len(train_loader),\n",
        "        #             pct_start=pct_start,\n",
        "        #         )\n",
        "        else:\n",
        "            scheduler = None\n",
        "    else:\n",
        "        # Creating the optimizer from its name\n",
        "        if optimizer_name == \"SGD\":\n",
        "            optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "        elif optimizer_name == \"Adam\":\n",
        "            optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "        elif optimizer_name == \"RMSprop\":\n",
        "            optimizer = optim.RMSprop(net.parameters(), lr=lr)\n",
        "        else:\n",
        "            optimizer = optim.Adagrad(net.parameters(), lr=lr)\n",
        "\n",
        "        # Creating the learning rate scheduler from its name\n",
        "        if scheduler_name == \"StepLR\":\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "        elif scheduler_name == \"ExponentialLR\":\n",
        "            scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "        elif scheduler_name == \"CosineAnnealingLR\":\n",
        "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer)\n",
        "        elif scheduler_name == \"ReduceLROnPlateau\":\n",
        "            # Creating the ReduceLROnPlateau scheduler with a threshold value of 0.01\n",
        "            #scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            #    optimizer, mode=\"min\", factor=0.1, patience=10, threshold=0.01\n",
        "            #)\n",
        "            # Use Dieseldorst et al. settings and add to that a minimum lr.\n",
        "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                        optimizer, mode=\"min\", factor=0.18979341786654758, patience=11, threshold=0.0017197466122611932 #, min_lr=1e-6\n",
        "                    )\n",
        "        else:\n",
        "            scheduler = None\n",
        "\n",
        "    # Returning all variables needed for saving and loading\n",
        "    return net, loss_fn, optimizer, batch_size, n_epochs, scheduler, loss_name, optimizer_name, scheduler_name, n_units, n_layers, hidden_activation, output_activation, lr\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l-czA7VvUZiD"
      },
      "source": [
        " ## The training and evaluation loop\n",
        "\n",
        " We first define a couple of functions used in the training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aD6FQNmxUZiD"
      },
      "outputs": [],
      "source": [
        "# Defining a function that computes loss and metrics for a given batch\n",
        "def compute_loss_and_metrics(y_pred, y_true, loss_fn):\n",
        "    \"\"\"Computes loss and metrics for a given batch.\n",
        "\n",
        "    Args:\n",
        "        y_pred (torch.Tensor): The predicted pressure tensor of shape (batch_size, 1).\n",
        "        y_true (torch.Tensor): The true pressure tensor of shape (batch_size,).\n",
        "        loss_fn (torch.nn.Module or function): The loss function to use.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple of (loss, l1_norm), where loss is a scalar tensor,\n",
        "            l1_norm is L1 norm for relative error of pressure,\n",
        "            each being a scalar tensor.\n",
        "            linf_norm is Linf norm for relative error of pressure.\n",
        "    \"\"\"\n",
        "    # Reshaping the target tensor to match the input tensor\n",
        "    y_true = y_true.view(-1, 1)\n",
        "\n",
        "    # Computing the loss using the loss function\n",
        "    loss = loss_fn(y_pred, y_true)\n",
        "\n",
        "    # Computing the relative error of pressure\n",
        "    rel_error = torch.abs((y_pred - y_true) / y_true)\n",
        "\n",
        "    # Computing the L1 norm for the relative error of pressure\n",
        "    l1_norm = torch.mean(rel_error) \n",
        "    # Computing the Linf norm for the relative error of pressure\n",
        "    linf_norm = torch.max(rel_error) \n",
        "\n",
        "    # Returning the loss and metrics\n",
        "    return loss, l1_norm, linf_norm\n",
        "\n",
        "\n",
        "# Defining a function that updates the learning rate scheduler with validation loss if applicable\n",
        "def update_scheduler(scheduler, test_loss):\n",
        "    \"\"\"Updates the learning rate scheduler with validation loss if applicable.\n",
        "\n",
        "    Args:\n",
        "        scheduler (torch.optim.lr_scheduler._LRScheduler or None): The learning rate scheduler to use.\n",
        "        test_loss (float): The validation loss to use.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Checking if scheduler is not None\n",
        "    if scheduler is not None:\n",
        "        # Checking if scheduler is ReduceLROnPlateau\n",
        "        if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "            # Updating the scheduler with test_loss\n",
        "            scheduler.step(test_loss)\n",
        "        else:\n",
        "            # Updating the scheduler without test_loss\n",
        "            scheduler.step()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w1nE662UUZiE"
      },
      "source": [
        "Now for the actual training and evaluation loop,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YAOjgKW3UZiF"
      },
      "outputs": [],
      "source": [
        "# Defining a function to train and evaluate a network\n",
        "def train_and_eval(net, loss_fn, optimizer, batch_size, n_epochs, scheduler, trial=None):\n",
        "    \"\"\"Trains and evaluates a network.\n",
        "\n",
        "    Args:\n",
        "        net (torch.nn.Module): The network to train and evaluate.\n",
        "        loss_fn (torch.nn.Module or function): The loss function.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer.\n",
        "        batch_size (int): The batch size.\n",
        "        n_epochs (int): The number of epochs.\n",
        "        scheduler (torch.optim.lr_scheduler._LRScheduler or None): The learning rate scheduler.\n",
        "    Returns:\n",
        "        tuple: A tuple of (train_losses, test_losses, train_metrics, test_metrics), where\n",
        "            train_losses is a list of training losses for each epoch,\n",
        "            test_losses is a list of validation losses for each epoch,\n",
        "            train_metrics is a list of dictionaries containing training metrics for each epoch,\n",
        "            test_metrics is a list of dictionaries containing validation metrics for each epoch.\n",
        "    \"\"\"\n",
        "    # Creating data loaders for train and test sets\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # Initializing lists to store the losses and metrics for each epoch\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_metrics = []\n",
        "    test_metrics = []\n",
        "\n",
        "    # Creating a SummaryWriter object to log data for tensorboard\n",
        "    writer = tbx.SummaryWriter()\n",
        "\n",
        "    # Looping over the epochs\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # Setting the network to training mode\n",
        "        net.train()\n",
        "\n",
        "        # Initializing variables to store the total loss and metrics for the train set\n",
        "        train_loss = 0.0\n",
        "        train_l1_norm = 0.0\n",
        "        train_linf_norm = 0.0\n",
        "\n",
        "        # Looping over the batches in the train set\n",
        "        for x_batch, y_batch in train_loader:\n",
        "\n",
        "            # Moving the batch tensors to the device\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            # Zeroing the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Performing a forward pass and computing the loss and metrics\n",
        "            y_pred = net(x_batch)\n",
        "            loss, l1_norm, linf_norm = compute_loss_and_metrics(\n",
        "                y_pred, y_batch, loss_fn\n",
        "            )\n",
        "\n",
        "\n",
        "            # Performing a backward pass and updating the weights\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Updating the total loss and metrics for the train set\n",
        "            train_loss += loss.item() * x_batch.size(0)\n",
        "            train_l1_norm += l1_norm.item() * x_batch.size(0)\n",
        "            train_linf_norm += linf_norm.item() * x_batch.size(0)\n",
        "\n",
        "        # Computing the average loss and metrics for the train set\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_l1_norm /= len(train_loader.dataset)\n",
        "        train_linf_norm /= len(train_loader.dataset)\n",
        "\n",
        "        # Appending the average loss and metrics for the train set to the lists\n",
        "        train_losses.append(train_loss)\n",
        "        train_metrics.append(\n",
        "            {\n",
        "                \"l1_norm\": train_l1_norm,\n",
        "                \"linf_norm\": train_linf_norm,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Logging the average loss and metrics for the train set to tensorboard\n",
        "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
        "        writer.add_scalar(\"L1 norm/train\", train_l1_norm, epoch)\n",
        "        writer.add_scalar(\"Linf norm/train\", train_linf_norm, epoch)\n",
        "\n",
        "        # Setting the network to evaluation mode\n",
        "        net.eval()\n",
        "\n",
        "        # Initializing variables to store the total loss and metrics for the test set\n",
        "        test_loss = 0.0\n",
        "        test_l1_norm = 0.0\n",
        "        test_linf_norm = 0.0\n",
        "\n",
        "        # Looping over the batches in the test set\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in test_loader:\n",
        "\n",
        "                # Moving the batch tensors to the device\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "\n",
        "                # Performing a forward pass and computing the loss and metrics\n",
        "                y_pred = net(x_batch)\n",
        "                loss, l1_norm, linf_norm = compute_loss_and_metrics(\n",
        "                    y_pred, y_batch, loss_fn\n",
        "                )\n",
        "\n",
        "\n",
        "                # Updating the total loss and metrics for the test set\n",
        "                test_loss += loss.item() * x_batch.size(0)\n",
        "                test_l1_norm += l1_norm.item() * x_batch.size(0)\n",
        "                test_linf_norm += linf_norm.item() * x_batch.size(0)\n",
        "\n",
        "        # Computing the average loss and metrics for the test set\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_l1_norm /= len(test_loader.dataset)\n",
        "        test_linf_norm /= len(test_loader.dataset)\n",
        "\n",
        "        # Appending the average loss and metrics for the test set to the lists\n",
        "        test_losses.append(test_loss)\n",
        "        test_metrics.append(\n",
        "            {\n",
        "                \"l1_norm\": test_l1_norm,\n",
        "                \"linf_norm\": test_linf_norm,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Logging the average loss and metrics for the test set to tensorboard\n",
        "        writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
        "        writer.add_scalar(\"L1 norm/test\", test_l1_norm, epoch)\n",
        "        writer.add_scalar(\"Linf norm/test\", test_linf_norm, epoch)\n",
        "\n",
        "        # Printing the average loss and metrics for both sets for this epoch\n",
        "        print(\n",
        "            f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, \"\n",
        "            f\"Train L1 Norm: {train_l1_norm:.4f}, Test L1 Norm: {test_l1_norm:.4f}, \"\n",
        "            f\"Train Linf Norm: {train_linf_norm:.4f}, Test Linf Norm: {test_linf_norm:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Updating the learning rate scheduler with validation loss if applicable\n",
        "        update_scheduler(scheduler, test_loss)\n",
        "\n",
        "        # Reporting the intermediate metric value to Optuna if trial is not None\n",
        "        if trial is not None:\n",
        "            trial.report(test_metrics[-1][\"l1_norm\"], epoch)\n",
        "\n",
        "            # Checking if the trial should be pruned based on the intermediate value if trial is not None\n",
        "            if trial.should_prune():\n",
        "                raise optuna.TrialPruned()\n",
        "\n",
        "    # Closing the SummaryWriter object\n",
        "    writer.close()\n",
        "\n",
        "    # Returning the losses and metrics lists\n",
        "    return train_losses, test_losses, train_metrics, test_metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xg9jz0SvUZiQ"
      },
      "source": [
        "## The objective function and hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fmRncQPuUZiR"
      },
      "outputs": [],
      "source": [
        "# Defining an objective function for Optuna to minimize\n",
        "def objective(trial):\n",
        "    \"\"\"Defines an objective function for Optuna to minimize.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): The trial object that contains the hyperparameters.\n",
        "\n",
        "    Returns:\n",
        "        float: The validation L1 norm to minimize.\n",
        "    \"\"\"\n",
        "    # Creating a trial network and optimizer using the create_model function\n",
        "    net, \\\n",
        "    loss_fn, \\\n",
        "    optimizer, \\\n",
        "    batch_size, \\\n",
        "    n_epochs, \\\n",
        "    scheduler, \\\n",
        "    loss_name, \\\n",
        "    optimizer_name, \\\n",
        "    scheduler_name, \\\n",
        "    n_units, \\\n",
        "    n_layers, \\\n",
        "    hidden_activation, \\\n",
        "    output_activation, \\\n",
        "    lr = create_model(trial, optimize=True)\n",
        "\n",
        "    # Training and evaluating the network using the train_and_eval function\n",
        "    _, _, _, test_metrics = train_and_eval(\n",
        "        net, loss_fn, optimizer, batch_size, n_epochs, scheduler, trial\n",
        "    )\n",
        "\n",
        "    # Returning the last validation L1 norm as the objective value to minimize\n",
        "    return test_metrics[-1][\"l1_norm\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GyES4NAyUZiS"
      },
      "outputs": [],
      "source": [
        "if OPTIMIZE:\n",
        "    # Creating a study object with Optuna with TPE sampler and median pruner \n",
        "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
        "\n",
        "    # Running Optuna with 100 trials when we are optimizing.\n",
        "    study.optimize(objective, n_trials=N_TRIALS)\n",
        "\n",
        "    # Printing the best trial information\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "    print(\"  Value: \", trial.value)\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(f\"    {key}: {value}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jmMfE9_dUZiS"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "phyiHlWEUZiT"
      },
      "outputs": [],
      "source": [
        "# Creating the best network and optimizer using the best hyperparameters\n",
        "if OPTIMIZE:\n",
        "    net, \\\n",
        "    loss_fn, \\\n",
        "    optimizer, \\\n",
        "    batch_size, \\\n",
        "    n_epochs, \\\n",
        "    scheduler, \\\n",
        "    loss_name, \\\n",
        "    optimizer_name, \\\n",
        "    scheduler_name, \\\n",
        "    n_units, \\\n",
        "    n_layers, \\\n",
        "    hidden_activation, \\\n",
        "    output_activation, \\\n",
        "    lr = create_model(trial, optimize=True)\n",
        "# Creating the network with predefined hyperparameters\n",
        "else:\n",
        "    net, \\\n",
        "    loss_fn, \\\n",
        "    optimizer, \\\n",
        "    batch_size, \\\n",
        "    n_epochs, \\\n",
        "    scheduler, \\\n",
        "    loss_name, \\\n",
        "    optimizer_name, \\\n",
        "    scheduler_name, \\\n",
        "    n_units, \\\n",
        "    n_layers, \\\n",
        "    hidden_activation, \\\n",
        "    output_activation, \\\n",
        "    lr = create_model(trial=None, optimize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yq-oY81UZiU",
        "outputId": "dbf2f465-bd50-4a20-8926-616c3d2157d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_fn: SmoothL1Loss()\n",
            "batch_size: 49\n",
            "n_epochs: 10\n",
            "scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f7cbfa001d0>\n",
            "loss_name: Huber\n",
            "optimizer_name: RMSprop\n",
            "scheduler_name: ReduceLROnPlateau\n",
            "n_units: [555, 458, 115]\n",
            "n_layers: 3\n",
            "hidden_activation: ReLU()\n",
            "output_activation: ReLU()\n"
          ]
        }
      ],
      "source": [
        "print(\"loss_fn:\", loss_fn)\n",
        "print(\"batch_size:\", batch_size)\n",
        "print(\"n_epochs:\", n_epochs)\n",
        "print(\"scheduler:\", scheduler)\n",
        "print(\"loss_name:\", loss_name)\n",
        "print(\"optimizer_name:\", optimizer_name)\n",
        "print(\"scheduler_name:\", scheduler_name)\n",
        "print(\"n_units:\", n_units)\n",
        "print(\"n_layers:\", n_layers)\n",
        "print(\"hidden_activation:\", hidden_activation)\n",
        "print(\"output_activation:\", output_activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7aLWdZyUZiW",
        "outputId": "8fb1e8c6-5aa3-43a1-a255-712cf9396d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss: 485.8985, Test Loss: 210.1299, Train L1 Norm: 2.0914, Test L1 Norm: 2.0894, Train Linf Norm: 17.8828, Test Linf Norm: 16.8918\n",
            "Epoch 2: Train Loss: 310.9262, Test Loss: 216.0311, Train L1 Norm: 1.8313, Test L1 Norm: 1.0000, Train Linf Norm: 13.6477, Test Linf Norm: 1.0000\n",
            "Epoch 3: Train Loss: 216.7807, Test Loss: 216.0133, Train L1 Norm: 1.0447, Test L1 Norm: 0.9889, Train Linf Norm: 1.4394, Test Linf Norm: 1.0179\n",
            "Epoch 4: Train Loss: 281.6633, Test Loss: 216.0311, Train L1 Norm: 1.9213, Test L1 Norm: 1.0000, Train Linf Norm: 14.7072, Test Linf Norm: 1.0000\n",
            "Epoch 5: Train Loss: 217.1945, Test Loss: 216.0311, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 6: Train Loss: 217.1945, Test Loss: 216.0311, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 7: Train Loss: 217.1945, Test Loss: 216.0311, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 8: Train Loss: 217.1945, Test Loss: 216.0311, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 9: Train Loss: 217.1945, Test Loss: 216.0311, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n",
            "Epoch 10: Train Loss: 217.1945, Test Loss: 216.0311, Train L1 Norm: 1.0000, Test L1 Norm: 1.0000, Train Linf Norm: 1.0000, Test Linf Norm: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluating the network using the train_and_eval function\n",
        "train_losses, test_losses, train_metrics, test_metrics = train_and_eval(\n",
        "    net, loss_fn, optimizer, batch_size, n_epochs, scheduler\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "akNucrgMUZiW"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LHsrs2Y-UZic"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# save the network to a .pth file\n",
        "torch.save(net.state_dict(), \"net.pth\")\n",
        "save_file(\"net.pth\")\n",
        "\n",
        "# save the optimizer to a .pth file\n",
        "torch.save(optimizer.state_dict(), \"optimizer.pth\")\n",
        "save_file(\"optimizer.pth\")\n",
        "\n",
        "# save the scheduler to a .pth file if it is not None\n",
        "if scheduler is not None:\n",
        "  torch.save(scheduler.state_dict(), \"scheduler.pth\")\n",
        "  save_file(\"scheduler.pth\")\n",
        "\n",
        "# create a dictionary to store the rest of the variables\n",
        "var_dict = {\n",
        "  \"batch_size\": batch_size,\n",
        "  \"n_epochs\": n_epochs,\n",
        "  \"loss_name\": loss_name,\n",
        "  \"optimizer_name\": optimizer_name,\n",
        "  \"scheduler_name\": scheduler_name,\n",
        "  \"n_units\": n_units,\n",
        "  \"n_layers\": n_layers,\n",
        "  \"hidden_activation_name\": hidden_activation.__class__.__name__,\n",
        "  \"output_activation_name\": output_activation.__class__.__name__,\n",
        "  \"lr\": lr,\n",
        "}\n",
        "\n",
        "# save the dictionary to a .json file\n",
        "with open(\"var_dict.json\", \"w\") as f:\n",
        "  json.dump(var_dict, f)\n",
        "save_file(\"var_dict.json\")\n",
        "\n",
        "# Saving the output of the training using pandas\n",
        "train_df = pd.DataFrame(\n",
        "    {\n",
        "        \"train_loss\": train_losses,\n",
        "        \"test_loss\": test_losses,\n",
        "        \"train_l1_norm\": [m[\"l1_norm\"] for m in train_metrics],\n",
        "        \"test_l1_norm\": [m[\"l1_norm\"] for m in test_metrics],\n",
        "        \"train_linf_norm\": [m[\"linf_norm\"] for m in train_metrics],\n",
        "        \"test_linf_norm\": [m[\"linf_norm\"] for m in test_metrics],\n",
        "    }\n",
        ")\n",
        "train_df.to_csv(\"train_output.csv\", index=False)\n",
        "save_file(\"train_output.csv\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qU23l7dIUZie"
      },
      "source": [
        "## Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cippWZS6UZie",
        "outputId": "f0d6e5c3-945f-481b-a153-e54fed7fe9fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cc1630b50>]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cbee2c1d0>]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'L1 Norm')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(0.001, 100.0)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7cbee870d0>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cbece58d0>]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cbecf5050>]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Linf Norm')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(0.001, 100.0)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7cbee2d3d0>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 0 Axes>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cbebd5150>]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cbed0e290>]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Huber Loss')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(1e-07, 1.0)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7cbea206d0>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting the losses and metrics for the best network \n",
        "plt.figure(figsize=(12, 8))\n",
        "#plt.subplot(2, 2, 1)\n",
        "#plt.plot(train_losses, label=\"Train Loss\")\n",
        "#plt.plot(test_losses, label=\"Test Loss\")\n",
        "#plt.xlabel(\"Epoch\")\n",
        "#plt.ylabel(\"Loss\")\n",
        "#plt.legend()\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot([m[\"l1_norm\"] for m in train_metrics], label=\"Train L1 Norm\")\n",
        "plt.plot([m[\"l1_norm\"] for m in test_metrics], label=\"Test L1 Norm\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"L1 Norm\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-3, 1e2)\n",
        "plt.legend()\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot([m[\"linf_norm\"] for m in train_metrics], label=\"Train Linf Norm\")\n",
        "plt.plot([m[\"linf_norm\"] for m in test_metrics], label=\"Test Linf Norm\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Linf Norm\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-3, 1e2)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Added plotting MSE of training data and MSE of test data in one plot \n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_losses,label=\"training data\")\n",
        "plt.plot(test_losses,label=\"test data\")\n",
        "#if scheduler is not None:\n",
        "#    plt.plot([scheduler.get_last_lr()[0] for _ in range(n_epochs)], label=\"Learning rate\") \n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(f\"{loss_name} Loss\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-7, 1e0)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tiEDutxIUZig"
      },
      "source": [
        "## Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Mj990wUZih",
        "outputId": "a1132948-c3b1-4d75-becf-4efa93c9a7d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# load the dictionary from the .json file\n",
        "with open(\"var_dict.json\", \"r\") as f:\n",
        "  var_dict_loaded = json.load(f)\n",
        "\n",
        "# extract the variables from the dictionary\n",
        "batch_size_loaded = var_dict_loaded[\"batch_size\"]\n",
        "n_epochs_loaded = var_dict_loaded[\"n_epochs\"]\n",
        "loss_name_loaded = var_dict_loaded[\"loss_name\"]\n",
        "optimizer_name_loaded = var_dict_loaded[\"optimizer_name\"]\n",
        "scheduler_name_loaded = var_dict_loaded[\"scheduler_name\"]\n",
        "n_units_loaded = var_dict_loaded[\"n_units\"]\n",
        "n_layers_loaded = var_dict_loaded[\"n_layers\"]\n",
        "hidden_activation_name_loaded = var_dict_loaded[\"hidden_activation_name\"]\n",
        "output_activation_name_loaded = var_dict_loaded[\"output_activation_name\"]\n",
        "lr_loaded = var_dict_loaded[\"lr\"]\n",
        "\n",
        "# create the activation functions from their names\n",
        "if hidden_activation_name_loaded == \"ReLU\":\n",
        "  hidden_activation_loaded = nn.ReLU()\n",
        "elif hidden_activation_name_loaded == \"LeakyReLU\":\n",
        "  hidden_activation_loaded = nn.LeakyReLU() \n",
        "elif hidden_activation_name_loaded == \"ELU\":\n",
        "  hidden_activation_loaded = nn.ELU() \n",
        "elif hidden_activation_name_loaded == \"Tanh\":\n",
        "  hidden_activation_loaded = nn.Tanh()\n",
        "else:\n",
        "  hidden_activation_loaded = nn.Sigmoid()\n",
        "\n",
        "if output_activation_name_loaded == \"ReLU\":\n",
        "    output_activation_loaded = nn.ReLU()\n",
        "elif output_activation_name_loaded == \"Softplus\":\n",
        "    output_activation_loaded = nn.Softplus()\n",
        "else:\n",
        "    output_activation_loaded = nn.Identity()\n",
        "\n",
        "\n",
        "\n",
        "# load the network from the .pth file\n",
        "net_loaded = Net(n_layers_loaded, n_units_loaded, hidden_activation_loaded, output_activation_loaded).to(device)\n",
        "if torch.cuda.is_available():\n",
        " net_loaded.load_state_dict(torch.load(\"net.pth\"))\n",
        "else: \n",
        "  net_loaded.load_state_dict(torch.load(\"net.pth\", map_location=torch.device('cpu')))\n",
        "\n",
        "# create the loss function from its name\n",
        "if loss_name_loaded == \"MSE\":\n",
        "  loss_fn_loaded = nn.MSELoss()\n",
        "elif loss_name_loaded == \"MAE\":\n",
        "  loss_fn_loaded = nn.L1Loss()\n",
        "elif loss_name_loaded == \"Huber\":\n",
        "  loss_fn_loaded = nn.SmoothL1Loss() \n",
        "else:\n",
        "  # create the log-cosh loss function\n",
        "  def log_cosh_loss_loaded(y_pred, y_true):\n",
        "    return torch.mean(torch.log(torch.cosh(y_pred - y_true)))\n",
        "  loss_fn_loaded = log_cosh_loss_loaded\n",
        "\n",
        "# load the optimizer from the .pth file\n",
        "if torch.cuda.is_available():\n",
        "  optimizer_loaded_state_dict = torch.load(\"optimizer.pth\")\n",
        "else:\n",
        "  optimizer_loaded_state_dict = torch.load(\"optimizer.pth\", map_location=torch.device('cpu'))\n",
        "\n",
        "if optimizer_name_loaded == \"SGD\":\n",
        "  # Added getting the weight decay and momentum parameters from the state dict\n",
        "  weight_decay_loaded = optimizer_loaded_state_dict[\"param_groups\"][0][\"weight_decay\"]\n",
        "  momentum_loaded = optimizer_loaded_state_dict[\"param_groups\"][0][\"momentum\"]\n",
        "  optimizer_loaded = optim.SGD(net_loaded.parameters(), lr=lr_loaded, weight_decay=weight_decay_loaded, momentum=momentum_loaded)\n",
        "elif optimizer_name_loaded == \"Adam\":\n",
        "  # Added getting the weight decay and beta parameters from the state dict\n",
        "  weight_decay_loaded = optimizer_loaded_state_dict[\"param_groups\"][0][\"weight_decay\"]\n",
        "  beta1_loaded = optimizer_loaded_state_dict[\"param_groups\"][0][\"betas\"][0]\n",
        "  beta2_loaded = optimizer_loaded_state_dict[\"param_groups\"][0][\"betas\"][1]\n",
        "  optimizer_loaded = optim.Adam(net_loaded.parameters(), lr=lr_loaded, weight_decay=weight_decay_loaded, betas=(beta1_loaded, beta2_loaded))\n",
        "elif optimizer_name_loaded == \"RMSprop\":\n",
        "  optimizer_loaded = optim.RMSprop(net_loaded.parameters(), lr=lr_loaded)\n",
        "else:\n",
        "  # Added loading the Adagrad optimizer\n",
        "  optimizer_loaded = optim.Adagrad(net_loaded.parameters(), lr=lr_loaded)\n",
        "optimizer_loaded.load_state_dict(optimizer_loaded_state_dict)\n",
        "\n",
        "# load the scheduler from the .pth file\n",
        "if torch.cuda.is_available():\n",
        "  scheduler_loaded_state_dict = torch.load(\"scheduler.pth\")\n",
        "else: \n",
        "  scheduler_loaded_state_dict = torch.load(\"scheduler.pth\", map_location=torch.device('cpu'))\n",
        "\n",
        "if scheduler_name_loaded == \"StepLR\":\n",
        "  # Added getting the step_size and gamma parameters from the state dict\n",
        "  step_size_loaded = scheduler_loaded_state_dict[\"step_size\"]\n",
        "  gamma_loaded = scheduler_loaded_state_dict[\"gamma\"]\n",
        "  scheduler_loaded = optim.lr_scheduler.StepLR(optimizer_loaded, step_size=step_size_loaded, gamma=gamma_loaded)\n",
        "elif scheduler_name_loaded == \"ExponentialLR\":\n",
        "  # Added getting the gamma parameter from the state dict\n",
        "  gamma_loaded = scheduler_loaded_state_dict[\"gamma\"]\n",
        "  scheduler_loaded = optim.lr_scheduler.ExponentialLR(optimizer_loaded, gamma=gamma_loaded)\n",
        "elif scheduler_name_loaded == \"CosineAnnealingLR\":\n",
        "  # Added getting the T_max parameter from the state dict\n",
        "  T_max_loaded = scheduler_loaded_state_dict[\"T_max\"]\n",
        "  scheduler_loaded = optim.lr_scheduler.CosineAnnealingLR(optimizer_loaded, T_max=T_max_loaded)\n",
        "elif scheduler_name_loaded == \"ReduceLROnPlateau\":\n",
        "  # Added getting the mode, factor, patience, threshold and min_lr parameters from the state dict\n",
        "  mode_loaded = scheduler_loaded_state_dict[\"mode\"]\n",
        "  factor_loaded = scheduler_loaded_state_dict[\"factor\"]\n",
        "  patience_loaded = scheduler_loaded_state_dict[\"patience\"]\n",
        "  threshold_loaded = scheduler_loaded_state_dict[\"threshold\"]\n",
        "  min_lr_loaded = scheduler_loaded_state_dict[\"min_lrs\"][0]\n",
        "  scheduler_loaded = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                    optimizer_loaded, mode=mode_loaded, factor=factor_loaded, patience=patience_loaded, threshold=threshold_loaded, min_lr=min_lr_loaded\n",
        "                )\n",
        "# elif scheduler_name_loaded == \"OneCycleLR\":\n",
        "#   max_lr_loaded = scheduler_loaded_state_dict[\"max_lr\"]\n",
        "#   epochs_loaded = scheduler_loaded_state_dict[\"epochs\"]\n",
        "#   steps_per_epoch_loaded = scheduler_loaded_state_dict[\"steps_per_epoch\"]\n",
        "#   pct_start_loaded = scheduler_loaded_state_dict[\"pct_start\"]\n",
        "#   max_lr_loaded = scheduler_loaded_state_dict[\"max_lr\"]\n",
        "#   scheduler_loaded = optim.lr_scheduler.OneCycleLR(\n",
        "#                     optimizer_loaded, max_lr=max_lr_loaded, epochs=epochs_loaded, steps_per_epoch=steps_per_epoch_loaded, pct_start=pct_start_loaded\n",
        "#                 )\n",
        "else:\n",
        "  scheduler_loaded = None\n",
        "\n",
        "if scheduler_loaded is not None:\n",
        "  # Added loading the state dict to the scheduler_loaded\n",
        "  scheduler_loaded.load_state_dict(scheduler_loaded_state_dict)\n",
        "\n",
        "# Loading the output of the training using pandas\n",
        "train_df_loaded = pd.read_csv(\"train_output.csv\")\n",
        "train_losses_loaded = train_df_loaded[\"train_loss\"].tolist()\n",
        "test_losses_loaded = train_df_loaded[\"test_loss\"].tolist()\n",
        "train_metrics_loaded = [\n",
        "    {\n",
        "        \"l1_norm\": train_df_loaded[\"train_l1_norm\"][i],\n",
        "        \"linf_norm\": train_df_loaded[\"train_linf_norm\"][i],\n",
        "    }\n",
        "    for i in range(len(train_df_loaded))\n",
        "]\n",
        "test_metrics_loaded = [\n",
        "    {\n",
        "        \"l1_norm\": train_df_loaded[\"test_l1_norm\"][i],\n",
        "        \"linf_norm\": train_df_loaded[\"test_linf_norm\"][i],\n",
        "    }\n",
        "    for i in range(len(train_df_loaded))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GQ_fcj7zUZii",
        "outputId": "c4979ef0-a99c-4754-e222-3af23a83c1cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skipping\n"
          ]
        }
      ],
      "source": [
        "%%script echo skipping\n",
        "\n",
        "batch_size_loaded\n",
        "n_epochs_loaded\n",
        "loss_name_loaded\n",
        "optimizer_name_loaded\n",
        "scheduler_name_loaded\n",
        "n_units_loaded\n",
        "n_layers_loaded\n",
        "hidden_activation_name_loaded\n",
        "output_activation_name_loaded\n",
        "lr_loaded\n",
        "hidden_activation_loaded\n",
        "output_activation_loaded\n",
        "net_loaded\n",
        "net_loaded.__dict__ # print the subparameters of the network\n",
        "loss_fn_loaded\n",
        "optimizer_loaded\n",
        "optimizer_loaded.__dict__ # print the subparameters of the optimizer\n",
        "scheduler_loaded\n",
        "scheduler_loaded.__dict__ # print the subparameters of the scheduler\n",
        "train_losses_loaded\n",
        "test_losses_loaded\n",
        "train_metrics_loaded\n",
        "test_metrics_loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "217.1945228248537"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "216.03108852069377"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_losses_loaded[-1]\n",
        "test_losses_loaded[-1]\n",
        "test_metrics_loaded[-1]['l1_norm']\n",
        "test_metrics_loaded[-1]['linf_norm']\n",
        "# print(f'Error is {test_metrics_loaded[-1][\"l1_norm\"] / (3.84e-4)} times bigger than in Dieselhorst et al.')\n",
        "# print(f'Error is {test_metrics_loaded[-1][\"linf_norm\"] / (8.14e-3)} times bigger than in Dieselhorst et al.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize loaded results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vwLGR1aSUZik"
      },
      "source": [
        "Let us verify correct loading of the train and test metrics by visualizing them again but now through the loaded values. Likewise for the train and test losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "sXiNgLsmUZil"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"last_expr_or_assign\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sgq4WfSiUZil",
        "outputId": "9934bd08-6c78-4a92-c8c6-d8e835c351b3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting the losses and metrics for the best network plt.figure(figsize=(12, \n",
        "#plt.subplot(2, 2, 1)\n",
        "#plt.plot(train_losses_loaded, label=\"Train Loss\")\n",
        "#plt.plot(test_losses_loaded, label=\"Test Loss\")\n",
        "#plt.xlabel(\"Epoch\")\n",
        "#plt.ylabel(\"Loss\")\n",
        "#plt.legend()\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot([m[\"l1_norm\"] for m in train_metrics_loaded], label=\"Train L1 Norm\")\n",
        "plt.plot([m[\"l1_norm\"] for m in test_metrics_loaded], label=\"Test L1 Norm\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"L1 Norm\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-3, 1e2)\n",
        "plt.legend()\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot([m[\"linf_norm\"] for m in train_metrics_loaded], label=\"Train Linf Norm\")\n",
        "plt.plot([m[\"linf_norm\"] for m in test_metrics_loaded], label=\"Test Linf Norm\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Linf Norm\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-3, 1e2)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Added plotting MSE of training data and MSE of test data in one plot \n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_losses_loaded,label=\"training data\")\n",
        "plt.plot(test_losses_loaded,label=\"test data\")\n",
        "#if scheduler is not None:\n",
        "#    plt.plot([scheduler.get_last_lr()[0] for _ in range(n_epochs)], label=\"Learning rate\") \n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(f\"{loss_name_loaded} Loss\")\n",
        "# Added setting the vertical axis to be in powers of 10\n",
        "plt.yscale(\"log\")\n",
        "# Added setting the vertical axis limits to be from 10^-7 to 10^0\n",
        "plt.ylim(1e-7, 1e0)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "lkgLqJ_UUZim"
      },
      "outputs": [],
      "source": [
        "%config InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Counting the number of parameters in the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (hidden_activation): ReLU()\n",
              "  (output_activation): ReLU()\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=14, out_features=555, bias=True)\n",
              "    (1): Linear(in_features=555, out_features=458, bias=True)\n",
              "    (2): Linear(in_features=458, out_features=115, bias=True)\n",
              "    (3): Linear(in_features=115, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 315874 parameters.\n"
          ]
        }
      ],
      "source": [
        "net_loaded.eval()\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {count_parameters(net_loaded)} parameters.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SxuzVSnlUZin"
      },
      "source": [
        "## Evaluating the network on arbirary input\n",
        "### Comparing `net` and `net_loaded`\n",
        "\n",
        "We compare `net` and `net_loaded` to confirm correct loading of the network. Note that `net` is only available if we have trained the model in this session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (hidden_activation): ReLU()\n",
              "  (output_activation): ReLU()\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=14, out_features=555, bias=True)\n",
              "    (1): Linear(in_features=555, out_features=458, bias=True)\n",
              "    (2): Linear(in_features=458, out_features=115, bias=True)\n",
              "    (3): Linear(in_features=115, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#%%script echo skipping\n",
        "\n",
        "# Set the network to evaluation mode\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (hidden_activation): ReLU()\n",
              "  (output_activation): ReLU()\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=14, out_features=555, bias=True)\n",
              "    (1): Linear(in_features=555, out_features=458, bias=True)\n",
              "    (2): Linear(in_features=458, out_features=115, bias=True)\n",
              "    (3): Linear(in_features=115, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set the network to evaluation mode\n",
        "net_loaded.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters are the same.\n",
            "Net device: cpu\n",
            "Net_loaded device: cpu\n"
          ]
        }
      ],
      "source": [
        "for p1, p2 in zip(net.parameters(), net_loaded.parameters()):\n",
        "    if p1.data.ne(p2.data).sum() > 0:\n",
        "        print(\"Parameters are NOT the same.\")\n",
        "        break\n",
        "else:\n",
        "    print(\"Parameters are the same.\")\n",
        "\n",
        "print(\"Net device:\", next(net.parameters()).device)\n",
        "print(\"Net_loaded device:\", next(net_loaded.parameters()).device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0PLAA0DUZin",
        "outputId": "c51e07dd-8b35-4ea4-cdf9-3118d7796e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.3159, -0.0649, -0.2168,  ..., -0.0371,  0.3013,  0.4135],\n",
            "        [-0.2336, -0.2635, -0.2063,  ...,  0.0615,  0.1547,  0.0311],\n",
            "        [-0.1370, -0.1472,  0.1281,  ..., -0.3203, -0.3451, -0.3116],\n",
            "        ...,\n",
            "        [-0.0519,  0.1711, -0.0290,  ..., -0.0589, -0.2497, -0.2148],\n",
            "        [ 0.0202,  0.0130,  0.0634,  ..., -0.0005,  0.0069,  0.1894],\n",
            "        [-0.0495, -0.1790, -0.2162,  ...,  0.3967,  0.0923,  0.2245]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 2.0588e-01, -1.9305e-01, -3.0101e-01, -5.1728e-01, -2.4763e-01,\n",
            "        -2.0962e-01,  2.7760e-01,  3.4975e-01, -6.7619e-02,  1.8556e-01,\n",
            "         3.0503e-02,  1.8390e-01, -1.6853e-01,  2.8958e-01, -1.0623e-01,\n",
            "         8.0919e-02,  7.4536e-02, -2.4037e-01,  8.6932e-02,  1.2053e-01,\n",
            "        -1.1944e-01,  5.9453e-03, -1.8307e-01, -1.9311e-01,  1.5377e-01,\n",
            "         8.2893e-02, -8.6109e-02,  4.7653e-01, -2.4865e-02, -8.3183e-02,\n",
            "         6.6792e-02, -2.9553e-01, -4.6941e-01, -1.8324e-01,  1.5912e-02,\n",
            "        -3.3994e-01,  1.8566e-01, -2.4563e-01, -1.1195e-02, -2.2146e-01,\n",
            "         7.9129e-02,  2.3136e-01, -2.9273e-01, -5.9733e-02, -6.7965e-03,\n",
            "         1.0222e-01,  1.1420e-01, -1.0040e-01, -1.0898e-01,  1.9044e-01,\n",
            "        -1.9786e-01, -2.9880e-01, -5.7297e-02, -3.7630e-01, -1.6025e-01,\n",
            "        -1.6762e-01,  8.0401e-04,  1.1664e-01, -3.7064e-02, -1.9179e-01,\n",
            "         1.4725e-02, -1.5003e-01,  2.7907e-02, -1.1941e-01,  2.6792e-01,\n",
            "         9.2453e-02, -1.7316e-01,  1.6110e-01,  7.2112e-02,  6.9632e-02,\n",
            "         1.0352e-01,  6.2849e-02,  1.6177e-01,  2.2803e-03, -6.7391e-02,\n",
            "         8.5557e-02, -9.2158e-02,  1.1707e-01, -4.9072e-01, -2.9632e-01,\n",
            "         3.6219e-01,  3.6151e-01,  2.4794e-01, -1.1813e-01, -4.4705e-01,\n",
            "        -3.6193e-01, -8.2615e-02,  1.3091e-03, -3.6154e-01, -8.1780e-02,\n",
            "         8.6485e-02, -1.4164e-01, -2.7033e-01, -3.9239e-01, -5.1772e-02,\n",
            "         4.1199e-01, -4.5400e-01, -1.4925e-01, -1.4238e-01,  3.3402e-02,\n",
            "        -3.4221e-01, -1.7351e-01, -4.4519e-01,  2.0338e-01,  9.5345e-02,\n",
            "        -1.8455e-01,  3.7593e-01, -3.2680e-01,  6.3817e-02,  3.6147e-01,\n",
            "        -2.9379e-01,  1.9933e-01,  3.9349e-01,  4.4056e-01,  1.8072e-01,\n",
            "        -4.5688e-01, -5.3385e-02,  2.5012e-01, -2.0024e-02, -1.7398e-01,\n",
            "        -8.9960e-02, -3.6617e-01, -2.6236e-01,  2.0631e-01, -1.0721e-01,\n",
            "         4.4706e-02, -1.8680e-01,  4.7401e-04,  4.0402e-01, -8.4989e-02,\n",
            "        -6.3677e-02,  1.7327e-01, -3.8237e-01,  3.4098e-01, -4.7686e-01,\n",
            "         4.0185e-01, -2.3006e-01,  1.1417e-01,  3.1241e-01, -1.4513e-01,\n",
            "         7.2144e-02,  7.2692e-02, -1.1493e-01,  6.8241e-02,  4.1139e-02,\n",
            "        -3.2033e-01,  3.8422e-02, -4.2652e-01, -4.5426e-02,  2.7291e-01,\n",
            "         1.4148e-01, -4.8934e-01, -1.7373e-02, -3.5998e-01,  1.7349e-01,\n",
            "        -1.7249e-01, -3.4145e-01, -4.1155e-01, -1.3268e-01, -2.1725e-02,\n",
            "         1.0635e-01,  1.9570e-01, -1.1426e-01, -3.5578e-01, -5.7672e-01,\n",
            "        -2.5749e-01, -1.2567e-01,  9.8504e-02, -1.7369e-02,  7.0227e-02,\n",
            "         3.6953e-03, -3.4672e-01, -3.0548e-01, -3.7887e-01, -1.6264e-01,\n",
            "         1.4039e-01, -1.9679e-01,  1.7876e-02,  1.3761e-01,  6.0899e-02,\n",
            "         3.8998e-02, -1.2943e-01, -1.8296e-01, -4.0720e-01, -1.2164e-01,\n",
            "        -1.8384e-01, -3.8165e-01,  3.7694e-01,  7.6722e-03, -3.2214e-01,\n",
            "        -4.1720e-01,  2.8907e-01, -2.6635e-01, -1.6116e-01, -1.7237e-02,\n",
            "        -1.1100e-01, -2.6093e-01,  2.5589e-01,  3.2110e-01,  1.9380e-01,\n",
            "        -1.4386e-01, -2.5993e-01, -2.7618e-01, -4.5316e-01, -3.1956e-01,\n",
            "        -2.3986e-01, -4.9278e-02,  2.5345e-01,  2.6798e-02,  2.0661e-01,\n",
            "        -1.2716e-01, -3.3278e-01, -9.0399e-02, -7.6747e-02,  8.6009e-02,\n",
            "        -1.3432e-02,  4.2588e-01,  2.6377e-01, -2.1094e-01, -1.3684e-02,\n",
            "         1.7743e-01, -1.3444e-01,  1.1443e-01, -5.0545e-01,  2.0264e-01,\n",
            "        -2.4707e-01,  4.1371e-01, -4.5546e-01, -3.5678e-01, -2.5189e-02,\n",
            "        -7.2217e-02, -2.3777e-01, -1.9828e-01, -8.1106e-02,  1.3008e-01,\n",
            "         8.2367e-02,  3.9728e-01, -1.3167e-01,  2.6319e-01,  1.8088e-02,\n",
            "         5.0076e-01,  2.1786e-02,  2.0203e-01, -3.4681e-02, -8.1311e-02,\n",
            "        -1.3473e-01, -2.6268e-01,  1.0614e-02,  9.8241e-02, -2.4949e-01,\n",
            "        -1.2426e-01, -1.6088e-01, -1.6834e-01, -5.3760e-01, -6.2445e-01,\n",
            "         7.7138e-02,  4.6507e-01,  3.9524e-01, -2.8447e-01,  1.2564e-02,\n",
            "        -1.4120e-01, -3.7902e-01, -1.7945e-01,  3.1023e-01,  2.0275e-01,\n",
            "         3.4889e-01, -4.4454e-01, -1.6195e-01,  3.3695e-02, -4.7766e-01,\n",
            "         3.1039e-01, -3.5513e-01, -2.8091e-01,  2.5845e-01, -3.1342e-01,\n",
            "        -3.1627e-01,  8.1072e-02, -2.1007e-01, -2.7382e-01,  5.8525e-03,\n",
            "        -2.8040e-01,  9.7899e-02, -2.0036e-01,  3.2368e-01, -5.3085e-02,\n",
            "        -2.4195e-01, -1.5689e-01,  4.1836e-01, -3.7462e-01,  3.0288e-01,\n",
            "        -1.8945e-01, -5.7286e-02,  6.8946e-02, -3.8417e-02,  1.3365e-01,\n",
            "         3.0410e-01,  3.2722e-01,  1.9658e-01, -4.2935e-01,  7.4424e-02,\n",
            "         3.8722e-01, -5.8526e-01,  2.8909e-01, -4.8185e-01,  1.3913e-01,\n",
            "        -8.1399e-02,  8.9916e-02,  1.5059e-01,  1.9781e-01,  1.4966e-01,\n",
            "        -2.0335e-01, -3.7986e-01, -2.1252e-01,  1.6347e-01, -3.2121e-01,\n",
            "         5.7943e-02, -3.8356e-02,  1.4515e-01, -1.5214e-01,  1.9471e-01,\n",
            "        -5.4984e-01, -2.8943e-01, -2.5663e-01, -2.8214e-01, -9.9286e-02,\n",
            "        -3.3184e-01, -3.0073e-01, -2.2658e-01, -7.6238e-02,  9.2659e-02,\n",
            "        -1.9267e-01, -2.2313e-01, -9.4374e-02, -2.2954e-02, -2.2297e-02,\n",
            "         2.2373e-01, -1.4857e-01, -1.8887e-01, -3.9183e-01, -1.3852e-01,\n",
            "         3.8167e-01,  2.7367e-02, -3.4740e-01,  3.3222e-01, -1.3077e-01,\n",
            "        -3.7890e-02, -5.2655e-01,  7.2913e-02, -9.5315e-02,  2.4509e-01,\n",
            "        -1.9020e-01, -1.6617e-01,  1.6301e-01, -1.9362e-01, -1.5296e-01,\n",
            "         2.6923e-01,  6.5615e-02,  3.2152e-01, -2.0504e-01,  1.0676e-01,\n",
            "        -3.3809e-02,  9.2808e-02,  2.4239e-01, -2.2409e-01, -2.5207e-03,\n",
            "        -2.0141e-02, -3.6328e-01, -2.6104e-01, -3.7320e-01, -3.6876e-01,\n",
            "        -9.6008e-02, -9.3144e-02,  2.3825e-01, -2.4572e-01,  8.0336e-02,\n",
            "         3.4587e-01, -1.1985e-02,  6.7888e-02, -3.5936e-02,  4.5511e-01,\n",
            "        -4.3733e-01,  1.8091e-01,  1.8772e-01, -3.7019e-01, -2.4957e-01,\n",
            "        -4.3855e-01, -2.8087e-01, -5.5334e-02, -1.4797e-02, -2.3006e-01,\n",
            "        -2.0763e-01, -1.4386e-01, -8.0051e-02, -4.1988e-01,  1.6198e-01,\n",
            "        -2.4702e-01,  2.3853e-01, -3.2432e-01,  1.2626e-01,  5.6511e-02,\n",
            "         3.4840e-01,  3.5222e-01,  1.8126e-01, -4.5142e-01,  1.0268e-01,\n",
            "         8.6561e-02, -4.3660e-01, -5.1914e-02, -2.9915e-01, -7.1143e-02,\n",
            "         8.2002e-02, -3.9986e-01, -1.1722e-01,  4.6767e-02, -7.5587e-02,\n",
            "        -1.9705e-01,  1.2666e-01, -1.0774e-01,  5.3669e-02, -1.9884e-02,\n",
            "        -5.0558e-01,  4.2794e-02, -2.3915e-02, -1.0502e-02,  2.6688e-01,\n",
            "         2.6824e-01, -5.1433e-01, -1.6495e-02, -1.4819e-03, -3.8437e-01,\n",
            "        -8.7899e-02,  1.9838e-01, -3.2787e-02, -7.2574e-02,  1.0291e-01,\n",
            "         9.8362e-03, -5.3070e-02,  3.5327e-02, -3.6211e-01, -1.4742e-01,\n",
            "        -2.3850e-01, -2.6813e-01, -3.3612e-01, -1.8880e-01, -2.3708e-01,\n",
            "        -5.2259e-01, -5.7756e-02, -1.5390e-01, -3.4311e-01,  1.2438e-01,\n",
            "         2.3575e-01, -1.6264e-01, -1.9403e-01, -3.7250e-02, -1.3269e-01,\n",
            "        -1.2736e-01,  2.8374e-01, -5.2109e-02, -2.2790e-01, -1.8739e-01,\n",
            "        -1.6039e-01, -4.7185e-01, -1.7941e-01,  6.0994e-02, -9.5169e-02,\n",
            "         3.9558e-02,  2.0657e-01, -3.1098e-01,  2.6100e-01, -4.7441e-03,\n",
            "         9.8920e-02,  3.5911e-01, -2.8216e-01, -5.4472e-01, -9.1303e-02,\n",
            "         2.3600e-01, -3.1029e-01,  4.1374e-01,  1.1157e-01,  1.4411e-01,\n",
            "        -1.5056e-01, -2.1224e-01,  3.7482e-01,  1.4302e-01, -5.3584e-02,\n",
            "        -1.7875e-01, -1.9165e-01, -1.0970e-02, -1.8759e-01,  2.0830e-02,\n",
            "         4.8061e-02, -4.9552e-01, -2.1365e-01, -1.1748e-02, -4.6506e-03,\n",
            "         2.9391e-01, -9.7113e-02, -3.8608e-01, -7.8843e-02, -1.4988e-01,\n",
            "        -2.7654e-01, -5.2548e-01, -3.5996e-01, -2.4851e-01, -2.4574e-01,\n",
            "         2.8503e-02,  3.6449e-02, -3.7317e-01, -4.0168e-01,  4.0303e-01,\n",
            "        -2.3274e-01,  3.6747e-01,  2.1945e-01, -7.8553e-02, -6.4229e-02,\n",
            "        -2.7917e-01, -2.9738e-01, -3.6281e-01, -4.2110e-02, -3.6332e-01,\n",
            "         1.9761e-01, -1.9214e-01, -6.3951e-01,  1.3061e-01, -8.6660e-02,\n",
            "        -6.0466e-02, -2.2589e-01,  9.8582e-03,  6.7469e-03,  1.4764e-01,\n",
            "        -2.3418e-01, -2.3177e-02,  4.6557e-02, -3.6946e-01,  3.4663e-01,\n",
            "        -1.2411e-01, -3.2976e-01,  1.3031e-01,  4.0028e-01, -1.2857e-02,\n",
            "        -3.3673e-01, -9.9200e-02,  3.5799e-02, -2.4606e-01, -1.4181e-01,\n",
            "        -4.4975e-01, -3.8280e-03,  4.2146e-01, -1.0332e-01, -1.2685e-02,\n",
            "        -1.4376e-01, -1.9429e-01, -1.1269e-02,  6.9136e-02,  3.9813e-01],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0245,  0.0011,  0.0105,  ..., -0.0239,  0.0367, -0.0615],\n",
            "        [ 0.1025, -0.0139, -0.0320,  ...,  0.0421,  0.0544,  0.0547],\n",
            "        [ 0.0174, -0.0367, -0.0101,  ...,  0.0319,  0.0189, -0.0384],\n",
            "        ...,\n",
            "        [ 0.0497,  0.0114, -0.0408,  ...,  0.0457,  0.0373,  0.0596],\n",
            "        [ 0.0289,  0.0121, -0.0390,  ...,  0.0342,  0.0330, -0.0117],\n",
            "        [ 0.0504, -0.0005,  0.0533,  ...,  0.0180,  0.0328,  0.0673]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-2.8524e-01,  2.2778e-01, -1.6855e-01, -7.4723e-02, -1.4963e-01,\n",
            "        -1.9457e-01,  1.8117e-01, -1.2915e-01, -2.0571e-01, -1.2386e-01,\n",
            "         2.3432e-01, -1.4910e-01,  3.8293e-02,  2.6963e-01, -2.0583e-02,\n",
            "         9.4513e-02, -3.3481e-02,  2.5640e-01, -4.9515e-02,  2.9558e-02,\n",
            "         5.3198e-02, -6.3222e-02, -5.7688e-02, -2.6391e-01, -2.3071e-01,\n",
            "        -8.9908e-02, -2.8467e-02, -1.4720e-01, -1.7851e-01,  6.2032e-03,\n",
            "         1.1007e-01, -6.7376e-02, -1.5804e-01, -1.8772e-01,  2.4962e-01,\n",
            "         1.6563e-01, -1.6277e-01, -4.2493e-02,  1.1057e-01, -3.9204e-02,\n",
            "        -2.0506e-01,  1.9776e-01, -9.6054e-02, -5.6929e-03, -2.2618e-01,\n",
            "        -2.0790e-01, -1.9029e-01,  1.3608e-01, -3.1422e-01, -2.6992e-01,\n",
            "         7.7991e-02,  1.6599e-01, -3.3837e-02, -1.6515e-01, -1.2745e-01,\n",
            "        -1.2462e-01,  2.6771e-01,  2.2729e-01, -1.3097e-01, -4.4253e-02,\n",
            "         1.0624e-01,  2.5705e-01, -7.1460e-03, -6.9641e-02,  3.8371e-03,\n",
            "        -3.3212e-02,  8.0364e-02,  2.6093e-01, -1.1961e-01, -9.6360e-02,\n",
            "        -1.1973e-01, -1.6606e-01, -1.2331e-01, -2.6920e-01,  1.9686e-02,\n",
            "        -5.8151e-02,  1.8136e-01,  1.6283e-01, -1.1121e-02, -4.4180e-03,\n",
            "         2.3748e-01,  3.2436e-02, -6.1248e-02,  3.6969e-02,  2.1368e-01,\n",
            "        -4.0069e-02, -2.4372e-01, -1.4889e-01,  9.7467e-02, -2.0477e-01,\n",
            "        -1.4921e-01,  1.9618e-01, -2.2439e-02, -1.7702e-01, -1.7497e-01,\n",
            "        -2.1761e-01, -1.7363e-01,  1.6062e-01,  7.8463e-02,  7.7665e-02,\n",
            "        -4.9445e-02,  2.7120e-01, -1.5003e-01, -6.6621e-02, -1.1990e-01,\n",
            "         2.0177e-01, -7.1820e-02,  1.2721e-01,  1.5460e-02,  2.2416e-01,\n",
            "         6.2091e-02, -6.3505e-02,  2.4907e-01,  1.4272e-01, -2.2068e-02,\n",
            "         2.1559e-02, -1.4154e-01,  2.7242e-02,  2.3874e-01, -7.9190e-02,\n",
            "         1.5738e-01,  2.0272e-01,  1.4287e-01,  1.8635e-01, -2.3943e-01,\n",
            "         1.1490e-01, -2.0185e-01,  2.3787e-01, -5.2482e-02, -2.0377e-01,\n",
            "         2.4973e-02, -6.3446e-02, -1.5013e-02, -9.4897e-02, -1.3791e-01,\n",
            "        -4.2057e-03,  3.7496e-02, -1.6187e-01,  2.1403e-01, -1.4203e-01,\n",
            "        -1.6643e-01,  1.3480e-01,  2.2877e-01, -2.3888e-01,  1.7462e-01,\n",
            "        -1.0010e-01, -2.1918e-01, -1.5073e-01,  5.5106e-03, -2.8983e-01,\n",
            "         3.9519e-02,  1.0612e-01, -1.1904e-01, -1.3116e-01,  7.7087e-02,\n",
            "         3.3636e-02, -1.1259e-02, -6.6855e-02,  1.8728e-01,  3.5370e-02,\n",
            "        -1.4826e-01, -1.5381e-01,  2.2215e-01, -5.3303e-02, -2.4012e-01,\n",
            "         3.2939e-02,  1.7497e-01,  1.3834e-02, -2.2246e-01,  4.1876e-02,\n",
            "        -2.5295e-01, -2.4224e-01, -1.5097e-02, -1.3286e-01, -2.3617e-03,\n",
            "        -1.9421e-01,  1.2107e-01, -3.1866e-01, -9.9694e-02, -1.6487e-01,\n",
            "        -2.3743e-01,  1.2651e-01,  2.9342e-01,  1.3139e-01, -1.6302e-01,\n",
            "        -1.4642e-01,  2.7736e-01,  1.2988e-01,  2.3338e-01, -9.5983e-02,\n",
            "        -1.7241e-02, -8.3651e-02, -1.2265e-01,  3.9998e-02, -1.2143e-01,\n",
            "        -1.1453e-01,  1.4432e-01,  2.7843e-01, -1.7687e-01,  2.0660e-01,\n",
            "        -1.5286e-01,  3.0892e-02,  1.0358e-01,  2.7308e-01, -5.1299e-03,\n",
            "         2.1930e-01, -2.7485e-01,  1.8858e-02, -1.2056e-01,  9.3188e-02,\n",
            "        -2.2645e-01, -8.1150e-02,  3.8373e-02, -2.7591e-02,  7.6312e-02,\n",
            "         1.1775e-01,  1.3246e-01, -1.3430e-05, -4.1699e-02, -2.1390e-01,\n",
            "        -5.3978e-02,  8.5891e-02, -5.9943e-04, -2.7095e-02, -2.5858e-01,\n",
            "         2.0038e-01, -2.9196e-01, -2.3861e-01, -7.1474e-02, -2.8718e-01,\n",
            "         2.2093e-02, -1.8361e-01,  4.7634e-02, -2.6366e-01, -7.8709e-02,\n",
            "         1.7256e-01,  1.0734e-01,  1.7849e-01,  1.8279e-02, -2.0203e-01,\n",
            "        -4.4676e-02, -1.3209e-01,  1.1593e-01,  1.4939e-01,  7.5014e-02,\n",
            "         8.2130e-03,  2.3789e-01, -3.7183e-02, -7.6328e-02,  9.0142e-02,\n",
            "        -1.1631e-01, -1.0621e-01, -2.6075e-01,  2.1613e-01, -1.6345e-01,\n",
            "         9.8094e-02, -2.7046e-01, -1.0739e-01,  3.5831e-02, -2.4461e-01,\n",
            "         2.4778e-01, -3.3989e-02, -4.9079e-02, -2.0332e-01, -1.5568e-01,\n",
            "        -7.1182e-02,  1.6221e-02, -8.3215e-02, -2.6384e-01,  2.3058e-02,\n",
            "         6.2858e-02,  1.4205e-01,  1.5802e-01, -1.4322e-01, -2.0908e-02,\n",
            "         2.5010e-01,  4.4301e-02,  2.1774e-01, -4.2732e-02,  1.0044e-02,\n",
            "        -4.3556e-02, -1.0293e-01, -1.4434e-01,  2.8577e-01,  2.7591e-02,\n",
            "         6.6783e-02,  2.3174e-01, -7.7368e-02, -6.7234e-02, -8.6208e-03,\n",
            "         2.0237e-02,  2.0930e-01, -1.8311e-01, -2.0396e-01,  2.8488e-01,\n",
            "        -3.8860e-02, -2.1005e-01, -8.4328e-02, -3.0160e-01, -2.5700e-02,\n",
            "        -1.7167e-01,  2.4176e-02,  1.5852e-01, -8.1036e-02, -1.6360e-01,\n",
            "         6.4859e-02,  2.1737e-03,  1.3229e-02, -7.4838e-03, -6.3765e-02,\n",
            "         6.2564e-02, -1.8505e-01,  1.9394e-03, -6.1344e-02, -8.3270e-03,\n",
            "        -1.4439e-01, -2.9505e-01, -6.6557e-02,  8.0074e-02, -3.7233e-02,\n",
            "         2.1297e-01,  2.8420e-01, -2.5521e-01, -1.7353e-01,  2.1210e-01,\n",
            "        -1.8531e-02,  7.8541e-02,  2.0787e-01,  1.0043e-01, -8.5423e-02,\n",
            "         1.5692e-01, -1.2499e-01,  1.0684e-05, -1.0039e-01,  2.4486e-01,\n",
            "        -1.8927e-01,  3.9411e-02, -5.4653e-02, -2.4305e-01,  2.0448e-01,\n",
            "        -1.6231e-02, -4.4087e-02,  4.6425e-02, -2.1628e-01,  9.3039e-02,\n",
            "        -5.5682e-02,  2.0469e-01, -1.0366e-01, -5.4396e-02, -4.3864e-02,\n",
            "        -3.4870e-02,  2.5083e-01, -5.7526e-02, -3.9453e-02,  1.9069e-01,\n",
            "        -4.2505e-02,  2.7988e-01,  2.5380e-01, -1.8806e-01,  3.8245e-02,\n",
            "        -2.4720e-01,  3.0499e-01, -3.7159e-02, -1.4628e-01,  1.5035e-01,\n",
            "         1.3570e-01,  1.4913e-01, -4.9035e-02,  6.7168e-02,  4.2100e-02,\n",
            "        -1.7789e-01, -2.2426e-03, -3.4225e-02,  1.7065e-01,  2.7011e-01,\n",
            "         1.1303e-01,  1.7576e-01,  1.3180e-01, -9.0848e-02, -1.3681e-01,\n",
            "        -3.5822e-02,  1.5912e-01,  8.0947e-03, -3.2705e-01, -1.3834e-01,\n",
            "        -2.7672e-01,  1.2542e-01, -2.1973e-01, -2.9827e-01,  7.4989e-02,\n",
            "        -2.3022e-01,  1.4232e-01,  2.7307e-02, -1.5754e-01,  2.1841e-01,\n",
            "        -1.2695e-01, -2.5028e-01, -1.9695e-01, -1.3075e-01, -4.9782e-02,\n",
            "        -1.0036e-02, -2.7365e-02, -6.9372e-02, -1.1022e-01,  4.7022e-04,\n",
            "         1.4109e-01, -6.9246e-02, -1.9885e-01, -2.5309e-01, -3.3871e-02,\n",
            "        -1.6048e-02,  2.5742e-01, -3.5216e-03, -1.1093e-02,  2.3339e-01,\n",
            "         1.1786e-02, -8.7763e-03, -3.3860e-01, -1.4307e-01,  3.3911e-02,\n",
            "        -2.3595e-01, -2.3503e-02, -4.6227e-02, -2.8498e-01,  6.2032e-03,\n",
            "        -5.3378e-02,  2.7131e-01,  6.6774e-02, -3.5523e-02, -1.3004e-01,\n",
            "         1.4573e-01, -1.7861e-01, -2.3548e-02, -1.0485e-01, -1.2945e-01,\n",
            "        -1.7518e-01, -1.3296e-01,  1.6577e-01,  1.8394e-01,  9.5158e-02,\n",
            "         3.3196e-02, -7.9609e-02,  3.1252e-01, -1.2111e-01, -2.4201e-01,\n",
            "        -1.8994e-01, -6.3138e-02,  2.5066e-01, -1.8752e-02,  6.0443e-02,\n",
            "        -4.7046e-02,  1.3971e-01, -4.7870e-02,  2.3542e-02, -1.4159e-01,\n",
            "         3.9214e-02, -2.5992e-02,  2.2892e-01], requires_grad=True), Parameter containing:\n",
            "tensor([[-1.3236e-02,  6.4811e-03, -1.1150e-02,  ...,  6.2891e-02,\n",
            "          4.4141e-02, -1.9368e-02],\n",
            "        [ 1.9880e-02,  3.6904e-02, -7.1891e-03,  ..., -3.0057e-02,\n",
            "         -2.6242e-05, -1.7400e-02],\n",
            "        [-4.7332e-02,  2.9110e-02,  3.7217e-02,  ..., -1.4356e-02,\n",
            "         -2.1899e-02,  4.0449e-02],\n",
            "        ...,\n",
            "        [-9.5422e-05, -3.6382e-02, -2.6586e-02,  ...,  1.8594e-02,\n",
            "          1.8981e-02,  3.1674e-02],\n",
            "        [ 4.6296e-02,  8.1037e-03,  1.7496e-02,  ...,  3.9549e-02,\n",
            "         -4.0304e-02, -3.8278e-02],\n",
            "        [ 3.6269e-02, -3.1633e-02, -3.1824e-02,  ..., -2.1174e-02,\n",
            "          3.0281e-02, -3.2938e-02]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.2336, -0.1860, -0.0338, -0.0208,  0.1478, -0.0483,  0.2174,  0.1591,\n",
            "        -0.1770,  0.1735, -0.0416,  0.0032,  0.2102,  0.0381, -0.0294,  0.1468,\n",
            "         0.0429,  0.1094, -0.2944,  0.0004, -0.0042, -0.1002, -0.2013,  0.0895,\n",
            "         0.0558, -0.0786,  0.0977,  0.0244, -0.0678,  0.0245,  0.0783, -0.1733,\n",
            "         0.0162, -0.1029,  0.1247, -0.2602, -0.2654,  0.0476, -0.2402,  0.0466,\n",
            "        -0.0181, -0.1951, -0.0875,  0.0376, -0.1288,  0.0680, -0.0856,  0.0047,\n",
            "        -0.2598, -0.2181,  0.1931,  0.0638,  0.0011, -0.2355,  0.1073,  0.1022,\n",
            "         0.0574,  0.1169,  0.2495,  0.0324, -0.1354,  0.0336, -0.1483,  0.2000,\n",
            "         0.0359,  0.1803, -0.0707, -0.1053, -0.0640,  0.0333,  0.1834,  0.1948,\n",
            "         0.0295, -0.0470, -0.0345, -0.0066, -0.1460,  0.0106,  0.0293, -0.2938,\n",
            "         0.0425,  0.2533,  0.1032, -0.2597,  0.2137, -0.1274, -0.0177, -0.3378,\n",
            "         0.1755,  0.0494,  0.1751,  0.1690,  0.1654,  0.0123, -0.1912, -0.0431,\n",
            "        -0.2380, -0.0465, -0.0466, -0.0044, -0.0099, -0.0603,  0.0010, -0.0928,\n",
            "        -0.2514, -0.1165, -0.0092,  0.1990, -0.2921, -0.2693,  0.0221, -0.1067,\n",
            "        -0.0129, -0.2545, -0.0719], requires_grad=True), Parameter containing:\n",
            "tensor([[-4.2872e-02,  1.0834e-02, -7.7581e-02, -1.4319e-02, -8.0473e-02,\n",
            "          8.6159e-02, -1.0799e-01, -9.2837e-02,  7.1019e-02, -4.1078e-03,\n",
            "         -4.0234e-02, -1.6205e-02, -7.9562e-02, -8.7361e-03, -8.0029e-02,\n",
            "         -1.0022e-01, -3.2595e-02, -1.0569e-01,  1.1490e-02, -4.8134e-02,\n",
            "         -4.9987e-02,  5.2834e-02,  3.1229e-02, -6.8182e-02, -5.2112e-02,\n",
            "         -4.2635e-02, -3.1956e-02, -7.6207e-03, -1.0799e-02, -1.0524e-02,\n",
            "         -9.7672e-02,  2.5081e-03, -5.8269e-02,  2.9862e-02,  1.0838e-01,\n",
            "          8.8252e-02,  9.7546e-02, -9.7802e-03,  6.9182e-02, -2.2035e-03,\n",
            "         -1.7511e-02,  5.5774e-02, -2.9448e-05, -5.6236e-03,  3.1253e-03,\n",
            "         -8.4724e-02,  8.8321e-02, -5.5764e-02,  8.7019e-03,  4.8530e-02,\n",
            "         -8.1958e-02, -3.0060e-02, -1.3156e-02,  7.6622e-02,  1.0933e-01,\n",
            "          1.5849e-01, -4.6840e-02, -4.2104e-02, -1.3525e-01,  5.3431e-02,\n",
            "          3.7436e-02, -8.8658e-03,  3.6114e-04, -1.1985e-01, -1.3024e-02,\n",
            "         -1.2482e-01, -2.4560e-02,  8.8538e-02,  1.0249e-01, -1.8680e-02,\n",
            "         -9.9498e-02, -1.1471e-01, -6.4317e-02, -5.6041e-02, -2.3953e-02,\n",
            "         -5.0327e-02,  3.5223e-02, -3.8054e-02, -7.6273e-02,  8.5961e-02,\n",
            "         -7.7879e-02, -5.3025e-02, -9.7310e-02,  1.8153e-03, -1.2934e-01,\n",
            "          1.0256e-02,  8.8620e-02,  5.3176e-02, -6.6520e-02, -7.0007e-02,\n",
            "         -1.4675e-01, -7.6832e-02, -5.8126e-02, -3.8785e-02,  9.2051e-02,\n",
            "          8.6022e-02,  5.0556e-02, -2.6091e-02,  8.2485e-02, -1.0869e-02,\n",
            "          6.8174e-02,  4.8566e-03, -3.4459e-02,  8.2095e-02,  2.7277e-02,\n",
            "          3.1504e-02,  6.1205e-02, -1.1220e-01,  8.7067e-02,  4.9831e-02,\n",
            "         -3.5357e-02,  2.7251e-02, -2.1248e-02,  6.1461e-02,  6.1719e-02]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.1878], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "#%%script echo skipping\n",
        "\n",
        "print(list(net.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NZ8iVA7UZio",
        "outputId": "6341def7-b7e7-44eb-c91f-edbe1d22ca1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.3159, -0.0649, -0.2168,  ..., -0.0371,  0.3013,  0.4135],\n",
            "        [-0.2336, -0.2635, -0.2063,  ...,  0.0615,  0.1547,  0.0311],\n",
            "        [-0.1370, -0.1472,  0.1281,  ..., -0.3203, -0.3451, -0.3116],\n",
            "        ...,\n",
            "        [-0.0519,  0.1711, -0.0290,  ..., -0.0589, -0.2497, -0.2148],\n",
            "        [ 0.0202,  0.0130,  0.0634,  ..., -0.0005,  0.0069,  0.1894],\n",
            "        [-0.0495, -0.1790, -0.2162,  ...,  0.3967,  0.0923,  0.2245]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 2.0588e-01, -1.9305e-01, -3.0101e-01, -5.1728e-01, -2.4763e-01,\n",
            "        -2.0962e-01,  2.7760e-01,  3.4975e-01, -6.7619e-02,  1.8556e-01,\n",
            "         3.0503e-02,  1.8390e-01, -1.6853e-01,  2.8958e-01, -1.0623e-01,\n",
            "         8.0919e-02,  7.4536e-02, -2.4037e-01,  8.6932e-02,  1.2053e-01,\n",
            "        -1.1944e-01,  5.9453e-03, -1.8307e-01, -1.9311e-01,  1.5377e-01,\n",
            "         8.2893e-02, -8.6109e-02,  4.7653e-01, -2.4865e-02, -8.3183e-02,\n",
            "         6.6792e-02, -2.9553e-01, -4.6941e-01, -1.8324e-01,  1.5912e-02,\n",
            "        -3.3994e-01,  1.8566e-01, -2.4563e-01, -1.1195e-02, -2.2146e-01,\n",
            "         7.9129e-02,  2.3136e-01, -2.9273e-01, -5.9733e-02, -6.7965e-03,\n",
            "         1.0222e-01,  1.1420e-01, -1.0040e-01, -1.0898e-01,  1.9044e-01,\n",
            "        -1.9786e-01, -2.9880e-01, -5.7297e-02, -3.7630e-01, -1.6025e-01,\n",
            "        -1.6762e-01,  8.0401e-04,  1.1664e-01, -3.7064e-02, -1.9179e-01,\n",
            "         1.4725e-02, -1.5003e-01,  2.7907e-02, -1.1941e-01,  2.6792e-01,\n",
            "         9.2453e-02, -1.7316e-01,  1.6110e-01,  7.2112e-02,  6.9632e-02,\n",
            "         1.0352e-01,  6.2849e-02,  1.6177e-01,  2.2803e-03, -6.7391e-02,\n",
            "         8.5557e-02, -9.2158e-02,  1.1707e-01, -4.9072e-01, -2.9632e-01,\n",
            "         3.6219e-01,  3.6151e-01,  2.4794e-01, -1.1813e-01, -4.4705e-01,\n",
            "        -3.6193e-01, -8.2615e-02,  1.3091e-03, -3.6154e-01, -8.1780e-02,\n",
            "         8.6485e-02, -1.4164e-01, -2.7033e-01, -3.9239e-01, -5.1772e-02,\n",
            "         4.1199e-01, -4.5400e-01, -1.4925e-01, -1.4238e-01,  3.3402e-02,\n",
            "        -3.4221e-01, -1.7351e-01, -4.4519e-01,  2.0338e-01,  9.5345e-02,\n",
            "        -1.8455e-01,  3.7593e-01, -3.2680e-01,  6.3817e-02,  3.6147e-01,\n",
            "        -2.9379e-01,  1.9933e-01,  3.9349e-01,  4.4056e-01,  1.8072e-01,\n",
            "        -4.5688e-01, -5.3385e-02,  2.5012e-01, -2.0024e-02, -1.7398e-01,\n",
            "        -8.9960e-02, -3.6617e-01, -2.6236e-01,  2.0631e-01, -1.0721e-01,\n",
            "         4.4706e-02, -1.8680e-01,  4.7401e-04,  4.0402e-01, -8.4989e-02,\n",
            "        -6.3677e-02,  1.7327e-01, -3.8237e-01,  3.4098e-01, -4.7686e-01,\n",
            "         4.0185e-01, -2.3006e-01,  1.1417e-01,  3.1241e-01, -1.4513e-01,\n",
            "         7.2144e-02,  7.2692e-02, -1.1493e-01,  6.8241e-02,  4.1139e-02,\n",
            "        -3.2033e-01,  3.8422e-02, -4.2652e-01, -4.5426e-02,  2.7291e-01,\n",
            "         1.4148e-01, -4.8934e-01, -1.7373e-02, -3.5998e-01,  1.7349e-01,\n",
            "        -1.7249e-01, -3.4145e-01, -4.1155e-01, -1.3268e-01, -2.1725e-02,\n",
            "         1.0635e-01,  1.9570e-01, -1.1426e-01, -3.5578e-01, -5.7672e-01,\n",
            "        -2.5749e-01, -1.2567e-01,  9.8504e-02, -1.7369e-02,  7.0227e-02,\n",
            "         3.6953e-03, -3.4672e-01, -3.0548e-01, -3.7887e-01, -1.6264e-01,\n",
            "         1.4039e-01, -1.9679e-01,  1.7876e-02,  1.3761e-01,  6.0899e-02,\n",
            "         3.8998e-02, -1.2943e-01, -1.8296e-01, -4.0720e-01, -1.2164e-01,\n",
            "        -1.8384e-01, -3.8165e-01,  3.7694e-01,  7.6722e-03, -3.2214e-01,\n",
            "        -4.1720e-01,  2.8907e-01, -2.6635e-01, -1.6116e-01, -1.7237e-02,\n",
            "        -1.1100e-01, -2.6093e-01,  2.5589e-01,  3.2110e-01,  1.9380e-01,\n",
            "        -1.4386e-01, -2.5993e-01, -2.7618e-01, -4.5316e-01, -3.1956e-01,\n",
            "        -2.3986e-01, -4.9278e-02,  2.5345e-01,  2.6798e-02,  2.0661e-01,\n",
            "        -1.2716e-01, -3.3278e-01, -9.0399e-02, -7.6747e-02,  8.6009e-02,\n",
            "        -1.3432e-02,  4.2588e-01,  2.6377e-01, -2.1094e-01, -1.3684e-02,\n",
            "         1.7743e-01, -1.3444e-01,  1.1443e-01, -5.0545e-01,  2.0264e-01,\n",
            "        -2.4707e-01,  4.1371e-01, -4.5546e-01, -3.5678e-01, -2.5189e-02,\n",
            "        -7.2217e-02, -2.3777e-01, -1.9828e-01, -8.1106e-02,  1.3008e-01,\n",
            "         8.2367e-02,  3.9728e-01, -1.3167e-01,  2.6319e-01,  1.8088e-02,\n",
            "         5.0076e-01,  2.1786e-02,  2.0203e-01, -3.4681e-02, -8.1311e-02,\n",
            "        -1.3473e-01, -2.6268e-01,  1.0614e-02,  9.8241e-02, -2.4949e-01,\n",
            "        -1.2426e-01, -1.6088e-01, -1.6834e-01, -5.3760e-01, -6.2445e-01,\n",
            "         7.7138e-02,  4.6507e-01,  3.9524e-01, -2.8447e-01,  1.2564e-02,\n",
            "        -1.4120e-01, -3.7902e-01, -1.7945e-01,  3.1023e-01,  2.0275e-01,\n",
            "         3.4889e-01, -4.4454e-01, -1.6195e-01,  3.3695e-02, -4.7766e-01,\n",
            "         3.1039e-01, -3.5513e-01, -2.8091e-01,  2.5845e-01, -3.1342e-01,\n",
            "        -3.1627e-01,  8.1072e-02, -2.1007e-01, -2.7382e-01,  5.8525e-03,\n",
            "        -2.8040e-01,  9.7899e-02, -2.0036e-01,  3.2368e-01, -5.3085e-02,\n",
            "        -2.4195e-01, -1.5689e-01,  4.1836e-01, -3.7462e-01,  3.0288e-01,\n",
            "        -1.8945e-01, -5.7286e-02,  6.8946e-02, -3.8417e-02,  1.3365e-01,\n",
            "         3.0410e-01,  3.2722e-01,  1.9658e-01, -4.2935e-01,  7.4424e-02,\n",
            "         3.8722e-01, -5.8526e-01,  2.8909e-01, -4.8185e-01,  1.3913e-01,\n",
            "        -8.1399e-02,  8.9916e-02,  1.5059e-01,  1.9781e-01,  1.4966e-01,\n",
            "        -2.0335e-01, -3.7986e-01, -2.1252e-01,  1.6347e-01, -3.2121e-01,\n",
            "         5.7943e-02, -3.8356e-02,  1.4515e-01, -1.5214e-01,  1.9471e-01,\n",
            "        -5.4984e-01, -2.8943e-01, -2.5663e-01, -2.8214e-01, -9.9286e-02,\n",
            "        -3.3184e-01, -3.0073e-01, -2.2658e-01, -7.6238e-02,  9.2659e-02,\n",
            "        -1.9267e-01, -2.2313e-01, -9.4374e-02, -2.2954e-02, -2.2297e-02,\n",
            "         2.2373e-01, -1.4857e-01, -1.8887e-01, -3.9183e-01, -1.3852e-01,\n",
            "         3.8167e-01,  2.7367e-02, -3.4740e-01,  3.3222e-01, -1.3077e-01,\n",
            "        -3.7890e-02, -5.2655e-01,  7.2913e-02, -9.5315e-02,  2.4509e-01,\n",
            "        -1.9020e-01, -1.6617e-01,  1.6301e-01, -1.9362e-01, -1.5296e-01,\n",
            "         2.6923e-01,  6.5615e-02,  3.2152e-01, -2.0504e-01,  1.0676e-01,\n",
            "        -3.3809e-02,  9.2808e-02,  2.4239e-01, -2.2409e-01, -2.5207e-03,\n",
            "        -2.0141e-02, -3.6328e-01, -2.6104e-01, -3.7320e-01, -3.6876e-01,\n",
            "        -9.6008e-02, -9.3144e-02,  2.3825e-01, -2.4572e-01,  8.0336e-02,\n",
            "         3.4587e-01, -1.1985e-02,  6.7888e-02, -3.5936e-02,  4.5511e-01,\n",
            "        -4.3733e-01,  1.8091e-01,  1.8772e-01, -3.7019e-01, -2.4957e-01,\n",
            "        -4.3855e-01, -2.8087e-01, -5.5334e-02, -1.4797e-02, -2.3006e-01,\n",
            "        -2.0763e-01, -1.4386e-01, -8.0051e-02, -4.1988e-01,  1.6198e-01,\n",
            "        -2.4702e-01,  2.3853e-01, -3.2432e-01,  1.2626e-01,  5.6511e-02,\n",
            "         3.4840e-01,  3.5222e-01,  1.8126e-01, -4.5142e-01,  1.0268e-01,\n",
            "         8.6561e-02, -4.3660e-01, -5.1914e-02, -2.9915e-01, -7.1143e-02,\n",
            "         8.2002e-02, -3.9986e-01, -1.1722e-01,  4.6767e-02, -7.5587e-02,\n",
            "        -1.9705e-01,  1.2666e-01, -1.0774e-01,  5.3669e-02, -1.9884e-02,\n",
            "        -5.0558e-01,  4.2794e-02, -2.3915e-02, -1.0502e-02,  2.6688e-01,\n",
            "         2.6824e-01, -5.1433e-01, -1.6495e-02, -1.4819e-03, -3.8437e-01,\n",
            "        -8.7899e-02,  1.9838e-01, -3.2787e-02, -7.2574e-02,  1.0291e-01,\n",
            "         9.8362e-03, -5.3070e-02,  3.5327e-02, -3.6211e-01, -1.4742e-01,\n",
            "        -2.3850e-01, -2.6813e-01, -3.3612e-01, -1.8880e-01, -2.3708e-01,\n",
            "        -5.2259e-01, -5.7756e-02, -1.5390e-01, -3.4311e-01,  1.2438e-01,\n",
            "         2.3575e-01, -1.6264e-01, -1.9403e-01, -3.7250e-02, -1.3269e-01,\n",
            "        -1.2736e-01,  2.8374e-01, -5.2109e-02, -2.2790e-01, -1.8739e-01,\n",
            "        -1.6039e-01, -4.7185e-01, -1.7941e-01,  6.0994e-02, -9.5169e-02,\n",
            "         3.9558e-02,  2.0657e-01, -3.1098e-01,  2.6100e-01, -4.7441e-03,\n",
            "         9.8920e-02,  3.5911e-01, -2.8216e-01, -5.4472e-01, -9.1303e-02,\n",
            "         2.3600e-01, -3.1029e-01,  4.1374e-01,  1.1157e-01,  1.4411e-01,\n",
            "        -1.5056e-01, -2.1224e-01,  3.7482e-01,  1.4302e-01, -5.3584e-02,\n",
            "        -1.7875e-01, -1.9165e-01, -1.0970e-02, -1.8759e-01,  2.0830e-02,\n",
            "         4.8061e-02, -4.9552e-01, -2.1365e-01, -1.1748e-02, -4.6506e-03,\n",
            "         2.9391e-01, -9.7113e-02, -3.8608e-01, -7.8843e-02, -1.4988e-01,\n",
            "        -2.7654e-01, -5.2548e-01, -3.5996e-01, -2.4851e-01, -2.4574e-01,\n",
            "         2.8503e-02,  3.6449e-02, -3.7317e-01, -4.0168e-01,  4.0303e-01,\n",
            "        -2.3274e-01,  3.6747e-01,  2.1945e-01, -7.8553e-02, -6.4229e-02,\n",
            "        -2.7917e-01, -2.9738e-01, -3.6281e-01, -4.2110e-02, -3.6332e-01,\n",
            "         1.9761e-01, -1.9214e-01, -6.3951e-01,  1.3061e-01, -8.6660e-02,\n",
            "        -6.0466e-02, -2.2589e-01,  9.8582e-03,  6.7469e-03,  1.4764e-01,\n",
            "        -2.3418e-01, -2.3177e-02,  4.6557e-02, -3.6946e-01,  3.4663e-01,\n",
            "        -1.2411e-01, -3.2976e-01,  1.3031e-01,  4.0028e-01, -1.2857e-02,\n",
            "        -3.3673e-01, -9.9200e-02,  3.5799e-02, -2.4606e-01, -1.4181e-01,\n",
            "        -4.4975e-01, -3.8280e-03,  4.2146e-01, -1.0332e-01, -1.2685e-02,\n",
            "        -1.4376e-01, -1.9429e-01, -1.1269e-02,  6.9136e-02,  3.9813e-01],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0245,  0.0011,  0.0105,  ..., -0.0239,  0.0367, -0.0615],\n",
            "        [ 0.1025, -0.0139, -0.0320,  ...,  0.0421,  0.0544,  0.0547],\n",
            "        [ 0.0174, -0.0367, -0.0101,  ...,  0.0319,  0.0189, -0.0384],\n",
            "        ...,\n",
            "        [ 0.0497,  0.0114, -0.0408,  ...,  0.0457,  0.0373,  0.0596],\n",
            "        [ 0.0289,  0.0121, -0.0390,  ...,  0.0342,  0.0330, -0.0117],\n",
            "        [ 0.0504, -0.0005,  0.0533,  ...,  0.0180,  0.0328,  0.0673]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-2.8524e-01,  2.2778e-01, -1.6855e-01, -7.4723e-02, -1.4963e-01,\n",
            "        -1.9457e-01,  1.8117e-01, -1.2915e-01, -2.0571e-01, -1.2386e-01,\n",
            "         2.3432e-01, -1.4910e-01,  3.8293e-02,  2.6963e-01, -2.0583e-02,\n",
            "         9.4513e-02, -3.3481e-02,  2.5640e-01, -4.9515e-02,  2.9558e-02,\n",
            "         5.3198e-02, -6.3222e-02, -5.7688e-02, -2.6391e-01, -2.3071e-01,\n",
            "        -8.9908e-02, -2.8467e-02, -1.4720e-01, -1.7851e-01,  6.2032e-03,\n",
            "         1.1007e-01, -6.7376e-02, -1.5804e-01, -1.8772e-01,  2.4962e-01,\n",
            "         1.6563e-01, -1.6277e-01, -4.2493e-02,  1.1057e-01, -3.9204e-02,\n",
            "        -2.0506e-01,  1.9776e-01, -9.6054e-02, -5.6929e-03, -2.2618e-01,\n",
            "        -2.0790e-01, -1.9029e-01,  1.3608e-01, -3.1422e-01, -2.6992e-01,\n",
            "         7.7991e-02,  1.6599e-01, -3.3837e-02, -1.6515e-01, -1.2745e-01,\n",
            "        -1.2462e-01,  2.6771e-01,  2.2729e-01, -1.3097e-01, -4.4253e-02,\n",
            "         1.0624e-01,  2.5705e-01, -7.1460e-03, -6.9641e-02,  3.8371e-03,\n",
            "        -3.3212e-02,  8.0364e-02,  2.6093e-01, -1.1961e-01, -9.6360e-02,\n",
            "        -1.1973e-01, -1.6606e-01, -1.2331e-01, -2.6920e-01,  1.9686e-02,\n",
            "        -5.8151e-02,  1.8136e-01,  1.6283e-01, -1.1121e-02, -4.4180e-03,\n",
            "         2.3748e-01,  3.2436e-02, -6.1248e-02,  3.6969e-02,  2.1368e-01,\n",
            "        -4.0069e-02, -2.4372e-01, -1.4889e-01,  9.7467e-02, -2.0477e-01,\n",
            "        -1.4921e-01,  1.9618e-01, -2.2439e-02, -1.7702e-01, -1.7497e-01,\n",
            "        -2.1761e-01, -1.7363e-01,  1.6062e-01,  7.8463e-02,  7.7665e-02,\n",
            "        -4.9445e-02,  2.7120e-01, -1.5003e-01, -6.6621e-02, -1.1990e-01,\n",
            "         2.0177e-01, -7.1820e-02,  1.2721e-01,  1.5460e-02,  2.2416e-01,\n",
            "         6.2091e-02, -6.3505e-02,  2.4907e-01,  1.4272e-01, -2.2068e-02,\n",
            "         2.1559e-02, -1.4154e-01,  2.7242e-02,  2.3874e-01, -7.9190e-02,\n",
            "         1.5738e-01,  2.0272e-01,  1.4287e-01,  1.8635e-01, -2.3943e-01,\n",
            "         1.1490e-01, -2.0185e-01,  2.3787e-01, -5.2482e-02, -2.0377e-01,\n",
            "         2.4973e-02, -6.3446e-02, -1.5013e-02, -9.4897e-02, -1.3791e-01,\n",
            "        -4.2057e-03,  3.7496e-02, -1.6187e-01,  2.1403e-01, -1.4203e-01,\n",
            "        -1.6643e-01,  1.3480e-01,  2.2877e-01, -2.3888e-01,  1.7462e-01,\n",
            "        -1.0010e-01, -2.1918e-01, -1.5073e-01,  5.5106e-03, -2.8983e-01,\n",
            "         3.9519e-02,  1.0612e-01, -1.1904e-01, -1.3116e-01,  7.7087e-02,\n",
            "         3.3636e-02, -1.1259e-02, -6.6855e-02,  1.8728e-01,  3.5370e-02,\n",
            "        -1.4826e-01, -1.5381e-01,  2.2215e-01, -5.3303e-02, -2.4012e-01,\n",
            "         3.2939e-02,  1.7497e-01,  1.3834e-02, -2.2246e-01,  4.1876e-02,\n",
            "        -2.5295e-01, -2.4224e-01, -1.5097e-02, -1.3286e-01, -2.3617e-03,\n",
            "        -1.9421e-01,  1.2107e-01, -3.1866e-01, -9.9694e-02, -1.6487e-01,\n",
            "        -2.3743e-01,  1.2651e-01,  2.9342e-01,  1.3139e-01, -1.6302e-01,\n",
            "        -1.4642e-01,  2.7736e-01,  1.2988e-01,  2.3338e-01, -9.5983e-02,\n",
            "        -1.7241e-02, -8.3651e-02, -1.2265e-01,  3.9998e-02, -1.2143e-01,\n",
            "        -1.1453e-01,  1.4432e-01,  2.7843e-01, -1.7687e-01,  2.0660e-01,\n",
            "        -1.5286e-01,  3.0892e-02,  1.0358e-01,  2.7308e-01, -5.1299e-03,\n",
            "         2.1930e-01, -2.7485e-01,  1.8858e-02, -1.2056e-01,  9.3188e-02,\n",
            "        -2.2645e-01, -8.1150e-02,  3.8373e-02, -2.7591e-02,  7.6312e-02,\n",
            "         1.1775e-01,  1.3246e-01, -1.3430e-05, -4.1699e-02, -2.1390e-01,\n",
            "        -5.3978e-02,  8.5891e-02, -5.9943e-04, -2.7095e-02, -2.5858e-01,\n",
            "         2.0038e-01, -2.9196e-01, -2.3861e-01, -7.1474e-02, -2.8718e-01,\n",
            "         2.2093e-02, -1.8361e-01,  4.7634e-02, -2.6366e-01, -7.8709e-02,\n",
            "         1.7256e-01,  1.0734e-01,  1.7849e-01,  1.8279e-02, -2.0203e-01,\n",
            "        -4.4676e-02, -1.3209e-01,  1.1593e-01,  1.4939e-01,  7.5014e-02,\n",
            "         8.2130e-03,  2.3789e-01, -3.7183e-02, -7.6328e-02,  9.0142e-02,\n",
            "        -1.1631e-01, -1.0621e-01, -2.6075e-01,  2.1613e-01, -1.6345e-01,\n",
            "         9.8094e-02, -2.7046e-01, -1.0739e-01,  3.5831e-02, -2.4461e-01,\n",
            "         2.4778e-01, -3.3989e-02, -4.9079e-02, -2.0332e-01, -1.5568e-01,\n",
            "        -7.1182e-02,  1.6221e-02, -8.3215e-02, -2.6384e-01,  2.3058e-02,\n",
            "         6.2858e-02,  1.4205e-01,  1.5802e-01, -1.4322e-01, -2.0908e-02,\n",
            "         2.5010e-01,  4.4301e-02,  2.1774e-01, -4.2732e-02,  1.0044e-02,\n",
            "        -4.3556e-02, -1.0293e-01, -1.4434e-01,  2.8577e-01,  2.7591e-02,\n",
            "         6.6783e-02,  2.3174e-01, -7.7368e-02, -6.7234e-02, -8.6208e-03,\n",
            "         2.0237e-02,  2.0930e-01, -1.8311e-01, -2.0396e-01,  2.8488e-01,\n",
            "        -3.8860e-02, -2.1005e-01, -8.4328e-02, -3.0160e-01, -2.5700e-02,\n",
            "        -1.7167e-01,  2.4176e-02,  1.5852e-01, -8.1036e-02, -1.6360e-01,\n",
            "         6.4859e-02,  2.1737e-03,  1.3229e-02, -7.4838e-03, -6.3765e-02,\n",
            "         6.2564e-02, -1.8505e-01,  1.9394e-03, -6.1344e-02, -8.3270e-03,\n",
            "        -1.4439e-01, -2.9505e-01, -6.6557e-02,  8.0074e-02, -3.7233e-02,\n",
            "         2.1297e-01,  2.8420e-01, -2.5521e-01, -1.7353e-01,  2.1210e-01,\n",
            "        -1.8531e-02,  7.8541e-02,  2.0787e-01,  1.0043e-01, -8.5423e-02,\n",
            "         1.5692e-01, -1.2499e-01,  1.0684e-05, -1.0039e-01,  2.4486e-01,\n",
            "        -1.8927e-01,  3.9411e-02, -5.4653e-02, -2.4305e-01,  2.0448e-01,\n",
            "        -1.6231e-02, -4.4087e-02,  4.6425e-02, -2.1628e-01,  9.3039e-02,\n",
            "        -5.5682e-02,  2.0469e-01, -1.0366e-01, -5.4396e-02, -4.3864e-02,\n",
            "        -3.4870e-02,  2.5083e-01, -5.7526e-02, -3.9453e-02,  1.9069e-01,\n",
            "        -4.2505e-02,  2.7988e-01,  2.5380e-01, -1.8806e-01,  3.8245e-02,\n",
            "        -2.4720e-01,  3.0499e-01, -3.7159e-02, -1.4628e-01,  1.5035e-01,\n",
            "         1.3570e-01,  1.4913e-01, -4.9035e-02,  6.7168e-02,  4.2100e-02,\n",
            "        -1.7789e-01, -2.2426e-03, -3.4225e-02,  1.7065e-01,  2.7011e-01,\n",
            "         1.1303e-01,  1.7576e-01,  1.3180e-01, -9.0848e-02, -1.3681e-01,\n",
            "        -3.5822e-02,  1.5912e-01,  8.0947e-03, -3.2705e-01, -1.3834e-01,\n",
            "        -2.7672e-01,  1.2542e-01, -2.1973e-01, -2.9827e-01,  7.4989e-02,\n",
            "        -2.3022e-01,  1.4232e-01,  2.7307e-02, -1.5754e-01,  2.1841e-01,\n",
            "        -1.2695e-01, -2.5028e-01, -1.9695e-01, -1.3075e-01, -4.9782e-02,\n",
            "        -1.0036e-02, -2.7365e-02, -6.9372e-02, -1.1022e-01,  4.7022e-04,\n",
            "         1.4109e-01, -6.9246e-02, -1.9885e-01, -2.5309e-01, -3.3871e-02,\n",
            "        -1.6048e-02,  2.5742e-01, -3.5216e-03, -1.1093e-02,  2.3339e-01,\n",
            "         1.1786e-02, -8.7763e-03, -3.3860e-01, -1.4307e-01,  3.3911e-02,\n",
            "        -2.3595e-01, -2.3503e-02, -4.6227e-02, -2.8498e-01,  6.2032e-03,\n",
            "        -5.3378e-02,  2.7131e-01,  6.6774e-02, -3.5523e-02, -1.3004e-01,\n",
            "         1.4573e-01, -1.7861e-01, -2.3548e-02, -1.0485e-01, -1.2945e-01,\n",
            "        -1.7518e-01, -1.3296e-01,  1.6577e-01,  1.8394e-01,  9.5158e-02,\n",
            "         3.3196e-02, -7.9609e-02,  3.1252e-01, -1.2111e-01, -2.4201e-01,\n",
            "        -1.8994e-01, -6.3138e-02,  2.5066e-01, -1.8752e-02,  6.0443e-02,\n",
            "        -4.7046e-02,  1.3971e-01, -4.7870e-02,  2.3542e-02, -1.4159e-01,\n",
            "         3.9214e-02, -2.5992e-02,  2.2892e-01], requires_grad=True), Parameter containing:\n",
            "tensor([[-1.3236e-02,  6.4811e-03, -1.1150e-02,  ...,  6.2891e-02,\n",
            "          4.4141e-02, -1.9368e-02],\n",
            "        [ 1.9880e-02,  3.6904e-02, -7.1891e-03,  ..., -3.0057e-02,\n",
            "         -2.6242e-05, -1.7400e-02],\n",
            "        [-4.7332e-02,  2.9110e-02,  3.7217e-02,  ..., -1.4356e-02,\n",
            "         -2.1899e-02,  4.0449e-02],\n",
            "        ...,\n",
            "        [-9.5422e-05, -3.6382e-02, -2.6586e-02,  ...,  1.8594e-02,\n",
            "          1.8981e-02,  3.1674e-02],\n",
            "        [ 4.6296e-02,  8.1037e-03,  1.7496e-02,  ...,  3.9549e-02,\n",
            "         -4.0304e-02, -3.8278e-02],\n",
            "        [ 3.6269e-02, -3.1633e-02, -3.1824e-02,  ..., -2.1174e-02,\n",
            "          3.0281e-02, -3.2938e-02]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.2336, -0.1860, -0.0338, -0.0208,  0.1478, -0.0483,  0.2174,  0.1591,\n",
            "        -0.1770,  0.1735, -0.0416,  0.0032,  0.2102,  0.0381, -0.0294,  0.1468,\n",
            "         0.0429,  0.1094, -0.2944,  0.0004, -0.0042, -0.1002, -0.2013,  0.0895,\n",
            "         0.0558, -0.0786,  0.0977,  0.0244, -0.0678,  0.0245,  0.0783, -0.1733,\n",
            "         0.0162, -0.1029,  0.1247, -0.2602, -0.2654,  0.0476, -0.2402,  0.0466,\n",
            "        -0.0181, -0.1951, -0.0875,  0.0376, -0.1288,  0.0680, -0.0856,  0.0047,\n",
            "        -0.2598, -0.2181,  0.1931,  0.0638,  0.0011, -0.2355,  0.1073,  0.1022,\n",
            "         0.0574,  0.1169,  0.2495,  0.0324, -0.1354,  0.0336, -0.1483,  0.2000,\n",
            "         0.0359,  0.1803, -0.0707, -0.1053, -0.0640,  0.0333,  0.1834,  0.1948,\n",
            "         0.0295, -0.0470, -0.0345, -0.0066, -0.1460,  0.0106,  0.0293, -0.2938,\n",
            "         0.0425,  0.2533,  0.1032, -0.2597,  0.2137, -0.1274, -0.0177, -0.3378,\n",
            "         0.1755,  0.0494,  0.1751,  0.1690,  0.1654,  0.0123, -0.1912, -0.0431,\n",
            "        -0.2380, -0.0465, -0.0466, -0.0044, -0.0099, -0.0603,  0.0010, -0.0928,\n",
            "        -0.2514, -0.1165, -0.0092,  0.1990, -0.2921, -0.2693,  0.0221, -0.1067,\n",
            "        -0.0129, -0.2545, -0.0719], requires_grad=True), Parameter containing:\n",
            "tensor([[-4.2872e-02,  1.0834e-02, -7.7581e-02, -1.4319e-02, -8.0473e-02,\n",
            "          8.6159e-02, -1.0799e-01, -9.2837e-02,  7.1019e-02, -4.1078e-03,\n",
            "         -4.0234e-02, -1.6205e-02, -7.9562e-02, -8.7361e-03, -8.0029e-02,\n",
            "         -1.0022e-01, -3.2595e-02, -1.0569e-01,  1.1490e-02, -4.8134e-02,\n",
            "         -4.9987e-02,  5.2834e-02,  3.1229e-02, -6.8182e-02, -5.2112e-02,\n",
            "         -4.2635e-02, -3.1956e-02, -7.6207e-03, -1.0799e-02, -1.0524e-02,\n",
            "         -9.7672e-02,  2.5081e-03, -5.8269e-02,  2.9862e-02,  1.0838e-01,\n",
            "          8.8252e-02,  9.7546e-02, -9.7802e-03,  6.9182e-02, -2.2035e-03,\n",
            "         -1.7511e-02,  5.5774e-02, -2.9448e-05, -5.6236e-03,  3.1253e-03,\n",
            "         -8.4724e-02,  8.8321e-02, -5.5764e-02,  8.7019e-03,  4.8530e-02,\n",
            "         -8.1958e-02, -3.0060e-02, -1.3156e-02,  7.6622e-02,  1.0933e-01,\n",
            "          1.5849e-01, -4.6840e-02, -4.2104e-02, -1.3525e-01,  5.3431e-02,\n",
            "          3.7436e-02, -8.8658e-03,  3.6114e-04, -1.1985e-01, -1.3024e-02,\n",
            "         -1.2482e-01, -2.4560e-02,  8.8538e-02,  1.0249e-01, -1.8680e-02,\n",
            "         -9.9498e-02, -1.1471e-01, -6.4317e-02, -5.6041e-02, -2.3953e-02,\n",
            "         -5.0327e-02,  3.5223e-02, -3.8054e-02, -7.6273e-02,  8.5961e-02,\n",
            "         -7.7879e-02, -5.3025e-02, -9.7310e-02,  1.8153e-03, -1.2934e-01,\n",
            "          1.0256e-02,  8.8620e-02,  5.3176e-02, -6.6520e-02, -7.0007e-02,\n",
            "         -1.4675e-01, -7.6832e-02, -5.8126e-02, -3.8785e-02,  9.2051e-02,\n",
            "          8.6022e-02,  5.0556e-02, -2.6091e-02,  8.2485e-02, -1.0869e-02,\n",
            "          6.8174e-02,  4.8566e-03, -3.4459e-02,  8.2095e-02,  2.7277e-02,\n",
            "          3.1504e-02,  6.1205e-02, -1.1220e-01,  8.7067e-02,  4.9831e-02,\n",
            "         -3.5357e-02,  2.7251e-02, -2.1248e-02,  6.1461e-02,  6.1719e-02]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.1878], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "print(list(net_loaded.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InGW0Xq6UZip",
        "outputId": "6c4a0e2c-b485-4362-b99d-7364dcf9443a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample failed checks. vx^2+vy^2+vz^2: 1.3489617859372234, wtemp_expr: -0.3259882519473023, sdet_expr: 0.8716841134918246\n",
            "Number of valid samples: 0\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.4820160923861849, wtemp_expr: 0.45526976535509844, sdet_expr: 1.0652460161697894\n",
            "Number of valid samples: 1\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.6683745499238223, wtemp_expr: 0.2563984514910911, sdet_expr: 1.0968003239456992\n",
            "Number of valid samples: 2\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.09814332819807603, wtemp_expr: 0.9023800736438466, sdet_expr: 0.7761165245831267\n",
            "Number of valid samples: 3\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 2.1479463268949925, wtemp_expr: -1.427440201116514, sdet_expr: 1.0162622110161006\n",
            "Number of valid samples: 3\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.7410170660124162, wtemp_expr: 0.2028013263473215, sdet_expr: 0.9872012007251454\n",
            "Number of valid samples: 4\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 1.4212347604605096, wtemp_expr: -0.551692869087187, sdet_expr: 0.9568561346336475\n",
            "Number of valid samples: 4\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.5359177627655631, wtemp_expr: 0.4754592882551727, sdet_expr: 0.904168374490072\n",
            "Number of valid samples: 5\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 1.0158491549325053, wtemp_expr: -0.06841355914342251, sdet_expr: 1.1139912428320113\n",
            "Number of valid samples: 5\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 1.007329396227336, wtemp_expr: 0.06627305820066942, sdet_expr: 0.7917982237753933\n",
            "Number of valid samples: 5\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 1.018607286761885, wtemp_expr: -0.17201890541410725, sdet_expr: 1.064740338309983\n",
            "Number of valid samples: 5\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.776913770505637, wtemp_expr: 0.07653143309762434, sdet_expr: 1.1590373807967616\n",
            "Number of valid samples: 6\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.8251882855812187, wtemp_expr: 0.145728664135931, sdet_expr: 0.9939861885436357\n",
            "Number of valid samples: 7\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.5703751615475823, wtemp_expr: 0.3861656118397484, sdet_expr: 0.9354284043755999\n",
            "Number of valid samples: 8\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.9040320272538238, wtemp_expr: 0.029975532511311798, sdet_expr: 0.8586341352875648\n",
            "Number of valid samples: 9\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.9148182566814812, wtemp_expr: 0.042048960302501825, sdet_expr: 0.9864291844855105\n",
            "Number of valid samples: 10\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 1.1129821295267899, wtemp_expr: -0.15221357974748062, sdet_expr: 0.9006942093681541\n",
            "Number of valid samples: 10\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 1.2246051492799306, wtemp_expr: -0.3001093368011025, sdet_expr: 0.9778840972591416\n",
            "Number of valid samples: 10\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.2225347674799428, wtemp_expr: 0.782615073268123, sdet_expr: 0.8400493251004422\n",
            "Number of valid samples: 11\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.7403329191483575, wtemp_expr: 0.15925096904628389, sdet_expr: 1.0938667222485765\n",
            "Number of valid samples: 12\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 1.4257980198262294, wtemp_expr: -0.5895909906605714, sdet_expr: 1.1418981859382062\n",
            "Number of valid samples: 12\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.4887600588307148, wtemp_expr: 0.47500872715968856, sdet_expr: 0.9707513957681773\n",
            "Number of valid samples: 13\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.0989527473725498, wtemp_expr: 0.8933118157511223, sdet_expr: 0.969906392323011\n",
            "Number of valid samples: 14\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.21700388282594674, wtemp_expr: 0.7645294381144037, sdet_expr: 0.9126837203295644\n",
            "Number of valid samples: 15\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.7759204571236022, wtemp_expr: 0.23792447893581925, sdet_expr: 0.8700562792459583\n",
            "Number of valid samples: 16\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.866702247375194, wtemp_expr: 0.03427033676663449, sdet_expr: 1.2648025778167056\n",
            "Number of valid samples: 17\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 1.766295566627581, wtemp_expr: -0.9910702943451302, sdet_expr: 1.1328020900037223\n",
            "Number of valid samples: 17\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.7466295621239599, wtemp_expr: 0.2625320411022255, sdet_expr: 0.906030054077364\n",
            "Number of valid samples: 18\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.5553453814636004, wtemp_expr: 0.4170966757924517, sdet_expr: 0.9247444064792363\n",
            "Number of valid samples: 19\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 1.3707299191692273, wtemp_expr: -0.5228120558723359, sdet_expr: 0.8989318404743553\n",
            "Number of valid samples: 19\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 1.0634969528511353, wtemp_expr: -0.13885287445085903, sdet_expr: 1.0687286274576575\n",
            "Number of valid samples: 19\n",
            "Sample failed checks. vx^2+vy^2+vz^2: 0.9172236679486043, wtemp_expr: -0.04200869220709369, sdet_expr: 1.073056225613698\n",
            "Number of valid samples: 19\n",
            "Sample passed checks. vx^2+vy^2+vz^2: 0.07122294915488418, wtemp_expr: 0.9256085111219005, sdet_expr: 1.0945842636609\n",
            "Number of valid samples: 20\n",
            "rho.shape:  torch.Size([20])\n",
            "epsilon.shape:  torch.Size([20])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.8716e-01,  7.5934e+01,  3.0697e+02,  8.6900e+01,  3.4032e+02,\n",
              "          2.8272e-01,  1.1556e+00, -5.3823e+00,  1.0734e+00,  1.9957e-02,\n",
              "          4.5727e-02,  1.0898e+00,  8.5216e-02,  9.1937e-01],\n",
              "        [ 7.3964e-01,  4.0687e+00,  2.6314e+00,  8.7986e+00,  9.2321e+00,\n",
              "         -2.4889e+00, -1.3945e+00,  1.4440e+00,  9.8269e-01,  8.6727e-02,\n",
              "          5.3552e-02,  1.0757e+00,  9.3174e-03,  1.0479e+00],\n",
              "        [ 1.4281e+00, -5.6663e+00,  5.6765e+00,  1.5042e+01,  4.5043e+01,\n",
              "         -5.3717e+00, -6.9323e+00,  3.6630e-01,  9.0125e-01,  7.9061e-02,\n",
              "          1.3871e-02,  9.2143e-01,  4.2960e-02,  9.4379e-01],\n",
              "        [ 9.7862e-01,  1.4682e+00,  3.5614e+00,  3.1396e+00,  4.9139e+00,\n",
              "          1.5630e+00, -1.0257e+00,  1.5204e+00,  9.6222e-01,  6.5207e-02,\n",
              "          9.0951e-03,  9.7345e-01,  5.7217e-02,  1.0621e+00],\n",
              "        [ 1.6973e+00,  3.9113e+03,  2.1128e+03,  6.4779e+02,  5.0700e+03,\n",
              "          4.0857e+00,  4.2504e+00, -9.0677e+00,  9.2459e-01,  4.4884e-02,\n",
              "          3.1889e-02,  9.9729e-01,  7.6113e-04,  9.8382e-01],\n",
              "        [ 4.3263e+00,  5.6050e+01,  1.3304e+01,  3.0452e+01,  6.6452e+01,\n",
              "          5.6473e-01, -9.0458e+00, -5.4847e-01,  1.0999e+00,  8.8986e-02,\n",
              "          5.1772e-02,  1.0371e+00,  7.3404e-02,  1.0303e+00],\n",
              "        [ 2.3651e+00,  2.2785e+01, -3.1563e-01,  6.8064e+01,  7.3953e+01,\n",
              "         -9.4368e+00, -1.1708e+00,  2.6225e+00,  9.8334e-01,  2.1372e-03,\n",
              "          4.2257e-02,  9.9288e-01,  2.1685e-02,  1.0204e+00],\n",
              "        [ 8.5270e-01,  3.4013e+01,  5.6034e+01,  1.0524e+01,  6.6417e+01,\n",
              "          2.3331e+00,  2.4704e-01, -9.0610e+00,  9.0948e-01,  9.8454e-03,\n",
              "          7.4059e-02,  1.0801e+00,  3.9685e-02,  9.5975e-01],\n",
              "        [ 2.1531e+00,  2.5230e+03,  9.9891e+02,  1.8717e+03,  3.1904e+03,\n",
              "         -5.9267e+00,  6.0316e+00, -3.0905e+00,  9.9892e-01,  9.1180e-02,\n",
              "          6.6254e-02,  9.5575e-01,  5.3972e-02,  9.1408e-01],\n",
              "        [ 6.5032e+00,  1.0252e+02,  1.4175e+02,  2.4845e+01,  1.6638e+02,\n",
              "         -6.2051e+00,  5.8968e+00, -8.2072e+00,  1.0588e+00,  3.9683e-02,\n",
              "          9.0261e-02,  9.7401e-01,  2.9316e-02,  9.6637e-01],\n",
              "        [ 7.5399e-01,  2.8494e+01,  2.0734e+01, -8.6472e+00,  5.4325e+01,\n",
              "          3.9965e+00, -2.0763e+00,  7.9726e+00,  9.0225e-01,  5.7723e-02,\n",
              "          8.9595e-02,  9.4433e-01,  3.3133e-02,  9.9952e-01],\n",
              "        [ 1.8162e+00,  4.7318e+01,  7.4329e+01,  4.3574e+01,  9.1048e+01,\n",
              "          8.7782e+00, -5.4216e+00, -4.5458e-01,  9.6999e-01,  4.2432e-02,\n",
              "          7.7863e-02,  1.0538e+00,  6.3264e-02,  1.0816e+00],\n",
              "        [ 2.3104e+00, -3.9501e+00,  1.6080e+01, -1.1919e-01,  9.1974e+01,\n",
              "          7.6816e+00,  4.0067e+00,  9.4833e+00,  9.5655e-01,  1.6192e-02,\n",
              "          2.4923e-02,  9.2985e-01,  4.0928e-02,  1.0941e+00],\n",
              "        [ 1.1061e+00,  2.0053e+01,  4.4208e+00,  2.5203e+00,  8.2413e+01,\n",
              "          2.6569e+00, -7.5790e+00, -9.5980e+00,  9.0164e-01,  1.1561e-02,\n",
              "          8.5620e-02,  1.0240e+00,  1.0478e-02,  1.0589e+00],\n",
              "        [ 1.3357e+00,  3.1082e+01,  1.9191e+01,  2.0128e+01,  5.0083e+01,\n",
              "         -5.9796e+00,  5.9191e+00,  3.5708e+00,  9.8226e-01,  6.4044e-02,\n",
              "          6.0183e-02,  9.6582e-01,  6.9351e-02,  9.7437e-01],\n",
              "        [ 3.5298e+00,  3.2161e+01,  1.6256e+01,  5.0061e+01,  6.0606e+01,\n",
              "         -5.8186e+00, -3.1248e+00,  4.4694e+00,  9.1034e-01,  2.7673e-02,\n",
              "          2.4769e-02,  1.0222e+00,  4.5064e-02,  9.3839e-01],\n",
              "        [ 8.2750e+00,  1.2311e+02,  3.1727e+02,  1.7687e+02,  3.5495e+02,\n",
              "         -9.7904e+00,  1.0224e+01, -1.1106e+01,  1.0725e+00,  1.3607e-02,\n",
              "          8.2892e-02,  1.0933e+00,  1.7172e-03,  1.0853e+00],\n",
              "        [ 1.0495e+00,  2.2185e+01,  7.9921e+01,  2.3274e+01,  8.7719e+01,\n",
              "         -3.5296e+00,  3.4854e+00, -8.7054e+00,  1.0157e+00,  3.3145e-03,\n",
              "          4.4639e-02,  9.2975e-01,  6.6787e-02,  9.6616e-01],\n",
              "        [ 4.2345e-01,  2.2717e+01,  7.5680e+00, -5.4198e+00,  4.6260e+01,\n",
              "          7.0440e-01, -6.8755e+00, -5.8717e+00,  1.0025e+00,  8.9579e-02,\n",
              "          4.1789e-02,  9.3358e-01,  4.9883e-02,  1.0007e+00],\n",
              "        [ 1.0111e+00,  2.8451e+01,  3.7240e+01,  2.1735e+01,  9.9488e+01,\n",
              "          6.2972e+00, -9.7457e+00,  8.2391e+00,  1.0954e+00,  8.9651e-02,\n",
              "          6.6049e-02,  9.5780e-01,  6.4763e-02,  1.0590e+00]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_example, epsilon_example, vx_example, vy_example, vz_example, Bx_example, By_example, Bz_example, gxx_example, gxy_example, gxz_example, gyy_example, gyz_example, gzz_example = generate_samples(20)\n",
        "\n",
        "inputs =  generate_input_data(rho_example, epsilon_example, vx_example, vy_example, vz_example, Bx_example, By_example, Bz_example, gxx_example, gxy_example, gxz_example, gyy_example, gyz_example, gzz_example)\n",
        "inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVa1upmFUZip",
        "outputId": "95a297df-88d8-4614-ffd7-ecc0cda58cf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>)]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#%%script echo skipping\n",
        "\n",
        "# Pass the inputs to the network and get the outputs\n",
        "outputs = [net(input.unsqueeze(0)) for input in inputs]\n",
        "# Print the outputs\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-Xjfo7VUZir",
        "outputId": "fb0478cb-bee3-429f-fdec-d99f11baf40f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>),\n",
              " tensor([[0.]], grad_fn=<ReluBackward0>)]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Pass the inputs to the network and get the outputs\n",
        "outputs = [net_loaded(input.unsqueeze(0)) for input in inputs]\n",
        "# Print the outputs\n",
        "outputs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xjpIvdybUZis"
      },
      "source": [
        "## Porting the model to C++"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMlEd4RoUZis",
        "outputId": "d5bfc697-8c96-47bb-a08c-6fb26f463797"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (hidden_activation): ReLU()\n",
              "  (output_activation): ReLU()\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=14, out_features=555, bias=True)\n",
              "    (1): Linear(in_features=555, out_features=458, bias=True)\n",
              "    (2): Linear(in_features=458, out_features=115, bias=True)\n",
              "    (3): Linear(in_features=115, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample passed checks. vx^2+vy^2+vz^2: 0.8723633650922286, wtemp_expr: 0.10750315113621878, sdet_expr: 1.0761958778634493\n",
            "Number of valid samples: 1\n",
            "rho.shape:  torch.Size([1])\n",
            "epsilon.shape:  torch.Size([1])\n",
            "input shape:  torch.Size([1, 14])\n",
            "input:  tensor([[ 3.5437e+00,  7.2699e+01,  1.4111e+02,  2.2304e+01,  1.5890e+02,\n",
            "         -7.6623e+00,  5.1201e+00, -8.6727e+00,  1.0809e+00,  3.0114e-02,\n",
            "          6.1212e-02,  9.2126e-01,  6.5708e-02,  1.0897e+00]])\n",
            "Output: tensor([[0.]], grad_fn=<ReluBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_937262/439735149.py:53: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert x.shape[1] == N_INPUTS, f\"x must have shape (batch_size, {N_INPUTS})\"\n"
          ]
        }
      ],
      "source": [
        "import torch.jit\n",
        "\n",
        "# Creating a dummy input tensor of shape (1, 5) to trace the model\n",
        "dummy_input = torch.randn(1, N_INPUTS).to(device)\n",
        "\n",
        "# Ensure that net_loaded is in evaluation mode.\n",
        "net_loaded.eval()\n",
        "\n",
        "# Tracing the model using the torch.jit.trace function\n",
        "traced_model = torch.jit.trace(net_loaded, dummy_input)\n",
        "\n",
        "# Saving the traced model to a file named \"net.pt\"\n",
        "traced_model.save(\"net.pt\")\n",
        "save_file(\"net.pt\")\n",
        "\n",
        "example_input_to_validate_correct_export_and_import = generate_input_data(*generate_samples(1))\n",
        "print(\"input shape: \", example_input_to_validate_correct_export_and_import.shape)\n",
        "print(\"input: \", example_input_to_validate_correct_export_and_import)\n",
        "print(\"Output:\", net_loaded(example_input_to_validate_correct_export_and_import))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "bsc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

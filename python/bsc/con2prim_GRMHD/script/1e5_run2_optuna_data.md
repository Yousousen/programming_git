Trial 0 finished with value: 2.552163498687744 and parameters: {'n_layers': 4, 'n_units_0': 2053, 'n_units_1': 4059, 'n_units_2': 3727, 'n_units_3': 1257, 'hidden_activation': 'Swish', 'output_activation': 'Linear', 'loss': 'Huber', 'optimizer': 'Adagrad', 'lr': 2.6509087606842e-05, 'batch_size': 256, 'n_epochs': 71, 'scheduler': 'StepLR', 'dropout_rate': 0.36776303756520623, 'step_size': 13, 'gamma': 0.10642296288904758}. Best is trial 0 with value: 2.552163498687744.

Trial 1 finished with value: 5.94577004292806 and parameters: {'n_layers': 3, 'n_units_0': 2268, 'n_units_1': 1775, 'n_units_2': 3284, 'hidden_activation': 'SoftPlus', 'output_activation': 'Linear', 'loss': 'MAE', 'optimizer': 'RMSprop', 'lr': 0.0005021164706187672, 'batch_size': 512, 'n_epochs': 129, 'scheduler': 'StepLR', 'softplus_beta': 0.7617702056213549, 'dropout_rate': 0.44684468825290435, 'step_size': 10, 'gamma': 0.15537786595917602}. Best is trial 0 with value: 2.552163498687744.

Trial 2 finished with value: 8.281688825003306 and parameters: {'n_layers': 7, 'n_units_0': 2371, 'n_units_1': 2529, 'n_units_2': 1888, 'n_units_3': 2104, 'n_units_4': 75, 'n_units_5': 3232, 'n_units_6': 3153, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'Huber', 'optimizer': 'RMSprop', 'lr': 0.0018224540342191714, 'batch_size': 64, 'n_epochs': 57, 'scheduler': 'StepLR', 'dropout_rate': 0.013897737867710813, 'step_size': 15, 'gamma': 0.1891374658626017}. Best is trial 0 with value: 2.552163498687744.

Trial 3 failed with parameters: {'n_layers': 4, 'n_units_0': 1387, 'n_units_1': 1567, 'n_units_2': 2294, 'n_units_3': 708, 'hidden_activation': 'LeakyReLU', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'SGD', 'lr': 0.7495032860814487, 'batch_size': 512, 'n_epochs': 61, 'scheduler': 'CosineAnnealingLR', 'leakyrelu_slope': 0.21987210123735673, 'dropout_rate': 0.28420253053887057, 'weight_decay': 0.0005661931887439569, 'momentum': 0.42294019040190944, 't_max_fraction': 0.27503241747787555, 'eta_min': 0.00013539963655338525} because of the following error: The value nan is not acceptable..

Trial 3 failed with value nan.

Trial 4 finished with value: 9.445874138132732 and parameters: {'n_layers': 5, 'n_units_0': 4043, 'n_units_1': 2262, 'n_units_2': 3902, 'n_units_3': 1598, 'n_units_4': 3824, 'hidden_activation': 'ELU', 'output_activation': 'Linear', 'loss': 'MSE', 'optimizer': 'RMSprop', 'lr': 0.0006904955569226454, 'batch_size': 32, 'n_epochs': 85, 'scheduler': 'ReduceLROnPlateau', 'dropout_rate': 0.42946926530338664, 'factor': 0.47341426538909503, 'patience': 9, 'threshold': 0.00737493307319516}. Best is trial 0 with value: 2.552163498687744.

Trial 5 finished with value: 7.6363470174789425 and parameters: {'n_layers': 2, 'n_units_0': 1273, 'n_units_1': 1809, 'hidden_activation': 'Swish', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'SGD', 'lr': 0.00015039909912584152, 'batch_size': 32, 'n_epochs': 135, 'scheduler': 'ReduceLROnPlateau', 'dropout_rate': 0.34500769019583016, 'weight_decay': 2.188978914255183e-05, 'momentum': 0.8315313234846106, 'factor': 0.3724005911265402, 'patience': 6, 'threshold': 0.0015182763445746425}. Best is trial 0 with value: 2.552163498687744.

Trial 9 finished with value: 7.221909285990397 and parameters: {'n_layers': 9, 'n_units_0': 1079, 'n_units_1': 138, 'n_units_2': 598, 'n_units_3': 4018, 'n_units_4': 277, 'n_units_5': 2016, 'n_units_6': 1140, 'n_units_7': 945, 'n_units_8': 1533, 'hidden_activation': 'PReLU', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'RMSprop', 'lr': 0.00012644103291808062, 'batch_size': 512, 'n_epochs': 80, 'scheduler': 'StepLR', 'prelu_init': 0.1314780150983471, 'dropout_rate': 0.014379708322539653, 'step_size': 12, 'gamma': 0.23142844393833426}. Best is trial 0 with value: 2.552163498687744.

Trial 10 finished with value: 3.1116695780436197 and parameters: {'n_layers': 8, 'n_units_0': 3325, 'n_units_1': 543, 'n_units_2': 659, 'n_units_3': 627, 'n_units_4': 2777, 'n_units_5': 3303, 'n_units_6': 2230, 'n_units_7': 783, 'hidden_activation': 'SoftPlus', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'Adagrad', 'lr': 1.2284395904877148e-06, 'batch_size': 1024, 'n_epochs': 141, 'scheduler': 'StepLR', 'softplus_beta': 1.1728352618485394, 'dropout_rate': 0.48064704761509275, 'step_size': 5, 'gamma': 0.15283190271307212}. Best is trial 0 with value: 2.552163498687744.

Trial 12 finished with value: 1.1268444461822509 and parameters: {'n_layers': 7, 'n_units_0': 3224, 'n_units_1': 3068, 'n_units_2': 400, 'n_units_3': 238, 'n_units_4': 2051, 'n_units_5': 4080, 'n_units_6': 115, 'hidden_activation': 'Swish', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'Adagrad', 'lr': 1.4062302204880328e-06, 'batch_size': 1024, 'n_epochs': 150, 'scheduler': 'StepLR', 'dropout_rate': 0.48461304180459536, 'step_size': 5, 'gamma': 0.10708399382224112}. Best is trial 12 with value: 1.1268444461822509.

Trial 14 finished with value: 2.232180579630534 and parameters: {'n_layers': 7, 'n_units_0': 3172, 'n_units_1': 3119, 'n_units_2': 1262, 'n_units_3': 404, 'n_units_4': 1476, 'n_units_5': 2076, 'n_units_6': 91, 'hidden_activation': 'Swish', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'Adagrad', 'lr': 1.134146956466598e-05, 'batch_size': 128, 'n_epochs': 118, 'scheduler': 'StepLR', 'dropout_rate': 0.3838698368247281, 'step_size': 8, 'gamma': 0.10618558777291492}. Best is trial 12 with value: 1.1268444461822509.

Trial 15 finished with value: 1.1146586100896199 and parameters: {'n_layers': 7, 'n_units_0': 3148, 'n_units_1': 2988, 'n_units_2': 1264, 'n_units_3': 330, 'n_units_4': 1583, 'n_units_5': 157, 'n_units_6': 22, 'hidden_activation': 'Swish', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'Adagrad', 'lr': 2.64154048801672e-06, 'batch_size': 128, 'n_epochs': 120, 'scheduler': 'StepLR', 'dropout_rate': 0.42442040633836087, 'step_size': 8, 'gamma': 0.27159366953571057}. Best is trial 15 with value: 1.1146586100896199.

Trial 16 finished with value: 7.357594332059224 and parameters: {'n_layers': 10, 'n_units_0': 4054, 'n_units_1': 2908, 'n_units_2': 1071, 'n_units_3': 2129, 'n_units_4': 2352, 'n_units_5': 402, 'n_units_6': 296, 'n_units_7': 4055, 'n_units_8': 103, 'n_units_9': 1923, 'hidden_activation': 'Swish', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'Adam', 'lr': 1.4368967345747019e-06, 'batch_size': 128, 'n_epochs': 126, 'scheduler': 'ReduceLROnPlateau', 'dropout_rate': 0.48165158670624597, 'weight_decay': 0.008921703564807034, 'beta1': 0.9970813104389141, 'beta2': 0.9990541889252061, 'factor': 0.1083668688269458, 'patience': 10, 'threshold': 0.00014209495243458476}. Best is trial 15 with value: 1.1146586100896199.

Trial 17 finished with value: 1.059615451812744 and parameters: {'n_layers': 7, 'n_units_0': 2796, 'n_units_1': 3240, 'n_units_2': 88, 'n_units_3': 61, 'n_units_4': 1179, 'n_units_5': 1556, 'n_units_6': 1168, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'Adagrad', 'lr': 1.0242217473973947e-06, 'batch_size': 1024, 'n_epochs': 149, 'scheduler': 'StepLR', 'dropout_rate': 0.4995829180835174, 'step_size': 7, 'gamma': 0.2918691285498852}. Best is trial 17 with value: 1.059615451812744.

Trial 19 finished with value: 1.1420103935241699 and parameters: {'n_layers': 8, 'n_units_0': 1718, 'n_units_1': 2601, 'n_units_2': 1210, 'n_units_3': 48, 'n_units_4': 923, 'n_units_5': 1337, 'n_units_6': 1298, 'n_units_7': 2247, 'hidden_activation': 'ReLU', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'Adagrad', 'lr': 4.868302609601456e-06, 'batch_size': 2048, 'n_epochs': 117, 'scheduler': 'ReduceLROnPlateau', 'dropout_rate': 0.4253393447723499, 'factor': 0.19822254425578656, 'patience': 5, 'threshold': 0.0003093288502197238}. Best is trial 17 with value: 1.059615451812744.

Trial 21 finished with value: 1.8515874045689902 and parameters: {'n_layers': 10, 'n_units_0': 2834, 'n_units_1': 3559, 'n_units_2': 814, 'n_units_3': 1115, 'n_units_4': 1921, 'n_units_5': 757, 'n_units_6': 1989, 'n_units_7': 184, 'n_units_8': 4084, 'n_units_9': 3667, 'hidden_activation': 'LeakyReLU', 'output_activation': 'Linear', 'loss': 'Quantile', 'optimizer': 'Adagrad', 'lr': 5.379884505422021e-06, 'batch_size': 128, 'n_epochs': 97, 'scheduler': 'StepLR', 'leakyrelu_slope': 0.010922998743112033, 'dropout_rate': 0.2677780049194333, 'step_size': 8, 'gamma': 0.2978668768055142}. Best is trial 17 with value: 1.059615451812744.
